{"analytic_hierarchy_process_pages": ["{\"py/object\": \"wikipedia.wikipedia.WikipediaPage\", \"title\": \"Analytic hierarchy process\", \"original_title\": \"Analytic hierarchy process\", \"pageid\": \"1245372\", \"url\": \"https://en.wikipedia.org/wiki/Analytic_hierarchy_process\"}", "{\"py/object\": \"wikipedia.wikipedia.WikipediaPage\", \"title\": \"Analytic network process\", \"original_title\": \"Analytic network process\", \"pageid\": \"13051518\", \"url\": \"https://en.wikipedia.org/wiki/Analytic_network_process\"}", "{\"py/object\": \"wikipedia.wikipedia.WikipediaPage\", \"title\": \"Arrow's impossibility theorem\", \"original_title\": \"Arrow's impossibility theorem\", \"pageid\": \"89425\", \"url\": \"https://en.wikipedia.org/wiki/Arrow%27s_impossibility_theorem\"}", "{\"py/object\": \"wikipedia.wikipedia.WikipediaPage\", \"title\": \"Decision-making\", \"original_title\": \"Decision-making\", \"pageid\": \"265752\", \"url\": \"https://en.wikipedia.org/wiki/Decision-making\"}", "{\"py/object\": \"wikipedia.wikipedia.WikipediaPage\", \"title\": \"Decision-making paradox\", \"original_title\": \"Decision-making paradox\", \"pageid\": \"28258023\", \"url\": \"https://en.wikipedia.org/wiki/Decision-making_paradox\"}", "{\"py/object\": \"wikipedia.wikipedia.WikipediaPage\", \"title\": \"Decision-making software\", \"original_title\": \"Decision-making software\", \"pageid\": \"24093035\", \"url\": \"https://en.wikipedia.org/wiki/Decision-making_software\"}", "{\"py/object\": \"wikipedia.wikipedia.WikipediaPage\", \"title\": \"Analytic hierarchy process\", \"original_title\": \"Analytic hierarchy process\", \"pageid\": \"1245372\", \"url\": \"https://en.wikipedia.org/wiki/Analytic_hierarchy_process\"}", "{\"py/object\": \"wikipedia.wikipedia.WikipediaPage\", \"title\": \"Louis Leon Thurstone\", \"original_title\": \"Louis Leon Thurstone\", \"pageid\": \"436290\", \"url\": \"https://en.wikipedia.org/wiki/Louis_Leon_Thurstone\"}", "{\"py/object\": \"wikipedia.wikipedia.WikipediaPage\", \"title\": \"Law of comparative judgment\", \"original_title\": \"Law of comparative judgment\", \"pageid\": \"2251120\", \"url\": \"https://en.wikipedia.org/wiki/Law_of_comparative_judgment\"}", "{\"py/object\": \"wikipedia.wikipedia.WikipediaPage\", \"title\": \"Multiple-criteria decision analysis\", \"original_title\": \"Multiple-criteria decision analysis\", \"pageid\": \"1050551\", \"url\": \"https://en.wikipedia.org/wiki/Multiple-criteria_decision_analysis\"}", "{\"py/object\": \"wikipedia.wikipedia.WikipediaPage\", \"title\": \"Pairwise comparison\", \"original_title\": \"Pairwise comparison\", \"pageid\": \"4395832\", \"url\": \"https://en.wikipedia.org/wiki/Pairwise_comparison\"}", "{\"py/object\": \"wikipedia.wikipedia.WikipediaPage\", \"title\": \"Preference\", \"original_title\": \"Preference\", \"pageid\": \"28737250\", \"url\": \"https://en.wikipedia.org/wiki/Preference\"}", "{\"py/object\": \"wikipedia.wikipedia.WikipediaPage\", \"title\": \"Principal component analysis\", \"original_title\": \"Principal component analysis\", \"pageid\": \"76340\", \"url\": \"https://en.wikipedia.org/wiki/Principal_component_analysis\"}", "{\"py/object\": \"wikipedia.wikipedia.WikipediaPage\", \"title\": \"Rank reversals in decision-making\", \"original_title\": \"Rank reversals in decision-making\", \"pageid\": \"28299520\", \"url\": \"https://en.wikipedia.org/wiki/Rank_reversals_in_decision-making\"}", "{\"py/object\": \"wikipedia.wikipedia.WikipediaPage\", \"title\": \"Analytic hierarchy process \\u2013 car example\", \"original_title\": \"Analytic hierarchy process \\u2013 car example\", \"pageid\": \"25092787\", \"url\": \"https://en.wikipedia.org/wiki/Analytic_hierarchy_process_%E2%80%93_car_example\"}", "{\"py/object\": \"wikipedia.wikipedia.WikipediaPage\", \"title\": \"Analytic hierarchy process \\u2013 leader example\", \"original_title\": \"Analytic hierarchy process \\u2013 leader example\", \"pageid\": \"30031210\", \"url\": \"https://en.wikipedia.org/wiki/Analytic_hierarchy_process_%E2%80%93_leader_example\"}", "{\"py/object\": \"wikipedia.wikipedia.WikipediaPage\", \"title\": \"Thomas L. Saaty\", \"original_title\": \"Thomas L. Saaty\", \"pageid\": \"528429\", \"url\": \"https://en.wikipedia.org/wiki/Thomas_L._Saaty\"}", "{\"py/object\": \"wikipedia.wikipedia.WikipediaPage\", \"title\": \"Analytic hierarchy process\", \"original_title\": \"Analytic hierarchy process\", \"pageid\": \"1245372\", \"url\": \"https://en.wikipedia.org/wiki/Analytic_hierarchy_process\"}", "{\"py/object\": \"wikipedia.wikipedia.WikipediaPage\", \"title\": \"Expert Choice\", \"original_title\": \"Expert Choice\", \"pageid\": \"37685305\", \"url\": \"https://en.wikipedia.org/wiki/Expert_Choice\"}", "{\"py/object\": \"wikipedia.wikipedia.WikipediaPage\", \"title\": \"Online analytical processing\", \"original_title\": \"Online analytical processing\", \"pageid\": \"189239\", \"url\": \"https://en.wikipedia.org/wiki/Online_analytical_processing\"}", "{\"py/object\": \"wikipedia.wikipedia.WikipediaPage\", \"title\": \"Comparison of OLAP servers\", \"original_title\": \"Comparison of OLAP servers\", \"pageid\": \"24523966\", \"url\": \"https://en.wikipedia.org/wiki/Comparison_of_OLAP_servers\"}", "{\"py/object\": \"wikipedia.wikipedia.WikipediaPage\", \"title\": \"Thomsen Diagrams\", \"original_title\": \"Thomsen Diagrams\", \"pageid\": \"7213203\", \"url\": \"https://en.wikipedia.org/wiki/Thomsen_Diagrams\"}", "{\"py/object\": \"wikipedia.wikipedia.WikipediaPage\", \"title\": \"Functional database model\", \"original_title\": \"Functional database model\", \"pageid\": \"46897862\", \"url\": \"https://en.wikipedia.org/wiki/Functional_database_model\"}", "{\"py/object\": \"wikipedia.wikipedia.WikipediaPage\", \"title\": \"Bibliography\", \"original_title\": \"Bibliography\", \"pageid\": \"190988\", \"url\": \"https://en.wikipedia.org/wiki/Bibliography\"}", "{\"py/object\": \"wikipedia.wikipedia.WikipediaPage\", \"title\": \"Super Decisions\", \"original_title\": \"Super Decisions\", \"pageid\": \"47534615\", \"url\": \"https://en.wikipedia.org/wiki/Super_Decisions\"}"], "analytic_hierarchy_process_articles": ["Analytic hierarchy process", "Analytic network process", "Arrow's impossibility theorem", "Decision making", "Decision-making paradox", "Decision-making software", "Hierarchical decision process", "L. L. Thurstone", "Law of comparative judgment", "Multi-criteria decision analysis", "Pairwise comparison", "Preference", "Principal component analysis", "Rank reversals in decision-making", "Analytic hierarchy process \u2013 car example", "Analytic hierarchy process \u2013 leader example", "Thomas L. Saaty", "International Symposium on the Analytic Hierarchy Process", "Expert Choice", "Online analytical processing", "Comparison of OLAP servers", "Thomsen Diagrams", "Functional Database Model", "== Bibliography ==", "Super Decisions"], "analytic_hierarchy_process_training_data": [["The analytic hierarchy process (AHP) is a structured technique for organizing and analyzing complex decisions, based on mathematics and psychology. It was developed by Thomas L. Saaty in the 1970s who partnered with Ernest Forman to develop Expert Choice in 1983, and has been extensively studied and refined since then. It represents an accurate approach for quantifying the weights of decision criteria. Individual experts\u2019 experiences are utilized to estimate the relative magnitudes of factors through pair-wise comparisons. Each of the respondents has to compare the relative importance between the two items under special designed questionnaire (note that while most of the surveys adopted the five point likert scale, AHP's questionnaire is 9 to 1 to 9, see Li et al. (2019)  )\n\n\n== Uses and applications ==\nAHP has particular application in group decision making, and is used around the world in a wide variety of decision situations, in fields such as government, business, industry, healthcare, shipbuilding and education.\nRather than prescribing a \"correct\" decision, the AHP helps decision makers find one that best suits their goal and their understanding of the problem. It provides a comprehensive and rational framework for structuring a decision problem, for representing and quantifying its elements, for relating those elements to overall goals, and for evaluating alternative solutions.\nUsers of the AHP first decompose their decision problem into a hierarchy of more easily comprehended sub-problems, each of which can be analyzed independently. The elements of the hierarchy can relate to any aspect of the decision problem\u2014tangible or intangible, carefully measured or roughly estimated, well or poorly understood\u2014anything at all that applies to the decision at hand.\nOnce the hierarchy is built, the decision makers systematically evaluate its various elements by comparing them to each other two at a time, with respect to their impact on an element above them in the hierarchy. In making the comparisons, the decision makers can use concrete data about the elements, but they typically use their judgments about the elements' relative meaning and importance. It is the essence of the AHP that human judgments, and not just the underlying information, can be used in performing the evaluations.The AHP converts these evaluations to numerical values that can be processed and compared over the entire range of the problem. A numerical weight or priority is derived for each element of the hierarchy, allowing diverse and often incommensurable elements to be compared to one another in a rational and consistent way. This capability distinguishes the AHP from other decision making techniques.\nIn the final step of the process, numerical priorities are calculated for each of the decision alternatives. These numbers represent the alternatives' relative ability to achieve the decision goal, so they allow a straightforward consideration of the various courses of action.\nSeveral firms supply computer software to assist in using the process.\nWhile it can be used by individuals working on straightforward decisions, the Analytic Hierarchy Process (AHP) is most useful where teams of people are working on complex problems, especially those with high stakes, involving human perceptions and judgments, whose resolutions have long-term repercussions.\nIt has unique advantages when important elements of the decision are difficult to quantify or compare, or where communication among team members is impeded by their different specializations, terminologies, or perspectives.\nDecision situations to which the AHP can be applied include:\nChoice \u2013 The selection of one alternative from a given set of alternatives, usually where there are multiple decision criteria involved.\nRanking \u2013 Putting a set of alternatives in order from most to least desirable.\nPrioritization \u2013 Determining the relative merit of members of a set of alternatives, as opposed to selecting a single one or merely ranking them\nResource allocation \u2013 Apportioning resources among a set of alternatives\nBenchmarking \u2013 Comparing the processes in one's own organization with those of other best-of-breed organizations\nQuality management \u2013 Dealing with the multidimensional aspects of quality and quality improvement\nConflict resolution \u2013 Settling disputes between parties with apparently incompatible goals or positionsThe applications of AHP to complex decision situations have numbered in the thousands, and have produced extensive results in problems involving planning, resource allocation, priority setting, and selection among alternatives. Other areas have included forecasting, total quality management, business process reengineering, quality function deployment, and the balanced scorecard. Many AHP applications are never reported to the world at large, because they take place at high levels of large organizations where security and privacy considerations prohibit their disclosure. But some uses of AHP are discussed in the literature. Recently these have included:\n\nSelect a type of nuclear reactors (Politecnico di Milano)\nDeciding how best to reduce the impact of global climate change (Fondazione Eni Enrico Mattei)\nQuantifying the overall quality of software systems (Microsoft Corporation)\nSelecting university faculty (Bloomsburg University of Pennsylvania)\nDeciding where to locate offshore manufacturing plants (University of Cambridge)\nAssessing risk in operating cross-country petroleum pipelines (American Society of Civil Engineers)\nDeciding how best to manage U.S. watersheds (U.S. Department of Agriculture)\nMore Effectively Define and Evaluate SAP Implementation Approaches (SAP Experts)\nAccelerated Bridge Construction Decision Making Tool to assist in determining the viability of accelerated bridge construction (ABC) over traditional construction methods and in selecting appropriate construction and contracting strategies on a case-by-case basis.AHP is sometimes used in designing highly specific procedures for particular situations, such as the rating of buildings by historic significance. It was recently applied to a project that uses video footage to assess the condition of highways in Virginia. Highway engineers first used it to determine the optimum scope of the project, then to justify its budget to lawmakers.\n\n\n== Education and scholarly research ==\nThough using the analytic hierarchy process requires no specialized academic training, it is considered an important subject in many institutions of higher learning, including schools of engineering and graduate schools of business. It is a particularly important subject in the quality field, and is taught in many specialized courses including Six Sigma, Lean Six Sigma, and QFD.The value of the AHP is recognized in developed and developing countries around the world. China is an example\u2014nearly a hundred Chinese universities offer courses in AHP, and many doctoral students choose AHP as the subject of their research and dissertations. Over 900 papers have been published on the subject in China, and there is at least one Chinese scholarly journal devoted exclusively to AHP.The International Symposium on the Analytic Hierarchy Process (ISAHP) holds biennial meetings of academics and practitioners interested in the field. A wide range of topics are covered. Those in 2005 ranged from \"Establishing Payment Standards for Surgical Specialists\", to \"Strategic Technology Roadmapping\", to \"Infrastructure Reconstruction in Devastated Countries\".\nAt the 2007 meeting in Valpara\u00edso, Chile, over 90 papers were presented from 19 countries, including the US, Germany, Japan, Chile, Malaysia, and Nepal. A similar number of papers were presented at the 2009 symposium in Pittsburgh, Pennsylvania, when 28 countries were represented. Subjects of the papers included Economic Stabilization in Latvia, Portfolio Selection in the Banking Sector, Wildfire Management to Help Mitigate Global Warming, and Rural Microprojects in Nepal.\n\n\n== Use ==\nAs can be seen in the material that follows, using the AHP involves the mathematical synthesis of numerous judgments about the decision problem at hand. It is not uncommon for these judgments to number in the dozens or even the hundreds. While the math can be done by hand or with a calculator, it is far more common to use one of several computerized methods for entering and synthesizing the judgments. The simplest of these involve standard spreadsheet software, while the most complex use custom software, often augmented by special devices for acquiring the judgments of decision makers gathered in a meeting room.\nThe procedure for using the AHP can be summarized as:\n\nModel the problem as a hierarchy containing the decision goal, the alternatives for reaching it, and the criteria for evaluating the alternatives.\nEstablish priorities among the elements of the hierarchy by making a series of judgments based on pairwise comparisons of the elements. For example, when comparing potential purchases of commercial real estate, the investors might say they prefer location over price and price over timing.\nSynthesize these judgments to yield a set of overall priorities for the hierarchy. This would combine the investors' judgments about location, price and timing for properties A, B, C, and D into overall priorities for each property.\nCheck the consistency of the judgments.\nCome to a final decision based on the results of this process.These steps are more fully described below.\n\n\n=== Model the problem as a hierarchy ===\nThe first step in the analytic hierarchy process is to model the problem as a hierarchy. In doing this, participants explore the aspects of the problem at levels from general to detailed, then express it in the multileveled way that the AHP requires. As they work to build the hierarchy, they increase their understanding of the problem, of its context, and of each other's thoughts and feelings about both.\n\n\n==== Hierarchies defined ====\nA hierarchy is a stratified system of ranking and organizing people, things, ideas, etc., where each element of the system, except for the top one, is subordinate to one or more other elements. Though the concept of hierarchy is easily grasped intuitively, it can also be described mathematically. Diagrams of hierarchies are often shaped roughly like pyramids, but other than having a single element at the top, there is nothing necessarily pyramid-shaped about a hierarchy.\nHuman organizations are often structured as hierarchies, where the hierarchical system is used for assigning responsibilities, exercising leadership, and facilitating communication. Familiar hierarchies of \"things\" include a desktop computer's tower unit at the \"top\", with its subordinate monitor, keyboard, and mouse \"below.\"\nIn the world of ideas, we use hierarchies to help us acquire detailed knowledge of complex reality: we structure the reality into its constituent parts, and these in turn into their own constituent parts, proceeding down the hierarchy as many levels as we care to. At each step, we focus on understanding a single component of the whole, temporarily disregarding the other components at this and all other levels. As we go through this process, we increase our global understanding of whatever complex reality we are studying.\nThink of the hierarchy that medical students use while learning anatomy\u2014they separately consider the musculoskeletal system (including parts and subparts like the hand and its constituent muscles and bones), the circulatory system (and its many levels and branches), the nervous system (and its numerous components and subsystems), etc., until they've covered all the systems and the important subdivisions of each. Advanced students continue the subdivision all the way to the level of the cell or molecule. In the end, the students understand the \"big picture\" and a considerable number of its details. Not only that, but they understand the relation of the individual parts to the whole. By working hierarchically, they've gained a comprehensive understanding of anatomy.\nSimilarly, when we approach a complex decision problem, we can use a hierarchy to integrate large amounts of information into our understanding of the situation. As we build this information structure, we form a better and better picture of the problem as a whole.\n\n\n==== Hierarchies in the AHP ====\nAn AHP hierarchy is a structured means of modeling the decision at hand. It consists of an overall goal, a group of options or alternatives for reaching the goal, and a group of factors or criteria that relate the alternatives to the goal. The criteria can be further broken down into subcriteria, sub-subcriteria, and so on, in as many levels as the problem requires. A criterion may not apply uniformly, but may have graded differences like a little sweetness is enjoyable but too much sweetness can be harmful. In that case the criterion is divided into subcriteria indicating different intensities of the criterion, like: little, medium, high and these intensities are prioritized through comparisons under the parent criterion, sweetness.\nPublished descriptions of AHP applications often include diagrams and descriptions of their hierarchies; some simple ones are shown throughout this article. More complex AHP hierarchies have been collected and reprinted in at least one book. More complex hierarchies can be found in a special talk page for this article.\nThe design of any AHP hierarchy will depend not only on the nature of the problem at hand, but also on the knowledge, judgments, values, opinions, needs, wants, etc. of the participants in the decision-making process. Constructing a hierarchy typically involves significant discussion, research, and discovery by those involved. Even after its initial construction, it can be changed to accommodate newly-thought-of criteria or criteria not originally considered to be important; alternatives can also be added, deleted, or changed.To better understand AHP hierarchies, consider a decision problem with a goal to be reached, three alternative ways of reaching the goal, and four criteria against which the alternatives need to be measured.\nSuch a hierarchy can be visualized as a diagram like the one immediately below, with the goal at the top, the three alternatives at the bottom, and the four criteria in between. There are useful terms for describing the parts of such diagrams: Each box is called a node. A node that is connected to one or more nodes in a level below it is called a parent node. The nodes to which it is so connected are called its children.\nApplying these definitions to the diagram below, the goal is the parent of the four criteria, and the four criteria are children of the goal. Each criterion is a parent of the three Alternatives. Note that there are only three Alternatives, but in the diagram, each of them is repeated under each of its parents.\n\nTo reduce the size of the drawing required, it is common to represent AHP hierarchies as shown in the diagram below, with only one node for each alternative, and with multiple lines connecting the alternatives and the criteria that apply to them. To avoid clutter, these lines are sometimes omitted or reduced in number. Regardless of any such simplifications in the diagram, in the actual hierarchy each criterion is individually connected to the alternatives. The lines may be thought of as being directed downward from the parent in one level to its children in the level below.\n\n\n=== Evaluate the hierarchy ===\nOnce the hierarchy has been constructed, the participants analyze it through a series of pairwise comparisons that derive numerical scales of measurement for the nodes. The criteria are pairwise compared against the goal for importance. The alternatives are pairwise compared against each of the criteria for preference. The comparisons are processed mathematically, and priorities are derived for each node.\nConsider the \"Choose a Leader\" example above. An important task of the decision makers is to determine the weight to be given each criterion in making the choice of a leader. Another important task is to determine the weight to be given to each candidate with regard to each of the criteria. The AHP not only lets them do that, but it lets them put a meaningful and objective numerical value on each of the four criteria.\n\n\n=== Establish priorities ===\nThis section explains priorities, shows how they are established, and provides a simple example.\n\n\n==== Priorities defined and explained ====\nPriorities are numbers associated with the nodes of an AHP hierarchy. They represent the relative weights of the nodes in any group.\nLike probabilities, priorities are absolute numbers between zero and one, without units or dimensions. A node with priority .200 has twice the weight in reaching the goal as one with priority .100, ten times the weight of one with priority .020, and so forth. Depending on the problem at hand, \"weight\" can refer to importance, or preference, or likelihood, or whatever factor is being considered by the decision makers.\nPriorities are distributed over a hierarchy according to its architecture, and their values depend on the information entered by users of the process. Priorities of the Goal, the Criteria, and the Alternatives are intimately related, but need to be considered separately.\nBy definition, the priority of the Goal is 1.000. The priorities of the alternatives always add up to 1.000. Things can become complicated with multiple levels of Criteria, but if there is only one level, their priorities also add to 1.000. All this is illustrated by the priorities in the example below.\n\nObserve that the priorities on each level of the example\u2014the goal, the criteria, and the alternatives\u2014all add up to 1.000.\nThe priorities shown are those that exist before any information has been entered about weights of the criteria or alternatives, so the priorities within each level are all equal. They are called the hierarchy's default priorities. If a fifth Criterion were added to this hierarchy, the default priority for each Criterion would be .200. If there were only two Alternatives, each would have a default priority of .500.\nTwo additional concepts apply when a hierarchy has more than one level of criteria: local priorities and global priorities. Consider the hierarchy shown below, which has several Subcriteria under each Criterion.\n\nThe local priorities, shown in gray, represent the relative weights of the nodes within a group of siblings with respect to their parent. The local priorities of each group of Criteria and their sibling Subcriteria add up to 1.000. The global priorities, shown in black, are obtained by multiplying the local priorities of the siblings by their parent's global priority. The global priorities for all the subcriteria in the level add up to 1.000.\nThe rule is this: Within a hierarchy, the global priorities of child nodes always add up to the global priority of their parent. Within a group of children, the local priorities add up to 1.000.\nSo far, we have looked only at default priorities. As the Analytical Hierarchy Process moves forward, the priorities will change from their default values as the decision makers input information about the importance of the various nodes. They do this by making a series of pairwise comparisons.\n\n\n== Practical examples ==\nExperienced practitioners know that the best way to understand the AHP is to work through cases and examples. Two detailed case studies, specifically designed as in-depth teaching examples, are provided as appendices to this article:\n\nSimple step-by-step example with four Criteria and three Alternatives: Choosing a leader for an organization.\nMore complex step-by-step example with ten Criteria/Subcriteria and six Alternatives: Buying a family car and Machinery Selection Example.Some of the books on AHP contain practical examples of its use, though they are not typically intended to be step-by-step learning aids. One of them contains a handful of expanded examples, plus about 400 AHP hierarchies briefly described and illustrated with figures. Many examples are discussed, mostly for professional audiences, in papers published by the International Symposium on the Analytic Hierarchy Process.\n\n\n== Criticisms ==\nThe AHP is included in most operations research and management science textbooks, and is taught in numerous universities; it is used extensively in organizations that have carefully investigated its theoretical underpinnings. While the general consensus is that it is both technically valid and practically useful, the method does have its critics. \nIn the early 1990s a series of debates between critics and proponents of AHP was published in Management Science and The Journal of the Operational Research Society. These debates seem to have been settled in favor of AHP: \n\nAn in-depth paper discussing and rebutting the academic criticisms of AHP was published in Operations Research in 2001.\nA  2008 Management Science paper reviewing 15 years of progress in all areas of Multicriteria Decision Making showed that AHP publications have far outnumbered those in any other area, characterizing their growth as \"enormous.\"\nAlso in 2008, the major society for operations research, the Institute for Operations Research and the Management Sciences formally recognized AHP's broad impact on its fields.Occasional criticisms still appear. A 1997 paper examined possible flaws in the verbal (vs. numerical) scale often used in AHP pairwise comparisons. Another from the same year claimed that innocuous changes to the AHP model can introduce order where no order exists. A 2006 paper found that the addition of criteria for which all alternatives perform equally can alter the priorities of alternatives.\n\n\n== Rank reversal ==\nDecision making involves ranking alternatives in terms of criteria or attributes of those alternatives. It is an axiom of some decision theories that when new alternatives are added to a decision problem, the ranking of the old alternatives must not change \u2014 that \"rank reversal\" must not occur.\nThere are two schools of thought about rank reversal. One maintains that new alternatives that introduce no additional attributes should not cause rank reversal under any circumstances. The other maintains that there are some situations in which rank reversal can reasonably be expected. The original formulation of AHP allowed rank reversals.  In 1993, Forman introduced a second AHP synthesis mode, called the ideal synthesis mode, to address choice situations in which the addition or removal of an 'irrelevant' alternative should not and will not cause a change in the ranks of existing alternatives. The current version of the AHP can accommodate both these schools\u2014its ideal mode preserves rank, while its distributive mode allows the ranks to change. Either mode is selected according to the problem at hand.\nRank reversal and AHP are extensively discussed in a 2001 paper in Operations Research, as well as a chapter entitled Rank Preservation and Reversal, in the current basic book on AHP. The latter presents published examples of rank reversal due to adding copies and near copies of an alternative, due to intransitivity of decision rules, due to adding phantom and decoy alternatives, and due to the switching phenomenon in utility functions. It also discusses the Distributive and Ideal Modes of AHP.\nA new form of rank reversal of AHP was found in 2014 in which AHP produces rank order reversal when eliminating irrelevant data, this is data that do not differentiate alternatives.\nThere are different types of rank reversals.  Also, other methods besides the AHP may exhibit such rank reversals.  More discussion on rank reversals with the AHP and other MCDM methods is provided in the rank reversals in decision-making page.\n\n\n== Non-monotonicity of some weight extraction methods ==\nWithin a comparison matrix one may replace a judgement with a less favorable judgment and then check to see if the indication of the new priority becomes less favorable then the original priority. In the context of tournament matrices, it has been proven by Oskar Perron that the principal right eigenvector method is not monotonic. This behaviour can also be demonstrated for reciprocal n x n matrices, where n > 3. Alternative approaches are discussed elsewhere.\n\n\n== See also ==\nAnalytic network process\nArrow's impossibility theorem\nDecision making\nDecision-making paradox\nDecision-making software\nHierarchical decision process\nL. L. Thurstone\nLaw of comparative judgment\nMulti-criteria decision analysis\nPairwise comparison\nPreference\nPrincipal component analysis\nRank reversals in decision-making\n\n\n== References ==\n\n\n== Further reading ==\nSaaty, Thomas L. Decision Making for Leaders: The Analytical Hierarchy Process for Decisions in a Complex World (1982). Belmont, California: Wadsworth. ISBN 0-534-97959-9; Paperback, Pittsburgh: RWS. ISBN 0-9620317-0-4. \"Focuses on practical application of the AHP; briefly covers theory.\"\nSaaty, Thomas L. Fundamentals of Decision Making and Priority Theory with the Analytic Hierarchy Process (1994). Pittsburgh: RWS. ISBN 0-9620317-6-3. \"A thorough exposition of the theoretical aspects of AHP.\"\nSaaty, Thomas L. Mathematical Principles of Decision Making (Principia Mathematica Decernendi) (2009). Pittsburgh: RWS. ISBN 1-888603-10-0. \"Comprehensive coverage of the AHP, its successor the ANP, and further developments of their underlying concepts.\"\nSaaty, Thomas L., with Ernest H. Forman. The Hierarchon: A Dictionary of Hierarchies. (1992) Pittsburgh: RWS. ISBN 0-9620317-5-5. \"Dozens of illustrations and examples of AHP hierarchies. A beginning classification of ideas relating to planning, conflict resolution, and decision making.\"\nSaaty, Thomas L., with Luis G. Vargas The Logic of Priorities: Applications in Business, Energy, Health, and Transportation (1982). Boston: Kluwer-Nijhoff. ISBN 0-89838-071-5 (Hardcover) ISBN 0-89838-078-2 (Paperback). Republished 1991 by RWS, ISBN 1-888603-07-0.\nKardi Teknomo. Analytic Hierarchy Process Tutorial (2012). Revoledu.\nKearns, Kevin P.; Saaty, Thomas L. Analytical Planning: The Organization of Systems (1985). Oxford: Pergamon Press. ISBN 0-08-032599-8. Republished 1991 by RWS, ISBN 1-888603-07-0.\nwith Joyce Alexander. Conflict Resolution: The Analytic Hierarchy Process (1989). New York: Praeger. ISBN 0-275-93229-X\nVargas, Luis L.; Saaty, Thomas L. Prediction, Projection and Forecasting: Applications of the Analytic Hierarchy Process in Economics, Finance, Politics, Games and Sports (1991). Boston: Kluwer Academic. ISBN 0-7923-9104-7\nVargas, Luis L.; Saaty, Thomas L. Decision Making in Economic, Social and Technological Environments (1994). Pittsburgh: RWS. ISBN 0-9620317-7-1\nVargas, Luis L.; Saaty, Thomas L. Models, Methods, Concepts & Applications of the Analytic Hierarchy Process (2001). Boston: Kluwer Academic. ISBN 0-7923-7267-0\nPeniwati, Kirti; Vargas, Luis L. Group Decision Making: Drawing Out and Reconciling Differences (2007). Pittsburgh: RWS. ISBN 1-888603-08-9\n\n\n== External links ==\nInternational Journal of the Analytic Hierarchy Process An online journal about multi-criteria decision making using the AHP.\neasyAHP Online tool to make collaborative decisions using AHP easyAHP is a free online tool to make decisions in a collaborative or individual way. easy AHP uses AHP methodology: Analytic hierarchy process.\nAHP video. (9:17 YouTube clip) Very thorough exposition of AHP by Dr. Klaus G\u00f6pel\nAnalytic Hierarchy Process (AHP) Example with Simulations using Matlab \u2013 Waqqas Farooq \u2013 AHP example for college selection using matlab.\nAn illustrated guide (pdf) \u2013 Dr. Oliver Meixner University of Wien \u2013 \"Analytic Hierarchy Process\", a very easy to understand summary of the mathematical theory\nAHP example with Matlab implementation \u2013 AHP explanation with an example and matlab code.\nR ahp package \u2013 An AHP open source package.\nIntroductory Mathematics of the Analytic Hierarchy Process \u2013 An introduction to the mathematics of the Analytic Hierarchy Process.\nHow to use AHP for Project Prioritization by Dr. James Brown (webinar)\nGuide to use AHP in Excel A guide to using AHP in Excel by Dr. Richard Hodgett\nUse the AHP Methodology to More Effectively Define and Evaluate Your SAP Implementation Approach by Jeetendra Kumar", {"entities": [[0, 30, "TRAINED_CATEGORY"], [32, 35, "TRAINED_CATEGORY"], [40, 62, "TRAINED_CATEGORY"], [92, 109, "TRAINED_CATEGORY"], [120, 131, "TRAINED_CATEGORY"], [136, 146, "TRAINED_CATEGORY"], [148, 150, "TRAINED_CATEGORY"], [168, 183, "TRAINED_CATEGORY"], [187, 196, "TRAINED_CATEGORY"], [197, 200, "TRAINED_CATEGORY"], [216, 229, "TRAINED_CATEGORY"], [241, 254, "TRAINED_CATEGORY"], [321, 323, "TRAINED_CATEGORY"], [335, 355, "TRAINED_CATEGORY"], [372, 383, "TRAINED_CATEGORY"], [387, 404, "TRAINED_CATEGORY"], [406, 437, "TRAINED_CATEGORY"], [463, 486, "TRAINED_CATEGORY"], [490, 497, "TRAINED_CATEGORY"], [506, 527, "TRAINED_CATEGORY"], [537, 552, "TRAINED_CATEGORY"], [568, 591, "TRAINED_CATEGORY"], [600, 613, "TRAINED_CATEGORY"], [620, 650, "TRAINED_CATEGORY"], [676, 687, "TRAINED_CATEGORY"], [696, 723, "TRAINED_CATEGORY"], [725, 744, "TRAINED_CATEGORY"], [765, 773, "TRAINED_CATEGORY"], [790, 794, "TRAINED_CATEGORY"], [799, 811, "TRAINED_CATEGORY"], [815, 818, "TRAINED_CATEGORY"], [823, 845, "TRAINED_CATEGORY"], [849, 870, "TRAINED_CATEGORY"], [891, 900, "TRAINED_CATEGORY"], [904, 918, "TRAINED_CATEGORY"], [922, 941, "TRAINED_CATEGORY"], [946, 952, "TRAINED_CATEGORY"], [961, 971, "TRAINED_CATEGORY"], [973, 981, "TRAINED_CATEGORY"], [983, 991, "TRAINED_CATEGORY"], [993, 1003, "TRAINED_CATEGORY"], [1005, 1017, "TRAINED_CATEGORY"], [1022, 1031, "TRAINED_CATEGORY"], [1057, 1077, "TRAINED_CATEGORY"], [1079, 1086, "TRAINED_CATEGORY"], [1093, 1108, "TRAINED_CATEGORY"], [1114, 1117, "TRAINED_CATEGORY"], [1134, 1144, "TRAINED_CATEGORY"], [1149, 1168, "TRAINED_CATEGORY"], [1172, 1183, "TRAINED_CATEGORY"], [1185, 1187, "TRAINED_CATEGORY"], [1197, 1235, "TRAINED_CATEGORY"], [1252, 1270, "TRAINED_CATEGORY"], [1305, 1317, "TRAINED_CATEGORY"], [1332, 1346, "TRAINED_CATEGORY"], [1350, 1363, "TRAINED_CATEGORY"], [1384, 1405, "TRAINED_CATEGORY"], [1407, 1412, "TRAINED_CATEGORY"], [1416, 1423, "TRAINED_CATEGORY"], [1440, 1462, "TRAINED_CATEGORY"], [1468, 1479, "TRAINED_CATEGORY"], [1483, 1520, "TRAINED_CATEGORY"], [1567, 1579, "TRAINED_CATEGORY"], [1583, 1596, "TRAINED_CATEGORY"], [1611, 1621, "TRAINED_CATEGORY"], [1625, 1645, "TRAINED_CATEGORY"], [1737, 1745, "TRAINED_CATEGORY"], [1769, 1781, "TRAINED_CATEGORY"], [1785, 1789, "TRAINED_CATEGORY"], [1796, 1809, "TRAINED_CATEGORY"], [1820, 1839, "TRAINED_CATEGORY"], [1864, 1884, "TRAINED_CATEGORY"], [1898, 1902, "TRAINED_CATEGORY"], [1924, 1930, "TRAINED_CATEGORY"], [1937, 1944, "TRAINED_CATEGORY"], [1948, 1960, "TRAINED_CATEGORY"], [1964, 1974, "TRAINED_CATEGORY"], [1981, 1985, "TRAINED_CATEGORY"], [1989, 2002, "TRAINED_CATEGORY"], [2014, 2029, "TRAINED_CATEGORY"], [2031, 2050, "TRAINED_CATEGORY"], [2059, 2072, "TRAINED_CATEGORY"], [2079, 2091, "TRAINED_CATEGORY"], [2097, 2101, "TRAINED_CATEGORY"], [2116, 2131, "TRAINED_CATEGORY"], [2138, 2168, "TRAINED_CATEGORY"], [2173, 2183, "TRAINED_CATEGORY"], [2185, 2187, "TRAINED_CATEGORY"], [2191, 2202, "TRAINED_CATEGORY"], [2206, 2213, "TRAINED_CATEGORY"], [2214, 2234, "TRAINED_CATEGORY"], [2240, 2275, "TRAINED_CATEGORY"], [2303, 2318, "TRAINED_CATEGORY"], [2319, 2326, "TRAINED_CATEGORY"], [2336, 2353, "TRAINED_CATEGORY"], [2357, 2373, "TRAINED_CATEGORY"], [2414, 2430, "TRAINED_CATEGORY"], [2434, 2445, "TRAINED_CATEGORY"], [2447, 2465, "TRAINED_CATEGORY"], [2469, 2477, "TRAINED_CATEGORY"], [2493, 2505, "TRAINED_CATEGORY"], [2509, 2522, "TRAINED_CATEGORY"], [2533, 2575, "TRAINED_CATEGORY"], [2609, 2638, "TRAINED_CATEGORY"], [2640, 2655, "TRAINED_CATEGORY"], [2670, 2677, "TRAINED_CATEGORY"], [2683, 2697, "TRAINED_CATEGORY"], [2705, 2715, "TRAINED_CATEGORY"], [2720, 2734, "TRAINED_CATEGORY"], [2738, 2749, "TRAINED_CATEGORY"], [2751, 2771, "TRAINED_CATEGORY"], [2799, 2824, "TRAINED_CATEGORY"], [2826, 2839, "TRAINED_CATEGORY"], [2850, 2884, "TRAINED_CATEGORY"], [2896, 2913, "TRAINED_CATEGORY"], [2918, 2922, "TRAINED_CATEGORY"], [2929, 2960, "TRAINED_CATEGORY"], [2964, 2983, "TRAINED_CATEGORY"], [2987, 2993, "TRAINED_CATEGORY"], [2995, 3008, "TRAINED_CATEGORY"], [3016, 3033, "TRAINED_CATEGORY"], [3053, 3064, "TRAINED_CATEGORY"], [3072, 3074, "TRAINED_CATEGORY"], [3090, 3101, "TRAINED_CATEGORY"], [3113, 3138, "TRAINED_CATEGORY"], [3140, 3170, "TRAINED_CATEGORY"], [3172, 3175, "TRAINED_CATEGORY"], [3198, 3203, "TRAINED_CATEGORY"], [3207, 3213, "TRAINED_CATEGORY"], [3229, 3245, "TRAINED_CATEGORY"], [3269, 3280, "TRAINED_CATEGORY"], [3292, 3309, "TRAINED_CATEGORY"], [3314, 3323, "TRAINED_CATEGORY"], [3325, 3342, "TRAINED_CATEGORY"], [3348, 3371, "TRAINED_CATEGORY"], [3373, 3375, "TRAINED_CATEGORY"], [3380, 3397, "TRAINED_CATEGORY"], [3403, 3421, "TRAINED_CATEGORY"], [3425, 3437, "TRAINED_CATEGORY"], [3485, 3498, "TRAINED_CATEGORY"], [3505, 3517, "TRAINED_CATEGORY"], [3532, 3563, "TRAINED_CATEGORY"], [3565, 3578, "TRAINED_CATEGORY"], [3583, 3595, "TRAINED_CATEGORY"], [3597, 3616, "TRAINED_CATEGORY"], [3626, 3633, "TRAINED_CATEGORY"], [3658, 3664, "TRAINED_CATEGORY"], [3667, 3680, "TRAINED_CATEGORY"], [3684, 3699, "TRAINED_CATEGORY"], [3705, 3716, "TRAINED_CATEGORY"], [3720, 3732, "TRAINED_CATEGORY"], [3758, 3784, "TRAINED_CATEGORY"], [3795, 3802, "TRAINED_CATEGORY"], [3813, 3818, "TRAINED_CATEGORY"], [3822, 3834, "TRAINED_CATEGORY"], [3838, 3843, "TRAINED_CATEGORY"], [3874, 3888, "TRAINED_CATEGORY"], [3903, 3921, "TRAINED_CATEGORY"], [3925, 3932, "TRAINED_CATEGORY"], [3936, 3941, "TRAINED_CATEGORY"], [3945, 3957, "TRAINED_CATEGORY"], [4014, 4018, "TRAINED_CATEGORY"], [4019, 4038, "TRAINED_CATEGORY"], [4054, 4063, "TRAINED_CATEGORY"], [4070, 4075, "TRAINED_CATEGORY"], [4079, 4091, "TRAINED_CATEGORY"], [4092, 4104, "TRAINED_CATEGORY"], [4117, 4130, "TRAINED_CATEGORY"], [4134, 4156, "TRAINED_CATEGORY"], [4185, 4190, "TRAINED_CATEGORY"], [4205, 4223, "TRAINED_CATEGORY"], [4239, 4267, "TRAINED_CATEGORY"], [4271, 4302, "TRAINED_CATEGORY"], [4303, 4322, "TRAINED_CATEGORY"], [4334, 4342, "TRAINED_CATEGORY"], [4351, 4358, "TRAINED_CATEGORY"], [4364, 4393, "TRAINED_CATEGORY"], [4397, 4422, "TRAINED_CATEGORY"], [4426, 4429, "TRAINED_CATEGORY"], [4433, 4460, "TRAINED_CATEGORY"], [4478, 4491, "TRAINED_CATEGORY"], [4511, 4528, "TRAINED_CATEGORY"], [4532, 4540, "TRAINED_CATEGORY"], [4551, 4559, "TRAINED_CATEGORY"], [4561, 4580, "TRAINED_CATEGORY"], [4582, 4598, "TRAINED_CATEGORY"], [4604, 4613, "TRAINED_CATEGORY"], [4620, 4632, "TRAINED_CATEGORY"], [4634, 4645, "TRAINED_CATEGORY"], [4660, 4671, "TRAINED_CATEGORY"], [4673, 4697, "TRAINED_CATEGORY"], [4699, 4715, "TRAINED_CATEGORY"], [4731, 4758, "TRAINED_CATEGORY"], [4764, 4786, "TRAINED_CATEGORY"], [4788, 4809, "TRAINED_CATEGORY"], [4832, 4841, "TRAINED_CATEGORY"], [4860, 4864, "TRAINED_CATEGORY"], [4870, 4875, "TRAINED_CATEGORY"], [4879, 4890, "TRAINED_CATEGORY"], [4894, 4913, "TRAINED_CATEGORY"], [4920, 4928, "TRAINED_CATEGORY"], [4933, 4940, "TRAINED_CATEGORY"], [4941, 4955, "TRAINED_CATEGORY"], [4965, 4981, "TRAINED_CATEGORY"], [4987, 4996, "TRAINED_CATEGORY"], [5000, 5003, "TRAINED_CATEGORY"], [5021, 5035, "TRAINED_CATEGORY"], [5075, 5081, "TRAINED_CATEGORY"], [5085, 5101, "TRAINED_CATEGORY"], [5103, 5124, "TRAINED_CATEGORY"], [5154, 5164, "TRAINED_CATEGORY"], [5168, 5189, "TRAINED_CATEGORY"], [5233, 5252, "TRAINED_CATEGORY"], [5256, 5272, "TRAINED_CATEGORY"], [5273, 5295, "TRAINED_CATEGORY"], [5297, 5306, "TRAINED_CATEGORY"], [5307, 5325, "TRAINED_CATEGORY"], [5327, 5348, "TRAINED_CATEGORY"], [5352, 5364, "TRAINED_CATEGORY"], [5391, 5420, "TRAINED_CATEGORY"], [5422, 5432, "TRAINED_CATEGORY"], [5436, 5445, "TRAINED_CATEGORY"], [5457, 5461, "TRAINED_CATEGORY"], [5465, 5508, "TRAINED_CATEGORY"], [5510, 5526, "TRAINED_CATEGORY"], [5530, 5545, "TRAINED_CATEGORY"], [5575, 5590, "TRAINED_CATEGORY"], [5592, 5607, "TRAINED_CATEGORY"], [5611, 5622, "TRAINED_CATEGORY"], [5661, 5690, "TRAINED_CATEGORY"], [5691, 5703, "TRAINED_CATEGORY"], [5705, 5757, "TRAINED_CATEGORY"], [5783, 5796, "TRAINED_CATEGORY"], [5800, 5831, "TRAINED_CATEGORY"], [5832, 5836, "TRAINED_CATEGORY"], [5843, 5875, "TRAINED_CATEGORY"], [5893, 5917, "TRAINED_CATEGORY"], [5922, 5944, "TRAINED_CATEGORY"], [5958, 5962, "TRAINED_CATEGORY"], [5969, 5972, "TRAINED_CATEGORY"], [6004, 6030, "TRAINED_CATEGORY"], [6035, 6056, "TRAINED_CATEGORY"], [6066, 6076, "TRAINED_CATEGORY"], [6080, 6089, "TRAINED_CATEGORY"], [6093, 6114, "TRAINED_CATEGORY"], [6116, 6118, "TRAINED_CATEGORY"], [6143, 6152, "TRAINED_CATEGORY"], [6163, 6176, "TRAINED_CATEGORY"], [6187, 6200, "TRAINED_CATEGORY"], [6204, 6212, "TRAINED_CATEGORY"], [6216, 6224, "TRAINED_CATEGORY"], [6226, 6243, "TRAINED_CATEGORY"], [6255, 6257, "TRAINED_CATEGORY"], [6271, 6288, "TRAINED_CATEGORY"], [6292, 6303, "TRAINED_CATEGORY"], [6321, 6331, "TRAINED_CATEGORY"], [6335, 6344, "TRAINED_CATEGORY"], [6349, 6360, "TRAINED_CATEGORY"], [6365, 6383, "TRAINED_CATEGORY"], [6400, 6430, "TRAINED_CATEGORY"], [6440, 6472, "TRAINED_CATEGORY"], [6474, 6476, "TRAINED_CATEGORY"], [6515, 6532, "TRAINED_CATEGORY"], [6536, 6551, "TRAINED_CATEGORY"], [6563, 6570, "TRAINED_CATEGORY"], [6574, 6606, "TRAINED_CATEGORY"], [6610, 6618, "TRAINED_CATEGORY"], [6620, 6622, "TRAINED_CATEGORY"], [6626, 6658, "TRAINED_CATEGORY"], [6662, 6679, "TRAINED_CATEGORY"], [6698, 6722, "TRAINED_CATEGORY"], [6733, 6742, "TRAINED_CATEGORY"], [6744, 6758, "TRAINED_CATEGORY"], [6764, 6777, "TRAINED_CATEGORY"], [6781, 6788, "TRAINED_CATEGORY"], [6806, 6840, "TRAINED_CATEGORY"], [6848, 6857, "TRAINED_CATEGORY"], [6859, 6864, "TRAINED_CATEGORY"], [6868, 6878, "TRAINED_CATEGORY"], [6879, 6916, "TRAINED_CATEGORY"], [6923, 6930, "TRAINED_CATEGORY"], [6934, 6937, "TRAINED_CATEGORY"], [6943, 6965, "TRAINED_CATEGORY"], [6973, 6976, "TRAINED_CATEGORY"], [6980, 6991, "TRAINED_CATEGORY"], [6995, 7009, "TRAINED_CATEGORY"], [7014, 7027, "TRAINED_CATEGORY"], [7029, 7044, "TRAINED_CATEGORY"], [7068, 7079, "TRAINED_CATEGORY"], [7083, 7088, "TRAINED_CATEGORY"], [7103, 7141, "TRAINED_CATEGORY"], [7165, 7196, "TRAINED_CATEGORY"], [7200, 7230, "TRAINED_CATEGORY"], [7232, 7237, "TRAINED_CATEGORY"], [7245, 7262, "TRAINED_CATEGORY"], [7266, 7275, "TRAINED_CATEGORY"], [7280, 7293, "TRAINED_CATEGORY"], [7308, 7317, "TRAINED_CATEGORY"], [7319, 7331, "TRAINED_CATEGORY"], [7335, 7341, "TRAINED_CATEGORY"], [7382, 7394, "TRAINED_CATEGORY"], [7395, 7412, "TRAINED_CATEGORY"], [7417, 7437, "TRAINED_CATEGORY"], [7444, 7476, "TRAINED_CATEGORY"], [7483, 7512, "TRAINED_CATEGORY"], [7516, 7536, "TRAINED_CATEGORY"], [7542, 7558, "TRAINED_CATEGORY"], [7562, 7572, "TRAINED_CATEGORY"], [7574, 7579, "TRAINED_CATEGORY"], [7581, 7595, "TRAINED_CATEGORY"], [7616, 7628, "TRAINED_CATEGORY"], [7640, 7646, "TRAINED_CATEGORY"], [7648, 7655, "TRAINED_CATEGORY"], [7657, 7662, "TRAINED_CATEGORY"], [7664, 7669, "TRAINED_CATEGORY"], [7671, 7679, "TRAINED_CATEGORY"], [7685, 7690, "TRAINED_CATEGORY"], [7692, 7708, "TRAINED_CATEGORY"], [7712, 7718, "TRAINED_CATEGORY"], [7737, 7755, "TRAINED_CATEGORY"], [7759, 7769, "TRAINED_CATEGORY"], [7771, 7783, "TRAINED_CATEGORY"], [7790, 7802, "TRAINED_CATEGORY"], [7821, 7829, "TRAINED_CATEGORY"], [7833, 7843, "TRAINED_CATEGORY"], [7853, 7875, "TRAINED_CATEGORY"], [7879, 7885, "TRAINED_CATEGORY"], [7887, 7906, "TRAINED_CATEGORY"], [7910, 7928, "TRAINED_CATEGORY"], [7930, 7949, "TRAINED_CATEGORY"], [7967, 7981, "TRAINED_CATEGORY"], [7987, 8006, "TRAINED_CATEGORY"], [8010, 8015, "TRAINED_CATEGORY"], [8020, 8025, "TRAINED_CATEGORY"], [8047, 8059, "TRAINED_CATEGORY"], [8080, 8087, "TRAINED_CATEGORY"], [8097, 8123, "TRAINED_CATEGORY"], [8127, 8145, "TRAINED_CATEGORY"], [8152, 8172, "TRAINED_CATEGORY"], [8176, 8180, "TRAINED_CATEGORY"], [8182, 8184, "TRAINED_CATEGORY"], [8205, 8220, "TRAINED_CATEGORY"], [8234, 8244, "TRAINED_CATEGORY"], [8248, 8265, "TRAINED_CATEGORY"], [8273, 8281, "TRAINED_CATEGORY"], [8297, 8301, "TRAINED_CATEGORY"], [8310, 8322, "TRAINED_CATEGORY"], [8324, 8326, "TRAINED_CATEGORY"], [8360, 8388, "TRAINED_CATEGORY"], [8419, 8432, "TRAINED_CATEGORY"], [8464, 8493, "TRAINED_CATEGORY"], [8558, 8573, "TRAINED_CATEGORY"], [8588, 8601, "TRAINED_CATEGORY"], [8605, 8620, "TRAINED_CATEGORY"], [8633, 8647, "TRAINED_CATEGORY"], [8649, 8662, "TRAINED_CATEGORY"], [8673, 8680, "TRAINED_CATEGORY"], [8710, 8721, "TRAINED_CATEGORY"], [8725, 8736, "TRAINED_CATEGORY"], [8748, 8765, "TRAINED_CATEGORY"], [8767, 8783, "TRAINED_CATEGORY"], [8797, 8799, "TRAINED_CATEGORY"], [8805, 8817, "TRAINED_CATEGORY"], [8833, 8849, "TRAINED_CATEGORY"], [8861, 8871, "TRAINED_CATEGORY"], [8878, 8890, "TRAINED_CATEGORY"], [8894, 8907, "TRAINED_CATEGORY"], [8918, 8926, "TRAINED_CATEGORY"], [8930, 8939, "TRAINED_CATEGORY"], [8949, 8969, "TRAINED_CATEGORY"], [8973, 8985, "TRAINED_CATEGORY"], [8991, 8998, "TRAINED_CATEGORY"], [9015, 9034, "TRAINED_CATEGORY"], [9038, 9060, "TRAINED_CATEGORY"], [9062, 9075, "TRAINED_CATEGORY"], [9086, 9090, "TRAINED_CATEGORY"], [9098, 9106, "TRAINED_CATEGORY"], [9112, 9117, "TRAINED_CATEGORY"], [9122, 9127, "TRAINED_CATEGORY"], [9133, 9139, "TRAINED_CATEGORY"], [9152, 9167, "TRAINED_CATEGORY"], [9177, 9182, "TRAINED_CATEGORY"], [9186, 9204, "TRAINED_CATEGORY"], [9209, 9222, "TRAINED_CATEGORY"], [9243, 9267, "TRAINED_CATEGORY"], [9274, 9282, "TRAINED_CATEGORY"], [9284, 9289, "TRAINED_CATEGORY"], [9294, 9300, "TRAINED_CATEGORY"], [9305, 9317, "TRAINED_CATEGORY"], [9317, 9323, "TRAINED_CATEGORY"], [9329, 9330, "TRAINED_CATEGORY"], [9336, 9354, "TRAINED_CATEGORY"], [9359, 9372, "TRAINED_CATEGORY"], [9380, 9395, "TRAINED_CATEGORY"], [9399, 9412, "TRAINED_CATEGORY"], [9422, 9438, "TRAINED_CATEGORY"], [9448, 9459, "TRAINED_CATEGORY"], [9463, 9475, "TRAINED_CATEGORY"], [9476, 9487, "TRAINED_CATEGORY"], [9532, 9543, "TRAINED_CATEGORY"], [9547, 9558, "TRAINED_CATEGORY"], [9563, 9577, "TRAINED_CATEGORY"], [9581, 9611, "TRAINED_CATEGORY"], [9624, 9635, "TRAINED_CATEGORY"], [9639, 9650, "TRAINED_CATEGORY"], [9667, 9679, "TRAINED_CATEGORY"], [9688, 9699, "TRAINED_CATEGORY"], [9703, 9714, "TRAINED_CATEGORY"], [9718, 9724, "TRAINED_CATEGORY"], [9764, 9766, "TRAINED_CATEGORY"], [9770, 9790, "TRAINED_CATEGORY"], [9796, 9803, "TRAINED_CATEGORY"], [9817, 9821, "TRAINED_CATEGORY"], [9836, 9849, "TRAINED_CATEGORY"], [9851, 9855, "TRAINED_CATEGORY"], [9865, 9884, "TRAINED_CATEGORY"], [9888, 9899, "TRAINED_CATEGORY"], [9904, 9915, "TRAINED_CATEGORY"], [9924, 9945, "TRAINED_CATEGORY"], [9950, 9958, "TRAINED_CATEGORY"], [9978, 9989, "TRAINED_CATEGORY"], [10003, 10014, "TRAINED_CATEGORY"], [10018, 10037, "TRAINED_CATEGORY"], [10064, 10070, "TRAINED_CATEGORY"], [10072, 10078, "TRAINED_CATEGORY"], [10080, 10085, "TRAINED_CATEGORY"], [10099, 10111, "TRAINED_CATEGORY"], [10115, 10125, "TRAINED_CATEGORY"], [10138, 10149, "TRAINED_CATEGORY"], [10169, 10195, "TRAINED_CATEGORY"], [10204, 10215, "TRAINED_CATEGORY"], [10219, 10228, "TRAINED_CATEGORY"], [10260, 10262, "TRAINED_CATEGORY"], [10301, 10309, "TRAINED_CATEGORY"], [10313, 10324, "TRAINED_CATEGORY"], [10355, 10363, "TRAINED_CATEGORY"], [10387, 10403, "TRAINED_CATEGORY"], [10407, 10414, "TRAINED_CATEGORY"], [10425, 10432, "TRAINED_CATEGORY"], [10466, 10477, "TRAINED_CATEGORY"], [10479, 10498, "TRAINED_CATEGORY"], [10523, 10534, "TRAINED_CATEGORY"], [10542, 10565, "TRAINED_CATEGORY"], [10588, 10604, "TRAINED_CATEGORY"], [10617, 10627, "TRAINED_CATEGORY"], [10646, 10659, "TRAINED_CATEGORY"], [10661, 10681, "TRAINED_CATEGORY"], [10685, 10692, "TRAINED_CATEGORY"], [10702, 10733, "TRAINED_CATEGORY"], [10753, 10776, "TRAINED_CATEGORY"], [10778, 10786, "TRAINED_CATEGORY"], [10792, 10797, "TRAINED_CATEGORY"], [10810, 10819, "TRAINED_CATEGORY"], [10823, 10828, "TRAINED_CATEGORY"], [10830, 10832, "TRAINED_CATEGORY"], [10837, 10848, "TRAINED_CATEGORY"], [10857, 10859, "TRAINED_CATEGORY"], [10868, 10886, "TRAINED_CATEGORY"], [10890, 10905, "TRAINED_CATEGORY"], [10907, 10909, "TRAINED_CATEGORY"], [10920, 10931, "TRAINED_CATEGORY"], [10937, 10958, "TRAINED_CATEGORY"], [10973, 10977, "TRAINED_CATEGORY"], [10983, 11010, "TRAINED_CATEGORY"], [11028, 11041, "TRAINED_CATEGORY"], [11042, 11056, "TRAINED_CATEGORY"], [11060, 11062, "TRAINED_CATEGORY"], [11075, 11084, "TRAINED_CATEGORY"], [11086, 11088, "TRAINED_CATEGORY"], [11112, 11130, "TRAINED_CATEGORY"], [11134, 11143, "TRAINED_CATEGORY"], [11170, 11190, "TRAINED_CATEGORY"], [11203, 11219, "TRAINED_CATEGORY"], [11224, 11226, "TRAINED_CATEGORY"], [11238, 11250, "TRAINED_CATEGORY"], [11252, 11254, "TRAINED_CATEGORY"], [11264, 11288, "TRAINED_CATEGORY"], [11292, 11316, "TRAINED_CATEGORY"], [11317, 11319, "TRAINED_CATEGORY"], [11343, 11356, "TRAINED_CATEGORY"], [11362, 11378, "TRAINED_CATEGORY"], [11398, 11405, "TRAINED_CATEGORY"], [11406, 11410, "TRAINED_CATEGORY"], [11431, 11457, "TRAINED_CATEGORY"], [11469, 11474, "TRAINED_CATEGORY"], [11479, 11487, "TRAINED_CATEGORY"], [11493, 11501, "TRAINED_CATEGORY"], [11506, 11529, "TRAINED_CATEGORY"], [11534, 11539, "TRAINED_CATEGORY"], [11542, 11564, "TRAINED_CATEGORY"], [11570, 11585, "TRAINED_CATEGORY"], [11590, 11598, "TRAINED_CATEGORY"], [11601, 11619, "TRAINED_CATEGORY"], [11625, 11648, "TRAINED_CATEGORY"], [11653, 11663, "TRAINED_CATEGORY"], [11678, 11682, "TRAINED_CATEGORY"], [11694, 11709, "TRAINED_CATEGORY"], [11714, 11740, "TRAINED_CATEGORY"], [11750, 11767, "TRAINED_CATEGORY"], [11777, 11792, "TRAINED_CATEGORY"], [11808, 11817, "TRAINED_CATEGORY"], [11821, 11829, "TRAINED_CATEGORY"], [11833, 11841, "TRAINED_CATEGORY"], [11846, 11853, "TRAINED_CATEGORY"], [11855, 11867, "TRAINED_CATEGORY"], [11879, 11895, "TRAINED_CATEGORY"], [11901, 11922, "TRAINED_CATEGORY"], [11926, 11937, "TRAINED_CATEGORY"], [11958, 11962, "TRAINED_CATEGORY"], [11974, 11986, "TRAINED_CATEGORY"], [11990, 12010, "TRAINED_CATEGORY"], [12014, 12023, "TRAINED_CATEGORY"], [12052, 12056, "TRAINED_CATEGORY"], [12067, 12096, "TRAINED_CATEGORY"], [12100, 12107, "TRAINED_CATEGORY"], [12125, 12127, "TRAINED_CATEGORY"], [12137, 12163, "TRAINED_CATEGORY"], [12165, 12167, "TRAINED_CATEGORY"], [12176, 12187, "TRAINED_CATEGORY"], [12201, 12214, "TRAINED_CATEGORY"], [12218, 12229, "TRAINED_CATEGORY"], [12235, 12252, "TRAINED_CATEGORY"], [12256, 12269, "TRAINED_CATEGORY"], [12274, 12276, "TRAINED_CATEGORY"], [12283, 12309, "TRAINED_CATEGORY"], [12311, 12313, "TRAINED_CATEGORY"], [12319, 12346, "TRAINED_CATEGORY"], [12350, 12361, "TRAINED_CATEGORY"], [12365, 12372, "TRAINED_CATEGORY"], [12381, 12392, "TRAINED_CATEGORY"], [12396, 12403, "TRAINED_CATEGORY"], [12409, 12425, "TRAINED_CATEGORY"], [12429, 12447, "TRAINED_CATEGORY"], [12460, 12472, "TRAINED_CATEGORY"], [12476, 12480, "TRAINED_CATEGORY"], [12482, 12484, "TRAINED_CATEGORY"], [12497, 12512, "TRAINED_CATEGORY"], [12514, 12521, "TRAINED_CATEGORY"], [12525, 12532, "TRAINED_CATEGORY"], [12536, 12548, "TRAINED_CATEGORY"], [12562, 12570, "TRAINED_CATEGORY"], [12576, 12583, "TRAINED_CATEGORY"], [12587, 12594, "TRAINED_CATEGORY"], [12598, 12606, "TRAINED_CATEGORY"], [12619, 12635, "TRAINED_CATEGORY"], [12639, 12647, "TRAINED_CATEGORY"], [12649, 12661, "TRAINED_CATEGORY"], [12738, 12752, "TRAINED_CATEGORY"], [12756, 12767, "TRAINED_CATEGORY"], [12778, 12789, "TRAINED_CATEGORY"], [12835, 12846, "TRAINED_CATEGORY"], [12852, 12870, "TRAINED_CATEGORY"], [12888, 12906, "TRAINED_CATEGORY"], [12926, 12935, "TRAINED_CATEGORY"], [12936, 12949, "TRAINED_CATEGORY"], [12966, 12977, "TRAINED_CATEGORY"], [12989, 13010, "TRAINED_CATEGORY"], [13014, 13027, "TRAINED_CATEGORY"], [13060, 13077, "TRAINED_CATEGORY"], [13102, 13113, "TRAINED_CATEGORY"], [13120, 13140, "TRAINED_CATEGORY"], [13142, 13151, "TRAINED_CATEGORY"], [13153, 13175, "TRAINED_CATEGORY"], [13179, 13195, "TRAINED_CATEGORY"], [13210, 13218, "TRAINED_CATEGORY"], [13223, 13235, "TRAINED_CATEGORY"], [13239, 13256, "TRAINED_CATEGORY"], [13258, 13274, "TRAINED_CATEGORY"], [13296, 13308, "TRAINED_CATEGORY"], [13310, 13338, "TRAINED_CATEGORY"], [13376, 13393, "TRAINED_CATEGORY"], [13395, 13419, "TRAINED_CATEGORY"], [13436, 13455, "TRAINED_CATEGORY"], [13460, 13472, "TRAINED_CATEGORY"], [13474, 13484, "TRAINED_CATEGORY"], [13488, 13505, "TRAINED_CATEGORY"], [13530, 13540, "TRAINED_CATEGORY"], [13544, 13555, "TRAINED_CATEGORY"], [13559, 13563, "TRAINED_CATEGORY"], [13577, 13590, "TRAINED_CATEGORY"], [13592, 13601, "TRAINED_CATEGORY"], [13603, 13609, "TRAINED_CATEGORY"], [13611, 13619, "TRAINED_CATEGORY"], [13621, 13626, "TRAINED_CATEGORY"], [13643, 13659, "TRAINED_CATEGORY"], [13663, 13690, "TRAINED_CATEGORY"], [13705, 13716, "TRAINED_CATEGORY"], [13736, 13758, "TRAINED_CATEGORY"], [13760, 13768, "TRAINED_CATEGORY"], [13774, 13783, "TRAINED_CATEGORY"], [13814, 13838, "TRAINED_CATEGORY"], [13840, 13842, "TRAINED_CATEGORY"], [13873, 13898, "TRAINED_CATEGORY"], [13902, 13910, "TRAINED_CATEGORY"], [13954, 13966, "TRAINED_CATEGORY"], [14027, 14042, "TRAINED_CATEGORY"], [14053, 14071, "TRAINED_CATEGORY"], [14077, 14083, "TRAINED_CATEGORY"], [14099, 14121, "TRAINED_CATEGORY"], [14134, 14142, "TRAINED_CATEGORY"], [14148, 14161, "TRAINED_CATEGORY"], [14176, 14192, "TRAINED_CATEGORY"], [14214, 14230, "TRAINED_CATEGORY"], [14252, 14261, "TRAINED_CATEGORY"], [14267, 14274, "TRAINED_CATEGORY"], [14299, 14307, "TRAINED_CATEGORY"], [14311, 14318, "TRAINED_CATEGORY"], [14320, 14342, "TRAINED_CATEGORY"], [14346, 14356, "TRAINED_CATEGORY"], [14362, 14379, "TRAINED_CATEGORY"], [14402, 14414, "TRAINED_CATEGORY"], [14430, 14439, "TRAINED_CATEGORY"], [14443, 14456, "TRAINED_CATEGORY"], [14458, 14466, "TRAINED_CATEGORY"], [14485, 14491, "TRAINED_CATEGORY"], [14513, 14530, "TRAINED_CATEGORY"], [14534, 14541, "TRAINED_CATEGORY"], [14548, 14550, "TRAINED_CATEGORY"], [14576, 14585, "TRAINED_CATEGORY"], [14595, 14597, "TRAINED_CATEGORY"], [14648, 14665, "TRAINED_CATEGORY"], [14669, 14680, "TRAINED_CATEGORY"], [14688, 14696, "TRAINED_CATEGORY"], [14700, 14710, "TRAINED_CATEGORY"], [14714, 14731, "TRAINED_CATEGORY"], [14737, 14754, "TRAINED_CATEGORY"], [14759, 14767, "TRAINED_CATEGORY"], [14771, 14779, "TRAINED_CATEGORY"], [14781, 14795, "TRAINED_CATEGORY"], [14799, 14807, "TRAINED_CATEGORY"], [14811, 14833, "TRAINED_CATEGORY"], [14855, 14878, "TRAINED_CATEGORY"], [14887, 14898, "TRAINED_CATEGORY"], [14908, 14912, "TRAINED_CATEGORY"], [14939, 14950, "TRAINED_CATEGORY"], [14963, 14971, "TRAINED_CATEGORY"], [14975, 14986, "TRAINED_CATEGORY"], [14997, 14999, "TRAINED_CATEGORY"], [15023, 15038, "TRAINED_CATEGORY"], [15051, 15062, "TRAINED_CATEGORY"], [15075, 15088, "TRAINED_CATEGORY"], [15093, 15109, "TRAINED_CATEGORY"], [15120, 15134, "TRAINED_CATEGORY"], [15146, 15162, "TRAINED_CATEGORY"], [15167, 15179, "TRAINED_CATEGORY"], [15194, 15198, "TRAINED_CATEGORY"], [15209, 15216, "TRAINED_CATEGORY"], [15218, 15229, "TRAINED_CATEGORY"], [15266, 15272, "TRAINED_CATEGORY"], [15288, 15312, "TRAINED_CATEGORY"], [15316, 15327, "TRAINED_CATEGORY"], [15332, 15352, "TRAINED_CATEGORY"], [15353, 15367, "TRAINED_CATEGORY"], [15397, 15413, "TRAINED_CATEGORY"], [15415, 15424, "TRAINED_CATEGORY"], [15475, 15485, "TRAINED_CATEGORY"], [15489, 15498, "TRAINED_CATEGORY"], [15502, 15514, "TRAINED_CATEGORY"], [15518, 15527, "TRAINED_CATEGORY"], [15550, 15563, "TRAINED_CATEGORY"], [15573, 15586, "TRAINED_CATEGORY"], [15609, 15625, "TRAINED_CATEGORY"], [15634, 15636, "TRAINED_CATEGORY"], [15645, 15653, "TRAINED_CATEGORY"], [15657, 15677, "TRAINED_CATEGORY"], [15690, 15706, "TRAINED_CATEGORY"], [15710, 15721, "TRAINED_CATEGORY"], [15726, 15735, "TRAINED_CATEGORY"], [15737, 15749, "TRAINED_CATEGORY"], [15780, 15788, "TRAINED_CATEGORY"], [15793, 15803, "TRAINED_CATEGORY"], [15805, 15821, "TRAINED_CATEGORY"], [15860, 15872, "TRAINED_CATEGORY"], [15877, 15887, "TRAINED_CATEGORY"], [15889, 15904, "TRAINED_CATEGORY"], [15939, 15949, "TRAINED_CATEGORY"], [15966, 15975, "TRAINED_CATEGORY"], [15986, 16015, "TRAINED_CATEGORY"], [16023, 16040, "TRAINED_CATEGORY"], [16044, 16063, "TRAINED_CATEGORY"], [16080, 16090, "TRAINED_CATEGORY"], [16103, 16117, "TRAINED_CATEGORY"], [16128, 16138, "TRAINED_CATEGORY"], [16142, 16150, "TRAINED_CATEGORY"], [16152, 16174, "TRAINED_CATEGORY"], [16191, 16201, "TRAINED_CATEGORY"], [16217, 16231, "TRAINED_CATEGORY"], [16237, 16243, "TRAINED_CATEGORY"], [16255, 16267, "TRAINED_CATEGORY"], [16269, 16276, "TRAINED_CATEGORY"], [16291, 16295, "TRAINED_CATEGORY"], [16309, 16311, "TRAINED_CATEGORY"], [16317, 16321, "TRAINED_CATEGORY"], [16326, 16368, "TRAINED_CATEGORY"], [16380, 16397, "TRAINED_CATEGORY"], [16415, 16425, "TRAINED_CATEGORY"], [16430, 16442, "TRAINED_CATEGORY"], [16452, 16462, "TRAINED_CATEGORY"], [16474, 16478, "TRAINED_CATEGORY"], [16509, 16525, "TRAINED_CATEGORY"], [16534, 16544, "TRAINED_CATEGORY"], [16572, 16582, "TRAINED_CATEGORY"], [16587, 16594, "TRAINED_CATEGORY"], [16611, 16620, "TRAINED_CATEGORY"], [16624, 16640, "TRAINED_CATEGORY"], [16642, 16646, "TRAINED_CATEGORY"], [16657, 16677, "TRAINED_CATEGORY"], [16681, 16690, "TRAINED_CATEGORY"], [16694, 16703, "TRAINED_CATEGORY"], [16710, 16723, "TRAINED_CATEGORY"], [16725, 16735, "TRAINED_CATEGORY"], [16740, 16756, "TRAINED_CATEGORY"], [16787, 16792, "TRAINED_CATEGORY"], [16796, 16806, "TRAINED_CATEGORY"], [16808, 16814, "TRAINED_CATEGORY"], [16820, 16828, "TRAINED_CATEGORY"], [16838, 16854, "TRAINED_CATEGORY"], [16867, 16875, "TRAINED_CATEGORY"], [16978, 16989, "TRAINED_CATEGORY"], [16993, 16997, "TRAINED_CATEGORY"], [17000, 17006, "TRAINED_CATEGORY"], [17021, 17031, "TRAINED_CATEGORY"], [17036, 17046, "TRAINED_CATEGORY"], [17051, 17061, "TRAINED_CATEGORY"], [17066, 17081, "TRAINED_CATEGORY"], [17105, 17124, "TRAINED_CATEGORY"], [17126, 17136, "TRAINED_CATEGORY"], [17158, 17169, "TRAINED_CATEGORY"], [17183, 17199, "TRAINED_CATEGORY"], [17205, 17217, "TRAINED_CATEGORY"], [17228, 17243, "TRAINED_CATEGORY"], [17255, 17260, "TRAINED_CATEGORY"], [17264, 17275, "TRAINED_CATEGORY"], [17277, 17287, "TRAINED_CATEGORY"], [17291, 17299, "TRAINED_CATEGORY"], [17301, 17313, "TRAINED_CATEGORY"], [17319, 17335, "TRAINED_CATEGORY"], [17401, 17411, "TRAINED_CATEGORY"], [17413, 17425, "TRAINED_CATEGORY"], [17429, 17437, "TRAINED_CATEGORY"], [17448, 17462, "TRAINED_CATEGORY"], [17466, 17482, "TRAINED_CATEGORY"], [17507, 17513, "TRAINED_CATEGORY"], [17542, 17557, "TRAINED_CATEGORY"], [17561, 17569, "TRAINED_CATEGORY"], [17587, 17601, "TRAINED_CATEGORY"], [17603, 17619, "TRAINED_CATEGORY"], [17666, 17680, "TRAINED_CATEGORY"], [17684, 17695, "TRAINED_CATEGORY"], [17717, 17731, "TRAINED_CATEGORY"], [17735, 17745, "TRAINED_CATEGORY"], [17749, 17760, "TRAINED_CATEGORY"], [17761, 17769, "TRAINED_CATEGORY"], [17771, 17783, "TRAINED_CATEGORY"], [17789, 17805, "TRAINED_CATEGORY"], [17827, 17841, "TRAINED_CATEGORY"], [17876, 17891, "TRAINED_CATEGORY"], [17915, 17922, "TRAINED_CATEGORY"], [17926, 17938, "TRAINED_CATEGORY"], [17942, 17954, "TRAINED_CATEGORY"], [17959, 17973, "TRAINED_CATEGORY"], [17981, 17991, "TRAINED_CATEGORY"], [18007, 18011, "TRAINED_CATEGORY"], [18062, 18079, "TRAINED_CATEGORY"], [18094, 18108, "TRAINED_CATEGORY"], [18110, 18130, "TRAINED_CATEGORY"], [18135, 18149, "TRAINED_CATEGORY"], [18179, 18200, "TRAINED_CATEGORY"], [18218, 18236, "TRAINED_CATEGORY"], [18246, 18269, "TRAINED_CATEGORY"], [18281, 18292, "TRAINED_CATEGORY"], [18297, 18316, "TRAINED_CATEGORY"], [18320, 18328, "TRAINED_CATEGORY"], [18330, 18346, "TRAINED_CATEGORY"], [18351, 18368, "TRAINED_CATEGORY"], [18379, 18392, "TRAINED_CATEGORY"], [18416, 18435, "TRAINED_CATEGORY"], [18442, 18456, "TRAINED_CATEGORY"], [18459, 18479, "TRAINED_CATEGORY"], [18506, 18526, "TRAINED_CATEGORY"], [18530, 18539, "TRAINED_CATEGORY"], [18547, 18554, "TRAINED_CATEGORY"], [18558, 18566, "TRAINED_CATEGORY"], [18572, 18579, "TRAINED_CATEGORY"], [18583, 18595, "TRAINED_CATEGORY"], [18597, 18617, "TRAINED_CATEGORY"], [18621, 18631, "TRAINED_CATEGORY"], [18635, 18643, "TRAINED_CATEGORY"], [18648, 18673, "TRAINED_CATEGORY"], [18691, 18712, "TRAINED_CATEGORY"], [18723, 18728, "TRAINED_CATEGORY"], [18758, 18778, "TRAINED_CATEGORY"], [18782, 18794, "TRAINED_CATEGORY"], [18798, 18828, "TRAINED_CATEGORY"], [18830, 18851, "TRAINED_CATEGORY"], [18856, 18875, "TRAINED_CATEGORY"], [18879, 18888, "TRAINED_CATEGORY"], [18906, 18914, "TRAINED_CATEGORY"], [18931, 18942, "TRAINED_CATEGORY"], [18944, 18965, "TRAINED_CATEGORY"], [18969, 18980, "TRAINED_CATEGORY"], [18998, 19017, "TRAINED_CATEGORY"], [19021, 19033, "TRAINED_CATEGORY"], [19042, 19049, "TRAINED_CATEGORY"], [19053, 19061, "TRAINED_CATEGORY"], [19063, 19083, "TRAINED_CATEGORY"], [19109, 19111, "TRAINED_CATEGORY"], [19132, 19150, "TRAINED_CATEGORY"], [19155, 19187, "TRAINED_CATEGORY"], [19203, 19217, "TRAINED_CATEGORY"], [19235, 19255, "TRAINED_CATEGORY"], [19259, 19278, "TRAINED_CATEGORY"], [19285, 19296, "TRAINED_CATEGORY"], [19303, 19317, "TRAINED_CATEGORY"], [19321, 19338, "TRAINED_CATEGORY"], [19340, 19344, "TRAINED_CATEGORY"], [19363, 19371, "TRAINED_CATEGORY"], [19375, 19395, "TRAINED_CATEGORY"], [19402, 19420, "TRAINED_CATEGORY"], [19424, 19449, "TRAINED_CATEGORY"], [19460, 19472, "TRAINED_CATEGORY"], [19487, 19494, "TRAINED_CATEGORY"], [19514, 19519, "TRAINED_CATEGORY"], [19524, 19532, "TRAINED_CATEGORY"], [19534, 19559, "TRAINED_CATEGORY"], [19589, 19594, "TRAINED_CATEGORY"], [19630, 19640, "TRAINED_CATEGORY"], [19644, 19656, "TRAINED_CATEGORY"], [19674, 19678, "TRAINED_CATEGORY"], [19692, 19705, "TRAINED_CATEGORY"], [19710, 19728, "TRAINED_CATEGORY"], [19739, 19747, "TRAINED_CATEGORY"], [19752, 19767, "TRAINED_CATEGORY"], [19790, 19794, "TRAINED_CATEGORY"], [19808, 19832, "TRAINED_CATEGORY"], [19837, 19853, "TRAINED_CATEGORY"], [19862, 19874, "TRAINED_CATEGORY"], [19879, 19906, "TRAINED_CATEGORY"], [19915, 19924, "TRAINED_CATEGORY"], [19928, 19931, "TRAINED_CATEGORY"], [19940, 19958, "TRAINED_CATEGORY"], [19962, 19969, "TRAINED_CATEGORY"], [19978, 19982, "TRAINED_CATEGORY"], [20024, 20028, "TRAINED_CATEGORY"], [20051, 20055, "TRAINED_CATEGORY"], [20065, 20074, "TRAINED_CATEGORY"], [20078, 20095, "TRAINED_CATEGORY"], [20102, 20127, "TRAINED_CATEGORY"], [20167, 20174, "TRAINED_CATEGORY"], [20176, 20189, "TRAINED_CATEGORY"], [20216, 20238, "TRAINED_CATEGORY"], [20243, 20249, "TRAINED_CATEGORY"], [20263, 20290, "TRAINED_CATEGORY"], [20294, 20324, "TRAINED_CATEGORY"], [20331, 20341, "TRAINED_CATEGORY"], [20345, 20352, "TRAINED_CATEGORY"], [20368, 20425, "TRAINED_CATEGORY"], [20444, 20465, "TRAINED_CATEGORY"], [20467, 20469, "TRAINED_CATEGORY"], [20493, 20506, "TRAINED_CATEGORY"], [20540, 20569, "TRAINED_CATEGORY"], [20577, 20598, "TRAINED_CATEGORY"], [20607, 20609, "TRAINED_CATEGORY"], [20660, 20670, "TRAINED_CATEGORY"], [20681, 20692, "TRAINED_CATEGORY"], [20698, 20713, "TRAINED_CATEGORY"], [20714, 20722, "TRAINED_CATEGORY"], [20726, 20733, "TRAINED_CATEGORY"], [20742, 20749, "TRAINED_CATEGORY"], [20754, 20764, "TRAINED_CATEGORY"], [20768, 20771, "TRAINED_CATEGORY"], [20789, 20807, "TRAINED_CATEGORY"], [20812, 20823, "TRAINED_CATEGORY"], [20827, 20859, "TRAINED_CATEGORY"], [20861, 20874, "TRAINED_CATEGORY"], [20904, 20909, "TRAINED_CATEGORY"], [20913, 20916, "TRAINED_CATEGORY"], [20926, 20931, "TRAINED_CATEGORY"], [20963, 20986, "TRAINED_CATEGORY"], [20990, 20993, "TRAINED_CATEGORY"], [21011, 21030, "TRAINED_CATEGORY"], [21040, 21072, "TRAINED_CATEGORY"], [21083, 21091, "TRAINED_CATEGORY"], [21095, 21103, "TRAINED_CATEGORY"], [21107, 21116, "TRAINED_CATEGORY"], [21120, 21149, "TRAINED_CATEGORY"], [21162, 21178, "TRAINED_CATEGORY"], [21209, 21223, "TRAINED_CATEGORY"], [21240, 21252, "TRAINED_CATEGORY"], [21282, 21299, "TRAINED_CATEGORY"], [21304, 21323, "TRAINED_CATEGORY"], [21325, 21338, "TRAINED_CATEGORY"], [21343, 21362, "TRAINED_CATEGORY"], [21367, 21390, "TRAINED_CATEGORY"], [21411, 21429, "TRAINED_CATEGORY"], [21433, 21443, "TRAINED_CATEGORY"], [21444, 21465, "TRAINED_CATEGORY"], [21480, 21492, "TRAINED_CATEGORY"], [21502, 21516, "TRAINED_CATEGORY"], [21520, 21552, "TRAINED_CATEGORY"], [21567, 21570, "TRAINED_CATEGORY"], [21571, 21591, "TRAINED_CATEGORY"], [21606, 21619, "TRAINED_CATEGORY"], [21633, 21650, "TRAINED_CATEGORY"], [21654, 21667, "TRAINED_CATEGORY"], [21682, 21687, "TRAINED_CATEGORY"], [21694, 21702, "TRAINED_CATEGORY"], [21711, 21723, "TRAINED_CATEGORY"], [21735, 21747, "TRAINED_CATEGORY"], [21751, 21759, "TRAINED_CATEGORY"], [21770, 21786, "TRAINED_CATEGORY"], [21813, 21827, "TRAINED_CATEGORY"], [21831, 21843, "TRAINED_CATEGORY"], [21850, 21863, "TRAINED_CATEGORY"], [21867, 21882, "TRAINED_CATEGORY"], [21892, 21912, "TRAINED_CATEGORY"], [21916, 21921, "TRAINED_CATEGORY"], [21925, 21933, "TRAINED_CATEGORY"], [21937, 21947, "TRAINED_CATEGORY"], [21951, 21969, "TRAINED_CATEGORY"], [21971, 21973, "TRAINED_CATEGORY"], [21977, 21985, "TRAINED_CATEGORY"], [21989, 22011, "TRAINED_CATEGORY"], [22022, 22038, "TRAINED_CATEGORY"], [22052, 22070, "TRAINED_CATEGORY"], [22072, 22083, "TRAINED_CATEGORY"], [22087, 22107, "TRAINED_CATEGORY"], [22131, 22145, "TRAINED_CATEGORY"], [22173, 22184, "TRAINED_CATEGORY"], [22188, 22195, "TRAINED_CATEGORY"], [22202, 22215, "TRAINED_CATEGORY"], [22217, 22220, "TRAINED_CATEGORY"], [22231, 22252, "TRAINED_CATEGORY"], [22268, 22292, "TRAINED_CATEGORY"], [22310, 22323, "TRAINED_CATEGORY"], [22330, 22347, "TRAINED_CATEGORY"], [22384, 22399, "TRAINED_CATEGORY"], [22409, 22422, "TRAINED_CATEGORY"], [22451, 22475, "TRAINED_CATEGORY"], [22479, 22482, "TRAINED_CATEGORY"], [22491, 22505, "TRAINED_CATEGORY"], [22517, 22523, "TRAINED_CATEGORY"], [22535, 22562, "TRAINED_CATEGORY"], [22608, 22625, "TRAINED_CATEGORY"], [22635, 22647, "TRAINED_CATEGORY"], [22651, 22658, "TRAINED_CATEGORY"], [22662, 22689, "TRAINED_CATEGORY"], [22720, 22728, "TRAINED_CATEGORY"], [22732, 22741, "TRAINED_CATEGORY"], [22745, 22766, "TRAINED_CATEGORY"], [22768, 22787, "TRAINED_CATEGORY"], [22791, 22798, "TRAINED_CATEGORY"], [22815, 22833, "TRAINED_CATEGORY"], [22834, 22863, "TRAINED_CATEGORY"], [22871, 22892, "TRAINED_CATEGORY"], [22900, 22909, "TRAINED_CATEGORY"], [22921, 22932, "TRAINED_CATEGORY"], [22958, 22969, "TRAINED_CATEGORY"], [22973, 22977, "TRAINED_CATEGORY"], [22979, 22992, "TRAINED_CATEGORY"], [22997, 23000, "TRAINED_CATEGORY"], [23030, 23042, "TRAINED_CATEGORY"], [23046, 23065, "TRAINED_CATEGORY"], [23078, 23087, "TRAINED_CATEGORY"], [23097, 23114, "TRAINED_CATEGORY"], [23119, 23127, "TRAINED_CATEGORY"], [23132, 23154, "TRAINED_CATEGORY"], [23158, 23161, "TRAINED_CATEGORY"], [23163, 23182, "TRAINED_CATEGORY"], [23193, 23201, "TRAINED_CATEGORY"], [23205, 23218, "TRAINED_CATEGORY"], [23233, 23239, "TRAINED_CATEGORY"], [23249, 23255, "TRAINED_CATEGORY"], [23259, 23273, "TRAINED_CATEGORY"], [23282, 23296, "TRAINED_CATEGORY"], [23300, 23314, "TRAINED_CATEGORY"], [23330, 23360, "TRAINED_CATEGORY"], [23373, 23397, "TRAINED_CATEGORY"], [23401, 23418, "TRAINED_CATEGORY"], [23420, 23422, "TRAINED_CATEGORY"], [23438, 23470, "TRAINED_CATEGORY"], [23474, 23477, "TRAINED_CATEGORY"], [23479, 23489, "TRAINED_CATEGORY"], [23493, 23506, "TRAINED_CATEGORY"], [23510, 23513, "TRAINED_CATEGORY"], [23541, 23544, "TRAINED_CATEGORY"], [23554, 23573, "TRAINED_CATEGORY"], [23591, 23606, "TRAINED_CATEGORY"], [23616, 23620, "TRAINED_CATEGORY"], [23647, 23659, "TRAINED_CATEGORY"], [23671, 23686, "TRAINED_CATEGORY"], [23690, 23704, "TRAINED_CATEGORY"], [23713, 23726, "TRAINED_CATEGORY"], [23735, 23742, "TRAINED_CATEGORY"], [23755, 23774, "TRAINED_CATEGORY"], [23777, 23792, "TRAINED_CATEGORY"], [23796, 23810, "TRAINED_CATEGORY"], [23816, 23823, "TRAINED_CATEGORY"], [23828, 23846, "TRAINED_CATEGORY"], [23862, 23880, "TRAINED_CATEGORY"], [23884, 23904, "TRAINED_CATEGORY"], [23911, 23927, "TRAINED_CATEGORY"], [23931, 23961, "TRAINED_CATEGORY"], [23972, 23991, "TRAINED_CATEGORY"], [23992, 23995, "TRAINED_CATEGORY"], [24008, 24019, "TRAINED_CATEGORY"], [24025, 24050, "TRAINED_CATEGORY"], [24076, 24090, "TRAINED_CATEGORY"], [24094, 24110, "TRAINED_CATEGORY"], [24165, 24176, "TRAINED_CATEGORY"], [24180, 24199, "TRAINED_CATEGORY"], [24201, 24203, "TRAINED_CATEGORY"], [24223, 24235, "TRAINED_CATEGORY"], [24241, 24279, "TRAINED_CATEGORY"], [24298, 24312, "TRAINED_CATEGORY"], [24342, 24367, "TRAINED_CATEGORY"], [24382, 24404, "TRAINED_CATEGORY"], [24447, 24471, "TRAINED_CATEGORY"], [24472, 24493, "TRAINED_CATEGORY"], [24518, 24541, "TRAINED_CATEGORY"], [24542, 24566, "TRAINED_CATEGORY"], [24567, 24596, "TRAINED_CATEGORY"], [24597, 24602, "TRAINED_CATEGORY"], [24603, 24612, "TRAINED_CATEGORY"], [24613, 24616, "TRAINED_CATEGORY"], [24620, 24640, "TRAINED_CATEGORY"], [24641, 24673, "TRAINED_CATEGORY"], [24674, 24693, "TRAINED_CATEGORY"], [24694, 24733, "TRAINED_CATEGORY"], [24734, 24748, "TRAINED_CATEGORY"], [24773, 24783, "TRAINED_CATEGORY"], [24792, 24807, "TRAINED_CATEGORY"], [24811, 24816, "TRAINED_CATEGORY"], [24848, 24855, "TRAINED_CATEGORY"], [24857, 24889, "TRAINED_CATEGORY"], [24894, 24903, "TRAINED_CATEGORY"], [24907, 24922, "TRAINED_CATEGORY"], [24931, 24938, "TRAINED_CATEGORY"], [24952, 24961, "TRAINED_CATEGORY"], [24963, 24967, "TRAINED_CATEGORY"], [24983, 24992, "TRAINED_CATEGORY"], [24994, 25004, "TRAINED_CATEGORY"], [25006, 25009, "TRAINED_CATEGORY"], [25011, 25015, "TRAINED_CATEGORY"], [25043, 25064, "TRAINED_CATEGORY"], [25068, 25075, "TRAINED_CATEGORY"], [25092, 25098, "TRAINED_CATEGORY"], [25101, 25106, "TRAINED_CATEGORY"], [25108, 25130, "TRAINED_CATEGORY"], [25134, 25149, "TRAINED_CATEGORY"], [25154, 25169, "TRAINED_CATEGORY"], [25175, 25205, "TRAINED_CATEGORY"], [25214, 25224, "TRAINED_CATEGORY"], [25226, 25229, "TRAINED_CATEGORY"], [25231, 25235, "TRAINED_CATEGORY"], [25252, 25273, "TRAINED_CATEGORY"], [25277, 25300, "TRAINED_CATEGORY"], [25304, 25307, "TRAINED_CATEGORY"], [25310, 25315, "TRAINED_CATEGORY"], [25317, 25350, "TRAINED_CATEGORY"], [25354, 25369, "TRAINED_CATEGORY"], [25370, 25403, "TRAINED_CATEGORY"], [25413, 25423, "TRAINED_CATEGORY"], [25425, 25428, "TRAINED_CATEGORY"], [25430, 25434, "TRAINED_CATEGORY"], [25451, 25473, "TRAINED_CATEGORY"], [25477, 25484, "TRAINED_CATEGORY"], [25486, 25499, "TRAINED_CATEGORY"], [25500, 25507, "TRAINED_CATEGORY"], [25513, 25533, "TRAINED_CATEGORY"], [25537, 25562, "TRAINED_CATEGORY"], [25565, 25570, "TRAINED_CATEGORY"], [25572, 25581, "TRAINED_CATEGORY"], [25588, 25604, "TRAINED_CATEGORY"], [25606, 25620, "TRAINED_CATEGORY"], [25622, 25634, "TRAINED_CATEGORY"], [25638, 25649, "TRAINED_CATEGORY"], [25651, 25668, "TRAINED_CATEGORY"], [25670, 25673, "TRAINED_CATEGORY"], [25675, 25679, "TRAINED_CATEGORY"], [25695, 25702, "TRAINED_CATEGORY"], [25706, 25719, "TRAINED_CATEGORY"], [25724, 25732, "TRAINED_CATEGORY"], [25736, 25751, "TRAINED_CATEGORY"], [25753, 25779, "TRAINED_CATEGORY"], [25783, 25788, "TRAINED_CATEGORY"], [25801, 25809, "TRAINED_CATEGORY"], [25811, 25830, "TRAINED_CATEGORY"], [25836, 25851, "TRAINED_CATEGORY"], [25854, 25859, "TRAINED_CATEGORY"], [25861, 25870, "TRAINED_CATEGORY"], [25877, 25891, "TRAINED_CATEGORY"], [25892, 25901, "TRAINED_CATEGORY"], [25905, 25915, "TRAINED_CATEGORY"], [25917, 25929, "TRAINED_CATEGORY"], [25933, 25941, "TRAINED_CATEGORY"], [25943, 25949, "TRAINED_CATEGORY"], [25951, 25957, "TRAINED_CATEGORY"], [25963, 25977, "TRAINED_CATEGORY"], [25986, 25992, "TRAINED_CATEGORY"], [25994, 26008, "TRAINED_CATEGORY"], [26010, 26014, "TRAINED_CATEGORY"], [26016, 26045, "TRAINED_CATEGORY"], [26047, 26070, "TRAINED_CATEGORY"], [26093, 26096, "TRAINED_CATEGORY"], [26098, 26102, "TRAINED_CATEGORY"], [26118, 26131, "TRAINED_CATEGORY"], [26133, 26168, "TRAINED_CATEGORY"], [26177, 26185, "TRAINED_CATEGORY"], [26187, 26193, "TRAINED_CATEGORY"], [26195, 26203, "TRAINED_CATEGORY"], [26205, 26210, "TRAINED_CATEGORY"], [26212, 26241, "TRAINED_CATEGORY"], [26243, 26259, "TRAINED_CATEGORY"], [26263, 26270, "TRAINED_CATEGORY"], [26279, 26285, "TRAINED_CATEGORY"], [26303, 26307, "TRAINED_CATEGORY"], [26343, 26346, "TRAINED_CATEGORY"], [26348, 26352, "TRAINED_CATEGORY"], [26373, 26388, "TRAINED_CATEGORY"], [26390, 26409, "TRAINED_CATEGORY"], [26411, 26441, "TRAINED_CATEGORY"], [26450, 26458, "TRAINED_CATEGORY"], [26460, 26467, "TRAINED_CATEGORY"], [26469, 26473, "TRAINED_CATEGORY"], [26488, 26494, "TRAINED_CATEGORY"], [26496, 26503, "TRAINED_CATEGORY"], [26505, 26510, "TRAINED_CATEGORY"], [26512, 26532, "TRAINED_CATEGORY"], [26534, 26544, "TRAINED_CATEGORY"], [26549, 26560, "TRAINED_CATEGORY"], [26562, 26574, "TRAINED_CATEGORY"], [26578, 26608, "TRAINED_CATEGORY"], [26612, 26621, "TRAINED_CATEGORY"], [26623, 26630, "TRAINED_CATEGORY"], [26632, 26640, "TRAINED_CATEGORY"], [26642, 26647, "TRAINED_CATEGORY"], [26652, 26658, "TRAINED_CATEGORY"], [26667, 26673, "TRAINED_CATEGORY"], [26675, 26690, "TRAINED_CATEGORY"], [26692, 26696, "TRAINED_CATEGORY"], [26698, 26717, "TRAINED_CATEGORY"], [26719, 26726, "TRAINED_CATEGORY"], [26728, 26733, "TRAINED_CATEGORY"], [26735, 26760, "TRAINED_CATEGORY"], [26764, 26811, "TRAINED_CATEGORY"], [26820, 26830, "TRAINED_CATEGORY"], [26832, 26835, "TRAINED_CATEGORY"], [26837, 26841, "TRAINED_CATEGORY"], [26843, 26862, "TRAINED_CATEGORY"], [26864, 26871, "TRAINED_CATEGORY"], [26873, 26878, "TRAINED_CATEGORY"], [26880, 26896, "TRAINED_CATEGORY"], [26898, 26905, "TRAINED_CATEGORY"], [26907, 26915, "TRAINED_CATEGORY"], [26918, 26930, "TRAINED_CATEGORY"], [26934, 26964, "TRAINED_CATEGORY"], [26973, 26979, "TRAINED_CATEGORY"], [26981, 26996, "TRAINED_CATEGORY"], [26998, 27002, "TRAINED_CATEGORY"], [27004, 27025, "TRAINED_CATEGORY"], [27027, 27032, "TRAINED_CATEGORY"], [27034, 27040, "TRAINED_CATEGORY"], [27042, 27071, "TRAINED_CATEGORY"], [27089, 27112, "TRAINED_CATEGORY"], [27121, 27131, "TRAINED_CATEGORY"], [27133, 27136, "TRAINED_CATEGORY"], [27138, 27142, "TRAINED_CATEGORY"], [27162, 27176, "TRAINED_CATEGORY"], [27180, 27201, "TRAINED_CATEGORY"], [27205, 27235, "TRAINED_CATEGORY"], [27236, 27253, "TRAINED_CATEGORY"], [27297, 27304, "TRAINED_CATEGORY"], [27306, 27313, "TRAINED_CATEGORY"], [27314, 27325, "TRAINED_CATEGORY"], [27334, 27357, "TRAINED_CATEGORY"], [27364, 27375, "TRAINED_CATEGORY"], [27379, 27397, "TRAINED_CATEGORY"], [27406, 27415, "TRAINED_CATEGORY"], [27419, 27452, "TRAINED_CATEGORY"], [27454, 27462, "TRAINED_CATEGORY"], [27468, 27483, "TRAINED_CATEGORY"], [27485, 27511, "TRAINED_CATEGORY"], [27513, 27522, "TRAINED_CATEGORY"], [27524, 27542, "TRAINED_CATEGORY"], [27544, 27568, "TRAINED_CATEGORY"], [27572, 27575, "TRAINED_CATEGORY"], [27579, 27594, "TRAINED_CATEGORY"], [27595, 27621, "TRAINED_CATEGORY"], [27622, 27626, "TRAINED_CATEGORY"], [27628, 27635, "TRAINED_CATEGORY"], [27641, 27652, "TRAINED_CATEGORY"], [27659, 27665, "TRAINED_CATEGORY"], [27668, 27681, "TRAINED_CATEGORY"], [27682, 27695, "TRAINED_CATEGORY"], [27700, 27717, "TRAINED_CATEGORY"], [27724, 27730, "TRAINED_CATEGORY"], [27732, 27752, "TRAINED_CATEGORY"], [27754, 27757, "TRAINED_CATEGORY"], [27761, 27790, "TRAINED_CATEGORY"], [27794, 27798, "TRAINED_CATEGORY"], [27801, 27828, "TRAINED_CATEGORY"], [27857, 27864, "TRAINED_CATEGORY"], [27868, 27891, "TRAINED_CATEGORY"], [27892, 27903, "TRAINED_CATEGORY"], [27909, 27930, "TRAINED_CATEGORY"], [27954, 27980, "TRAINED_CATEGORY"], [27982, 27995, "TRAINED_CATEGORY"], [27998, 28024, "TRAINED_CATEGORY"], [28026, 28050, "TRAINED_CATEGORY"], [28054, 28084, "TRAINED_CATEGORY"], [28087, 28102, "TRAINED_CATEGORY"], [28106, 28121, "TRAINED_CATEGORY"], [28125, 28155, "TRAINED_CATEGORY"], [28168, 28171, "TRAINED_CATEGORY"], [28176, 28198, "TRAINED_CATEGORY"], [28202, 28217, "TRAINED_CATEGORY"], [28218, 28226, "TRAINED_CATEGORY"], [28228, 28233, "TRAINED_CATEGORY"], [28241, 28244, "TRAINED_CATEGORY"], [28248, 28261, "TRAINED_CATEGORY"], [28271, 28274, "TRAINED_CATEGORY"], [28278, 28283, "TRAINED_CATEGORY"], [28287, 28306, "TRAINED_CATEGORY"], [28311, 28330, "TRAINED_CATEGORY"], [28371, 28403, "TRAINED_CATEGORY"], [28407, 28422, "TRAINED_CATEGORY"], [32, 35, "ORG"], [168, 183, "PERSON"], [187, 196, "DATE"], [216, 229, "PERSON"], [241, 254, "ORG"], [258, 262, "DATE"], [604, 607, "CARDINAL"], [700, 704, "CARDINAL"], [725, 728, "ORG"], [748, 749, "CARDINAL"], [753, 754, "CARDINAL"], [758, 759, "CARDINAL"], [765, 773, "PERSON"], [776, 780, "DATE"], [815, 818, "ORG"], [1083, 1086, "ORG"], [1420, 1423, "ORG"], [1917, 1920, "CARDINAL"], [2210, 2213, "ORG"], [2323, 2326, "ORG"], [2674, 2677, "ORG"], [3140, 3175, "ORG"], [3630, 3633, "ORG"], [3684, 3687, "CARDINAL"], [4426, 4429, "ORG"], [4482, 4491, "CARDINAL"], [4793, 4796, "ORG"], [5000, 5003, "ORG"], [5103, 5114, "ORG"], [5118, 5124, "PERSON"], [5191, 5219, "ORG"], [5274, 5295, "ORG"], [5327, 5364, "ORG"], [5422, 5445, "ORG"], [5510, 5545, "ORG"], [5575, 5579, "GPE"], [5592, 5622, "ORG"], [5833, 5836, "ORG"], [5969, 5972, "ORG"], [6216, 6224, "GPE"], [6244, 6249, "ORDINAL"], [6351, 6360, "ORG"], [6733, 6742, "LOC"], [6744, 6758, "PERSON"], [6764, 6771, "CARDINAL"], [6785, 6788, "ORG"], [6859, 6864, "GPE"], [6879, 6895, "CARDINAL"], [6896, 6903, "NORP"], [6934, 6937, "ORG"], [6973, 6976, "ORG"], [7083, 7088, "GPE"], [7103, 7115, "CARDINAL"], [7116, 7123, "NORP"], [7165, 7232, "ORG"], [7364, 7368, "DATE"], [7382, 7437, "WORK_OF_ART"], [7483, 7536, "WORK_OF_ART"], [7546, 7550, "DATE"], [7562, 7572, "GPE"], [7574, 7579, "GPE"], [7581, 7588, "CARDINAL"], [7616, 7618, "CARDINAL"], [7644, 7646, "GPE"], [7648, 7655, "GPE"], [7657, 7662, "GPE"], [7664, 7669, "GPE"], [7671, 7679, "GPE"], [7685, 7690, "GPE"], [7741, 7745, "DATE"], [7759, 7769, "GPE"], [7771, 7783, "GPE"], [7790, 7792, "CARDINAL"], [7879, 7885, "GPE"], [7987, 8006, "ORG"], [8010, 8015, "GPE"], [8084, 8087, "ORG"], [8238, 8244, "CARDINAL"], [8257, 8265, "CARDINAL"], [8353, 8356, "CARDINAL"], [8677, 8680, "ORG"], [9526, 9531, "PRODUCT"], [9567, 9572, "ORDINAL"], [9800, 9803, "ORG"], [12400, 12403, "ORG"], [12412, 12415, "ORG"], [13179, 13182, "ORG"], [13323, 13326, "ORG"], [13376, 13388, "CARDINAL"], [13492, 13495, "ORG"], [14027, 14030, "ORG"], [14099, 14104, "CARDINAL"], [14148, 14152, "CARDINAL"], [14271, 14274, "CARDINAL"], [14324, 14329, "CARDINAL"], [14366, 14370, "CARDINAL"], [14513, 14516, "CARDINAL"], [14718, 14722, "CARDINAL"], [14741, 14745, "CARDINAL"], [14815, 14820, "CARDINAL"], [14855, 14865, "CARDINAL"], [15023, 15026, "ORG"], [15075, 15083, "CARDINAL"], [15489, 15492, "CARDINAL"], [16273, 16276, "ORG"], [16384, 16388, "CARDINAL"], [16405, 16414, "NORP"], [16534, 16544, "ORG"], [16627, 16630, "ORG"], [16757, 16777, "CARDINAL"], [16879, 16882, "CARDINAL"], [16903, 16906, "CARDINAL"], [16927, 16930, "CARDINAL"], [16945, 16949, "CARDINAL"], [17305, 17313, "ORG"], [17323, 17335, "NORP"], [17433, 17437, "LOC"], [17441, 17446, "CARDINAL"], [17500, 17505, "CARDINAL"], [17561, 17569, "ORG"], [17632, 17637, "CARDINAL"], [17820, 17825, "CARDINAL"], [18064, 18069, "ORDINAL"], [18179, 18187, "CARDINAL"], [18188, 18200, "NORP"], [18240, 18244, "CARDINAL"], [18246, 18249, "CARDINAL"], [18297, 18310, "CARDINAL"], [18424, 18435, "NORP"], [18635, 18643, "ORG"], [18662, 18673, "NORP"], [18684, 18689, "CARDINAL"], [18899, 18904, "CARDINAL"], [19094, 19099, "CARDINAL"], [19402, 19411, "ORG"], [19491, 19494, "ORG"], [19534, 19537, "CARDINAL"], [19692, 19696, "CARDINAL"], [19710, 19715, "CARDINAL"], [19808, 19811, "CARDINAL"], [19812, 19832, "ORG"], [19837, 19840, "CARDINAL"], [19928, 19931, "ORG"], [20044, 20047, "CARDINAL"], [20102, 20111, "CARDINAL"], [20112, 20115, "ORG"], [20263, 20324, "EVENT"], [20331, 20341, "ORG"], [20349, 20352, "ORG"], [20698, 20713, "DATE"], [20768, 20771, "ORG"], [20789, 20859, "ORG"], [20913, 20916, "ORG"], [20990, 20993, "ORG"], [21011, 21030, "ORG"], [21034, 21038, "DATE"], [21043, 21047, "DATE"], [21048, 21066, "ORG"], [21083, 21091, "DATE"], [21120, 21149, "ORG"], [21162, 21165, "ORG"], [21276, 21280, "DATE"], [21325, 21362, "ORG"], [21367, 21390, "ORG"], [21411, 21414, "ORG"], [21482, 21486, "DATE"], [21567, 21570, "ORG"], [21606, 21619, "DATE"], [21658, 21661, "ORG"], [21713, 21717, "DATE"], [21850, 21854, "ORG"], [22173, 22176, "CARDINAL"], [22217, 22220, "CARDINAL"], [22479, 22482, "ORG"], [22511, 22515, "DATE"], [22517, 22523, "ORG"], [22537, 22543, "ORDINAL"], [22544, 22547, "ORG"], [22795, 22798, "ORG"], [22997, 23000, "ORG"], [23032, 23036, "DATE"], [23046, 23065, "ORG"], [23097, 23114, "ORG"], [23119, 23127, "PERSON"], [23158, 23161, "ORG"], [23438, 23477, "ORG"], [23510, 23513, "ORG"], [23527, 23531, "DATE"], [23541, 23544, "ORG"], [23739, 23742, "ORG"], [23820, 23823, "ORG"], [24223, 24235, "PERSON"], [24377, 24380, "DATE"], [24447, 24455, "ORG"], [24472, 24477, "ORG"], [24567, 24579, "ORG"], [24597, 24602, "PERSON"], [24641, 24646, "ORG"], [24734, 24738, "PRODUCT"], [24818, 24836, "PERSON"], [24924, 24928, "DATE"], [24931, 24938, "GPE"], [24940, 24950, "GPE"], [24952, 24961, "PERSON"], [24983, 24992, "GPE"], [24994, 25004, "GPE"], [25006, 25009, "ORG"], [25072, 25075, "ORG"], [25108, 25130, "PERSON"], [25134, 25169, "ORG"], [25207, 25211, "DATE"], [25214, 25224, "GPE"], [25226, 25229, "ORG"], [25304, 25307, "ORG"], [25317, 25339, "PERSON"], [25371, 25403, "PERSON"], [25406, 25410, "DATE"], [25413, 25423, "GPE"], [25425, 25428, "ORG"], [25435, 25436, "CARDINAL"], [25481, 25484, "ORG"], [25504, 25507, "ORG"], [25572, 25581, "PERSON"], [25588, 25604, "PERSON"], [25610, 25620, "PERSON"], [25652, 25656, "DATE"], [25658, 25668, "GPE"], [25696, 25702, "CARDINAL"], [25736, 25739, "ORG"], [25861, 25870, "PERSON"], [25877, 25891, "PERSON"], [25892, 25915, "PERSON"], [25979, 25983, "DATE"], [25986, 25992, "GPE"], [25994, 26008, "ORG"], [26085, 26089, "DATE"], [26093, 26096, "ORG"], [26098, 26102, "ORG"], [26118, 26131, "PERSON"], [26170, 26174, "DATE"], [26187, 26193, "PERSON"], [26195, 26203, "PERSON"], [26212, 26242, "PERSON"], [26243, 26270, "ORG"], [26272, 26276, "DATE"], [26287, 26301, "ORG"], [26335, 26339, "DATE"], [26343, 26346, "ORG"], [26348, 26352, "ORG"], [26373, 26388, "PERSON"], [26443, 26447, "DATE"], [26450, 26458, "GPE"], [26460, 26467, "ORG"], [26488, 26494, "GPE"], [26496, 26503, "PERSON"], [26512, 26532, "PERSON"], [26660, 26664, "DATE"], [26667, 26673, "GPE"], [26711, 26717, "GPE"], [26719, 26726, "PERSON"], [26735, 26760, "PERSON"], [26813, 26817, "DATE"], [26820, 26830, "GPE"], [26832, 26835, "ORG"], [26856, 26862, "GPE"], [26864, 26871, "PERSON"], [26880, 26896, "PERSON"], [26898, 26964, "ORG"], [26966, 26970, "DATE"], [26973, 26979, "GPE"], [27017, 27025, "GPE"], [27027, 27032, "GPE"], [27034, 27040, "GPE"], [27042, 27055, "PERSON"], [27114, 27118, "DATE"], [27121, 27131, "GPE"], [27133, 27136, "ORG"], [27143, 27144, "CARDINAL"], [27162, 27170, "ORG"], [27180, 27235, "ORG"], [27301, 27304, "ORG"], [27364, 27367, "ORG"], [27459, 27462, "ORG"], [27468, 27471, "ORG"], [27513, 27516, "ORG"], [27525, 27537, "CARDINAL"], [27572, 27575, "ORG"], [27583, 27594, "PERSON"], [27659, 27665, "PERSON"], [27684, 27687, "ORG"], [27765, 27779, "PERSON"], [27802, 27829, "WORK_OF_ART"], [27892, 27895, "ORG"], [27933, 27936, "ORG"], [28001, 28004, "ORG"], [28168, 28171, "ORG"], [28206, 28217, "PERSON"], [28241, 28244, "ORG"], [28248, 28253, "PRODUCT"], [28271, 28274, "ORG"], [28278, 28283, "PRODUCT"], [28291, 28306, "PERSON"], [28407, 28422, "PERSON"]]}], ["The analytic network process (ANP) is a more general form of the analytic hierarchy process (AHP) used in multi-criteria decision analysis.\nAHP structures a decision problem into a hierarchy with a goal, decision criteria, and alternatives, while the ANP structures it as a network. Both then use a system of pairwise comparisons to measure the weights of the components of the structure, and finally to rank the alternatives in the decision.\n\n\n== Hierarchy vs. network ==\nIn the AHP, each element in the hierarchy is considered to be independent of all the others\u2014the decision criteria are considered to be independent of one another, and the alternatives are considered to be independent of the decision criteria and of each other. But in many real-world cases, there is interdependence among the items and the alternatives. ANP does not require independence among elements, so it can be used as an effective tool in these cases.\nTo illustrate this, consider a simple decision about buying an automobile. The decision maker may want to decide among several moderately-priced full-size sedans. He might choose to base his decision on only three factors: purchase price, safety, and comfort. Both the AHP and ANP would provide useful frameworks to use in making his decision.\nThe AHP would assume that purchase price, safety, and comfort are independent of one another, and would evaluate each of the sedans independently on those criteria.\nThe ANP would allow consideration of the interdependence of price, safety, and comfort. If one could get more safety or comfort by paying more for the automobile (or less by paying less), the ANP could take that into account. Similarly, the ANP could allow the decision criteria to be affected by the traits of the cars under consideration. If, for example, all the cars are very, very safe, the importance of safety as a decision criterion could appropriately be reduced.\n\n\n== Literature and community ==\nAcademic articles about ANP appear in journals dealing with the decision sciences, and several books have been written on the subject.There are numerous practical applications of ANP, many of them involving complex decisions about benefits (B), opportunities (O), costs (C) and risks (R). Studying these applications can be very useful in understanding the complexities of the ANP. The literature contains hundreds of elaborately worked out examples of the process, developed by executives, managers, engineers, MBA and Ph.D. students and others from many countries. About a hundred such uses are illustrated and discussed in The Encyclicon, a dictionary of decisions with dependence and feedback.Academics and practitioners meet biennially at the International Symposium on the Analytic Hierarchy Process (ISAHP), which, despite its name, devotes considerable attention to the ANP.\n\n\n== Outline of the steps ==\nUnderstanding of the ANP is best achieved by using ANP software to work with previously-completed decisions. One of the field's standard texts gives this outline of the steps involved:\nMake sure that you understand the decision problem in detail, including its objectives, criteria and subcriteria, actors and their objectives and the possible outcomes of that decision. Give details of influences that determine how that decision may come out.\nDetermine the control criteria and subcriteria in the four control hierarchies one each for the benefits, opportunities, costs and risks of that decision and obtain their priorities from paired comparison matrices. You may use the same control criteria and perhaps subcriteria for all of the four merits. If a control criterion or subcriterion has a global priority of 3% or less, you may consider carefully eliminating it from further consideration. The software automatically deals only with those criteria or subcriteria that have subnets under them. For benefits and opportunities, ask what gives the most benefits or presents the greatest opportunity to influence fulfillment of that control criterion. For costs and risks, ask what incurs the most cost or faces the greatest risk. Sometimes (very rarely), the comparisons are made simply in terms of benefits, opportunities, costs, and risks by aggregating all the criteria of each BOCR into their merit.\nDetermine a complete set of network clusters (components) and their elements that are relevant to each and every control criterion. To better organize the development of the model as well as you can, number and arrange the clusters and their elements in a convenient way (perhaps in a column). Use the identical label to represent the same cluster and the same elements for all the control criteria.\nFor each control criterion or subcriterion, determine the appropriate subset of clusters of the comprehensive set with their elements and connect them according to their outer and inner dependence influences. An arrow is drawn from a cluster to any cluster whose elements influence it.\nDetermine the approach you want to follow in the analysis of each cluster or element, influencing (the suggested approach) other clusters and elements with respect to a criterion, or being influenced by other clusters and elements. The sense (being influenced or influencing) must apply to all the criteria for the four control hierarchies for the entire decision.\nFor each control criterion, construct the supermatrix by laying out the clusters in the order they are numbered and all the elements in each cluster both vertically on the left and horizontally at the top. Enter in the appropriate position the priorities derived from the paired comparisons as subcolumns of the corresponding column of the supermatrix.\nPerform paired comparisons on the elements within the clusters themselves according to their influence on each element in another cluster they are connected to (outer dependence) or on elements in their own cluster (inner dependence). In making comparisons, you must always have a criterion in mind. Comparisons of elements according to which element influences a third element more and how strongly more than another element it is compared with are made with a control criterion or subcriterion of the control hierarchy in mind.\nPerform paired comparisons on the clusters as they influence each cluster to which they are connected with respect to the given control criterion. The derived weights are used to weight the elements of the corresponding column blocks of the supermatrix. Assign a zero when there is no influence. Thus obtain the weighted column stochastic supermatrix.\nCompute the limit priorities of the stochastic supermatrix according to whether it is irreducible (primitive or imprimitive [cyclic]) or it is reducible with one being a simple or a multiple root and whether the system is cyclic or not. Two kinds of outcomes are possible. In the first, all the columns of the matrix are identical and each gives the relative priorities of the elements from which the priorities of the elements in each cluster are normalized to one. In the second, the limit cycles in blocks and the different limits are summed and averaged and again normalized to one for each cluster. Although the priority vectors are entered in the supermatrix in normalized form, the limit priorities are put in idealized form because the control criteria do not depend on the alternatives.\nSynthesize the limiting priorities by weighting each idealized limit vector by the weight of its control criterion and adding the resulting vectors for each of the four merits: Benefits (B), Opportunities (O), Costs (C) and Risks (R). There are now four vectors, one for each of the four merits. An answer involving ratio values of the merits is obtained by forming the ratio BiOi / CiRi for alternative i from each of the four vectors. The synthesized ideals for all the control criteria under each merit may result in an ideal whose priority is less than one for that merit. Only an alternative that is ideal for all the control criteria under a merit receives the value one after synthesis for that merit. The alternative with the largest ratio is chosen for some decisions. Companies and individuals with limited resources often prefer this type of synthesis.\nDetermine strategic criteria and their priorities to rate the top ranked (ideal) alternative for each of the four merits one at a time. Normalize the four ratings thus obtained and use them to calculate the overall synthesis of the four vectors. For each alternative, subtract the sum of the weighted costs and risks from the sum of the weighted benefits and opportunities.\nPerform sensitivity analysis on the final outcome. Sensitivity analysis is concerned with \u201cwhat if\u201d kinds of questions to see if the final answer is stable to changes in the inputs, whether judgments or priorities. Of special interest is to see if these changes change the order of the alternatives. How significant the change is can be measured with the Compatibility Index of the original outcome and each new outcome.\n\n\n== See also ==\nAnalytic hierarchy process\nDecision making\nDecision making software\nL. L. Thurstone\nLaw of comparative judgment\nMulti-criteria decision analysis\nPairwise comparison\nPreference\nThomas L. Saaty\n\n\n== References ==\n\n\n== External links ==\nSuperdecisions tutorial software for the ANP", {"entities": [[0, 28, "TRAINED_CATEGORY"], [30, 33, "TRAINED_CATEGORY"], [38, 57, "TRAINED_CATEGORY"], [61, 91, "TRAINED_CATEGORY"], [93, 96, "TRAINED_CATEGORY"], [106, 138, "TRAINED_CATEGORY"], [140, 143, "TRAINED_CATEGORY"], [155, 173, "TRAINED_CATEGORY"], [179, 190, "TRAINED_CATEGORY"], [196, 202, "TRAINED_CATEGORY"], [204, 221, "TRAINED_CATEGORY"], [227, 239, "TRAINED_CATEGORY"], [247, 254, "TRAINED_CATEGORY"], [266, 268, "TRAINED_CATEGORY"], [272, 281, "TRAINED_CATEGORY"], [297, 305, "TRAINED_CATEGORY"], [309, 329, "TRAINED_CATEGORY"], [341, 352, "TRAINED_CATEGORY"], [356, 370, "TRAINED_CATEGORY"], [374, 387, "TRAINED_CATEGORY"], [409, 425, "TRAINED_CATEGORY"], [429, 441, "TRAINED_CATEGORY"], [448, 457, "TRAINED_CATEGORY"], [462, 469, "TRAINED_CATEGORY"], [476, 483, "TRAINED_CATEGORY"], [485, 497, "TRAINED_CATEGORY"], [501, 514, "TRAINED_CATEGORY"], [550, 564, "TRAINED_CATEGORY"], [565, 586, "TRAINED_CATEGORY"], [623, 626, "TRAINED_CATEGORY"], [640, 656, "TRAINED_CATEGORY"], [693, 714, "TRAINED_CATEGORY"], [741, 762, "TRAINED_CATEGORY"], [773, 788, "TRAINED_CATEGORY"], [795, 804, "TRAINED_CATEGORY"], [809, 825, "TRAINED_CATEGORY"], [827, 830, "TRAINED_CATEGORY"], [848, 860, "TRAINED_CATEGORY"], [867, 875, "TRAINED_CATEGORY"], [880, 882, "TRAINED_CATEGORY"], [898, 915, "TRAINED_CATEGORY"], [919, 930, "TRAINED_CATEGORY"], [961, 978, "TRAINED_CATEGORY"], [992, 1005, "TRAINED_CATEGORY"], [1007, 1025, "TRAINED_CATEGORY"], [1051, 1093, "TRAINED_CATEGORY"], [1095, 1097, "TRAINED_CATEGORY"], [1119, 1131, "TRAINED_CATEGORY"], [1135, 1153, "TRAINED_CATEGORY"], [1155, 1169, "TRAINED_CATEGORY"], [1171, 1177, "TRAINED_CATEGORY"], [1183, 1190, "TRAINED_CATEGORY"], [1192, 1204, "TRAINED_CATEGORY"], [1209, 1212, "TRAINED_CATEGORY"], [1227, 1244, "TRAINED_CATEGORY"], [1262, 1274, "TRAINED_CATEGORY"], [1276, 1283, "TRAINED_CATEGORY"], [1302, 1316, "TRAINED_CATEGORY"], [1318, 1324, "TRAINED_CATEGORY"], [1330, 1337, "TRAINED_CATEGORY"], [1357, 1360, "TRAINED_CATEGORY"], [1397, 1407, "TRAINED_CATEGORY"], [1425, 1439, "TRAINED_CATEGORY"], [1441, 1448, "TRAINED_CATEGORY"], [1461, 1474, "TRAINED_CATEGORY"], [1478, 1497, "TRAINED_CATEGORY"], [1501, 1506, "TRAINED_CATEGORY"], [1508, 1514, "TRAINED_CATEGORY"], [1520, 1527, "TRAINED_CATEGORY"], [1532, 1535, "TRAINED_CATEGORY"], [1546, 1557, "TRAINED_CATEGORY"], [1561, 1568, "TRAINED_CATEGORY"], [1588, 1602, "TRAINED_CATEGORY"], [1629, 1636, "TRAINED_CATEGORY"], [1658, 1665, "TRAINED_CATEGORY"], [1678, 1685, "TRAINED_CATEGORY"], [1698, 1719, "TRAINED_CATEGORY"], [1738, 1748, "TRAINED_CATEGORY"], [1752, 1760, "TRAINED_CATEGORY"], [1767, 1780, "TRAINED_CATEGORY"], [1790, 1797, "TRAINED_CATEGORY"], [1799, 1811, "TRAINED_CATEGORY"], [1833, 1847, "TRAINED_CATEGORY"], [1851, 1857, "TRAINED_CATEGORY"], [1861, 1881, "TRAINED_CATEGORY"], [1919, 1929, "TRAINED_CATEGORY"], [1934, 1943, "TRAINED_CATEGORY"], [1947, 1964, "TRAINED_CATEGORY"], [1971, 1974, "TRAINED_CATEGORY"], [1985, 1993, "TRAINED_CATEGORY"], [2007, 2028, "TRAINED_CATEGORY"], [2034, 2047, "TRAINED_CATEGORY"], [2069, 2080, "TRAINED_CATEGORY"], [2091, 2122, "TRAINED_CATEGORY"], [2126, 2129, "TRAINED_CATEGORY"], [2139, 2143, "TRAINED_CATEGORY"], [2154, 2171, "TRAINED_CATEGORY"], [2178, 2186, "TRAINED_CATEGORY"], [2188, 2189, "TRAINED_CATEGORY"], [2192, 2205, "TRAINED_CATEGORY"], [2211, 2216, "TRAINED_CATEGORY"], [2218, 2219, "TRAINED_CATEGORY"], [2225, 2230, "TRAINED_CATEGORY"], [2232, 2233, "TRAINED_CATEGORY"], [2245, 2263, "TRAINED_CATEGORY"], [2300, 2316, "TRAINED_CATEGORY"], [2320, 2327, "TRAINED_CATEGORY"], [2329, 2343, "TRAINED_CATEGORY"], [2353, 2361, "TRAINED_CATEGORY"], [2388, 2396, "TRAINED_CATEGORY"], [2400, 2411, "TRAINED_CATEGORY"], [2426, 2436, "TRAINED_CATEGORY"], [2438, 2446, "TRAINED_CATEGORY"], [2448, 2457, "TRAINED_CATEGORY"], [2459, 2462, "TRAINED_CATEGORY"], [2467, 2481, "TRAINED_CATEGORY"], [2486, 2492, "TRAINED_CATEGORY"], [2498, 2512, "TRAINED_CATEGORY"], [2514, 2539, "TRAINED_CATEGORY"], [2573, 2587, "TRAINED_CATEGORY"], [2589, 2601, "TRAINED_CATEGORY"], [2605, 2614, "TRAINED_CATEGORY"], [2620, 2630, "TRAINED_CATEGORY"], [2635, 2643, "TRAINED_CATEGORY"], [2644, 2653, "TRAINED_CATEGORY"], [2658, 2671, "TRAINED_CATEGORY"], [2691, 2718, "TRAINED_CATEGORY"], [2722, 2752, "TRAINED_CATEGORY"], [2754, 2759, "TRAINED_CATEGORY"], [2777, 2785, "TRAINED_CATEGORY"], [2795, 2817, "TRAINED_CATEGORY"], [2821, 2828, "TRAINED_CATEGORY"], [2835, 2842, "TRAINED_CATEGORY"], [2846, 2855, "TRAINED_CATEGORY"], [2859, 2872, "TRAINED_CATEGORY"], [2876, 2883, "TRAINED_CATEGORY"], [2910, 2922, "TRAINED_CATEGORY"], [2936, 2966, "TRAINED_CATEGORY"], [2975, 3001, "TRAINED_CATEGORY"], [3008, 3020, "TRAINED_CATEGORY"], [3024, 3033, "TRAINED_CATEGORY"], [3059, 3062, "TRAINED_CATEGORY"], [3074, 3094, "TRAINED_CATEGORY"], [3098, 3104, "TRAINED_CATEGORY"], [3116, 3130, "TRAINED_CATEGORY"], [3132, 3140, "TRAINED_CATEGORY"], [3145, 3156, "TRAINED_CATEGORY"], [3158, 3164, "TRAINED_CATEGORY"], [3169, 3185, "TRAINED_CATEGORY"], [3190, 3211, "TRAINED_CATEGORY"], [3215, 3228, "TRAINED_CATEGORY"], [3235, 3242, "TRAINED_CATEGORY"], [3246, 3256, "TRAINED_CATEGORY"], [3276, 3289, "TRAINED_CATEGORY"], [3314, 3334, "TRAINED_CATEGORY"], [3354, 3370, "TRAINED_CATEGORY"], [3396, 3408, "TRAINED_CATEGORY"], [3410, 3423, "TRAINED_CATEGORY"], [3425, 3430, "TRAINED_CATEGORY"], [3435, 3440, "TRAINED_CATEGORY"], [3444, 3457, "TRAINED_CATEGORY"], [3469, 3485, "TRAINED_CATEGORY"], [3491, 3517, "TRAINED_CATEGORY"], [3519, 3522, "TRAINED_CATEGORY"], [3531, 3556, "TRAINED_CATEGORY"], [3592, 3607, "TRAINED_CATEGORY"], [3612, 3631, "TRAINED_CATEGORY"], [3635, 3647, "TRAINED_CATEGORY"], [3652, 3669, "TRAINED_CATEGORY"], [3673, 3675, "TRAINED_CATEGORY"], [3685, 3688, "TRAINED_CATEGORY"], [3724, 3726, "TRAINED_CATEGORY"], [3732, 3753, "TRAINED_CATEGORY"], [3755, 3767, "TRAINED_CATEGORY"], [3798, 3812, "TRAINED_CATEGORY"], [3816, 3827, "TRAINED_CATEGORY"], [3838, 3845, "TRAINED_CATEGORY"], [3852, 3856, "TRAINED_CATEGORY"], [3862, 3870, "TRAINED_CATEGORY"], [3875, 3888, "TRAINED_CATEGORY"], [3894, 3898, "TRAINED_CATEGORY"], [3905, 3922, "TRAINED_CATEGORY"], [3935, 3959, "TRAINED_CATEGORY"], [3973, 3984, "TRAINED_CATEGORY"], [3988, 4010, "TRAINED_CATEGORY"], [4016, 4021, "TRAINED_CATEGORY"], [4026, 4031, "TRAINED_CATEGORY"], [4049, 4062, "TRAINED_CATEGORY"], [4072, 4089, "TRAINED_CATEGORY"], [4116, 4131, "TRAINED_CATEGORY"], [4151, 4156, "TRAINED_CATEGORY"], [4160, 4168, "TRAINED_CATEGORY"], [4170, 4183, "TRAINED_CATEGORY"], [4185, 4190, "TRAINED_CATEGORY"], [4196, 4201, "TRAINED_CATEGORY"], [4217, 4233, "TRAINED_CATEGORY"], [4237, 4246, "TRAINED_CATEGORY"], [4252, 4263, "TRAINED_CATEGORY"], [4275, 4289, "TRAINED_CATEGORY"], [4293, 4309, "TRAINED_CATEGORY"], [4311, 4321, "TRAINED_CATEGORY"], [4327, 4341, "TRAINED_CATEGORY"], [4372, 4395, "TRAINED_CATEGORY"], [4416, 4431, "TRAINED_CATEGORY"], [4435, 4444, "TRAINED_CATEGORY"], [4456, 4459, "TRAINED_CATEGORY"], [4484, 4496, "TRAINED_CATEGORY"], [4501, 4515, "TRAINED_CATEGORY"], [4519, 4535, "TRAINED_CATEGORY"], [4548, 4556, "TRAINED_CATEGORY"], [4563, 4582, "TRAINED_CATEGORY"], [4596, 4612, "TRAINED_CATEGORY"], [4617, 4634, "TRAINED_CATEGORY"], [4639, 4663, "TRAINED_CATEGORY"], [4669, 4691, "TRAINED_CATEGORY"], [4695, 4707, "TRAINED_CATEGORY"], [4719, 4741, "TRAINED_CATEGORY"], [4745, 4753, "TRAINED_CATEGORY"], [4757, 4778, "TRAINED_CATEGORY"], [4784, 4798, "TRAINED_CATEGORY"], [4811, 4815, "TRAINED_CATEGORY"], [4829, 4872, "TRAINED_CATEGORY"], [4874, 4882, "TRAINED_CATEGORY"], [4897, 4906, "TRAINED_CATEGORY"], [4910, 4921, "TRAINED_CATEGORY"], [4922, 4936, "TRAINED_CATEGORY"], [4947, 4949, "TRAINED_CATEGORY"], [4961, 4973, "TRAINED_CATEGORY"], [4974, 4977, "TRAINED_CATEGORY"], [4996, 5008, "TRAINED_CATEGORY"], [5012, 5024, "TRAINED_CATEGORY"], [5028, 5035, "TRAINED_CATEGORY"], [5049, 5072, "TRAINED_CATEGORY"], [5074, 5088, "TRAINED_CATEGORY"], [5093, 5101, "TRAINED_CATEGORY"], [5107, 5114, "TRAINED_CATEGORY"], [5118, 5129, "TRAINED_CATEGORY"], [5154, 5168, "TRAINED_CATEGORY"], [5173, 5181, "TRAINED_CATEGORY"], [5183, 5192, "TRAINED_CATEGORY"], [5241, 5257, "TRAINED_CATEGORY"], [5262, 5290, "TRAINED_CATEGORY"], [5295, 5314, "TRAINED_CATEGORY"], [5320, 5342, "TRAINED_CATEGORY"], [5354, 5369, "TRAINED_CATEGORY"], [5384, 5396, "TRAINED_CATEGORY"], [5400, 5409, "TRAINED_CATEGORY"], [5410, 5414, "TRAINED_CATEGORY"], [5432, 5448, "TRAINED_CATEGORY"], [5452, 5464, "TRAINED_CATEGORY"], [5484, 5492, "TRAINED_CATEGORY"], [5513, 5520, "TRAINED_CATEGORY"], [5531, 5555, "TRAINED_CATEGORY"], [5556, 5570, "TRAINED_CATEGORY"], [5584, 5606, "TRAINED_CATEGORY"], [5610, 5620, "TRAINED_CATEGORY"], [5624, 5648, "TRAINED_CATEGORY"], [5652, 5667, "TRAINED_CATEGORY"], [5684, 5695, "TRAINED_CATEGORY"], [5699, 5711, "TRAINED_CATEGORY"], [5719, 5731, "TRAINED_CATEGORY"], [5756, 5771, "TRAINED_CATEGORY"], [5775, 5787, "TRAINED_CATEGORY"], [5791, 5806, "TRAINED_CATEGORY"], [5807, 5811, "TRAINED_CATEGORY"], [5829, 5846, "TRAINED_CATEGORY"], [5854, 5862, "TRAINED_CATEGORY"], [5866, 5883, "TRAINED_CATEGORY"], [5885, 5901, "TRAINED_CATEGORY"], [5914, 5925, "TRAINED_CATEGORY"], [5927, 5930, "TRAINED_CATEGORY"], [5948, 5959, "TRAINED_CATEGORY"], [5963, 5967, "TRAINED_CATEGORY"], [5969, 5980, "TRAINED_CATEGORY"], [5984, 5992, "TRAINED_CATEGORY"], [6012, 6019, "TRAINED_CATEGORY"], [6031, 6046, "TRAINED_CATEGORY"], [6079, 6094, "TRAINED_CATEGORY"], [6095, 6097, "TRAINED_CATEGORY"], [6129, 6148, "TRAINED_CATEGORY"], [6152, 6164, "TRAINED_CATEGORY"], [6168, 6189, "TRAINED_CATEGORY"], [6193, 6197, "TRAINED_CATEGORY"], [6214, 6225, "TRAINED_CATEGORY"], [6229, 6241, "TRAINED_CATEGORY"], [6245, 6249, "TRAINED_CATEGORY"], [6260, 6272, "TRAINED_CATEGORY"], [6282, 6286, "TRAINED_CATEGORY"], [6306, 6313, "TRAINED_CATEGORY"], [6317, 6344, "TRAINED_CATEGORY"], [6346, 6365, "TRAINED_CATEGORY"], [6385, 6397, "TRAINED_CATEGORY"], [6401, 6432, "TRAINED_CATEGORY"], [6436, 6451, "TRAINED_CATEGORY"], [6481, 6493, "TRAINED_CATEGORY"], [6507, 6549, "TRAINED_CATEGORY"], [6559, 6579, "TRAINED_CATEGORY"], [6583, 6609, "TRAINED_CATEGORY"], [6631, 6633, "TRAINED_CATEGORY"], [6637, 6682, "TRAINED_CATEGORY"], [6688, 6690, "TRAINED_CATEGORY"], [6731, 6746, "TRAINED_CATEGORY"], [6759, 6769, "TRAINED_CATEGORY"], [6788, 6797, "TRAINED_CATEGORY"], [6801, 6809, "TRAINED_CATEGORY"], [6838, 6853, "TRAINED_CATEGORY"], [6857, 6867, "TRAINED_CATEGORY"], [6897, 6920, "TRAINED_CATEGORY"], [6924, 6936, "TRAINED_CATEGORY"], [6948, 6962, "TRAINED_CATEGORY"], [6966, 6978, "TRAINED_CATEGORY"], [6982, 6994, "TRAINED_CATEGORY"], [7033, 7049, "TRAINED_CATEGORY"], [7053, 7059, "TRAINED_CATEGORY"], [7064, 7084, "TRAINED_CATEGORY"], [7141, 7153, "TRAINED_CATEGORY"], [7164, 7184, "TRAINED_CATEGORY"], [7200, 7215, "TRAINED_CATEGORY"], [7219, 7234, "TRAINED_CATEGORY"], [7236, 7256, "TRAINED_CATEGORY"], [7268, 7282, "TRAINED_CATEGORY"], [7291, 7311, "TRAINED_CATEGORY"], [7329, 7345, "TRAINED_CATEGORY"], [7358, 7381, "TRAINED_CATEGORY"], [7395, 7422, "TRAINED_CATEGORY"], [7426, 7436, "TRAINED_CATEGORY"], [7440, 7461, "TRAINED_CATEGORY"], [7473, 7494, "TRAINED_CATEGORY"], [7507, 7522, "TRAINED_CATEGORY"], [7524, 7532, "TRAINED_CATEGORY"], [7534, 7535, "TRAINED_CATEGORY"], [7538, 7551, "TRAINED_CATEGORY"], [7553, 7554, "TRAINED_CATEGORY"], [7557, 7562, "TRAINED_CATEGORY"], [7563, 7565, "TRAINED_CATEGORY"], [7571, 7576, "TRAINED_CATEGORY"], [7578, 7579, "TRAINED_CATEGORY"], [7596, 7608, "TRAINED_CATEGORY"], [7626, 7641, "TRAINED_CATEGORY"], [7643, 7652, "TRAINED_CATEGORY"], [7663, 7675, "TRAINED_CATEGORY"], [7679, 7689, "TRAINED_CATEGORY"], [7713, 7722, "TRAINED_CATEGORY"], [7723, 7734, "TRAINED_CATEGORY"], [7739, 7752, "TRAINED_CATEGORY"], [7766, 7782, "TRAINED_CATEGORY"], [7784, 7806, "TRAINED_CATEGORY"], [7811, 7835, "TRAINED_CATEGORY"], [7842, 7852, "TRAINED_CATEGORY"], [7876, 7890, "TRAINED_CATEGORY"], [7912, 7922, "TRAINED_CATEGORY"], [7924, 7943, "TRAINED_CATEGORY"], [7962, 7986, "TRAINED_CATEGORY"], [7993, 8000, "TRAINED_CATEGORY"], [8010, 8019, "TRAINED_CATEGORY"], [8030, 8039, "TRAINED_CATEGORY"], [8044, 8054, "TRAINED_CATEGORY"], [8056, 8071, "TRAINED_CATEGORY"], [8077, 8094, "TRAINED_CATEGORY"], [8109, 8123, "TRAINED_CATEGORY"], [8125, 8134, "TRAINED_CATEGORY"], [8139, 8150, "TRAINED_CATEGORY"], [8156, 8173, "TRAINED_CATEGORY"], [8187, 8196, "TRAINED_CATEGORY"], [8200, 8209, "TRAINED_CATEGORY"], [8221, 8239, "TRAINED_CATEGORY"], [8244, 8260, "TRAINED_CATEGORY"], [8269, 8303, "TRAINED_CATEGORY"], [8316, 8331, "TRAINED_CATEGORY"], [8339, 8345, "TRAINED_CATEGORY"], [8357, 8373, "TRAINED_CATEGORY"], [8396, 8400, "TRAINED_CATEGORY"], [8414, 8435, "TRAINED_CATEGORY"], [8439, 8455, "TRAINED_CATEGORY"], [8461, 8477, "TRAINED_CATEGORY"], [8488, 8495, "TRAINED_CATEGORY"], [8499, 8517, "TRAINED_CATEGORY"], [8522, 8527, "TRAINED_CATEGORY"], [8533, 8540, "TRAINED_CATEGORY"], [8544, 8565, "TRAINED_CATEGORY"], [8570, 8583, "TRAINED_CATEGORY"], [8593, 8613, "TRAINED_CATEGORY"], [8617, 8634, "TRAINED_CATEGORY"], [8636, 8656, "TRAINED_CATEGORY"], [8694, 8703, "TRAINED_CATEGORY"], [8714, 8730, "TRAINED_CATEGORY"], [8744, 8751, "TRAINED_CATEGORY"], [8755, 8765, "TRAINED_CATEGORY"], [8775, 8784, "TRAINED_CATEGORY"], [8788, 8798, "TRAINED_CATEGORY"], [8803, 8819, "TRAINED_CATEGORY"], [8833, 8846, "TRAINED_CATEGORY"], [8854, 8863, "TRAINED_CATEGORY"], [8867, 8883, "TRAINED_CATEGORY"], [8901, 8911, "TRAINED_CATEGORY"], [8936, 8959, "TRAINED_CATEGORY"], [8963, 8983, "TRAINED_CATEGORY"], [8988, 9004, "TRAINED_CATEGORY"], [9023, 9049, "TRAINED_CATEGORY"], [9050, 9058, "TRAINED_CATEGORY"], [9082, 9090, "TRAINED_CATEGORY"], [9091, 9093, "TRAINED_CATEGORY"], [9094, 9106, "TRAINED_CATEGORY"], [9107, 9110, "TRAINED_CATEGORY"], [9114, 9134, "TRAINED_CATEGORY"], [9135, 9167, "TRAINED_CATEGORY"], [9168, 9187, "TRAINED_CATEGORY"], [9188, 9198, "TRAINED_CATEGORY"], [9199, 9214, "TRAINED_CATEGORY"], [9220, 9230, "TRAINED_CATEGORY"], [9239, 9253, "TRAINED_CATEGORY"], [9257, 9289, "TRAINED_CATEGORY"], [9294, 9301, "TRAINED_CATEGORY"], [30, 33, "ORG"], [93, 96, "ORG"], [140, 143, "ORG"], [251, 254, "ORG"], [480, 483, "ORG"], [827, 830, "ORG"], [1135, 1145, "CARDINAL"], [1201, 1204, "ORG"], [1209, 1212, "ORG"], [1280, 1283, "ORG"], [1445, 1448, "ORG"], [1633, 1636, "ORG"], [1682, 1685, "ORG"], [1971, 1974, "ORG"], [2126, 2129, "ORG"], [2324, 2327, "ORG"], [2353, 2361, "CARDINAL"], [2467, 2472, "WORK_OF_ART"], [2514, 2529, "CARDINAL"], [2691, 2752, "EVENT"], [2825, 2828, "ORG"], [2880, 2883, "ORG"], [2910, 2913, "ORG"], [2968, 2971, "CARDINAL"], [3358, 3362, "CARDINAL"], [3383, 3386, "CARDINAL"], [3596, 3600, "CARDINAL"], [3673, 3675, "PERCENT"], [5266, 5270, "CARDINAL"], [6033, 6038, "ORDINAL"], [6462, 6466, "CARDINAL"], [6709, 6712, "CARDINAL"], [6788, 6791, "CARDINAL"], [6831, 6836, "ORDINAL"], [7025, 7031, "ORDINAL"], [7133, 7136, "CARDINAL"], [7511, 7515, "CARDINAL"], [7596, 7600, "CARDINAL"], [7610, 7613, "CARDINAL"], [7630, 7634, "CARDINAL"], [7723, 7734, "ORG"], [7770, 7774, "CARDINAL"], [8320, 8324, "CARDINAL"], [8361, 8365, "CARDINAL"], [8443, 8447, "CARDINAL"], [9135, 9140, "ORG"], [9199, 9214, "PERSON"], [9239, 9247, "ORG"], [9298, 9301, "ORG"]]}], ["In social choice theory, Arrow's impossibility theorem, the general possibility theorem or Arrow's paradox is an impossibility theorem stating that when voters have three or more distinct alternatives (options), no ranked voting electoral system can convert the ranked preferences of individuals into a community-wide (complete and transitive) ranking while also meeting a specified set of criteria: unrestricted domain, non-dictatorship, Pareto efficiency, and independence of irrelevant alternatives. The theorem is often cited in discussions of voting theory as it is further interpreted by the Gibbard\u2013Satterthwaite theorem. The theorem is named after economist and Nobel laureate Kenneth Arrow, who demonstrated the theorem in his doctoral thesis and popularized it in his 1951 book Social Choice and Individual Values.  The original paper was titled \"A Difficulty in the Concept of Social Welfare\".In short, the theorem states that no rank-order electoral system can be designed that always satisfies these three \"fairness\" criteria:\n\nIf every voter prefers alternative X over alternative Y, then the group prefers X over Y.\nIf every voter's preference between X and Y remains unchanged, then the group's preference between X and Y will also remain unchanged (even if voters' preferences between other pairs like X and Z, Y and Z, or Z and W change).\nThere is no \"dictator\": no single voter possesses the power to always determine the group's preference.Cardinal voting electoral systems are not covered by the theorem, as they convey more information than rank orders. However, Gibbard's theorem extends Arrow's theorem for that case. The theorem can also be sidestepped by weakening the notion of independence.The axiomatic approach Arrow adopted can treat all conceivable rules (that are based on preferences) within one unified framework. In that sense, the approach is qualitatively different from the earlier one in voting theory, in which rules were investigated one by one. One can therefore say that the contemporary paradigm of social choice theory started from this theorem.The practical consequences of the theorem are debatable: Arrow has said \"Most systems are not going to work badly all of the time. All I proved is that all can work badly at times.\"\n\n\n== Statement of the theorem ==\nThe need to aggregate preferences occurs in many disciplines: in welfare economics, where one attempts to find an economic outcome which would be acceptable and stable; in decision theory, where a person has to make a rational choice based on several criteria; and most naturally in electoral systems, which are mechanisms for extracting a governance-related decision from a multitude of voters' preferences.\nThe framework for Arrow's theorem assumes that we need to extract a preference order on a given set of options (outcomes). Each individual in the society (or equivalently, each decision criterion) gives a particular order of preferences on the set of outcomes. We are searching for a ranked voting electoral system, called a social welfare function (preference aggregation rule), which transforms the set of preferences (profile of preferences) into a single global societal preference order. Arrow's theorem says that if the decision-making body has at least two members and at least three options to decide among, then it is impossible to design a social welfare function that satisfies all these conditions (assumed to be a reasonable requirement of a fair electoral system) at once:\n\nNon-dictatorship\nThe social welfare function should account for the wishes of multiple voters. It cannot simply mimic the preferences of a single voter.\nUnrestricted domain, or universality\nFor any set of individual voter preferences, the social welfare function should yield a unique and complete ranking of societal choices. Thus:\nIndependence of irrelevant alternatives (IIA)\nThe social preference between x and y should depend only on the individual preferences between x and y (pairwise independence). More generally, changes in individuals' rankings of irrelevant alternatives (ones outside a certain subset) should have no impact on the societal ranking of the subset. For example, if candidate x ranks socially before candidate y, then x should rank socially before y even if a third candidate z is removed from participation. (See Remarks below.)\nMonotonicity, or positive association of social and individual values\nIf any individual modifies his or her preference order by promoting a certain option, then the societal preference order should respond only by promoting that same option or not changing, never by placing it lower than before. An individual should not be able to hurt an option by ranking it higher.\nNon-imposition, or citizen sovereignty\nEvery possible societal preference order should be achievable by some set of individual preference orders. This means that the social welfare function is surjective: It has an unrestricted target space.A later (1963) version of Arrow's theorem replaced the monotonicity and non-imposition criteria with:\n\nPareto efficiency, or unanimity\nIf every individual prefers a certain option to another, then so must the resulting societal preference order. This, again, is a demand that the social welfare function will be minimally sensitive to the preference profile.This later version is more general, having weaker conditions. The axioms of monotonicity, non-imposition, and IIA together imply Pareto efficiency, whereas Pareto efficiency (itself implying non-imposition) and IIA together do not imply monotonicity.\n\n\n=== Independence of irrelevant alternatives (IIA) ===\nThe IIA condition has three purposes (or effects):\nNormative\nIrrelevant alternatives should not matter.\nPractical\nUse of minimal information.\nStrategic\nProviding the right incentives for the truthful revelation of individual preferences. Though the strategic property is conceptually different from IIA, it is closely related.Arrow's death-of-a-candidate example (1963, page 26) suggests that the agenda (the set of feasible alternatives) shrinks from, say, X = {a, b, c} to S = {a, b} because of the death of candidate c. This example is misleading since it can give the reader an impression that IIA is a condition involving two agenda and one profile. The fact is that IIA involves just one agendum ({x, y} in case of pairwise independence) but two profiles. If the condition is applied to this confusing example, it requires this: Suppose an aggregation rule satisfying IIA chooses b from the agenda {a, b} when the profile is given by (cab, cba), that is, individual 1 prefers c to a to b, 2 prefers c to b to a. Then, it must still choose b from {a, b} if the profile were, say: (abc, bac); (acb, bca); (acb, cba); or (abc, cba).\nIn different words, Arrow defines IIA as saying that the social preferences between alternatives x and y depend only on the individual preferences between x and y (not on those involving other candidates).\n\n\n== Formal statement of the theorem ==\nLet A be a set of outcomes, N a number of voters or decision criteria. We shall denote the set of all full linear orderings of A by L(A).\nA (strict) social welfare function (preference aggregation rule) is a function\n\n  \n    \n      \n        F\n        :\n        \n          \n            L\n            (\n            A\n            )\n          \n          \n            N\n          \n        \n        \u2192\n        \n          L\n          (\n          A\n          )\n        \n      \n    \n    {\\displaystyle F:\\mathrm {L(A)} ^{N}\\to \\mathrm {L(A)} }\n  which aggregates voters' preferences into a single preference order on A.An N-tuple (R1, \u2026, RN) \u2208 L(A)N of voters' preferences is called a preference profile.  In its strongest and simplest form, Arrow's impossibility theorem states that whenever the set A of possible alternatives has more than 2 elements, then the following three conditions become incompatible:\n\nUnanimity, or weak Pareto efficiency\nIf alternative, a, is ranked strictly higher than b for all orderings R1 , \u2026, RN, then a is ranked strictly higher than b by F(R1, R2, \u2026, RN). (Unanimity implies non-imposition.)\nNon-dictatorship\nThere is no individual, i whose strict preferences always prevail. That is, there is no i \u2208 {1, \u2026, N}  such that for all (R1, \u2026, RN) \u2208 L(A)N, a ranked strictly higher than b by Ri implies a ranked strictly higher than b by F(R1, R2, \u2026, RN), for all a and b.\nIndependence of irrelevant alternatives\nFor two preference profiles (R1, \u2026, RN) and (S1, \u2026, SN) such that for all individuals i, alternatives a and b have the same order in Ri as in Si, alternatives a and b have the same order in F(R1, \u2026, RN) as in F(S1, \u2026, SN).\n\n\n== Informal proof ==\nBased on two proofs appearing in Economic Theory.  For simplicity we have presented all rankings as if ties are impossible.  A complete proof taking possible ties into account is not essentially different from the one given here, except that one ought to say \"not above\" instead of \"below\" or \"not below\" instead of \"above\" in some cases.  Full details are given in the original articles.\nWe will prove that any social choice system respecting unrestricted domain, unanimity, and independence of irrelevant alternatives (IIA) is a dictatorship.  The key idea is to identify a pivotal voter whose ballot swings the societal outcome.  We then prove that this voter is a partial dictator (in a specific technical sense, described below).  Finally we conclude by showing that all of the partial dictators are the same person, hence this voter is a dictator.\n\n\n=== Part one: There is a \"pivotal\" voter for B over A ===\n\nSay there are three choices for society, call them A, B, and C.  Suppose first that everyone prefers option B the least: everyone prefers  A to B, and everyone prefers C to B.  By unanimity, society must also prefer both A and C to B.  Call this situation profile 0.\nOn the other hand, if everyone preferred B to everything else, then society would have to prefer B to everything else by unanimity.  Now arrange all the voters in some arbitrary but fixed order, and for each i let profile i be the same as profile 0, but move B to the top of the ballots for voters 1 through i.  So profile 1 has B at the top of the ballot for voter 1, but not for any of the others.  Profile 2 has B at the top for voters 1 and 2, but no others, and so on.\nSince B eventually moves to the top of the societal preference, there must be some profile, number k, for which B moves above A in the societal rank.  We call the voter whose ballot change causes this to happen the pivotal voter for B over A.  Note that the pivotal voter for B over A is not, a priori, the same as the pivotal voter for A over B.  In part three of the proof we will show that these do turn out to be the same.\nAlso note that by IIA the same argument applies if profile 0 is any profile in which A is ranked above B by every voter, and the pivotal voter for B over A will still be voter k.  We will use this observation below.\n\n\n=== Part two: The pivotal voter for B over A is a dictator for B over C ===\nIn this part of the argument we refer to voter k, the pivotal voter for B over A, as pivotal voter for simplicity.  We will show that pivotal voter dictates society's decision for B over C.  That is, we show that no matter how the rest of society votes, if Pivotal Voter ranks B over C, then that is the societal outcome.  Note again that the dictator for B over C is not a priori the same as that for C over B.  In part three of the proof we will see that these turn out to be the same too.\n\nIn the following, we call voters 1 through k \u2212 1, segment one, and voters k + 1 through N, segment two.  To begin, suppose that the ballots are as follows:\n\nEvery voter in segment one ranks B above C and C above A.\nPivotal voter ranks A above B and B above C.\nEvery voter in segment two ranks A above B and B above C.Then by the argument in part one (and the last observation in that part), the societal outcome must rank A above B.  This is because, except for a repositioning of C, this profile is the same as profile k \u2212 1 from part one.  Furthermore, by unanimity the societal outcome must rank B above C.  Therefore, we know the outcome in this case completely.\nNow suppose that pivotal voter moves B above A, but keeps C in the same position and imagine that any number (or all!) of the other voters change their ballots to move B below C, without changing the position of A.    Then aside from a repositioning of C this is the same as profile k from part one and hence the societal outcome ranks B above A.  Furthermore, by IIA the societal outcome must rank A above C, as in the previous case.  In particular, the societal outcome ranks B above C, even though Pivotal Voter may have been the only voter to rank B above C.  By IIA, this conclusion holds independently of how A is positioned on the ballots, so pivotal voter is a dictator for B over C.\n\n\n=== Part three: There exists a dictator ===\n\nIn this part of the argument we refer back to the original ordering of voters, and compare the positions of the different pivotal voters (identified by applying parts one and two to the other pairs of candidates).  First, the pivotal voter for B over C must appear earlier (or at the same position) in the line than the dictator for B over C:  As we consider the argument of part one applied to B and C, successively moving B to the top of voters' ballots, the pivot point where society ranks B above C must come at or before we reach the dictator for B over C.  Likewise, reversing the roles of B and C, the pivotal voter for C over B must be at or later in line than the dictator for B over C.  In short, if kX/Y denotes the position of the pivotal voter for X over Y (for any two candidates X and Y), then we have shown\n\nkB/C \u2264 kB/A \u2264 kC/B.Now repeating the entire argument above with B and C switched, we also have\n\nkC/B \u2264 kB/C.Therefore, we have\n\nkB/C = kB/A = kC/Band the same argument for other pairs shows that all the pivotal voters (and hence all the dictators) occur at the same position in the list of voters.  This voter is the dictator for the whole election.\n\n\n== Interpretations of the theorem ==\nAlthough Arrow's theorem is a mathematical result, it is often expressed in a non-mathematical way with a statement such as no voting method is fair, every ranked voting method is flawed, or the only voting method that isn't flawed is a dictatorship. These statements are simplifications of Arrow's result which are not universally considered to be true. What Arrow's theorem does state is that a deterministic preferential voting mechanism\u2014that is, one where a preference order is the only information in a vote, and any possible set of votes gives a unique result\u2014cannot comply with all of the conditions given above simultaneously.\nVarious theorists have suggested weakening the IIA criterion as a way out of the paradox. Proponents of ranked voting methods contend that the IIA is an unreasonably strong criterion.  It is the one breached in most useful electoral systems. Advocates of this position point out that failure of the standard IIA criterion is trivially implied by the possibility of cyclic preferences. If voters cast ballots as follows:\n\n1 vote for A > B > C\n1 vote for B > C > A\n1 vote for C > A > Bthen the pairwise majority preference of the group is that A wins over B, B wins over C, and C wins over A: these yield rock-paper-scissors preferences for any pairwise comparison.  In this circumstance, any aggregation rule that satisfies the very basic majoritarian requirement that a candidate who receives a majority of votes must win the election, will fail the IIA criterion, if social preference is required to be transitive (or acyclic).  To see this, suppose that such a rule satisfies IIA.  Since majority preferences are respected, the society prefers A to B (two votes for A > B and one for B > A), B to C, and C to A.  Thus a cycle is generated, which contradicts the assumption that social preference is transitive.\nSo, what Arrow's theorem really shows is that any majority-wins electoral system is a non-trivial game, and that game theory should be used to predict the outcome of most voting mechanisms. This could be seen as a discouraging result, because a game need not have efficient equilibria; e.g., a ballot could result in an alternative nobody really wanted in the first place, yet everybody voted for.\n\n\n=== Remark: Scalar rankings from a vector of attributes and the IIA property ===\nThe IIA property might not be satisfied in human decision-making of realistic  complexity because the scalar preference ranking is effectively derived from the weighting\u2014not usually explicit\u2014of a vector of attributes (one book dealing with the Arrow theorem invites the reader to consider the related problem of creating a scalar measure for the track and field decathlon event\u2014e.g. how does one make scoring 600 points in the discus event \"commensurable\" with scoring 600 points in the 1500 m race) and this scalar ranking can depend sensitively on the weighting of different attributes, with the tacit weighting itself affected by the context and contrast created by apparently \"irrelevant\" choices.  Edward MacNeal discusses this sensitivity problem with respect to the ranking of \"most livable city\" in the chapter \"Surveys\" of his book MathSemantics: making numbers talk sense (1994).\n\n\n== Other possibilities ==\nIn an attempt to escape from the negative conclusion of Arrow's theorem, social choice theorists have investigated various possibilities (\"ways out\"). These investigations can be divided into the following two:\n\nthose investigating functions whose domain, like that of Arrow's social welfare functions, consists of profiles of preferences;\nthose investigating other kinds of rules.\n\n\n=== Approaches investigating functions of preference profiles ===\nThis section includes approaches that deal with\n\naggregation rules (functions that map each preference profile into a social preference), and\nother functions, such as functions that map each preference profile into an alternative.Since these two approaches often overlap, we discuss them at the same time. What is characteristic of these approaches is that they investigate various possibilities by eliminating or weakening or replacing one or more conditions (criteria) that Arrow imposed.\n\n\n==== Infinitely many individuals ====\nSeveral theorists (e.g., Kirman and Sondermann) point out that when one drops the assumption that there are only finitely many individuals, one can find aggregation rules that satisfy all of Arrow's other conditions.\nHowever, such aggregation rules are practically of limited interest, since they are based on ultrafilters, highly non-constructive mathematical objects. In particular, Kirman and Sondermann argue that there is an \"invisible dictator\" behind such a rule. Mihara shows that such a rule violates algorithmic computability. These results can be seen to establish the robustness of Arrow's theorem.\n\n\n==== Limiting the number of alternatives ====\nWhen there are only two alternatives to choose from, May's theorem shows that only simple majority rule satisfies a certain set of criteria (e.g., equal treatment of individuals and of alternatives; increased support for a winning alternative should not make it into a losing one). On the other hand, when there are at least three alternatives, Arrow's theorem points out the difficulty of collective decision making. Why is there such a sharp difference between the case of less than three alternatives and that of at least three alternatives?\nNakamura's theorem (about the core of simple games) gives an answer more generally. It establishes that if the number of alternatives is less than a certain integer called the Nakamura number, then the rule in question will identify \"best\" alternatives without any problem; if the number of alternatives is greater or equal to the Nakamura number, then the rule will not always work, since for some profile a voting paradox (a cycle such as alternative A socially preferred to alternative B, B to C, and C to A) will arise. Since the Nakamura number of majority rule is 3 (except the case of four individuals), one can conclude from Nakamura's theorem that majority rule can deal with up to two alternatives rationally. Some super-majority rules (such as those requiring 2/3 of the votes) can have a Nakamura number greater than 3, but such rules violate other conditions given by Arrow.\n\n\n==== Pairwise voting ====\nA common way \"around\" Arrow's paradox is limiting the alternative set to two alternatives. Thus, whenever more than two alternatives should be put to the test, it seems very tempting to use a mechanism that pairs them and votes by pairs. As tempting as this mechanism seems at first glance, it is generally far from satisfying even Pareto efficiency, not to mention IIA. The specific order by which the pairs are decided strongly influences the outcome. This is not necessarily a bad feature of the mechanism. Many sports use the tournament mechanism\u2014essentially a pairing mechanism\u2014to choose a winner.  This gives considerable opportunity for weaker teams to win, thus adding interest and tension throughout the tournament. This means that the person controlling the order by which the choices are paired (the agenda maker) has great control over the outcome. In any case, when viewing the entire voting process as one game, Arrow's theorem still applies.\n\n\n==== Domain restrictions ====\nAnother approach is relaxing the universality condition, which means restricting the domain of aggregation rules. The best-known result along this line assumes \"single peaked\" preferences.\nDuncan Black has shown that if there is only one dimension on which every individual has a \"single-peaked\" preference, then all of Arrow's conditions are met by majority rule. Suppose that there is some predetermined linear ordering of the alternative set. An individual's preference is single-peaked with respect to this ordering if he has some special place that he likes best along that line, and his dislike for an alternative grows larger as the alternative goes further away from that spot (i.e., the graph of his utility function has a single peak if alternatives are placed according to the linear ordering on the horizontal axis).  For example, if voters were voting on where to set the volume for music, it would be reasonable to assume that each voter had their own ideal volume preference and that as the volume got progressively too loud or too quiet they would be increasingly dissatisfied.\nIf the domain is restricted to profiles in which every individual has a single peaked preference with respect to the linear ordering, then simple aggregation rules, which include majority rule, have an acyclic (defined below) social preference, hence \"best\" alternative. In particular, when there are odd number of individuals, then the social preference becomes transitive, and the socially \"best\" alternative is equal to the median of all the peaks of the individuals (Black's median voter theorem). Under single-peaked preferences, the majority rule is in some respects the most natural voting mechanism.\nOne can define the notion of \"single-peaked\" preferences on higher-dimensional sets of alternatives. However, one can identify the \"median\" of the peaks only in exceptional cases. Instead, we typically have the destructive situation suggested by McKelvey's Chaos Theorem: for any x and y, one can find a sequence of alternatives such that x is beaten by x1 by a majority, x1 by x2, up to xk by y.\n\n\n==== Relaxing transitivity ====\nBy relaxing the transitivity of social preferences, we can find aggregation rules that satisfy Arrow's other conditions. If we impose neutrality (equal treatment of alternatives) on such rules, however, there exists an individual who has a \"veto\". So the possibility provided by this approach is also very limited.\nFirst, suppose that a social preference is quasi-transitive (instead of transitive); this means that the strict preference \n  \n    \n      \n        \u227b\n      \n    \n    {\\displaystyle \\succ }\n   (\"better than\") is transitive: if \n  \n    \n      \n        x\n        \u227b\n        y\n      \n    \n    {\\displaystyle x\\succ y}\n   and \n  \n    \n      \n        y\n        \u227b\n        z\n      \n    \n    {\\displaystyle y\\succ z}\n  , then \n  \n    \n      \n        x\n        \u227b\n        z\n      \n    \n    {\\displaystyle x\\succ z}\n  . Then, there do exist non-dictatorial aggregation rules satisfying Arrow's conditions, but such rules are oligarchic. This means that there exists a coalition L such that L is decisive (if every member in L prefers x to y, then the society prefers x to y), and each member in L has a veto (if she prefers x to y, then the society cannot prefer y to x).\nSecond, suppose that a social preference is acyclic (instead of transitive): there do not exist alternatives \n  \n    \n      \n        \n          x\n          \n            1\n          \n        \n        ,\n        \u2026\n        ,\n        \n          x\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle x_{1},\\ldots ,x_{k}}\n   that form a cycle (\n  \n    \n      \n        \n          x\n          \n            1\n          \n        \n        \u227b\n        \n          x\n          \n            2\n          \n        \n        ,\n        \n        \n          x\n          \n            2\n          \n        \n        \u227b\n        \n          x\n          \n            3\n          \n        \n        ,\n        \n        \u2026\n        ,\n        \n        \n          x\n          \n            k\n            \u2212\n            1\n          \n        \n        \u227b\n        \n          x\n          \n            k\n          \n        \n        ,\n        \n        \n          x\n          \n            k\n          \n        \n        \u227b\n        \n          x\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle x_{1}\\succ x_{2},\\;x_{2}\\succ x_{3},\\;\\ldots ,\\;x_{k-1}\\succ x_{k},\\;x_{k}\\succ x_{1}}\n  ). Then, provided that there are at least as many alternatives as individuals, an aggregation rule satisfying Arrow's other conditions is collegial. This means that there are individuals who belong to the intersection (\"collegium\") of all decisive coalitions. If there is someone who has a veto, then he belongs to the collegium. If the rule is assumed to be neutral, then it does have someone who has a veto.\nFinally, Brown's theorem left open the case of acyclic social preferences where the number of alternatives is less than the number of individuals. One can give a definite answer for that case using the Nakamura number.  See limiting the number of alternatives.\n\n\n==== Relaxing IIA ====\nThere are numerous examples of aggregation rules satisfying Arrow's conditions except IIA. The Borda rule is one of them. These rules, however, are susceptible to strategic manipulation by individuals.See also Interpretations of the theorem above.\n\n\n==== Relaxing the Pareto criterion ====\nWilson (1972) shows that if an aggregation rule is non-imposed and non-null, then there is either a dictator or an inverse dictator, provided that Arrow's conditions other than Pareto are also satisfied. Here, an inverse dictator is an individual i such that whenever i prefers x to y, then the society prefers y to x.\n\n\n===== Remark =====\nAmartya Sen offered both relaxation of transitivity and removal of the Pareto principle. He demonstrated another interesting impossibility result, known as the \"impossibility of the Paretian Liberal\" (see liberal paradox for details). Sen went on to argue that this demonstrates the futility of demanding Pareto optimality in relation to voting mechanisms.\n\n\n==== Social choice instead of social preference ====\nIn social decision making, to rank all alternatives is not usually a goal.  It often suffices to find some alternative. The approach focusing on choosing an alternative investigates either social choice functions (functions that map each preference profile into an alternative) or social choice rules (functions that map each preference profile into a subset of alternatives).\nAs for social choice functions, the Gibbard\u2013Satterthwaite theorem is well-known, which states that if a social choice function whose range contains at least three alternatives is strategy-proof, then it is dictatorial.\nAs for social choice rules, we should assume there is a social preference behind them. That is, we should regard a rule as choosing the maximal elements (\"best\" alternatives) of some social preference. The set of maximal elements of a social preference is called the core. Conditions for existence of an alternative in the core have been investigated in two approaches. The first approach assumes that preferences are at least acyclic (which is necessary and sufficient for the preferences to have a maximal element on any finite subset).  For this reason, it is closely related to relaxing transitivity. The second approach drops the assumption of acyclic preferences. Kumabe and Mihara adopt this approach. They make a more direct assumption that individual preferences have maximal elements, and examine conditions for the social preference to have a maximal element. See Nakamura number for details of these two approaches.\n\n\n=== Rated electoral system and other approaches ===\nArrow originally rejected cardinal utility as a meaningful tool for expressing social welfare, and so focused his theorem on preference rankings, but later stated that a cardinal score system with three or four classes \"is probably the best\".Arrow's framework assumes that individual and social preferences are \"orderings\" (i.e., satisfy completeness and transitivity) on the set of alternatives. This means that if the preferences are represented by a utility function, its value is an ordinal utility in the sense that it is meaningful so far as the greater value indicates the better alternative. For instance, having ordinal utilities of 4, 3, 2, 1 for alternatives a, b, c, d, respectively, is the same as having 1000, 100.01, 100, 0, which in turn is the same as having 99, 98, 1, .997. They all represent the ordering in which a is preferred to b to c to d. The assumption of ordinal preferences, which precludes interpersonal comparisons of utility, is an integral part of Arrow's theorem.\nFor various reasons, an approach based on cardinal utility, where the utility has a meaning beyond just giving a ranking of alternatives, is not common in contemporary economics. However, once one adopts that approach, one can take intensities of preferences into consideration, or one can compare (i) gains and losses of utility or (ii) levels of utility, across different individuals. In particular, Harsanyi (1955) gives a justification of utilitarianism (which evaluates alternatives in terms of the sum of individual utilities), originating from Jeremy Bentham. Hammond (1976) gives a justification of the maximin principle (which evaluates alternatives in terms of the utility of the worst-off individual), originating from John Rawls.\nNot all voting methods use, as input, only an ordering of all candidates. Methods which don't, often called \"rated\" or \"cardinal\" (as opposed to \"ranked\", \"ordinal\", or \"preferential\") electoral system, can be viewed as using information that only cardinal utility can convey. In that case, it is not surprising if some of them satisfy all of Arrow's conditions that are reformulated.Range voting is such a method.\nWhether such a claim is correct depends on how each condition is reformulated. Other rated electoral system which pass certain generalizations of Arrow's criteria include approval voting and majority judgment. Note that Arrow's theorem does not apply to single-winner methods such as these, but Gibbard's theorem still does: no non-defective electoral system is fully strategy-free, so the informal dictum that \"no electoral system is perfect\" still has a mathematical basis.Finally, though not an approach investigating some kind of rules, there is a criticism by James M. Buchanan, Charles Plott, and others. It argues that it is silly to think that there might be social preferences that are analogous to individual preferences. Arrow (1963, Chapter 8) answers this sort of criticism seen in the early period, which come at least partly from misunderstanding.\nA multi-pronged refutation of Arrow's theorem was published by philosophy Professor Howard DeLong in 1991. He challenges the theorem on the basis that Arrow wrongly assumes Preference is transitive property and that Collective Preference is the same as summing up individual preferences.   He also claims that Arrow's model fails to model democracy as it exists in the real world as the model ignores the possibility of consensual temporary dictatorships (i.e.: Greek tyrants in times of war)  and the effect of allowing lotteries to decide tie breakers and to avoid the problem of the tyranny of the majority, the example used being a group of campers at a summer camp, 8 of whom prefer cake, 7 who prefer ice cream, but funds are limited to one choice or the other on a weekly basis. Under the collective preference of majority rule each week the group would select cake.  By drawing lots the choices would more accurately reflect the preferences of the collective than the majority.\n\n\n== See also ==\n\nHolmstr\u00f6m's theorem\nMarket failure\nVoting paradox\nComparison of electoral systems\n\n\n== Notes ==\n\n\n== References ==\nArrow, Kenneth J. (1950). \"A Difficulty in the Concept of Social Welfare\" (PDF). Journal of Political Economy. 58 (4): 328\u2013346. doi:10.1086/256963. JSTOR 1828886. Archived from the original (PDF) on 2011-07-20.CS1 maint: ref=harv (link)\nArrow, Kenneth J.; Sen, Amartya K.; Suzumura, K\u014dtar\u014d, eds. (2002). Handbook of social choice and welfare. 1. Amsterdam, Netherlands: Elsevier. ISBN 978-0-444-82914-6.CS1 maint: ref=harv (link)\nCampbell, D. E.; Kelly, J. S. \"Impossibility theorems in the Arrovian framework\". In Arrow, Sen & Suzumura (2002, pp. 35\u201394).   Surveys many of approaches discussed in #Approaches investigating functions of preference profiles.\nGeanakoplos, John (2005). \"Three Brief Proofs of Arrow's Impossibility Theorem\" (PDF). Economic Theory. 26 (1): 211\u2013215. CiteSeerX 10.1.1.193.6817. doi:10.1007/s00199-004-0556-7. JSTOR 25055941.CS1 maint: ref=harv (link).\nHunt, Earl (2007). The Mathematics of Behavior. Cambridge University Press. ISBN 9780521850124.. The chapter \"Defining Rationality: Personal and Group Decision Making\" has a detailed discussion of the Arrow Theorem, with proof.\nLewis, Harold W. (1997). Why flip a coin? : The art and science of good decisions. John Wiley.  Gives explicit examples of preference rankings and apparently anomalous results under different electoral system.  States but does not prove Arrow's theorem. ISBN 0-471-29645-7\nSen, A. K. (1979). \"Personal utilities and public judgements: or what's wrong with welfare economics?\". The Economic Journal. 89 (355): 537\u2013558. doi:10.2307/2231867. JSTOR 2231867, arguing that Arrow's theorem was wrong because it did not incorporate non-utility information and the utility information it did allow was impoverished\nSen, Amartya Kumar (1979). Collective choice and social welfare. Amsterdam: North-Holland. ISBN 978-0-444-85127-7.CS1 maint: ref=harv (link)\nTaylor, Alan D. (2005). Social choice and the mathematics of manipulation. New York: Cambridge University Press. ISBN 978-0-521-00883-9.CS1 maint: ref=harv (link)\nYu, Ning Neil (2012). \"A one-shot proof of Arrow's theorem\". Economic Theory. 50 (2): 523\u2013525. doi:10.1007/s00199-012-0693-3. JSTOR 41486021.CS1 maint: ref=harv (link)preprint.\n\n\n== External links ==\nArrow's impossibility theorem entry  in the Stanford Encyclopedia of Philosophy\nA proof by Terence Tao, assuming a much stronger version of non-dictatorship\nDardanoni, Valentino (2001). \"A pedagogical proof of Arrow's Impossibility Theorem\" (PDF). Social Choice and Welfare. 18 (1): 107\u2013112. doi:10.1007/s003550000062. JSTOR 41106398. preprint.\nHansen, Paul (2002). \"Another Graphical Proof of Arrow's Impossibility Theorem\". The Journal of Economic Education. 33 (3): 217\u2013235. doi:10.1080/00220480209595188.\nTang, Pingzhong; Lin, Fangzhen (2009). \"Computer-aided Proofs of Arrow's and Other Impossibility Theorems\". Artificial Intelligence. 173 (11): 1041\u20131053. doi:10.1016/j.artint.2009.02.005.\nStef\u00e1nsson, Bj\u00f6rn S. (1991). \"On irrelevant and infeasible alternatives\". Quality and Quantity. 25 (3): 297\u2013306. doi:10.1007/BF00167534.\nStef\u00e1nsson, Bj\u00f6rn S. (1995). \"On the fundamental thought behind voting rules\". Quality and Quantity. 29 (4): 433\u2013438. doi:10.1007/BF01106068.", {"entities": [[3, 23, "TRAINED_CATEGORY"], [25, 46, "TRAINED_CATEGORY"], [56, 87, "TRAINED_CATEGORY"], [91, 106, "TRAINED_CATEGORY"], [110, 126, "TRAINED_CATEGORY"], [153, 159, "TRAINED_CATEGORY"], [165, 200, "TRAINED_CATEGORY"], [201, 209, "TRAINED_CATEGORY"], [212, 245, "TRAINED_CATEGORY"], [258, 280, "TRAINED_CATEGORY"], [284, 295, "TRAINED_CATEGORY"], [371, 386, "TRAINED_CATEGORY"], [390, 398, "TRAINED_CATEGORY"], [400, 419, "TRAINED_CATEGORY"], [439, 456, "TRAINED_CATEGORY"], [462, 474, "TRAINED_CATEGORY"], [478, 501, "TRAINED_CATEGORY"], [503, 514, "TRAINED_CATEGORY"], [533, 544, "TRAINED_CATEGORY"], [548, 561, "TRAINED_CATEGORY"], [565, 567, "TRAINED_CATEGORY"], [594, 605, "TRAINED_CATEGORY"], [629, 640, "TRAINED_CATEGORY"], [656, 665, "TRAINED_CATEGORY"], [670, 698, "TRAINED_CATEGORY"], [700, 703, "TRAINED_CATEGORY"], [717, 728, "TRAINED_CATEGORY"], [732, 751, "TRAINED_CATEGORY"], [768, 770, "TRAINED_CATEGORY"], [774, 787, "TRAINED_CATEGORY"], [788, 801, "TRAINED_CATEGORY"], [806, 823, "TRAINED_CATEGORY"], [826, 844, "TRAINED_CATEGORY"], [873, 884, "TRAINED_CATEGORY"], [888, 903, "TRAINED_CATEGORY"], [938, 968, "TRAINED_CATEGORY"], [1007, 1038, "TRAINED_CATEGORY"], [1044, 1055, "TRAINED_CATEGORY"], [1103, 1112, "TRAINED_CATEGORY"], [1121, 1122, "TRAINED_CATEGORY"], [1128, 1130, "TRAINED_CATEGORY"], [1134, 1158, "TRAINED_CATEGORY"], [1167, 1168, "TRAINED_CATEGORY"], [1173, 1174, "TRAINED_CATEGORY"], [1199, 1221, "TRAINED_CATEGORY"], [1230, 1231, "TRAINED_CATEGORY"], [1236, 1237, "TRAINED_CATEGORY"], [1302, 1313, "TRAINED_CATEGORY"], [1319, 1320, "TRAINED_CATEGORY"], [1325, 1326, "TRAINED_CATEGORY"], [1328, 1329, "TRAINED_CATEGORY"], [1334, 1335, "TRAINED_CATEGORY"], [1340, 1354, "TRAINED_CATEGORY"], [1366, 1378, "TRAINED_CATEGORY"], [1381, 1396, "TRAINED_CATEGORY"], [1407, 1416, "TRAINED_CATEGORY"], [1437, 1459, "TRAINED_CATEGORY"], [1460, 1493, "TRAINED_CATEGORY"], [1513, 1524, "TRAINED_CATEGORY"], [1529, 1533, "TRAINED_CATEGORY"], [1541, 1557, "TRAINED_CATEGORY"], [1563, 1574, "TRAINED_CATEGORY"], [1585, 1602, "TRAINED_CATEGORY"], [1611, 1626, "TRAINED_CATEGORY"], [1631, 1640, "TRAINED_CATEGORY"], [1642, 1653, "TRAINED_CATEGORY"], [1691, 1701, "TRAINED_CATEGORY"], [1705, 1717, "TRAINED_CATEGORY"], [1718, 1740, "TRAINED_CATEGORY"], [1741, 1746, "TRAINED_CATEGORY"], [1765, 1786, "TRAINED_CATEGORY"], [1806, 1817, "TRAINED_CATEGORY"], [1826, 1847, "TRAINED_CATEGORY"], [1852, 1862, "TRAINED_CATEGORY"], [1864, 1876, "TRAINED_CATEGORY"], [1928, 1941, "TRAINED_CATEGORY"], [1952, 1957, "TRAINED_CATEGORY"], [1988, 1991, "TRAINED_CATEGORY"], [2015, 2040, "TRAINED_CATEGORY"], [2044, 2064, "TRAINED_CATEGORY"], [2078, 2090, "TRAINED_CATEGORY"], [2091, 2117, "TRAINED_CATEGORY"], [2121, 2132, "TRAINED_CATEGORY"], [2148, 2153, "TRAINED_CATEGORY"], [2164, 2176, "TRAINED_CATEGORY"], [2212, 2220, "TRAINED_CATEGORY"], [2226, 2227, "TRAINED_CATEGORY"], [2265, 2270, "TRAINED_CATEGORY"], [2278, 2287, "TRAINED_CATEGORY"], [2291, 2302, "TRAINED_CATEGORY"], [2306, 2314, "TRAINED_CATEGORY"], [2328, 2339, "TRAINED_CATEGORY"], [2350, 2366, "TRAINED_CATEGORY"], [2371, 2388, "TRAINED_CATEGORY"], [2417, 2436, "TRAINED_CATEGORY"], [2478, 2493, "TRAINED_CATEGORY"], [2501, 2509, "TRAINED_CATEGORY"], [2522, 2539, "TRAINED_CATEGORY"], [2549, 2565, "TRAINED_CATEGORY"], [2589, 2606, "TRAINED_CATEGORY"], [2618, 2628, "TRAINED_CATEGORY"], [2644, 2673, "TRAINED_CATEGORY"], [2679, 2690, "TRAINED_CATEGORY"], [2694, 2713, "TRAINED_CATEGORY"], [2715, 2728, "TRAINED_CATEGORY"], [2733, 2748, "TRAINED_CATEGORY"], [2762, 2764, "TRAINED_CATEGORY"], [2781, 2799, "TRAINED_CATEGORY"], [2803, 2814, "TRAINED_CATEGORY"], [2818, 2825, "TRAINED_CATEGORY"], [2827, 2835, "TRAINED_CATEGORY"], [2838, 2853, "TRAINED_CATEGORY"], [2857, 2868, "TRAINED_CATEGORY"], [2885, 2910, "TRAINED_CATEGORY"], [2918, 2936, "TRAINED_CATEGORY"], [2940, 2951, "TRAINED_CATEGORY"], [2955, 2962, "TRAINED_CATEGORY"], [2966, 2974, "TRAINED_CATEGORY"], [2976, 2978, "TRAINED_CATEGORY"], [2997, 3029, "TRAINED_CATEGORY"], [3064, 3092, "TRAINED_CATEGORY"], [3112, 3119, "TRAINED_CATEGORY"], [3123, 3134, "TRAINED_CATEGORY"], [3136, 3143, "TRAINED_CATEGORY"], [3147, 3158, "TRAINED_CATEGORY"], [3165, 3206, "TRAINED_CATEGORY"], [3208, 3223, "TRAINED_CATEGORY"], [3237, 3261, "TRAINED_CATEGORY"], [3266, 3286, "TRAINED_CATEGORY"], [3291, 3313, "TRAINED_CATEGORY"], [3336, 3338, "TRAINED_CATEGORY"], [3363, 3388, "TRAINED_CATEGORY"], [3404, 3424, "TRAINED_CATEGORY"], [3440, 3464, "TRAINED_CATEGORY"], [3468, 3491, "TRAINED_CATEGORY"], [3503, 3519, "TRAINED_CATEGORY"], [3520, 3547, "TRAINED_CATEGORY"], [3567, 3577, "TRAINED_CATEGORY"], [3581, 3596, "TRAINED_CATEGORY"], [3598, 3600, "TRAINED_CATEGORY"], [3621, 3636, "TRAINED_CATEGORY"], [3640, 3654, "TRAINED_CATEGORY"], [3656, 3675, "TRAINED_CATEGORY"], [3680, 3692, "TRAINED_CATEGORY"], [3697, 3704, "TRAINED_CATEGORY"], [3708, 3736, "TRAINED_CATEGORY"], [3738, 3765, "TRAINED_CATEGORY"], [3779, 3808, "TRAINED_CATEGORY"], [3812, 3828, "TRAINED_CATEGORY"], [3852, 3875, "TRAINED_CATEGORY"], [3876, 3880, "TRAINED_CATEGORY"], [3882, 3903, "TRAINED_CATEGORY"], [3918, 3919, "TRAINED_CATEGORY"], [3942, 3968, "TRAINED_CATEGORY"], [3983, 3984, "TRAINED_CATEGORY"], [3985, 4007, "TRAINED_CATEGORY"], [4026, 4033, "TRAINED_CATEGORY"], [4037, 4058, "TRAINED_CATEGORY"], [4062, 4085, "TRAINED_CATEGORY"], [4086, 4091, "TRAINED_CATEGORY"], [4100, 4116, "TRAINED_CATEGORY"], [4130, 4139, "TRAINED_CATEGORY"], [4143, 4163, "TRAINED_CATEGORY"], [4167, 4177, "TRAINED_CATEGORY"], [4183, 4190, "TRAINED_CATEGORY"], [4195, 4204, "TRAINED_CATEGORY"], [4229, 4240, "TRAINED_CATEGORY"], [4277, 4278, "TRAINED_CATEGORY"], [4287, 4304, "TRAINED_CATEGORY"], [4305, 4306, "TRAINED_CATEGORY"], [4323, 4336, "TRAINED_CATEGORY"], [4359, 4371, "TRAINED_CATEGORY"], [4376, 4396, "TRAINED_CATEGORY"], [4400, 4428, "TRAINED_CATEGORY"], [4456, 4483, "TRAINED_CATEGORY"], [4497, 4513, "TRAINED_CATEGORY"], [4520, 4549, "TRAINED_CATEGORY"], [4583, 4599, "TRAINED_CATEGORY"], [4634, 4636, "TRAINED_CATEGORY"], [4656, 4669, "TRAINED_CATEGORY"], [4697, 4706, "TRAINED_CATEGORY"], [4718, 4720, "TRAINED_CATEGORY"], [4729, 4743, "TRAINED_CATEGORY"], [4748, 4767, "TRAINED_CATEGORY"], [4768, 4808, "TRAINED_CATEGORY"], [4833, 4841, "TRAINED_CATEGORY"], [4845, 4873, "TRAINED_CATEGORY"], [4891, 4918, "TRAINED_CATEGORY"], [4934, 4936, "TRAINED_CATEGORY"], [4941, 4969, "TRAINED_CATEGORY"], [4970, 4992, "TRAINED_CATEGORY"], [4996, 5001, "TRAINED_CATEGORY"], [5021, 5065, "TRAINED_CATEGORY"], [5073, 5090, "TRAINED_CATEGORY"], [5095, 5104, "TRAINED_CATEGORY"], [5108, 5124, "TRAINED_CATEGORY"], [5133, 5149, "TRAINED_CATEGORY"], [5175, 5214, "TRAINED_CATEGORY"], [5232, 5240, "TRAINED_CATEGORY"], [5246, 5273, "TRAINED_CATEGORY"], [5305, 5327, "TRAINED_CATEGORY"], [5328, 5346, "TRAINED_CATEGORY"], [5371, 5388, "TRAINED_CATEGORY"], [5390, 5400, "TRAINED_CATEGORY"], [5404, 5416, "TRAINED_CATEGORY"], [5438, 5441, "TRAINED_CATEGORY"], [5457, 5474, "TRAINED_CATEGORY"], [5484, 5501, "TRAINED_CATEGORY"], [5503, 5509, "TRAINED_CATEGORY"], [5539, 5542, "TRAINED_CATEGORY"], [5565, 5577, "TRAINED_CATEGORY"], [5585, 5597, "TRAINED_CATEGORY"], [5601, 5624, "TRAINED_CATEGORY"], [5625, 5629, "TRAINED_CATEGORY"], [5635, 5652, "TRAINED_CATEGORY"], [5657, 5671, "TRAINED_CATEGORY"], [5676, 5683, "TRAINED_CATEGORY"], [5686, 5695, "TRAINED_CATEGORY"], [5696, 5719, "TRAINED_CATEGORY"], [5739, 5748, "TRAINED_CATEGORY"], [5749, 5752, "TRAINED_CATEGORY"], [5756, 5775, "TRAINED_CATEGORY"], [5777, 5786, "TRAINED_CATEGORY"], [5797, 5817, "TRAINED_CATEGORY"], [5822, 5845, "TRAINED_CATEGORY"], [5849, 5871, "TRAINED_CATEGORY"], [5880, 5902, "TRAINED_CATEGORY"], [5934, 5937, "TRAINED_CATEGORY"], [5939, 5941, "TRAINED_CATEGORY"], [5978, 5989, "TRAINED_CATEGORY"], [6005, 6009, "TRAINED_CATEGORY"], [6028, 6038, "TRAINED_CATEGORY"], [6040, 6047, "TRAINED_CATEGORY"], [6051, 6072, "TRAINED_CATEGORY"], [6098, 6105, "TRAINED_CATEGORY"], [6110, 6111, "TRAINED_CATEGORY"], [6132, 6141, "TRAINED_CATEGORY"], [6145, 6157, "TRAINED_CATEGORY"], [6158, 6170, "TRAINED_CATEGORY"], [6191, 6193, "TRAINED_CATEGORY"], [6203, 6213, "TRAINED_CATEGORY"], [6214, 6227, "TRAINED_CATEGORY"], [6233, 6236, "TRAINED_CATEGORY"], [6240, 6251, "TRAINED_CATEGORY"], [6262, 6272, "TRAINED_CATEGORY"], [6277, 6288, "TRAINED_CATEGORY"], [6290, 6298, "TRAINED_CATEGORY"], [6307, 6310, "TRAINED_CATEGORY"], [6320, 6336, "TRAINED_CATEGORY"], [6348, 6352, "TRAINED_CATEGORY"], [6356, 6377, "TRAINED_CATEGORY"], [6383, 6395, "TRAINED_CATEGORY"], [6400, 6413, "TRAINED_CATEGORY"], [6428, 6450, "TRAINED_CATEGORY"], [6452, 6454, "TRAINED_CATEGORY"], [6478, 6497, "TRAINED_CATEGORY"], [6509, 6522, "TRAINED_CATEGORY"], [6528, 6538, "TRAINED_CATEGORY"], [6551, 6562, "TRAINED_CATEGORY"], [6575, 6584, "TRAINED_CATEGORY"], [6617, 6618, "TRAINED_CATEGORY"], [6622, 6623, "TRAINED_CATEGORY"], [6624, 6628, "TRAINED_CATEGORY"], [6640, 6641, "TRAINED_CATEGORY"], [6645, 6646, "TRAINED_CATEGORY"], [6650, 6652, "TRAINED_CATEGORY"], [6659, 6661, "TRAINED_CATEGORY"], [6680, 6681, "TRAINED_CATEGORY"], [6697, 6708, "TRAINED_CATEGORY"], [6774, 6789, "TRAINED_CATEGORY"], [6791, 6796, "TRAINED_CATEGORY"], [6805, 6808, "TRAINED_CATEGORY"], [6824, 6846, "TRAINED_CATEGORY"], [6874, 6875, "TRAINED_CATEGORY"], [6891, 6917, "TRAINED_CATEGORY"], [6932, 6933, "TRAINED_CATEGORY"], [6958, 6974, "TRAINED_CATEGORY"], [6982, 6998, "TRAINED_CATEGORY"], [7002, 7013, "TRAINED_CATEGORY"], [7026, 7031, "TRAINED_CATEGORY"], [7035, 7043, "TRAINED_CATEGORY"], [7047, 7055, "TRAINED_CATEGORY"], [7059, 7065, "TRAINED_CATEGORY"], [7069, 7086, "TRAINED_CATEGORY"], [7088, 7090, "TRAINED_CATEGORY"], [7104, 7111, "TRAINED_CATEGORY"], [7115, 7140, "TRAINED_CATEGORY"], [7144, 7145, "TRAINED_CATEGORY"], [7149, 7152, "TRAINED_CATEGORY"], [7155, 7189, "TRAINED_CATEGORY"], [7191, 7218, "TRAINED_CATEGORY"], [7223, 7233, "TRAINED_CATEGORY"], [7258, 7259, "TRAINED_CATEGORY"], [7302, 7303, "TRAINED_CATEGORY"], [7330, 7381, "TRAINED_CATEGORY"], [7455, 7523, "TRAINED_CATEGORY"], [7524, 7546, "TRAINED_CATEGORY"], [7570, 7589, "TRAINED_CATEGORY"], [7595, 7620, "TRAINED_CATEGORY"], [7638, 7640, "TRAINED_CATEGORY"], [7651, 7656, "TRAINED_CATEGORY"], [7660, 7679, "TRAINED_CATEGORY"], [7716, 7747, "TRAINED_CATEGORY"], [7749, 7770, "TRAINED_CATEGORY"], [7800, 7809, "TRAINED_CATEGORY"], [7813, 7834, "TRAINED_CATEGORY"], [7839, 7859, "TRAINED_CATEGORY"], [7866, 7896, "TRAINED_CATEGORY"], [7956, 7970, "TRAINED_CATEGORY"], [8006, 8007, "TRAINED_CATEGORY"], [8012, 8028, "TRAINED_CATEGORY"], [8076, 8077, "TRAINED_CATEGORY"], [8081, 8085, "TRAINED_CATEGORY"], [8087, 8089, "TRAINED_CATEGORY"], [8100, 8109, "TRAINED_CATEGORY"], [8118, 8132, "TRAINED_CATEGORY"], [8135, 8151, "TRAINED_CATEGORY"], [8161, 8174, "TRAINED_CATEGORY"], [8176, 8177, "TRAINED_CATEGORY"], [8178, 8202, "TRAINED_CATEGORY"], [8237, 8241, "TRAINED_CATEGORY"], [8251, 8252, "TRAINED_CATEGORY"], [8281, 8286, "TRAINED_CATEGORY"], [8287, 8292, "TRAINED_CATEGORY"], [8294, 8302, "TRAINED_CATEGORY"], [8324, 8325, "TRAINED_CATEGORY"], [8329, 8331, "TRAINED_CATEGORY"], [8370, 8371, "TRAINED_CATEGORY"], [8375, 8379, "TRAINED_CATEGORY"], [8381, 8383, "TRAINED_CATEGORY"], [8386, 8390, "TRAINED_CATEGORY"], [8407, 8409, "TRAINED_CATEGORY"], [8410, 8422, "TRAINED_CATEGORY"], [8426, 8449, "TRAINED_CATEGORY"], [8454, 8477, "TRAINED_CATEGORY"], [8479, 8481, "TRAINED_CATEGORY"], [8484, 8488, "TRAINED_CATEGORY"], [8494, 8497, "TRAINED_CATEGORY"], [8520, 8535, "TRAINED_CATEGORY"], [8536, 8537, "TRAINED_CATEGORY"], [8558, 8559, "TRAINED_CATEGORY"], [8565, 8579, "TRAINED_CATEGORY"], [8583, 8585, "TRAINED_CATEGORY"], [8592, 8594, "TRAINED_CATEGORY"], [8596, 8610, "TRAINED_CATEGORY"], [8615, 8616, "TRAINED_CATEGORY"], [8622, 8636, "TRAINED_CATEGORY"], [8640, 8644, "TRAINED_CATEGORY"], [8659, 8663, "TRAINED_CATEGORY"], [8678, 8692, "TRAINED_CATEGORY"], [8705, 8715, "TRAINED_CATEGORY"], [8729, 8744, "TRAINED_CATEGORY"], [8751, 8761, "TRAINED_CATEGORY"], [8762, 8764, "TRAINED_CATEGORY"], [8780, 8792, "TRAINED_CATEGORY"], [8799, 8803, "TRAINED_CATEGORY"], [8821, 8837, "TRAINED_CATEGORY"], [8845, 8858, "TRAINED_CATEGORY"], [8864, 8871, "TRAINED_CATEGORY"], [8906, 8913, "TRAINED_CATEGORY"], [8938, 8941, "TRAINED_CATEGORY"], [9023, 9033, "TRAINED_CATEGORY"], [9036, 9048, "TRAINED_CATEGORY"], [9062, 9083, "TRAINED_CATEGORY"], [9085, 9087, "TRAINED_CATEGORY"], [9104, 9128, "TRAINED_CATEGORY"], [9140, 9159, "TRAINED_CATEGORY"], [9161, 9170, "TRAINED_CATEGORY"], [9176, 9188, "TRAINED_CATEGORY"], [9192, 9215, "TRAINED_CATEGORY"], [9216, 9220, "TRAINED_CATEGORY"], [9225, 9239, "TRAINED_CATEGORY"], [9242, 9254, "TRAINED_CATEGORY"], [9270, 9285, "TRAINED_CATEGORY"], [9286, 9298, "TRAINED_CATEGORY"], [9306, 9326, "TRAINED_CATEGORY"], [9329, 9331, "TRAINED_CATEGORY"], [9348, 9358, "TRAINED_CATEGORY"], [9362, 9380, "TRAINED_CATEGORY"], [9385, 9411, "TRAINED_CATEGORY"], [9440, 9442, "TRAINED_CATEGORY"], [9475, 9496, "TRAINED_CATEGORY"], [9501, 9516, "TRAINED_CATEGORY"], [9524, 9534, "TRAINED_CATEGORY"], [9538, 9548, "TRAINED_CATEGORY"], [9556, 9560, "TRAINED_CATEGORY"], [9575, 9592, "TRAINED_CATEGORY"], [9597, 9598, "TRAINED_CATEGORY"], [9604, 9605, "TRAINED_CATEGORY"], [9625, 9638, "TRAINED_CATEGORY"], [9643, 9650, "TRAINED_CATEGORY"], [9657, 9661, "TRAINED_CATEGORY"], [9672, 9674, "TRAINED_CATEGORY"], [9695, 9703, "TRAINED_CATEGORY"], [9712, 9720, "TRAINED_CATEGORY"], [9732, 9740, "TRAINED_CATEGORY"], [9750, 9751, "TRAINED_CATEGORY"], [9755, 9756, "TRAINED_CATEGORY"], [9762, 9770, "TRAINED_CATEGORY"], [9779, 9780, "TRAINED_CATEGORY"], [9784, 9786, "TRAINED_CATEGORY"], [9791, 9800, "TRAINED_CATEGORY"], [9802, 9809, "TRAINED_CATEGORY"], [9827, 9833, "TRAINED_CATEGORY"], [9838, 9839, "TRAINED_CATEGORY"], [9852, 9874, "TRAINED_CATEGORY"], [9881, 9895, "TRAINED_CATEGORY"], [9900, 9908, "TRAINED_CATEGORY"], [9919, 9920, "TRAINED_CATEGORY"], [9924, 9934, "TRAINED_CATEGORY"], [9946, 9953, "TRAINED_CATEGORY"], [9975, 9976, "TRAINED_CATEGORY"], [9980, 9990, "TRAINED_CATEGORY"], [9999, 10008, "TRAINED_CATEGORY"], [10023, 10037, "TRAINED_CATEGORY"], [10041, 10071, "TRAINED_CATEGORY"], [10086, 10087, "TRAINED_CATEGORY"], [10100, 10101, "TRAINED_CATEGORY"], [10117, 10124, "TRAINED_CATEGORY"], [10137, 10138, "TRAINED_CATEGORY"], [10142, 10149, "TRAINED_CATEGORY"], [10153, 10164, "TRAINED_CATEGORY"], [10169, 10175, "TRAINED_CATEGORY"], [10186, 10188, "TRAINED_CATEGORY"], [10193, 10200, "TRAINED_CATEGORY"], [10207, 10208, "TRAINED_CATEGORY"], [10212, 10219, "TRAINED_CATEGORY"], [10223, 10233, "TRAINED_CATEGORY"], [10238, 10243, "TRAINED_CATEGORY"], [10266, 10276, "TRAINED_CATEGORY"], [10279, 10286, "TRAINED_CATEGORY"], [10293, 10294, "TRAINED_CATEGORY"], [10298, 10305, "TRAINED_CATEGORY"], [10310, 10316, "TRAINED_CATEGORY"], [10330, 10339, "TRAINED_CATEGORY"], [10358, 10359, "TRAINED_CATEGORY"], [10380, 10387, "TRAINED_CATEGORY"], [10391, 10414, "TRAINED_CATEGORY"], [10430, 10442, "TRAINED_CATEGORY"], [10444, 10452, "TRAINED_CATEGORY"], [10464, 10465, "TRAINED_CATEGORY"], [10483, 10500, "TRAINED_CATEGORY"], [10503, 10505, "TRAINED_CATEGORY"], [10511, 10520, "TRAINED_CATEGORY"], [10521, 10540, "TRAINED_CATEGORY"], [10563, 10580, "TRAINED_CATEGORY"], [10585, 10586, "TRAINED_CATEGORY"], [10606, 10623, "TRAINED_CATEGORY"], [10628, 10629, "TRAINED_CATEGORY"], [10635, 10636, "TRAINED_CATEGORY"], [10667, 10684, "TRAINED_CATEGORY"], [10696, 10698, "TRAINED_CATEGORY"], [10703, 10707, "TRAINED_CATEGORY"], [10717, 10726, "TRAINED_CATEGORY"], [10727, 10729, "TRAINED_CATEGORY"], [10797, 10800, "TRAINED_CATEGORY"], [10801, 10818, "TRAINED_CATEGORY"], [10830, 10837, "TRAINED_CATEGORY"], [10843, 10854, "TRAINED_CATEGORY"], [10864, 10865, "TRAINED_CATEGORY"], [10882, 10883, "TRAINED_CATEGORY"], [10887, 10898, "TRAINED_CATEGORY"], [10904, 10921, "TRAINED_CATEGORY"], [10926, 10927, "TRAINED_CATEGORY"], [10933, 10934, "TRAINED_CATEGORY"], [10949, 10954, "TRAINED_CATEGORY"], [10959, 10961, "TRAINED_CATEGORY"], [10971, 10987, "TRAINED_CATEGORY"], [11011, 11028, "TRAINED_CATEGORY"], [11033, 11034, "TRAINED_CATEGORY"], [11040, 11041, "TRAINED_CATEGORY"], [11045, 11055, "TRAINED_CATEGORY"], [11060, 11061, "TRAINED_CATEGORY"], [11067, 11068, "TRAINED_CATEGORY"], [11076, 11085, "TRAINED_CATEGORY"], [11089, 11101, "TRAINED_CATEGORY"], [11102, 11104, "TRAINED_CATEGORY"], [11114, 11121, "TRAINED_CATEGORY"], [11123, 11140, "TRAINED_CATEGORY"], [11145, 11146, "TRAINED_CATEGORY"], [11152, 11153, "TRAINED_CATEGORY"], [11158, 11171, "TRAINED_CATEGORY"], [11176, 11186, "TRAINED_CATEGORY"], [11189, 11191, "TRAINED_CATEGORY"], [11207, 11220, "TRAINED_CATEGORY"], [11230, 11248, "TRAINED_CATEGORY"], [11253, 11254, "TRAINED_CATEGORY"], [11260, 11262, "TRAINED_CATEGORY"], [11273, 11275, "TRAINED_CATEGORY"], [11300, 11308, "TRAINED_CATEGORY"], [11312, 11325, "TRAINED_CATEGORY"], [11330, 11343, "TRAINED_CATEGORY"], [11350, 11351, "TRAINED_CATEGORY"], [11357, 11358, "TRAINED_CATEGORY"], [11373, 11393, "TRAINED_CATEGORY"], [11412, 11424, "TRAINED_CATEGORY"], [11429, 11430, "TRAINED_CATEGORY"], [11436, 11437, "TRAINED_CATEGORY"], [11475, 11476, "TRAINED_CATEGORY"], [11482, 11484, "TRAINED_CATEGORY"], [11489, 11493, "TRAINED_CATEGORY"], [11503, 11512, "TRAINED_CATEGORY"], [11513, 11515, "TRAINED_CATEGORY"], [11569, 11582, "TRAINED_CATEGORY"], [11584, 11586, "TRAINED_CATEGORY"], [11592, 11598, "TRAINED_CATEGORY"], [11609, 11612, "TRAINED_CATEGORY"], [11633, 11639, "TRAINED_CATEGORY"], [11640, 11641, "TRAINED_CATEGORY"], [11657, 11664, "TRAINED_CATEGORY"], [11694, 11705, "TRAINED_CATEGORY"], [11723, 11734, "TRAINED_CATEGORY"], [11738, 11745, "TRAINED_CATEGORY"], [11756, 11757, "TRAINED_CATEGORY"], [11764, 11765, "TRAINED_CATEGORY"], [11770, 11771, "TRAINED_CATEGORY"], [11778, 11780, "TRAINED_CATEGORY"], [11781, 11794, "TRAINED_CATEGORY"], [11809, 11810, "TRAINED_CATEGORY"], [11815, 11816, "TRAINED_CATEGORY"], [11823, 11825, "TRAINED_CATEGORY"], [11826, 11837, "TRAINED_CATEGORY"], [11841, 11848, "TRAINED_CATEGORY"], [11867, 11868, "TRAINED_CATEGORY"], [11873, 11874, "TRAINED_CATEGORY"], [11881, 11887, "TRAINED_CATEGORY"], [11891, 11903, "TRAINED_CATEGORY"], [11907, 11911, "TRAINED_CATEGORY"], [11945, 11954, "TRAINED_CATEGORY"], [11957, 11977, "TRAINED_CATEGORY"], [11996, 11998, "TRAINED_CATEGORY"], [12028, 12043, "TRAINED_CATEGORY"], [12047, 12048, "TRAINED_CATEGORY"], [12050, 12062, "TRAINED_CATEGORY"], [12078, 12089, "TRAINED_CATEGORY"], [12097, 12101, "TRAINED_CATEGORY"], [12124, 12133, "TRAINED_CATEGORY"], [12134, 12154, "TRAINED_CATEGORY"], [12165, 12166, "TRAINED_CATEGORY"], [12173, 12175, "TRAINED_CATEGORY"], [12188, 12190, "TRAINED_CATEGORY"], [12196, 12207, "TRAINED_CATEGORY"], [12211, 12220, "TRAINED_CATEGORY"], [12250, 12263, "TRAINED_CATEGORY"], [12270, 12271, "TRAINED_CATEGORY"], [12278, 12279, "TRAINED_CATEGORY"], [12291, 12292, "TRAINED_CATEGORY"], [12296, 12313, "TRAINED_CATEGORY"], [12331, 12341, "TRAINED_CATEGORY"], [12355, 12371, "TRAINED_CATEGORY"], [12379, 12392, "TRAINED_CATEGORY"], [12401, 12402, "TRAINED_CATEGORY"], [12409, 12410, "TRAINED_CATEGORY"], [12429, 12441, "TRAINED_CATEGORY"], [12445, 12447, "TRAINED_CATEGORY"], [12467, 12482, "TRAINED_CATEGORY"], [12486, 12487, "TRAINED_CATEGORY"], [12508, 12517, "TRAINED_CATEGORY"], [12523, 12527, "TRAINED_CATEGORY"], [12542, 12562, "TRAINED_CATEGORY"], [12569, 12570, "TRAINED_CATEGORY"], [12577, 12579, "TRAINED_CATEGORY"], [12597, 12600, "TRAINED_CATEGORY"], [12601, 12621, "TRAINED_CATEGORY"], [12640, 12641, "TRAINED_CATEGORY"], [12649, 12666, "TRAINED_CATEGORY"], [12684, 12704, "TRAINED_CATEGORY"], [12711, 12712, "TRAINED_CATEGORY"], [12719, 12720, "TRAINED_CATEGORY"], [12734, 12747, "TRAINED_CATEGORY"], [12762, 12776, "TRAINED_CATEGORY"], [12785, 12786, "TRAINED_CATEGORY"], [12793, 12795, "TRAINED_CATEGORY"], [12800, 12803, "TRAINED_CATEGORY"], [12805, 12820, "TRAINED_CATEGORY"], [12848, 12849, "TRAINED_CATEGORY"], [12867, 12878, "TRAINED_CATEGORY"], [12883, 12896, "TRAINED_CATEGORY"], [12900, 12910, "TRAINED_CATEGORY"], [12915, 12916, "TRAINED_CATEGORY"], [12922, 12924, "TRAINED_CATEGORY"], [12956, 12966, "TRAINED_CATEGORY"], [12975, 12984, "TRAINED_CATEGORY"], [12988, 13000, "TRAINED_CATEGORY"], [13001, 13003, "TRAINED_CATEGORY"], [13018, 13039, "TRAINED_CATEGORY"], [13043, 13049, "TRAINED_CATEGORY"], [13063, 13076, "TRAINED_CATEGORY"], [13080, 13108, "TRAINED_CATEGORY"], [13133, 13138, "TRAINED_CATEGORY"], [13154, 13169, "TRAINED_CATEGORY"], [13173, 13183, "TRAINED_CATEGORY"], [13194, 13211, "TRAINED_CATEGORY"], [13216, 13217, "TRAINED_CATEGORY"], [13223, 13224, "TRAINED_CATEGORY"], [13252, 13269, "TRAINED_CATEGORY"], [13274, 13282, "TRAINED_CATEGORY"], [13288, 13300, "TRAINED_CATEGORY"], [13305, 13306, "TRAINED_CATEGORY"], [13312, 13313, "TRAINED_CATEGORY"], [13319, 13321, "TRAINED_CATEGORY"], [13331, 13343, "TRAINED_CATEGORY"], [13347, 13351, "TRAINED_CATEGORY"], [13367, 13368, "TRAINED_CATEGORY"], [13373, 13374, "TRAINED_CATEGORY"], [13396, 13397, "TRAINED_CATEGORY"], [13401, 13408, "TRAINED_CATEGORY"], [13412, 13427, "TRAINED_CATEGORY"], [13429, 13444, "TRAINED_CATEGORY"], [13451, 13458, "TRAINED_CATEGORY"], [13465, 13466, "TRAINED_CATEGORY"], [13473, 13474, "TRAINED_CATEGORY"], [13498, 13500, "TRAINED_CATEGORY"], [13507, 13519, "TRAINED_CATEGORY"], [13524, 13525, "TRAINED_CATEGORY"], [13531, 13533, "TRAINED_CATEGORY"], [13555, 13564, "TRAINED_CATEGORY"], [13568, 13569, "TRAINED_CATEGORY"], [13574, 13575, "TRAINED_CATEGORY"], [13577, 13594, "TRAINED_CATEGORY"], [13599, 13600, "TRAINED_CATEGORY"], [13606, 13607, "TRAINED_CATEGORY"], [13631, 13635, "TRAINED_CATEGORY"], [13641, 13653, "TRAINED_CATEGORY"], [13658, 13659, "TRAINED_CATEGORY"], [13665, 13667, "TRAINED_CATEGORY"], [13682, 13686, "TRAINED_CATEGORY"], [13695, 13707, "TRAINED_CATEGORY"], [13711, 13728, "TRAINED_CATEGORY"], [13733, 13734, "TRAINED_CATEGORY"], [13740, 13741, "TRAINED_CATEGORY"], [13747, 13765, "TRAINED_CATEGORY"], [13766, 13767, "TRAINED_CATEGORY"], [13772, 13773, "TRAINED_CATEGORY"], [13781, 13783, "TRAINED_CATEGORY"], [13810, 13818, "TRAINED_CATEGORY"], [13829, 13848, "TRAINED_CATEGORY"], [13860, 13861, "TRAINED_CATEGORY"], [13866, 13867, "TRAINED_CATEGORY"], [13878, 13880, "TRAINED_CATEGORY"], [13915, 13917, "TRAINED_CATEGORY"], [13924, 13926, "TRAINED_CATEGORY"], [13926, 13928, "TRAINED_CATEGORY"], [13931, 13935, "TRAINED_CATEGORY"], [13946, 13963, "TRAINED_CATEGORY"], [13968, 13979, "TRAINED_CATEGORY"], [13991, 14013, "TRAINED_CATEGORY"], [14019, 14042, "TRAINED_CATEGORY"], [14053, 14070, "TRAINED_CATEGORY"], [14074, 14082, "TRAINED_CATEGORY"], [14086, 14092, "TRAINED_CATEGORY"], [14095, 14105, "TRAINED_CATEGORY"], [14109, 14121, "TRAINED_CATEGORY"], [14126, 14144, "TRAINED_CATEGORY"], [14151, 14166, "TRAINED_CATEGORY"], [14170, 14181, "TRAINED_CATEGORY"], [14194, 14209, "TRAINED_CATEGORY"], [14213, 14234, "TRAINED_CATEGORY"], [14236, 14238, "TRAINED_CATEGORY"], [14261, 14283, "TRAINED_CATEGORY"], [14289, 14300, "TRAINED_CATEGORY"], [14309, 14325, "TRAINED_CATEGORY"], [14335, 14361, "TRAINED_CATEGORY"], [14376, 14398, "TRAINED_CATEGORY"], [14420, 14434, "TRAINED_CATEGORY"], [14436, 14452, "TRAINED_CATEGORY"], [14457, 14472, "TRAINED_CATEGORY"], [14476, 14490, "TRAINED_CATEGORY"], [14540, 14560, "TRAINED_CATEGORY"], [14566, 14571, "TRAINED_CATEGORY"], [14580, 14625, "TRAINED_CATEGORY"], [14645, 14663, "TRAINED_CATEGORY"], [14667, 14687, "TRAINED_CATEGORY"], [14691, 14697, "TRAINED_CATEGORY"], [14703, 14719, "TRAINED_CATEGORY"], [14723, 14728, "TRAINED_CATEGORY"], [14735, 14750, "TRAINED_CATEGORY"], [14751, 14757, "TRAINED_CATEGORY"], [14777, 14791, "TRAINED_CATEGORY"], [14820, 14837, "TRAINED_CATEGORY"], [14863, 14880, "TRAINED_CATEGORY"], [14884, 14889, "TRAINED_CATEGORY"], [14897, 14908, "TRAINED_CATEGORY"], [14910, 14920, "TRAINED_CATEGORY"], [14924, 14945, "TRAINED_CATEGORY"], [14959, 14966, "TRAINED_CATEGORY"], [14970, 15002, "TRAINED_CATEGORY"], [15005, 15007, "TRAINED_CATEGORY"], [15031, 15060, "TRAINED_CATEGORY"], [15062, 15071, "TRAINED_CATEGORY"], [15075, 15088, "TRAINED_CATEGORY"], [15099, 15111, "TRAINED_CATEGORY"], [15115, 15141, "TRAINED_CATEGORY"], [15166, 15181, "TRAINED_CATEGORY"], [15185, 15203, "TRAINED_CATEGORY"], [15208, 15214, "TRAINED_CATEGORY"], [15220, 15227, "TRAINED_CATEGORY"], [15241, 15247, "TRAINED_CATEGORY"], [15252, 15268, "TRAINED_CATEGORY"], [15273, 15274, "TRAINED_CATEGORY"], [15277, 15278, "TRAINED_CATEGORY"], [15281, 15289, "TRAINED_CATEGORY"], [15294, 15295, "TRAINED_CATEGORY"], [15308, 15340, "TRAINED_CATEGORY"], [15344, 15353, "TRAINED_CATEGORY"], [15374, 15375, "TRAINED_CATEGORY"], [15377, 15378, "TRAINED_CATEGORY"], [15389, 15390, "TRAINED_CATEGORY"], [15396, 15397, "TRAINED_CATEGORY"], [15411, 15454, "TRAINED_CATEGORY"], [15459, 15482, "TRAINED_CATEGORY"], [15488, 15505, "TRAINED_CATEGORY"], [15507, 15527, "TRAINED_CATEGORY"], [15543, 15582, "TRAINED_CATEGORY"], [15588, 15599, "TRAINED_CATEGORY"], [15600, 15603, "TRAINED_CATEGORY"], [15613, 15623, "TRAINED_CATEGORY"], [15627, 15632, "TRAINED_CATEGORY"], [15642, 15654, "TRAINED_CATEGORY"], [15666, 15683, "TRAINED_CATEGORY"], [15688, 15705, "TRAINED_CATEGORY"], [15776, 15787, "TRAINED_CATEGORY"], [15798, 15801, "TRAINED_CATEGORY"], [15810, 15830, "TRAINED_CATEGORY"], [15846, 15857, "TRAINED_CATEGORY"], [15866, 15867, "TRAINED_CATEGORY"], [15871, 15872, "TRAINED_CATEGORY"], [15873, 15883, "TRAINED_CATEGORY"], [15888, 15893, "TRAINED_CATEGORY"], [15906, 15907, "TRAINED_CATEGORY"], [15908, 15911, "TRAINED_CATEGORY"], [15912, 15915, "TRAINED_CATEGORY"], [15919, 15920, "TRAINED_CATEGORY"], [15926, 15927, "TRAINED_CATEGORY"], [15928, 15933, "TRAINED_CATEGORY"], [15940, 15947, "TRAINED_CATEGORY"], [15980, 15994, "TRAINED_CATEGORY"], [16000, 16017, "TRAINED_CATEGORY"], [16037, 16041, "TRAINED_CATEGORY"], [16042, 16047, "TRAINED_CATEGORY"], [16050, 16057, "TRAINED_CATEGORY"], [16079, 16113, "TRAINED_CATEGORY"], [16117, 16135, "TRAINED_CATEGORY"], [16146, 16157, "TRAINED_CATEGORY"], [16184, 16195, "TRAINED_CATEGORY"], [16199, 16221, "TRAINED_CATEGORY"], [16245, 16266, "TRAINED_CATEGORY"], [16276, 16282, "TRAINED_CATEGORY"], [16297, 16317, "TRAINED_CATEGORY"], [16325, 16333, "TRAINED_CATEGORY"], [16365, 16371, "TRAINED_CATEGORY"], [16389, 16404, "TRAINED_CATEGORY"], [16410, 16419, "TRAINED_CATEGORY"], [16437, 16443, "TRAINED_CATEGORY"], [16445, 16460, "TRAINED_CATEGORY"], [16466, 16474, "TRAINED_CATEGORY"], [16478, 16488, "TRAINED_CATEGORY"], [16493, 16509, "TRAINED_CATEGORY"], [16514, 16530, "TRAINED_CATEGORY"], [16557, 16578, "TRAINED_CATEGORY"], [16582, 16603, "TRAINED_CATEGORY"], [16612, 16641, "TRAINED_CATEGORY"], [16670, 16683, "TRAINED_CATEGORY"], [16708, 16716, "TRAINED_CATEGORY"], [16720, 16730, "TRAINED_CATEGORY"], [16732, 16740, "TRAINED_CATEGORY"], [16754, 16763, "TRAINED_CATEGORY"], [16780, 16790, "TRAINED_CATEGORY"], [16803, 16822, "TRAINED_CATEGORY"], [16835, 16851, "TRAINED_CATEGORY"], [16856, 16891, "TRAINED_CATEGORY"], [16906, 16909, "TRAINED_CATEGORY"], [16923, 16933, "TRAINED_CATEGORY"], [16937, 16953, "TRAINED_CATEGORY"], [16983, 16993, "TRAINED_CATEGORY"], [16997, 17012, "TRAINED_CATEGORY"], [17018, 17037, "TRAINED_CATEGORY"], [17064, 17077, "TRAINED_CATEGORY"], [17081, 17101, "TRAINED_CATEGORY"], [17128, 17134, "TRAINED_CATEGORY"], [17147, 17158, "TRAINED_CATEGORY"], [17163, 17171, "TRAINED_CATEGORY"], [17183, 17214, "TRAINED_CATEGORY"], [17217, 17231, "TRAINED_CATEGORY"], [17242, 17266, "TRAINED_CATEGORY"], [17272, 17279, "TRAINED_CATEGORY"], [17283, 17294, "TRAINED_CATEGORY"], [17298, 17316, "TRAINED_CATEGORY"], [17321, 17341, "TRAINED_CATEGORY"], [17346, 17354, "TRAINED_CATEGORY"], [17355, 17368, "TRAINED_CATEGORY"], [17377, 17384, "TRAINED_CATEGORY"], [17390, 17395, "TRAINED_CATEGORY"], [17409, 17428, "TRAINED_CATEGORY"], [17435, 17445, "TRAINED_CATEGORY"], [17461, 17484, "TRAINED_CATEGORY"], [17488, 17503, "TRAINED_CATEGORY"], [17505, 17528, "TRAINED_CATEGORY"], [17547, 17568, "TRAINED_CATEGORY"], [17569, 17575, "TRAINED_CATEGORY"], [17583, 17603, "TRAINED_CATEGORY"], [17644, 17673, "TRAINED_CATEGORY"], [17674, 17686, "TRAINED_CATEGORY"], [17701, 17733, "TRAINED_CATEGORY"], [17747, 17755, "TRAINED_CATEGORY"], [17759, 17770, "TRAINED_CATEGORY"], [17792, 17803, "TRAINED_CATEGORY"], [17807, 17812, "TRAINED_CATEGORY"], [17820, 17830, "TRAINED_CATEGORY"], [17845, 17854, "TRAINED_CATEGORY"], [17858, 17877, "TRAINED_CATEGORY"], [17882, 17894, "TRAINED_CATEGORY"], [17904, 17914, "TRAINED_CATEGORY"], [17931, 17948, "TRAINED_CATEGORY"], [17950, 17959, "TRAINED_CATEGORY"], [17998, 18017, "TRAINED_CATEGORY"], [18024, 18039, "TRAINED_CATEGORY"], [18049, 18058, "TRAINED_CATEGORY"], [18097, 18111, "TRAINED_CATEGORY"], [18118, 18138, "TRAINED_CATEGORY"], [18154, 18156, "TRAINED_CATEGORY"], [18165, 18169, "TRAINED_CATEGORY"], [18173, 18186, "TRAINED_CATEGORY"], [18188, 18192, "TRAINED_CATEGORY"], [18214, 18230, "TRAINED_CATEGORY"], [18239, 18243, "TRAINED_CATEGORY"], [18256, 18277, "TRAINED_CATEGORY"], [18319, 18341, "TRAINED_CATEGORY"], [18343, 18351, "TRAINED_CATEGORY"], [18358, 18363, "TRAINED_CATEGORY"], [18380, 18407, "TRAINED_CATEGORY"], [18413, 18430, "TRAINED_CATEGORY"], [18438, 18444, "TRAINED_CATEGORY"], [18449, 18459, "TRAINED_CATEGORY"], [18481, 18484, "TRAINED_CATEGORY"], [18491, 18505, "TRAINED_CATEGORY"], [18521, 18551, "TRAINED_CATEGORY"], [18553, 18556, "TRAINED_CATEGORY"], [18566, 18583, "TRAINED_CATEGORY"], [18604, 18628, "TRAINED_CATEGORY"], [18639, 18661, "TRAINED_CATEGORY"], [18681, 18697, "TRAINED_CATEGORY"], [18705, 18709, "TRAINED_CATEGORY"], [18723, 18735, "TRAINED_CATEGORY"], [18737, 18781, "TRAINED_CATEGORY"], [18798, 18804, "TRAINED_CATEGORY"], [18809, 18819, "TRAINED_CATEGORY"], [18840, 18862, "TRAINED_CATEGORY"], [18871, 18882, "TRAINED_CATEGORY"], [18884, 18890, "TRAINED_CATEGORY"], [18902, 18913, "TRAINED_CATEGORY"], [18923, 18948, "TRAINED_CATEGORY"], [18950, 18963, "TRAINED_CATEGORY"], [18989, 19003, "TRAINED_CATEGORY"], [19007, 19022, "TRAINED_CATEGORY"], [19040, 19050, "TRAINED_CATEGORY"], [19054, 19066, "TRAINED_CATEGORY"], [19087, 19108, "TRAINED_CATEGORY"], [19125, 19138, "TRAINED_CATEGORY"], [19150, 19175, "TRAINED_CATEGORY"], [19186, 19199, "TRAINED_CATEGORY"], [19203, 19211, "TRAINED_CATEGORY"], [19212, 19234, "TRAINED_CATEGORY"], [19238, 19249, "TRAINED_CATEGORY"], [19257, 19269, "TRAINED_CATEGORY"], [19271, 19288, "TRAINED_CATEGORY"], [19293, 19314, "TRAINED_CATEGORY"], [19331, 19333, "TRAINED_CATEGORY"], [19339, 19351, "TRAINED_CATEGORY"], [19357, 19371, "TRAINED_CATEGORY"], [19388, 19415, "TRAINED_CATEGORY"], [19417, 19432, "TRAINED_CATEGORY"], [19444, 19458, "TRAINED_CATEGORY"], [19462, 19488, "TRAINED_CATEGORY"], [19503, 19526, "TRAINED_CATEGORY"], [19535, 19543, "TRAINED_CATEGORY"], [19547, 19575, "TRAINED_CATEGORY"], [19588, 19615, "TRAINED_CATEGORY"], [19617, 19635, "TRAINED_CATEGORY"], [19643, 19651, "TRAINED_CATEGORY"], [19655, 19667, "TRAINED_CATEGORY"], [19675, 19684, "TRAINED_CATEGORY"], [19701, 19703, "TRAINED_CATEGORY"], [19724, 19734, "TRAINED_CATEGORY"], [19738, 19750, "TRAINED_CATEGORY"], [19764, 19781, "TRAINED_CATEGORY"], [19815, 19823, "TRAINED_CATEGORY"], [19827, 19835, "TRAINED_CATEGORY"], [19850, 19869, "TRAINED_CATEGORY"], [19878, 19889, "TRAINED_CATEGORY"], [19894, 19904, "TRAINED_CATEGORY"], [19908, 19920, "TRAINED_CATEGORY"], [19944, 19963, "TRAINED_CATEGORY"], [19970, 19978, "TRAINED_CATEGORY"], [20011, 20023, "TRAINED_CATEGORY"], [20024, 20040, "TRAINED_CATEGORY"], [20042, 20049, "TRAINED_CATEGORY"], [20091, 20107, "TRAINED_CATEGORY"], [20109, 20110, "TRAINED_CATEGORY"], [20114, 20115, "TRAINED_CATEGORY"], [20121, 20122, "TRAINED_CATEGORY"], [20126, 20127, "TRAINED_CATEGORY"], [20147, 20166, "TRAINED_CATEGORY"], [20170, 20183, "TRAINED_CATEGORY"], [20197, 20205, "TRAINED_CATEGORY"], [20209, 20225, "TRAINED_CATEGORY"], [20228, 20231, "TRAINED_CATEGORY"], [20250, 20268, "TRAINED_CATEGORY"], [20274, 20287, "TRAINED_CATEGORY"], [20302, 20324, "TRAINED_CATEGORY"], [20337, 20362, "TRAINED_CATEGORY"], [20395, 20404, "TRAINED_CATEGORY"], [20415, 20432, "TRAINED_CATEGORY"], [20453, 20463, "TRAINED_CATEGORY"], [20472, 20488, "TRAINED_CATEGORY"], [20498, 20503, "TRAINED_CATEGORY"], [20521, 20527, "TRAINED_CATEGORY"], [20533, 20545, "TRAINED_CATEGORY"], [20555, 20570, "TRAINED_CATEGORY"], [20583, 20598, "TRAINED_CATEGORY"], [20606, 20622, "TRAINED_CATEGORY"], [20639, 20665, "TRAINED_CATEGORY"], [20683, 20691, "TRAINED_CATEGORY"], [20693, 20695, "TRAINED_CATEGORY"], [20723, 20734, "TRAINED_CATEGORY"], [20746, 20750, "TRAINED_CATEGORY"], [20755, 20760, "TRAINED_CATEGORY"], [20764, 20769, "TRAINED_CATEGORY"], [20786, 20800, "TRAINED_CATEGORY"], [20810, 20822, "TRAINED_CATEGORY"], [20824, 20826, "TRAINED_CATEGORY"], [20860, 20882, "TRAINED_CATEGORY"], [20899, 20902, "TRAINED_CATEGORY"], [20904, 20922, "TRAINED_CATEGORY"], [20932, 20941, "TRAINED_CATEGORY"], [20974, 20985, "TRAINED_CATEGORY"], [21011, 21024, "TRAINED_CATEGORY"], [21028, 21041, "TRAINED_CATEGORY"], [21043, 21054, "TRAINED_CATEGORY"], [21059, 21083, "TRAINED_CATEGORY"], [21084, 21115, "TRAINED_CATEGORY"], [21126, 21134, "TRAINED_CATEGORY"], [21148, 21172, "TRAINED_CATEGORY"], [21177, 21189, "TRAINED_CATEGORY"], [21210, 21218, "TRAINED_CATEGORY"], [21223, 21230, "TRAINED_CATEGORY"], [21242, 21256, "TRAINED_CATEGORY"], [21274, 21284, "TRAINED_CATEGORY"], [21297, 21306, "TRAINED_CATEGORY"], [21316, 21327, "TRAINED_CATEGORY"], [21339, 21356, "TRAINED_CATEGORY"], [21362, 21375, "TRAINED_CATEGORY"], [21381, 21392, "TRAINED_CATEGORY"], [21397, 21405, "TRAINED_CATEGORY"], [21420, 21445, "TRAINED_CATEGORY"], [21449, 21457, "TRAINED_CATEGORY"], [21459, 21474, "TRAINED_CATEGORY"], [21497, 21516, "TRAINED_CATEGORY"], [21522, 21538, "TRAINED_CATEGORY"], [21551, 21577, "TRAINED_CATEGORY"], [21603, 21613, "TRAINED_CATEGORY"], [21617, 21634, "TRAINED_CATEGORY"], [21636, 21657, "TRAINED_CATEGORY"], [21664, 21673, "TRAINED_CATEGORY"], [21682, 21709, "TRAINED_CATEGORY"], [21711, 21723, "TRAINED_CATEGORY"], [21751, 21769, "TRAINED_CATEGORY"], [21779, 21795, "TRAINED_CATEGORY"], [21800, 21828, "TRAINED_CATEGORY"], [21842, 21860, "TRAINED_CATEGORY"], [21872, 21885, "TRAINED_CATEGORY"], [21947, 21966, "TRAINED_CATEGORY"], [21968, 21994, "TRAINED_CATEGORY"], [22017, 22024, "TRAINED_CATEGORY"], [22028, 22041, "TRAINED_CATEGORY"], [22045, 22047, "TRAINED_CATEGORY"], [22052, 22070, "TRAINED_CATEGORY"], [22076, 22078, "TRAINED_CATEGORY"], [22096, 22105, "TRAINED_CATEGORY"], [22111, 22122, "TRAINED_CATEGORY"], [22158, 22173, "TRAINED_CATEGORY"], [22197, 22206, "TRAINED_CATEGORY"], [22214, 22223, "TRAINED_CATEGORY"], [22227, 22247, "TRAINED_CATEGORY"], [22252, 22265, "TRAINED_CATEGORY"], [22269, 22281, "TRAINED_CATEGORY"], [22306, 22316, "TRAINED_CATEGORY"], [22329, 22348, "TRAINED_CATEGORY"], [22356, 22363, "TRAINED_CATEGORY"], [22368, 22374, "TRAINED_CATEGORY"], [22403, 22413, "TRAINED_CATEGORY"], [22418, 22423, "TRAINED_CATEGORY"], [22425, 22427, "TRAINED_CATEGORY"], [22463, 22473, "TRAINED_CATEGORY"], [22478, 22511, "TRAINED_CATEGORY"], [22524, 22534, "TRAINED_CATEGORY"], [22575, 22579, "TRAINED_CATEGORY"], [22619, 22629, "TRAINED_CATEGORY"], [22647, 22655, "TRAINED_CATEGORY"], [22665, 22681, "TRAINED_CATEGORY"], [22686, 22712, "TRAINED_CATEGORY"], [22718, 22725, "TRAINED_CATEGORY"], [22755, 22779, "TRAINED_CATEGORY"], [22795, 22808, "TRAINED_CATEGORY"], [22815, 22825, "TRAINED_CATEGORY"], [22842, 22859, "TRAINED_CATEGORY"], [22861, 22885, "TRAINED_CATEGORY"], [22917, 22927, "TRAINED_CATEGORY"], [22931, 22942, "TRAINED_CATEGORY"], [22949, 22970, "TRAINED_CATEGORY"], [22995, 23026, "TRAINED_CATEGORY"], [23039, 23049, "TRAINED_CATEGORY"], [23053, 23066, "TRAINED_CATEGORY"], [23070, 23085, "TRAINED_CATEGORY"], [23124, 23149, "TRAINED_CATEGORY"], [23151, 23168, "TRAINED_CATEGORY"], [23175, 23188, "TRAINED_CATEGORY"], [23189, 23222, "TRAINED_CATEGORY"], [23224, 23227, "TRAINED_CATEGORY"], [23239, 23249, "TRAINED_CATEGORY"], [23253, 23280, "TRAINED_CATEGORY"], [23284, 23307, "TRAINED_CATEGORY"], [23311, 23323, "TRAINED_CATEGORY"], [23334, 23337, "TRAINED_CATEGORY"], [23367, 23376, "TRAINED_CATEGORY"], [23385, 23402, "TRAINED_CATEGORY"], [23413, 23415, "TRAINED_CATEGORY"], [23431, 23456, "TRAINED_CATEGORY"], [23470, 23494, "TRAINED_CATEGORY"], [23500, 23505, "TRAINED_CATEGORY"], [23510, 23511, "TRAINED_CATEGORY"], [23513, 23516, "TRAINED_CATEGORY"], [23526, 23536, "TRAINED_CATEGORY"], [23540, 23552, "TRAINED_CATEGORY"], [23578, 23580, "TRAINED_CATEGORY"], [23584, 23594, "TRAINED_CATEGORY"], [23596, 23598, "TRAINED_CATEGORY"], [23602, 23604, "TRAINED_CATEGORY"], [23612, 23614, "TRAINED_CATEGORY"], [23618, 23620, "TRAINED_CATEGORY"], [23637, 23649, "TRAINED_CATEGORY"], [23667, 23683, "TRAINED_CATEGORY"], [23687, 23705, "TRAINED_CATEGORY"], [23707, 23709, "TRAINED_CATEGORY"], [23719, 23736, "TRAINED_CATEGORY"], [23750, 23774, "TRAINED_CATEGORY"], [23779, 23781, "TRAINED_CATEGORY"], [23789, 23799, "TRAINED_CATEGORY"], [23800, 23816, "TRAINED_CATEGORY"], [23820, 23832, "TRAINED_CATEGORY"], [23837, 23847, "TRAINED_CATEGORY"], [23871, 23884, "TRAINED_CATEGORY"], [23885, 23888, "TRAINED_CATEGORY"], [23893, 23900, "TRAINED_CATEGORY"], [23906, 23921, "TRAINED_CATEGORY"], [23934, 23947, "TRAINED_CATEGORY"], [23990, 24009, "TRAINED_CATEGORY"], [24117, 24118, "TRAINED_CATEGORY"], [24192, 24240, "TRAINED_CATEGORY"], [24272, 24280, "TRAINED_CATEGORY"], [24313, 24314, "TRAINED_CATEGORY"], [24323, 24324, "TRAINED_CATEGORY"], [24333, 24334, "TRAINED_CATEGORY"], [24352, 24365, "TRAINED_CATEGORY"], [24366, 24372, "TRAINED_CATEGORY"], [24374, 24430, "TRAINED_CATEGORY"], [24462, 24470, "TRAINED_CATEGORY"], [24497, 24530, "TRAINED_CATEGORY"], [24542, 24560, "TRAINED_CATEGORY"], [24566, 24576, "TRAINED_CATEGORY"], [24622, 24633, "TRAINED_CATEGORY"], [24646, 24647, "TRAINED_CATEGORY"], [24664, 24676, "TRAINED_CATEGORY"], [24695, 24696, "TRAINED_CATEGORY"], [24703, 24714, "TRAINED_CATEGORY"], [24728, 24729, "TRAINED_CATEGORY"], [24736, 24747, "TRAINED_CATEGORY"], [24751, 24752, "TRAINED_CATEGORY"], [24757, 24763, "TRAINED_CATEGORY"], [24768, 24771, "TRAINED_CATEGORY"], [24780, 24781, "TRAINED_CATEGORY"], [24785, 24786, "TRAINED_CATEGORY"], [24793, 24804, "TRAINED_CATEGORY"], [24819, 24820, "TRAINED_CATEGORY"], [24849, 24868, "TRAINED_CATEGORY"], [24924, 24936, "TRAINED_CATEGORY"], [25093, 25094, "TRAINED_CATEGORY"], [25180, 25187, "TRAINED_CATEGORY"], [25614, 25615, "TRAINED_CATEGORY"], [25789, 25790, "TRAINED_CATEGORY"], [25819, 25820, "TRAINED_CATEGORY"], [25904, 25928, "TRAINED_CATEGORY"], [25929, 25962, "TRAINED_CATEGORY"], [25964, 26002, "TRAINED_CATEGORY"], [26040, 26069, "TRAINED_CATEGORY"], [26073, 26084, "TRAINED_CATEGORY"], [26086, 26105, "TRAINED_CATEGORY"], [26117, 26141, "TRAINED_CATEGORY"], [26182, 26193, "TRAINED_CATEGORY"], [26194, 26197, "TRAINED_CATEGORY"], [26208, 26224, "TRAINED_CATEGORY"], [26225, 26236, "TRAINED_CATEGORY"], [26242, 26265, "TRAINED_CATEGORY"], [26279, 26286, "TRAINED_CATEGORY"], [26287, 26290, "TRAINED_CATEGORY"], [26295, 26301, "TRAINED_CATEGORY"], [26308, 26310, "TRAINED_CATEGORY"], [26322, 26335, "TRAINED_CATEGORY"], [26340, 26348, "TRAINED_CATEGORY"], [26380, 26382, "TRAINED_CATEGORY"], [26393, 26400, "TRAINED_CATEGORY"], [26401, 26404, "TRAINED_CATEGORY"], [26409, 26415, "TRAINED_CATEGORY"], [26426, 26431, "TRAINED_CATEGORY"], [26452, 26460, "TRAINED_CATEGORY"], [26464, 26490, "TRAINED_CATEGORY"], [26497, 26507, "TRAINED_CATEGORY"], [26511, 26523, "TRAINED_CATEGORY"], [26537, 26547, "TRAINED_CATEGORY"], [26551, 26562, "TRAINED_CATEGORY"], [26564, 26567, "TRAINED_CATEGORY"], [26577, 26594, "TRAINED_CATEGORY"], [26599, 26608, "TRAINED_CATEGORY"], [26615, 26634, "TRAINED_CATEGORY"], [26650, 26660, "TRAINED_CATEGORY"], [26664, 26676, "TRAINED_CATEGORY"], [26694, 26697, "TRAINED_CATEGORY"], [26713, 26730, "TRAINED_CATEGORY"], [26734, 26751, "TRAINED_CATEGORY"], [26763, 26781, "TRAINED_CATEGORY"], [26789, 26792, "TRAINED_CATEGORY"], [26794, 26808, "TRAINED_CATEGORY"], [26819, 26823, "TRAINED_CATEGORY"], [26825, 26836, "TRAINED_CATEGORY"], [26866, 26888, "TRAINED_CATEGORY"], [26892, 26903, "TRAINED_CATEGORY"], [26913, 26928, "TRAINED_CATEGORY"], [26932, 26943, "TRAINED_CATEGORY"], [26967, 26987, "TRAINED_CATEGORY"], [26993, 26999, "TRAINED_CATEGORY"], [27021, 27040, "TRAINED_CATEGORY"], [27084, 27101, "TRAINED_CATEGORY"], [27105, 27124, "TRAINED_CATEGORY"], [27140, 27158, "TRAINED_CATEGORY"], [27170, 27176, "TRAINED_CATEGORY"], [27203, 27222, "TRAINED_CATEGORY"], [27226, 27239, "TRAINED_CATEGORY"], [27240, 27241, "TRAINED_CATEGORY"], [27261, 27262, "TRAINED_CATEGORY"], [27271, 27272, "TRAINED_CATEGORY"], [27276, 27277, "TRAINED_CATEGORY"], [27284, 27295, "TRAINED_CATEGORY"], [27304, 27305, "TRAINED_CATEGORY"], [27309, 27311, "TRAINED_CATEGORY"], [27320, 27326, "TRAINED_CATEGORY"], [27333, 27344, "TRAINED_CATEGORY"], [27353, 27368, "TRAINED_CATEGORY"], [27372, 27384, "TRAINED_CATEGORY"], [27389, 27396, "TRAINED_CATEGORY"], [27400, 27420, "TRAINED_CATEGORY"], [27422, 27424, "TRAINED_CATEGORY"], [27438, 27478, "TRAINED_CATEGORY"], [27489, 27507, "TRAINED_CATEGORY"], [27511, 27531, "TRAINED_CATEGORY"], [27538, 27553, "TRAINED_CATEGORY"], [27558, 27565, "TRAINED_CATEGORY"], [27568, 27571, "TRAINED_CATEGORY"], [27612, 27624, "TRAINED_CATEGORY"], [27628, 27655, "TRAINED_CATEGORY"], [27659, 27667, "TRAINED_CATEGORY"], [27671, 27688, "TRAINED_CATEGORY"], [27697, 27710, "TRAINED_CATEGORY"], [27722, 27739, "TRAINED_CATEGORY"], [27748, 27770, "TRAINED_CATEGORY"], [27780, 27796, "TRAINED_CATEGORY"], [27812, 27818, "TRAINED_CATEGORY"], [27821, 27823, "TRAINED_CATEGORY"], [27847, 27863, "TRAINED_CATEGORY"], [27865, 27877, "TRAINED_CATEGORY"], [27899, 27926, "TRAINED_CATEGORY"], [27927, 27957, "TRAINED_CATEGORY"], [27959, 27968, "TRAINED_CATEGORY"], [28007, 28021, "TRAINED_CATEGORY"], [28026, 28045, "TRAINED_CATEGORY"], [28047, 28056, "TRAINED_CATEGORY"], [28095, 28103, "TRAINED_CATEGORY"], [28107, 28119, "TRAINED_CATEGORY"], [28129, 28152, "TRAINED_CATEGORY"], [28154, 28165, "TRAINED_CATEGORY"], [28166, 28187, "TRAINED_CATEGORY"], [28249, 28260, "TRAINED_CATEGORY"], [28270, 28297, "TRAINED_CATEGORY"], [28322, 28324, "TRAINED_CATEGORY"], [28348, 28367, "TRAINED_CATEGORY"], [28369, 28371, "TRAINED_CATEGORY"], [28395, 28414, "TRAINED_CATEGORY"], [28422, 28426, "TRAINED_CATEGORY"], [28437, 28439, "TRAINED_CATEGORY"], [28454, 28460, "TRAINED_CATEGORY"], [28473, 28493, "TRAINED_CATEGORY"], [28494, 28514, "TRAINED_CATEGORY"], [28519, 28541, "TRAINED_CATEGORY"], [28543, 28550, "TRAINED_CATEGORY"], [28554, 28570, "TRAINED_CATEGORY"], [28574, 28593, "TRAINED_CATEGORY"], [28614, 28624, "TRAINED_CATEGORY"], [28629, 28638, "TRAINED_CATEGORY"], [28642, 28656, "TRAINED_CATEGORY"], [28660, 28668, "TRAINED_CATEGORY"], [28695, 28709, "TRAINED_CATEGORY"], [28711, 28729, "TRAINED_CATEGORY"], [28743, 28754, "TRAINED_CATEGORY"], [28815, 28830, "TRAINED_CATEGORY"], [28839, 28856, "TRAINED_CATEGORY"], [28860, 28877, "TRAINED_CATEGORY"], [28885, 28896, "TRAINED_CATEGORY"], [28898, 28900, "TRAINED_CATEGORY"], [28932, 28944, "TRAINED_CATEGORY"], [28946, 28965, "TRAINED_CATEGORY"], [28972, 28986, "TRAINED_CATEGORY"], [28990, 29009, "TRAINED_CATEGORY"], [29011, 29017, "TRAINED_CATEGORY"], [29022, 29028, "TRAINED_CATEGORY"], [29035, 29048, "TRAINED_CATEGORY"], [29050, 29054, "TRAINED_CATEGORY"], [29060, 29084, "TRAINED_CATEGORY"], [29090, 29112, "TRAINED_CATEGORY"], [29118, 29134, "TRAINED_CATEGORY"], [29148, 29158, "TRAINED_CATEGORY"], [29163, 29184, "TRAINED_CATEGORY"], [29193, 29210, "TRAINED_CATEGORY"], [29216, 29231, "TRAINED_CATEGORY"], [29236, 29243, "TRAINED_CATEGORY"], [29247, 29267, "TRAINED_CATEGORY"], [29275, 29297, "TRAINED_CATEGORY"], [29302, 29318, "TRAINED_CATEGORY"], [29323, 29328, "TRAINED_CATEGORY"], [29349, 29365, "TRAINED_CATEGORY"], [29369, 29386, "TRAINED_CATEGORY"], [29402, 29416, "TRAINED_CATEGORY"], [29433, 29444, "TRAINED_CATEGORY"], [29448, 29467, "TRAINED_CATEGORY"], [29491, 29514, "TRAINED_CATEGORY"], [29520, 29541, "TRAINED_CATEGORY"], [29555, 29564, "TRAINED_CATEGORY"], [29565, 29582, "TRAINED_CATEGORY"], [29596, 29629, "TRAINED_CATEGORY"], [29635, 29644, "TRAINED_CATEGORY"], [29647, 29673, "TRAINED_CATEGORY"], [29678, 29690, "TRAINED_CATEGORY"], [29695, 29702, "TRAINED_CATEGORY"], [29706, 29718, "TRAINED_CATEGORY"], [29739, 29754, "TRAINED_CATEGORY"], [29774, 29792, "TRAINED_CATEGORY"], [29794, 29803, "TRAINED_CATEGORY"], [29807, 29825, "TRAINED_CATEGORY"], [29829, 29838, "TRAINED_CATEGORY"], [29844, 29846, "TRAINED_CATEGORY"], [29871, 29888, "TRAINED_CATEGORY"], [29899, 29921, "TRAINED_CATEGORY"], [29927, 29935, "TRAINED_CATEGORY"], [29944, 29961, "TRAINED_CATEGORY"], [29980, 29992, "TRAINED_CATEGORY"], [29993, 30003, "TRAINED_CATEGORY"], [30072, 30076, "TRAINED_CATEGORY"], [30116, 30120, "TRAINED_CATEGORY"], [30135, 30147, "TRAINED_CATEGORY"], [30175, 30176, "TRAINED_CATEGORY"], [30180, 30181, "TRAINED_CATEGORY"], [30188, 30202, "TRAINED_CATEGORY"], [30206, 30225, "TRAINED_CATEGORY"], [30243, 30268, "TRAINED_CATEGORY"], [30272, 30279, "TRAINED_CATEGORY"], [30284, 30300, "TRAINED_CATEGORY"], [30304, 30319, "TRAINED_CATEGORY"], [30325, 30340, "TRAINED_CATEGORY"], [30342, 30353, "TRAINED_CATEGORY"], [30363, 30379, "TRAINED_CATEGORY"], [30387, 30398, "TRAINED_CATEGORY"], [30403, 30412, "TRAINED_CATEGORY"], [30432, 30441, "TRAINED_CATEGORY"], [30445, 30457, "TRAINED_CATEGORY"], [30476, 30498, "TRAINED_CATEGORY"], [30525, 30538, "TRAINED_CATEGORY"], [30540, 30543, "TRAINED_CATEGORY"], [30553, 30564, "TRAINED_CATEGORY"], [30568, 30579, "TRAINED_CATEGORY"], [30585, 30598, "TRAINED_CATEGORY"], [30603, 30606, "TRAINED_CATEGORY"], [30620, 30621, "TRAINED_CATEGORY"], [30633, 30639, "TRAINED_CATEGORY"], [30643, 30650, "TRAINED_CATEGORY"], [30654, 30665, "TRAINED_CATEGORY"], [30669, 30676, "TRAINED_CATEGORY"], [30685, 30706, "TRAINED_CATEGORY"], [30723, 30731, "TRAINED_CATEGORY"], [30745, 30760, "TRAINED_CATEGORY"], [30764, 30778, "TRAINED_CATEGORY"], [30796, 30808, "TRAINED_CATEGORY"], [30812, 30817, "TRAINED_CATEGORY"], [30821, 30828, "TRAINED_CATEGORY"], [30832, 30852, "TRAINED_CATEGORY"], [30872, 30886, "TRAINED_CATEGORY"], [30888, 30895, "TRAINED_CATEGORY"], [30909, 30924, "TRAINED_CATEGORY"], [30928, 30949, "TRAINED_CATEGORY"], [30967, 30979, "TRAINED_CATEGORY"], [30983, 30988, "TRAINED_CATEGORY"], [30992, 31003, "TRAINED_CATEGORY"], [31007, 31031, "TRAINED_CATEGORY"], [31051, 31061, "TRAINED_CATEGORY"], [31094, 31099, "TRAINED_CATEGORY"], [31101, 31117, "TRAINED_CATEGORY"], [31121, 31135, "TRAINED_CATEGORY"], [31137, 31144, "TRAINED_CATEGORY"], [31289, 31300, "TRAINED_CATEGORY"], [31306, 31327, "TRAINED_CATEGORY"], [31343, 31352, "TRAINED_CATEGORY"], [31354, 31356, "TRAINED_CATEGORY"], [31386, 31390, "TRAINED_CATEGORY"], [31406, 31424, "TRAINED_CATEGORY"], [31447, 31459, "TRAINED_CATEGORY"], [31463, 31476, "TRAINED_CATEGORY"], [31486, 31498, "TRAINED_CATEGORY"], [31525, 31539, "TRAINED_CATEGORY"], [31557, 31585, "TRAINED_CATEGORY"], [31597, 31620, "TRAINED_CATEGORY"], [31624, 31640, "TRAINED_CATEGORY"], [31649, 31686, "TRAINED_CATEGORY"], [31698, 31713, "TRAINED_CATEGORY"], [31732, 31753, "TRAINED_CATEGORY"], [31773, 31790, "TRAINED_CATEGORY"], [31803, 31836, "TRAINED_CATEGORY"], [31864, 31883, "TRAINED_CATEGORY"], [31890, 31909, "TRAINED_CATEGORY"], [31932, 31952, "TRAINED_CATEGORY"], [31969, 31984, "TRAINED_CATEGORY"], [31999, 32008, "TRAINED_CATEGORY"], [32012, 32017, "TRAINED_CATEGORY"], [32028, 32039, "TRAINED_CATEGORY"], [32043, 32060, "TRAINED_CATEGORY"], [32062, 32075, "TRAINED_CATEGORY"], [32081, 32087, "TRAINED_CATEGORY"], [32089, 32091, "TRAINED_CATEGORY"], [32104, 32106, "TRAINED_CATEGORY"], [32145, 32163, "TRAINED_CATEGORY"], [32186, 32208, "TRAINED_CATEGORY"], [32210, 32215, "TRAINED_CATEGORY"], [32242, 32251, "TRAINED_CATEGORY"], [32255, 32264, "TRAINED_CATEGORY"], [32273, 32289, "TRAINED_CATEGORY"], [32323, 32339, "TRAINED_CATEGORY"], [32341, 32367, "TRAINED_CATEGORY"], [32371, 32386, "TRAINED_CATEGORY"], [32404, 32438, "TRAINED_CATEGORY"], [32448, 32450, "TRAINED_CATEGORY"], [32462, 32473, "TRAINED_CATEGORY"], [32477, 32486, "TRAINED_CATEGORY"], [32492, 32497, "TRAINED_CATEGORY"], [32514, 32524, "TRAINED_CATEGORY"], [32528, 32547, "TRAINED_CATEGORY"], [32557, 32578, "TRAINED_CATEGORY"], [32605, 32627, "TRAINED_CATEGORY"], [32631, 32633, "TRAINED_CATEGORY"], [32651, 32664, "TRAINED_CATEGORY"], [32680, 32689, "TRAINED_CATEGORY"], [32693, 32695, "TRAINED_CATEGORY"], [32706, 32720, "TRAINED_CATEGORY"], [32724, 32733, "TRAINED_CATEGORY"], [32742, 32757, "TRAINED_CATEGORY"], [32761, 32795, "TRAINED_CATEGORY"], [32796, 32816, "TRAINED_CATEGORY"], [32820, 32825, "TRAINED_CATEGORY"], [32829, 32832, "TRAINED_CATEGORY"], [32839, 32849, "TRAINED_CATEGORY"], [32862, 32871, "TRAINED_CATEGORY"], [32882, 32894, "TRAINED_CATEGORY"], [32908, 32919, "TRAINED_CATEGORY"], [32923, 32934, "TRAINED_CATEGORY"], [32938, 32950, "TRAINED_CATEGORY"], [32952, 32963, "TRAINED_CATEGORY"], [32975, 32982, "TRAINED_CATEGORY"], [32986, 32993, "TRAINED_CATEGORY"], [32997, 33010, "TRAINED_CATEGORY"], [33017, 33021, "TRAINED_CATEGORY"], [33029, 33033, "TRAINED_CATEGORY"], [33037, 33040, "TRAINED_CATEGORY"], [33048, 33057, "TRAINED_CATEGORY"], [33063, 33068, "TRAINED_CATEGORY"], [33084, 33094, "TRAINED_CATEGORY"], [33111, 33125, "TRAINED_CATEGORY"], [33133, 33158, "TRAINED_CATEGORY"], [33162, 33175, "TRAINED_CATEGORY"], [33186, 33195, "TRAINED_CATEGORY"], [33209, 33213, "TRAINED_CATEGORY"], [33227, 33231, "TRAINED_CATEGORY"], [33232, 33243, "TRAINED_CATEGORY"], [33274, 33289, "TRAINED_CATEGORY"], [33293, 33307, "TRAINED_CATEGORY"], [33313, 33325, "TRAINED_CATEGORY"], [33345, 33354, "TRAINED_CATEGORY"], [33365, 33379, "TRAINED_CATEGORY"], [33380, 33394, "TRAINED_CATEGORY"], [33395, 33405, "TRAINED_CATEGORY"], [33409, 33426, "TRAINED_CATEGORY"], [33432, 33437, "TRAINED_CATEGORY"], [33446, 33456, "TRAINED_CATEGORY"], [33460, 33465, "TRAINED_CATEGORY"], [33467, 33477, "TRAINED_CATEGORY"], [33487, 33499, "TRAINED_CATEGORY"], [33503, 33514, "TRAINED_CATEGORY"], [33518, 33532, "TRAINED_CATEGORY"], [33534, 33538, "TRAINED_CATEGORY"], [33541, 33548, "TRAINED_CATEGORY"], [33552, 33569, "TRAINED_CATEGORY"], [33608, 33613, "TRAINED_CATEGORY"], [33637, 33654, "TRAINED_CATEGORY"], [33659, 33679, "TRAINED_CATEGORY"], [33697, 33702, "TRAINED_CATEGORY"], [33704, 33714, "TRAINED_CATEGORY"], [33716, 33719, "TRAINED_CATEGORY"], [33721, 33731, "TRAINED_CATEGORY"], [33733, 33741, "TRAINED_CATEGORY"], [33743, 33749, "TRAINED_CATEGORY"], [33764, 33772, "TRAINED_CATEGORY"], [33776, 33789, "TRAINED_CATEGORY"], [33794, 33801, "TRAINED_CATEGORY"], [33806, 33828, "TRAINED_CATEGORY"], [33840, 33872, "TRAINED_CATEGORY"], [33874, 33888, "TRAINED_CATEGORY"], [33890, 33898, "TRAINED_CATEGORY"], [33900, 33905, "TRAINED_CATEGORY"], [33907, 33912, "TRAINED_CATEGORY"], [33914, 33919, "TRAINED_CATEGORY"], [33920, 33943, "TRAINED_CATEGORY"], [33947, 33969, "TRAINED_CATEGORY"], [33975, 33980, "TRAINED_CATEGORY"], [33982, 33985, "TRAINED_CATEGORY"], [33988, 33996, "TRAINED_CATEGORY"], [34018, 34025, "TRAINED_CATEGORY"], [34034, 34044, "TRAINED_CATEGORY"], [34084, 34093, "TRAINED_CATEGORY"], [34097, 34116, "TRAINED_CATEGORY"], [34118, 34129, "TRAINED_CATEGORY"], [34131, 34135, "TRAINED_CATEGORY"], [34144, 34163, "TRAINED_CATEGORY"], [34167, 34196, "TRAINED_CATEGORY"], [34198, 34202, "TRAINED_CATEGORY"], [34205, 34220, "TRAINED_CATEGORY"], [34266, 34284, "TRAINED_CATEGORY"], [34297, 34321, "TRAINED_CATEGORY"], [34323, 34337, "TRAINED_CATEGORY"], [34340, 34344, "TRAINED_CATEGORY"], [34346, 34350, "TRAINED_CATEGORY"], [34359, 34374, "TRAINED_CATEGORY"], [34378, 34386, "TRAINED_CATEGORY"], [34388, 34414, "TRAINED_CATEGORY"], [34416, 34420, "TRAINED_CATEGORY"], [34437, 34448, "TRAINED_CATEGORY"], [34459, 34470, "TRAINED_CATEGORY"], [34472, 34506, "TRAINED_CATEGORY"], [34512, 34533, "TRAINED_CATEGORY"], [34537, 34554, "TRAINED_CATEGORY"], [34561, 34566, "TRAINED_CATEGORY"], [34568, 34573, "TRAINED_CATEGORY"], [34575, 34584, "TRAINED_CATEGORY"], [34602, 34608, "TRAINED_CATEGORY"], [34612, 34619, "TRAINED_CATEGORY"], [34624, 34631, "TRAINED_CATEGORY"], [34635, 34649, "TRAINED_CATEGORY"], [34651, 34661, "TRAINED_CATEGORY"], [34670, 34687, "TRAINED_CATEGORY"], [34691, 34710, "TRAINED_CATEGORY"], [34715, 34743, "TRAINED_CATEGORY"], [34750, 34776, "TRAINED_CATEGORY"], [34779, 34785, "TRAINED_CATEGORY"], [34805, 34820, "TRAINED_CATEGORY"], [34822, 34826, "TRAINED_CATEGORY"], [34841, 34844, "TRAINED_CATEGORY"], [34846, 34851, "TRAINED_CATEGORY"], [34860, 34879, "TRAINED_CATEGORY"], [34884, 34901, "TRAINED_CATEGORY"], [34906, 34910, "TRAINED_CATEGORY"], [34924, 34941, "TRAINED_CATEGORY"], [34945, 34965, "TRAINED_CATEGORY"], [34986, 35005, "TRAINED_CATEGORY"], [35007, 35012, "TRAINED_CATEGORY"], [35035, 35050, "TRAINED_CATEGORY"], [35069, 35071, "TRAINED_CATEGORY"], [35092, 35115, "TRAINED_CATEGORY"], [35120, 35143, "TRAINED_CATEGORY"], [35144, 35146, "TRAINED_CATEGORY"], [35174, 35177, "TRAINED_CATEGORY"], [35179, 35192, "TRAINED_CATEGORY"], [35201, 35218, "TRAINED_CATEGORY"], [35223, 35237, "TRAINED_CATEGORY"], [35239, 35248, "TRAINED_CATEGORY"], [35250, 35263, "TRAINED_CATEGORY"], [35265, 35297, "TRAINED_CATEGORY"], [35299, 35313, "TRAINED_CATEGORY"], [35315, 35321, "TRAINED_CATEGORY"], [35323, 35330, "TRAINED_CATEGORY"], [35339, 35352, "TRAINED_CATEGORY"], [35357, 35372, "TRAINED_CATEGORY"], [35376, 35388, "TRAINED_CATEGORY"], [35390, 35398, "TRAINED_CATEGORY"], [35400, 35426, "TRAINED_CATEGORY"], [35428, 35460, "TRAINED_CATEGORY"], [35462, 35476, "TRAINED_CATEGORY"], [35478, 35480, "TRAINED_CATEGORY"], [35482, 35491, "TRAINED_CATEGORY"], [35500, 35517, "TRAINED_CATEGORY"], [35521, 35536, "TRAINED_CATEGORY"], [35539, 35554, "TRAINED_CATEGORY"], [35573, 35591, "TRAINED_CATEGORY"], [35604, 35628, "TRAINED_CATEGORY"], [35630, 35638, "TRAINED_CATEGORY"], [35640, 35653, "TRAINED_CATEGORY"], [35660, 35674, "TRAINED_CATEGORY"], [35678, 35699, "TRAINED_CATEGORY"], [35718, 35743, "TRAINED_CATEGORY"], [35747, 35757, "TRAINED_CATEGORY"], [35758, 35765, "TRAINED_CATEGORY"], [35769, 35780, "TRAINED_CATEGORY"], [35791, 35814, "TRAINED_CATEGORY"], [35818, 35844, "TRAINED_CATEGORY"], [35846, 35855, "TRAINED_CATEGORY"], [35865, 35884, "TRAINED_CATEGORY"], [35888, 35917, "TRAINED_CATEGORY"], [35919, 35923, "TRAINED_CATEGORY"], [35926, 35939, "TRAINED_CATEGORY"], [35944, 35951, "TRAINED_CATEGORY"], [35970, 35995, "TRAINED_CATEGORY"], [35997, 36002, "TRAINED_CATEGORY"], [36013, 36021, "TRAINED_CATEGORY"], [36023, 36029, "TRAINED_CATEGORY"], [36031, 36035, "TRAINED_CATEGORY"], [36045, 36068, "TRAINED_CATEGORY"], [36072, 36101, "TRAINED_CATEGORY"], [36104, 36115, "TRAINED_CATEGORY"], [36119, 36137, "TRAINED_CATEGORY"], [36156, 36185, "TRAINED_CATEGORY"], [36187, 36191, "TRAINED_CATEGORY"], [36193, 36202, "TRAINED_CATEGORY"], [36204, 36207, "TRAINED_CATEGORY"], [36209, 36217, "TRAINED_CATEGORY"], [36252, 36257, "TRAINED_CATEGORY"], [36264, 36292, "TRAINED_CATEGORY"], [36295, 36318, "TRAINED_CATEGORY"], [36341, 36352, "TRAINED_CATEGORY"], [36353, 36373, "TRAINED_CATEGORY"], [36375, 36385, "TRAINED_CATEGORY"], [36387, 36395, "TRAINED_CATEGORY"], [36408, 36446, "TRAINED_CATEGORY"], [36449, 36456, "TRAINED_CATEGORY"], [36461, 36469, "TRAINED_CATEGORY"], [36488, 36499, "TRAINED_CATEGORY"], [36499, 36510, "TRAINED_CATEGORY"], [36512, 36522, "TRAINED_CATEGORY"], [36524, 36532, "TRAINED_CATEGORY"], [36545, 36568, "TRAINED_CATEGORY"], [36576, 36588, "TRAINED_CATEGORY"], [36591, 36598, "TRAINED_CATEGORY"], [36603, 36611, "TRAINED_CATEGORY"], [36630, 36652, "TRAINED_CATEGORY"], [25, 30, "ORG"], [91, 96, "ORG"], [165, 178, "CARDINAL"], [439, 445, "ORG"], [598, 605, "ORG"], [670, 675, "WORK_OF_ART"], [685, 698, "PERSON"], [778, 782, "DATE"], [788, 801, "ORG"], [857, 903, "WORK_OF_ART"], [1013, 1018, "CARDINAL"], [1585, 1592, "PERSON"], [1611, 1616, "ORG"], [1741, 1746, "ORG"], [1826, 1829, "CARDINAL"], [1976, 1979, "CARDINAL"], [1983, 1986, "CARDINAL"], [1988, 1991, "CARDINAL"], [2148, 2153, "ORG"], [2396, 2399, "CARDINAL"], [2733, 2738, "ORG"], [3208, 3213, "ORG"], [3266, 3278, "CARDINAL"], [3291, 3305, "CARDINAL"], [3877, 3880, "ORG"], [4289, 4294, "ORDINAL"], [4970, 4983, "DATE"], [4996, 5001, "ORG"], [5073, 5079, "ORG"], [5438, 5441, "ORG"], [5457, 5463, "ORG"], [5484, 5490, "ORG"], [5539, 5542, "ORG"], [5626, 5629, "ORG"], [5639, 5642, "ORG"], [5657, 5662, "CARDINAL"], [5934, 5937, "ORG"], [5961, 5966, "ORG"], [5999, 6003, "DATE"], [6010, 6012, "CARDINAL"], [6233, 6236, "ORG"], [6262, 6265, "CARDINAL"], [6277, 6280, "CARDINAL"], [6307, 6310, "ORG"], [6325, 6328, "CARDINAL"], [6383, 6386, "CARDINAL"], [6509, 6512, "ORG"], [6607, 6608, "CARDINAL"], [6630, 6631, "CARDINAL"], [6721, 6724, "ORG"], [6726, 6729, "ORG"], [6760, 6763, "ORG"], [6791, 6796, "ORG"], [6805, 6808, "ORG"], [7045, 7046, "ORG"], [7258, 7259, "PRODUCT"], [7526, 7546, "PRODUCT"], [7624, 7636, "ORG"], [7645, 7647, "ORG"], [7749, 7754, "ORG"], [7839, 7850, "CARDINAL"], [7880, 7885, "CARDINAL"], [7938, 7944, "ORG"], [8034, 8036, "ORG"], [8087, 8089, "PRODUCT"], [8094, 8096, "ORG"], [8245, 8246, "CARDINAL"], [8281, 8283, "ORG"], [8287, 8292, "PRODUCT"], [8381, 8383, "PRODUCT"], [8388, 8390, "ORG"], [8454, 8457, "CARDINAL"], [8486, 8488, "ORG"], [8502, 8504, "ORG"], [8583, 8585, "LOC"], [8592, 8594, "PERSON"], [8649, 8651, "ORG"], [8668, 8670, "ORG"], [8678, 8686, "ORG"], [8705, 8708, "CARDINAL"], [8729, 8744, "ORG"], [9217, 9220, "ORG"], [9561, 9564, "CARDINAL"], [9625, 9630, "CARDINAL"], [9684, 9689, "ORDINAL"], [10176, 10177, "CARDINAL"], [10201, 10202, "CARDINAL"], [10244, 10245, "CARDINAL"], [10287, 10288, "CARDINAL"], [10317, 10318, "CARDINAL"], [10323, 10324, "CARDINAL"], [10708, 10713, "CARDINAL"], [10797, 10800, "ORG"], [11006, 11009, "CARDINAL"], [11330, 11343, "ORG"], [11494, 11499, "CARDINAL"], [11599, 11600, "CARDINAL"], [11644, 11645, "CARDINAL"], [11665, 11668, "CARDINAL"], [11746, 11749, "CARDINAL"], [11849, 11852, "CARDINAL"], [12445, 12447, "ORG"], [12597, 12600, "ORG"], [12734, 12747, "ORG"], [12800, 12803, "ORG"], [12936, 12941, "CARDINAL"], [13139, 13142, "CARDINAL"], [13147, 13150, "CARDINAL"], [13187, 13192, "ORDINAL"], [13352, 13355, "CARDINAL"], [13433, 13438, "NORP"], [13751, 13754, "CARDINAL"], [13796, 13802, "ORG"], [13803, 13805, "GPE"], [14194, 14199, "ORG"], [14476, 14481, "ORG"], [14545, 14550, "ORG"], [14867, 14870, "ORG"], [14963, 14966, "ORG"], [15015, 15018, "CARDINAL"], [15128, 15131, "ORG"], [15241, 15242, "CARDINAL"], [15262, 15263, "CARDINAL"], [15283, 15284, "CARDINAL"], [15558, 15570, "NORP"], [15670, 15673, "ORG"], [15798, 15801, "ORG"], [15874, 15877, "CARDINAL"], [15898, 15901, "CARDINAL"], [16042, 16047, "ORG"], [16393, 16398, "ORDINAL"], [16437, 16443, "PERSON"], [16497, 16500, "ORG"], [16518, 16521, "ORG"], [16732, 16735, "CARDINAL"], [16758, 16763, "ORG"], [16906, 16909, "CARDINAL"], [16923, 16926, "CARDINAL"], [16983, 16986, "CARDINAL"], [17001, 17007, "QUANTITY"], [17217, 17231, "PERSON"], [17355, 17368, "WORK_OF_ART"], [17397, 17401, "DATE"], [17488, 17493, "ORG"], [17638, 17641, "CARDINAL"], [17701, 17706, "ORG"], [17820, 17830, "ORG"], [18124, 18127, "CARDINAL"], [18319, 18322, "CARDINAL"], [18358, 18363, "ORG"], [18438, 18444, "PERSON"], [18449, 18459, "PERSON"], [18481, 18484, "CARDINAL"], [18604, 18609, "ORG"], [18798, 18804, "PERSON"], [18809, 18819, "ORG"], [18884, 18890, "PERSON"], [19007, 19012, "ORG"], [19087, 19095, "CARDINAL"], [19125, 19128, "DATE"], [19388, 19402, "CARDINAL"], [19417, 19422, "ORG"], [19547, 19562, "CARDINAL"], [19588, 19602, "CARDINAL"], [19617, 19625, "PERSON"], [19793, 19801, "PERSON"], [19948, 19956, "PERSON"], [20151, 20159, "PERSON"], [20187, 20188, "CARDINAL"], [20209, 20213, "CARDINAL"], [20250, 20258, "PERSON"], [20302, 20311, "CARDINAL"], [20388, 20391, "CARDINAL"], [20417, 20425, "PERSON"], [20433, 20447, "CARDINAL"], [20498, 20503, "ORG"], [20555, 20560, "WORK_OF_ART"], [20606, 20609, "CARDINAL"], [20639, 20652, "CARDINAL"], [20810, 20815, "ORDINAL"], [20865, 20871, "PERSON"], [20899, 20902, "ORG"], [21449, 21452, "CARDINAL"], [21459, 21464, "ORG"], [21711, 21723, "PERSON"], [21751, 21759, "CARDINAL"], [21842, 21847, "ORG"], [23087, 23116, "WORK_OF_ART"], [23224, 23227, "CARDINAL"], [23334, 23337, "CARDINAL"], [23470, 23478, "ORG"], [23578, 23580, "PRODUCT"], [23596, 23598, "PRODUCT"], [23602, 23604, "ORG"], [23750, 23755, "ORG"], [23970, 23975, "ORDINAL"], [24229, 24230, "ORG"], [24323, 24324, "ORG"], [24419, 24420, "ORG"], [24462, 24468, "ORG"], [24542, 24547, "ORG"], [24646, 24647, "ORG"], [24751, 24752, "ORG"], [24828, 24834, "ORDINAL"], [25132, 25158, "PERSON"], [25614, 25615, "ORG"], [25628, 25629, "CARDINAL"], [25904, 25928, "WORK_OF_ART"], [25979, 26002, "PERSON"], [26117, 26122, "ORG"], [26426, 26431, "PERSON"], [26564, 26567, "CARDINAL"], [26619, 26627, "PERSON"], [26763, 26768, "ORG"], [26789, 26792, "ORG"], [26798, 26803, "PERSON"], [26971, 26977, "ORG"], [26993, 26999, "PERSON"], [27001, 27005, "DATE"], [27140, 27145, "ORG"], [27170, 27176, "ORG"], [27333, 27344, "PERSON"], [27404, 27410, "ORG"], [27511, 27531, "FAC"], [27697, 27703, "ORG"], [28158, 28165, "ORG"], [28270, 28284, "CARDINAL"], [28695, 28698, "CARDINAL"], [28715, 28720, "ORDINAL"], [28950, 28956, "ORDINAL"], [29011, 29017, "GPE"], [29022, 29028, "GPE"], [29216, 29224, "PERSON"], [29253, 29256, "CARDINAL"], [29323, 29328, "ORG"], [29520, 29533, "CARDINAL"], [29565, 29570, "ORG"], [29965, 29966, "CARDINAL"], [29968, 29969, "DATE"], [29971, 29972, "DATE"], [29974, 29975, "CARDINAL"], [30041, 30045, "CARDINAL"], [30047, 30053, "CARDINAL"], [30055, 30058, "CARDINAL"], [30060, 30061, "DATE"], [30099, 30101, "DATE"], [30103, 30105, "DATE"], [30107, 30108, "DATE"], [30110, 30114, "CARDINAL"], [30304, 30309, "ORG"], [30514, 30517, "CARDINAL"], [30723, 30731, "PERSON"], [30733, 30737, "DATE"], [30872, 30886, "PERSON"], [30897, 30901, "DATE"], [31051, 31061, "PERSON"], [31406, 31411, "ORG"], [31624, 31629, "ORG"], [31698, 31703, "ORG"], [31773, 31780, "ORG"], [32043, 32060, "PERSON"], [32062, 32075, "PERSON"], [32217, 32221, "DATE"], [32223, 32233, "LAW"], [32273, 32289, "DATE"], [32371, 32376, "ORG"], [32425, 32438, "PERSON"], [32442, 32446, "DATE"], [32492, 32497, "ORG"], [32514, 32524, "NORP"], [32557, 32578, "ORG"], [32651, 32656, "ORG"], [32803, 32808, "NORP"], [32997, 33010, "DATE"], [33012, 33013, "CARDINAL"], [33035, 33036, "CARDINAL"], [33084, 33087, "CARDINAL"], [33113, 33119, "DATE"], [33176, 33185, "DATE"], [33345, 33354, "ORG"], [33432, 33437, "PRODUCT"], [33460, 33465, "ORG"], [33467, 33477, "PERSON"], [33479, 33483, "DATE"], [33487, 33532, "WORK_OF_ART"], [33541, 33569, "ORG"], [33571, 33573, "CARDINAL"], [33575, 33576, "CARDINAL"], [33579, 33586, "CARDINAL"], [33608, 33621, "PERSON"], [33659, 33673, "DATE"], [33697, 33702, "ORG"], [33704, 33714, "PERSON"], [33721, 33731, "PERSON"], [33733, 33741, "GPE"], [33743, 33749, "GPE"], [33751, 33754, "CARDINAL"], [33757, 33761, "DATE"], [33803, 33804, "CARDINAL"], [33806, 33815, "GPE"], [33817, 33828, "GPE"], [33845, 33848, "CARDINAL"], [33890, 33898, "ORG"], [33900, 33905, "PERSON"], [33907, 33912, "PERSON"], [33951, 33959, "NORP"], [33975, 33996, "ORG"], [33998, 34002, "DATE"], [34008, 34013, "PERSON"], [34059, 34069, "PERSON"], [34118, 34129, "PERSON"], [34131, 34135, "PERSON"], [34137, 34141, "DATE"], [34145, 34150, "CARDINAL"], [34167, 34196, "ORG"], [34205, 34220, "ORG"], [34222, 34224, "CARDINAL"], [34226, 34227, "CARDINAL"], [34230, 34237, "CARDINAL"], [34297, 34302, "ORG"], [34340, 34344, "PERSON"], [34346, 34350, "PERSON"], [34352, 34356, "DATE"], [34359, 34386, "ORG"], [34388, 34414, "ORG"], [34450, 34506, "WORK_OF_ART"], [34537, 34554, "ORG"], [34568, 34573, "PERSON"], [34575, 34584, "PERSON"], [34586, 34590, "DATE"], [34651, 34661, "PERSON"], [34805, 34810, "ORG"], [34853, 34857, "DATE"], [34945, 34965, "ORG"], [34971, 34974, "CARDINAL"], [34977, 34984, "CARDINAL"], [35007, 35020, "PERSON"], [35035, 35040, "ORG"], [35179, 35192, "PERSON"], [35194, 35198, "DATE"], [35239, 35248, "PERSON"], [35250, 35263, "GPE"], [35270, 35273, "CARDINAL"], [35315, 35321, "PERSON"], [35323, 35330, "PERSON"], [35332, 35336, "DATE"], [35390, 35399, "GPE"], [35400, 35426, "ORG"], [35433, 35436, "CARDINAL"], [35478, 35480, "PERSON"], [35482, 35491, "PERSON"], [35493, 35497, "DATE"], [35503, 35506, "CARDINAL"], [35521, 35526, "ORG"], [35556, 35558, "CARDINAL"], [35560, 35561, "CARDINAL"], [35564, 35571, "CARDINAL"], [35604, 35609, "ORG"], [35640, 35653, "ORG"], [35660, 35668, "ORG"], [35678, 35683, "ORG"], [35769, 35780, "PERSON"], [35835, 35844, "GPE"], [35846, 35855, "PERSON"], [35857, 35861, "DATE"], [35888, 35917, "ORG"], [35926, 35951, "ORG"], [35953, 35955, "CARDINAL"], [35957, 35958, "CARDINAL"], [35961, 35968, "CARDINAL"], [35997, 36011, "PERSON"], [36013, 36021, "ORG"], [36023, 36029, "PERSON"], [36031, 36035, "PERSON"], [36037, 36041, "DATE"], [36045, 36101, "WORK_OF_ART"], [36104, 36137, "ORG"], [36139, 36141, "CARDINAL"], [36143, 36144, "CARDINAL"], [36147, 36154, "CARDINAL"], [36187, 36191, "GPE"], [36193, 36202, "GPE"], [36204, 36207, "PERSON"], [36219, 36223, "DATE"], [36242, 36259, "WORK_OF_ART"], [36264, 36292, "ORG"], [36295, 36318, "ORG"], [36320, 36323, "CARDINAL"], [36325, 36327, "CARDINAL"], [36375, 36385, "PERSON"], [36387, 36401, "PERSON"], [36471, 36473, "CARDINAL"], [36475, 36476, "CARDINAL"], [36479, 36486, "CARDINAL"], [36512, 36522, "PERSON"], [36524, 36532, "PERSON"], [36534, 36538, "DATE"], [36613, 36615, "CARDINAL"], [36617, 36618, "CARDINAL"], [36621, 36628, "CARDINAL"]]}], ["In psychology, decision-making (also spelled decision making and decisionmaking) is regarded as the cognitive process resulting in the selection of a belief or a course of action among several possible alternative options. Decision-making is the process of identifying and choosing alternatives based on the values, preferences and beliefs of the decision-maker. Every decision-making process produces a final choice, which may or may not prompt action.\nResearch about decision-making is also published under the label problem solving, particularly in European psychological research.\n\n\n== Overview ==\nDecision-making can be regarded as a problem-solving activity yielding a solution deemed to be optimal, or at least satisfactory. It is therefore a process which can be more or less rational or irrational and can be based on explicit or tacit knowledge and beliefs. Tacit knowledge is often used to fill the gaps in complex decision making processes. Usually both of these types of knowledge, tacit and explicit, are used together in the decision-making process.\nHuman performance has been the subject of active research from several perspectives:\n\nPsychological: examining individual decisions in the context of a set of needs, preferences and values the individual has or seeks.\nCognitive: the decision-making process regarded as a continuous process integrated in the interaction with the environment.\nNormative: the analysis of individual decisions concerned with the logic of decision-making, or communicative rationality, and the invariant choice it leads to.A major part of decision-making involves the analysis of a finite set of alternatives described in terms of evaluative criteria. Then the task might be to rank these alternatives in terms of how attractive they are to the decision-maker(s) when all the criteria are considered simultaneously. Another task might be to find the best alternative or to determine the relative total priority of each alternative (for instance, if alternatives represent projects competing for funds) when all the criteria are considered simultaneously. Solving such problems is the focus of multiple-criteria decision analysis (MCDA). This area of decision-making, although very old, has attracted the interest of many researchers and practitioners and is still highly debated as there are many MCDA methods which may yield very different results when they are applied on exactly the same data. This leads to the formulation of a decision-making paradox. Logical decision-making is an important part of all science-based professions, where specialists apply their knowledge in a given area to make informed decisions. For example, medical decision-making often involves a diagnosis and the selection of appropriate treatment. But naturalistic decision-making research shows that in situations with higher time pressure, higher stakes, or increased ambiguities, experts may use intuitive decision-making rather than structured approaches. They may follow a recognition primed decision that fits their experience and arrive at a course of action without weighing alternatives.The decision-maker's environment can play a part in the decision-making process. For example, environmental complexity is a factor that influences cognitive function. A complex environment is an environment with a large number of different possible states which come and go over time. Studies done at the University of Colorado have shown that more complex environments correlate with higher cognitive function, which means that a decision can be influenced by the location. One experiment measured complexity in a room by the number of small objects and appliances present; a simple room had less of those things. Cognitive function was greatly affected by the higher measure of environmental complexity making it easier to think about the situation and make a better decision.\n\n\n== Problem solving vs. decision making ==\nIt is important to differentiate between problem solving, or problem analysis, and decision-making. Problem solving is the process of investigating the given information and finding all possible solutions through invention or discovery. Traditionally, it is argued that problem solving is a step towards decision making, so that the information gathered in that process may be used towards decision-making.\nCharacteristics of problem solving\nProblems are merely deviations from performance standards\nProblems must be precisely identified and described\nProblems are caused by a change from a distinctive feature\nSomething can always be used to distinguish between what has and hasn't been affected by a cause\nCauses of problems can be deduced from relevant changes found in analyzing the problem\nMost likely cause of a problem is the one that exactly explains all the facts, while having the fewest (or weakest) assumptions (Occam's razor).Characteristics of decision-making\nObjectives must first be established\nObjectives must be classified and placed in order of importance\nAlternative actions must be developed\nThe alternatives must be evaluated against all the objectives\nThe alternative that is able to achieve all the objectives is the tentative decision\nThe tentative decision is evaluated for more possible consequences\nThe decisive actions are taken, and additional actions are taken to prevent any adverse consequences from becoming problems and starting both systems (problem analysis and decision-making) all over again\nThere are steps that are generally followed that result in a decision model that can be used to determine an optimal production plan\nIn a situation featuring conflict, role-playing may be helpful for predicting decisions to be made by involved parties\n\n\n=== Analysis paralysis ===\n\nWhen a group or individual is unable to make it through the problem-solving step on the way to making a decision, they could be experiencing analysis paralysis. Analysis paralysis is the state that a person enters where they are unable to make a decision, in effect paralyzing the outcome. Some of the main causes for analysis paralysis is the overwhelming flood of incoming data or the tendency to overanalyze the situation at hand. According to Lon Roberts, there are three different types of analysis paralysis.\nThe first is analysis process paralysis. This type of paralysis is often spoken of as a cyclical process. One is unable to make a decision because they get stuck go over the information again and again for fear of making the wrong decision.\nThe second is decision precision paralysis. This paralysis is cyclical, just like the first one, but instead of going over the same information, the decision-maker will find new questions and information from their analysis and that will lead them to explore into further possibilities rather than making a decision.\nThe third is risk uncertainty paralysis. This paralysis occurs when the decision-maker wants to eliminate any uncertainty but the examination of provided information is unable to get rid of all uncertainty.\n\n\n=== Extinction by instinct ===\nOn the opposite side of analysis paralysis is the phenomenon called extinction by instinct. Extinction by instinct is the state that a person is in when they make careless decisions without detailed planning or thorough systematic processes. Extinction by instinct can possibly be fixed by implementing a structural system, like checks and balances. into a group or one\u2019s life. Analysis paralysis is the exact opposite where a group\u2019s schedule could be saturated by too much of a structural checks and balance system.Extinction by instinct in a group setting\nGroupthink is another occurrence that falls under the idea of extinction by instinct. According to Irving L. Janis, groupthink is when members in a group become more involved in the \u201cvalue of the group (and their being part of it) higher than anything else\u201d; thus, creating a habit of making decisions quickly and unanimously. In other words, a group stuck in groupthink are participating in the phenomenon of extinction by instinct.\n\n\n=== Information overload ===\n\nInformation overload is \"a gap between the volume of information and the tools we have to assimilate\" it. Information used in decision making is to reduce or eliminate uncertainty. Excessive information affects problem processing and tasking, which affects decision-making. Psychologist George Armitage Miller suggests that humans\u2019 decision making becomes inhibited because human brains can only hold a limited amount of information. Crystal C. Hall and colleagues described an \"illusion of knowledge\", which means that as individuals encounter too much knowledge it can interfere with their ability to make rational decisions. Other names for information overload are information anxiety, information explosion, infobesity, and infoxication.\n\n\n=== Decision fatigue ===\n\nDecision fatigue is when a sizable amount of decision-making leads to a decline in decision-making skills. People who make decisions in an extended period of time begin to lose mental energy needed to analyze all possible solutions. It is speculated that decision fatigue only happens to those who believe willpower has a limited capacity. Impulsive decision-making or decision avoidance are two possible paths that extend from decision fatigue. Impulse decisions are made more often when a person is tired of analysis situations or solutions; the solution they make is to act and not think. Decision avoidance is when a person evades the situation entirely by not ever making a decision. Decision avoidance is different from analysis paralysis because this sensation is about avoiding the situation entirely, while analysis paralysis is continually looking at the decisions to be made but still unable to make a choice.\n\n\n=== Post-decision analysis ===\nEvaluation and analysis of past decisions is complementary to decision-making. See also Mental accounting and Postmortem documentation.\n\n\n== Neuroscience ==\nDecision-making is a region of intense study in the fields of systems neuroscience, and cognitive neuroscience. Several brain structures, including the anterior cingulate cortex (ACC), orbitofrontal cortex and the overlapping ventromedial prefrontal cortex are believed to be involved in decision-making processes. A neuroimaging study found distinctive patterns of neural activation in these regions depending on whether decisions were made on the basis of perceived personal volition or following directions from someone else. Patients with damage to the ventromedial prefrontal cortex have difficulty making advantageous decisions.A common laboratory paradigm for studying neural decision-making is the two-alternative forced choice task (2AFC), in which a subject has to choose between two alternatives within a certain time. A study of a two-alternative forced choice task involving rhesus monkeys found that neurons in the parietal cortex not only represent the formation of a decision but also signal the degree of certainty (or \"confidence\") associated with the decision. Another recent study found that lesions to the ACC in the macaque resulted in impaired decision-making in the long run of reinforcement guided tasks suggesting that the ACC may be involved in evaluating past reinforcement information and guiding future action. A 2012 study found that rats and humans can optimally accumulate incoming sensory evidence, to make statistically optimal decisions.\n\n\n=== Emotions ===\n\nEmotion appears able to aid the decision-making process. Decision-making often occurs in the face of uncertainty about whether one's choices will lead to benefit or harm (see also Risk). The somatic marker hypothesis is a neurobiological theory of how decisions are made in the face of uncertain outcome. This theory holds that such decisions are aided by emotions, in the form of bodily states, that are elicited during the deliberation of future consequences and that mark different options for behavior as being advantageous or disadvantageous. This process involves an interplay between neural systems that elicit emotional/bodily states and neural systems that map these emotional/bodily states. A recent lesion mapping study of 152 patients with focal brain lesions conducted by Aron K. Barbey and colleagues provided evidence to help discover the neural mechanisms of emotional intelligence.\n\n\n== Decision-making techniques ==\nDecision-making techniques can be separated into two broad categories: group decision-making techniques and individual decision-making techniques. Individual decision-making techniques can also often be applied by a group.\n\n\n=== Group ===\nConsensus decision-making tries to avoid \"winners\" and \"losers\". Consensus requires that a majority approve a given course of action, but that the minority agree to go along with the course of action. In other words, if the minority opposes the course of action, consensus requires that the course of action be modified to remove objectionable features.\nVoting-based methods:\nMajority requires support from more than 50% of the members of the group. Thus, the bar for action is lower than with consensus.\nPlurality, where the largest block in a group decides, even if it falls short of a majority.\nQuadratic voting allows participants to cast their preference and intensity of preference for each decision (as opposed to a simple for or against decision). It addresses issues of voting paradox and majority-rule.\nRange voting lets each member score one or more of the available options. The option with the highest average is chosen. This method has experimentally been shown to produce the lowest Bayesian regret among common voting methods, even when voters are strategic.\nDelphi method is a structured communication technique for groups, originally developed for collaborative forecasting but has also been used for policy making. \nDotmocracy is a facilitation method that relies on the use of special forms called Dotmocracy. They are sheets that allows large groups to collectively brainstorm and recognize agreements on an unlimited number of ideas they have each wrote.\nParticipative decision-making occurs when an authority opens up the decision-making process to a group of people for a collaborative effort.\nDecision engineering uses a visual map of the decision-making process based on system dynamics and can be automated through a decision modeling tool, integrating big data, machine learning, and expert knowledge as appropriate.\n\n\n=== Individual ===\nDecisional balance sheet: listing the advantages and disadvantages (benefits and costs, pros and cons) of each option, as suggested by Plato's Protagoras and by Benjamin Franklin.\nExpected-value optimization: choosing the alternative with the highest probability-weighted utility, possibly with some consideration for risk aversion. This may involve considering the opportunity cost of different alternatives. See also Decision analysis and Decision theory.\nSatisficing: examining alternatives only until the first acceptable one is found. The opposite is maximizing or optimizing, in which many or all alternatives are examined in order to find the best option.\nAcquiesce to a person in authority or an \"expert\"; \"just following orders\".\nAnti-authoritarianism: taking the most opposite action compared to the advice of mistrusted authorities.\nFlipism e.g. flipping a coin, cutting a deck of playing cards, and other random or coincidence methods \u2013 or prayer, tarot cards, astrology, augurs, revelation, or other forms of divination, superstition or pseudoscience.\nAutomated decision support: setting up criteria for automated decisions.\nDecision support systems: using decision-making software when faced with highly complex decisions or when considering many stakeholders, categories, or other factors that affect decisions.\n\n\n== Steps ==\nA variety of researchers have formulated similar prescriptive steps aimed at improving decision-making.\n\n\n=== GOFER ===\nIn the 1980s, psychologist Leon Mann and colleagues developed a decision-making process called GOFER, which they taught to adolescents, as summarized in the book Teaching Decision Making To Adolescents. The process was based on extensive earlier research conducted with psychologist Irving Janis. GOFER is an acronym for five decision-making steps:\nGoals clarification: Survey values and objectives.\nOptions generation: Consider a wide range of alternative actions.\nFacts-finding: Search for information.\nConsideration of Effects: Weigh the positive and negative consequences of the options.\nReview and implementation: Plan how to review the options and implement them.\n\n\n=== DECIDE ===\nIn 2008, Kristina Guo published the DECIDE model of decision-making, which has six parts:\nDefine the problem\nEstablish or Enumerate all the criteria (constraints)\nConsider or Collect all the alternatives\nIdentify the best alternative\nDevelop and implement a plan of action\nEvaluate and monitor the solution and examine feedback when necessary\n\n\n=== Other ===\nIn 2007, Pam Brown of Singleton Hospital in Swansea, Wales, divided the decision-making process into seven steps:\nOutline the goal and outcome.\nGather data.\nDevelop alternatives (i.e., brainstorming).\nList pros and cons of each alternative.\nMake the decision.\nImmediately take action to implement it.\nLearn from and reflect on the decision.In 2009, professor John Pijanowski described how the Arkansas Program, an ethics curriculum at the University of Arkansas, used eight stages of moral decision-making based on the work of James Rest:\nEstablishing community: Create and nurture the relationships, norms, and procedures that will influence how problems are understood and communicated. This stage takes place prior to and during a moral dilemma.\nPerception: Recognize that a problem exists.\nInterpretation: Identify competing explanations for the problem, and evaluate the drivers behind those interpretations.\nJudgment: Sift through various possible actions or responses and determine which is more justifiable.\nMotivation: Examine the competing commitments which may distract from a more moral course of action and then prioritize and commit to moral values over other personal, institutional or social values.\nAction: Follow through with action that supports the more justified decision.\nReflection in action.\nReflection on action.\n\n\n=== Group stages ===\nAccording to B. Aubrey Fisher, there are four stages or phases that should be involved in all group decision-making:\nOrientation. Members meet for the first time and start to get to know each other.\nConflict. Once group members become familiar with each other, disputes, little fights and arguments occur. Group members eventually work it out.\nEmergence. The group begins to clear up vague opinions by talking about them.\nReinforcement. Members finally make a decision and provide justification for it.It is said that establishing critical norms in a group improves the quality of decisions, while the majority of opinions (called consensus norms) do not.Conflicts in socialization are divided in to functional and dysfunctional types. Functional conflicts are mostly the questioning the managers assumptions in their decision making and dysfunctional conflicts are like personal attacks and every action which decrease team effectiveness. Functional conflicts are the better ones to gain higher quality decision making caused by the increased team knowledge and shared understanding.\n\n\n== Rational and irrational ==\nIn economics, it is thought that if humans are rational and free to make their own decisions, then they would behave according to rational choice theory. Rational choice theory says that a person consistently makes choices that lead to the best situation for himself or herself, taking into account all available considerations including costs and benefits; the rationality of these considerations is from the point of view of the person himself, so a decision is not irrational just because someone else finds it questionable.\nIn reality, however, there are some factors that affect decision-making abilities and cause people to make irrational decisions \u2013 for example, to make contradictory choices when faced with the same problem framed in two different ways (see also Allais paradox).\nOne of the most prominent theories of decision making is subjective expected utility (SEU) theory, which describes the rational behavior of the decision maker. The decision maker assesses different alternatives by their utilities and the subjective probability of occurrence.Rational decision-making is often grounded on experience and theories that are able to put this approach on solid mathematical grounds so that subjectivity is reduced to a minimum, see e.g. scenario optimization.\n\n\n== Children, adolescents, and adults ==\n\n\n=== Children ===\nIt has been found that, unlike adults, children are less likely to have research strategy behaviors. One such behavior is adaptive decision-making, which is described as funneling and then analyzing the more promising information provided if the number of options to choose from increases. Adaptive decision-making behavior is somewhat present for children, ages 11\u201312 and older, but decreases in presence the younger they are. The reason children aren\u2019t as fluid in their decision making is because they lack the inability to weigh in the cost and effort needed to gather information in the decision-making process. Some possibilities that explain this inability is knowledge deficits and lack of utilization skills. Children lack the metacognitive knowledge necessary to know when to use any strategies they do possess to change their approach to decision-making.When it comes to the idea of fairness in decision making, children and adults differ much less. Children are able to understand the concept of fairness decision making from an early age. Toddlers and infants, ranging from 9\u201321 months, understand basic principles equality. The only difference found is that more complex principles of fairness in decision making such as contextual and intentional information don\u2019t come until later on as children get older.\n\n\n=== Adolescents ===\nDuring their adolescent years, teens are known for their high-risk behaviors and rash decisions. Recent research has shown that there are differences in cognitive processes between adolescents and adults during decision-making. Researchers have concluded that differences in decision-making are not due to a lack of logic or reasoning, but more due to the immaturity of psychosocial capacities that influence decision-making. Examples of their undeveloped capacities which influence decision-making would be impulse control, emotion regulation, delayed gratification and resistance to peer pressure. In the past, researchers have thought that adolescent behavior was simply due to incompetency regarding decision-making. Currently, researchers have concluded that adults and adolescents are both competent decision-makers, not just adults. However, adolescents' competent decision-making skills decrease when psychosocial capacities become present.\nRecent research has shown that risk-taking behaviors in adolescents may be the product of interactions between the socioemotional brain network and its cognitive-control network. The socioemotional part of the brain processes social and emotional stimuli and has been shown to be important in reward processing. The cognitive-control network assists in planning and self-regulation. Both of these sections of the brain change over the course of puberty. However, the socioemotional network changes quickly and abruptly, while the cognitive-control network changes more gradually. Because of this difference in change, the cognitive-control network, which usually regulates the socioemotional network, struggles to control the socioemotional network when psychosocial capacities are present.When adolescents are exposed to social and emotional stimuli, their socioemotional network is activated as well as areas of the brain involved in reward processing. Because teens often gain a sense of reward from risk-taking behaviors, their repetition becomes ever more probable due to the reward experienced. In this, the process mirrors addiction. Teens can become addicted to risky behavior because they are in a high state of arousal and are rewarded for it not only by their own internal functions but also by their peers around them. A recent study suggests that adolescents have difficulties adequately adjusting beliefs in response to bad news (such as reading that smoking poses a greater risk to health than they thought), but do not differ from adults in their ability to alter beliefs in response to good news. This creates biased beliefs, which may lead to greater risk taking.\n\n\n=== Adults ===\nAdults are generally better able to control their risk-taking because their cognitive-control system has matured enough to the point where it can control the socioemotional network, even in the context of high arousal or when psychosocial capacities are present. Also, adults are less likely to find themselves in situations that push them to do risky things. For example, teens are more likely to be around peers who peer pressure them into doing things, while adults are not as exposed to this sort of social setting.\n\n\n== Cognitive and personal biases ==\nBiases usually affect decision-making processes. They appear more when decision task has time pressure, is done under high stress and/or task is highly complex.Here is a list of commonly debated biases in judgment and decision-making:\n\nSelective search for evidence (also known as confirmation bias): People tend to be willing to gather facts that support certain conclusions but disregard other facts that support different conclusions. Individuals who are highly defensive in this manner show significantly greater left prefrontal cortex activity as measured by EEG than do less defensive individuals.\nPremature termination of search for evidence: People tend to accept the first alternative that looks like it might work.\nCognitive inertia is the unwillingness to change existing thought patterns in the face of new circumstances.\nSelective perception: People actively screen out information that they do not think is important (see also Prejudice). In one demonstration of this effect, discounting of arguments with which one disagrees (by judging them as untrue or irrelevant) was decreased by selective activation of right prefrontal cortex.\nWishful thinking is a tendency to want to see things in a certain \u2013 usually positive \u2013 light, which can distort perception and thinking.\nChoice-supportive bias occurs when people distort their memories of chosen and rejected options to make the chosen options seem more attractive.\nRecency: People tend to place more attention on more recent information and either ignore or forget more distant information (see Semantic priming). The opposite effect in the first set of data or other information is termed primacy effect.\nRepetition bias is a willingness to believe what one has been told most often and by the greatest number of different sources.\nAnchoring and adjustment: Decisions are unduly influenced by initial information that shapes our view of subsequent information.\nGroupthink is peer pressure to conform to the opinions held by the group.\nSource credibility bias is a tendency to reject a person's statement on the basis of a bias against the person, organization, or group to which the person belongs. People preferentially accept statements by others that they like (see also Prejudice).\nIncremental decision-making and escalating commitment: People look at a decision as a small step in a process, and this tends to perpetuate a series of similar decisions. This can be contrasted with zero-based decision-making (see Slippery slope).\nAttribution asymmetry: People tend to attribute their own success to internal factors, including abilities and talents, but explain their failures in terms of external factors such as bad luck. The reverse bias is shown when people explain others' success or failure.\nRole fulfillment is a tendency to conform to others' decision-making expectations.\nUnderestimating uncertainty and the illusion of control: People tend to underestimate future uncertainty because of a tendency to believe they have more control over events than they really do.\nFraming bias: This is best avoided by increasing numeracy and presenting data in several formats (for example, using both absolute and relative scales).Sunk-cost fallacy is a specific type of framing effect that affects decision-making. It involves an individual making a decision about a current situation based on what they have previously invested in the situation. An example of this would be an individual that is refraining from dropping a class that they are most likely to fail, due to the fact that they feel as though they have done so much work in the course thus far.\nProspect theory involves the idea that when faced with a decision-making event, an individual is more likely to take on a risk when evaluating potential losses, and are more likely to avoid risks when evaluating potential gains. This can influence one's decision-making depending if the situation entails a threat, or opportunity.\nOptimism bias is a tendency to overestimate the likelihood of positive events occurring in the future and underestimate the likelihood of negative life events. Such biased expectations are generated and maintained in the face of counter-evidence through a tendency to discount undesirable information. An optimism bias can alter risk perception and decision-making in many domains, ranging from finance to health.\nReference class forecasting was developed to eliminate or reduce cognitive biases in decision-making.\n\n\n== Cognitive limitations in groups ==\n\nIn groups, people generate decisions through active and complex processes. One method consists of three steps: initial preferences are expressed by members; the members of the group then gather and share information concerning those preferences; finally, the members combine their views and make a single choice about how to face the problem. Although these steps are relatively ordinary, judgements are often distorted by cognitive and motivational biases, include \"sins of commission\", \"sins of omission\", and \"sins of imprecision\".\n\n\n== Cognitive styles ==\n\n\n=== Optimizing vs. satisficing ===\n\nHerbert A. Simon coined the phrase \"bounded rationality\" to express the idea that human decision-making is limited by available information, available time and the mind's information-processing ability. Further psychological research has identified individual differences between two cognitive styles: maximizers try to make an optimal decision, whereas satisficers simply try to find a solution that is \"good enough\". Maximizers tend to take longer making decisions due to the need to maximize performance across all variables and make tradeoffs carefully; they also tend to more often regret their decisions (perhaps because they are more able than satisficers to recognize that a decision turned out to be sub-optimal).\n\n\n=== Intuitive vs. rational ===\n\nThe psychologist Daniel Kahneman, adopting terms originally proposed by the psychologists Keith Stanovich and Richard West, has theorized that a person's decision-making is the result of an interplay between two kinds of cognitive processes: an automatic intuitive system (called \"System 1\") and an effortful rational system (called \"System 2\"). System 1 is a bottom-up, fast, and implicit system of decision-making, while system 2 is a top-down, slow, and explicit system of decision-making. System 1 includes simple heuristics in judgment and decision-making such as the affect heuristic, the availability heuristic, the familiarity heuristic, and the representativeness heuristic.\n\n\n=== Combinatorial vs. positional ===\nStyles and methods of decision-making were elaborated by Aron Katsenelinboigen, the founder of predispositioning theory. In his analysis on styles and methods, Katsenelinboigen referred to the game of chess, saying that \"chess does disclose various methods of operation, notably the creation of predisposition-methods which may be applicable to other, more complex systems.\"Katsenelinboigen states that apart from the methods (reactive and selective) and sub-methods (randomization, predispositioning, programming), there are two major styles: positional and combinational. Both styles are utilized in the game of chess. According to Katsenelinboigen, the two styles reflect two basic approaches to uncertainty: deterministic (combinational style) and indeterministic (positional style). Katsenelinboigen's definition of the two styles are the following.\nThe combinational style is characterized by:\n\na very narrow, clearly defined, primarily material goal; and\na program that links the initial position with the final outcome.In defining the combinational style in chess, Katsenelinboigen wrote: \"The combinational style features a clearly formulated limited objective, namely the capture of material (the main constituent element of a chess position). The objective is implemented via a well-defined, and in some cases, unique sequence of moves aimed at reaching the set goal. As a rule, this sequence leaves no options for the opponent. Finding a combinational objective allows the player to focus all his energies on efficient execution, that is, the player's analysis may be limited to the pieces directly partaking in the combination. This approach is the crux of the combination and the combinational style of play.The positional style is distinguished by:\n\na positional goal; and\na formation of semi-complete linkages between the initial step and final outcome.\"Unlike the combinational player, the positional player is occupied, first and foremost, with the elaboration of the position that will allow him to develop in the unknown future. In playing the positional style, the player must evaluate relational and material parameters as independent variables. ... The positional style gives the player the opportunity to develop a position until it becomes pregnant with a combination. However, the combination is not the final goal of the positional player \u2013 it helps him to achieve the desirable, keeping in mind a predisposition for the future development. The pyrrhic victory is the best example of one's inability to think positionally.\"The positional style serves to:\n\ncreate a predisposition to the future development of the position;\ninduce the environment in a certain way;\nabsorb an unexpected outcome in one's favor; and\navoid the negative aspects of unexpected outcomes.\n\n\n=== Influence of Myers-Briggs type ===\nAccording to Isabel Briggs Myers, a person's decision-making process depends to a significant degree on their cognitive style. Myers developed a set of four bi-polar dimensions, called the Myers-Briggs Type Indicator (MBTI). The terminal points on these dimensions are: thinking and feeling; extroversion and introversion; judgment and perception; and sensing and intuition. She claimed that a person's decision-making style correlates well with how they score on these four dimensions. For example, someone who scored near the thinking, extroversion, sensing, and judgment ends of the dimensions would tend to have a logical, analytical, objective, critical, and empirical decision-making style. However, some psychologists say that the MBTI lacks reliability and validity and is poorly constructed.Other studies suggest that these national or cross-cultural differences in decision-making exist across entire societies. For example, Maris Martinsons has found that American, Japanese and Chinese business leaders each exhibit a distinctive national style of decision-making.The Myers-Briggs typology has been the subject of criticism regarding its poor psychometric properties.\n\n\n=== General decision-making style (GDMS) ===\nIn the general decision-making style (GDMS) test developed by Suzanne Scott and Reginald Bruce, there are five decision-making styles: rational, intuitive, dependent, avoidant, and spontaneous. These five different decision-making styles change depending on the context and situation, and one style is not necessarily better than any other. In the examples below, the individual is working for a company and is offered a job from a different company.\n\nThe rational style is an in-depth search for, and a strong consideration of, other options and/or information prior to making a decision. In this style, the individual would research the new job being offered, review their current job, and look at the pros and cons of taking the new job versus staying with their current company.\nThe intuitive style is confidence in one's initial feelings and gut reactions. In this style, if the individual initially prefers the new job because they have a feeling that the work environment is better suited for them, then they would decide to take the new job. The individual might not make this decision as soon as the job is offered.\nThe dependent style is asking for other people's input and instructions on what decision should be made. In this style, the individual could ask friends, family, coworkers, etc., but the individual might not ask all of these people.\nThe avoidant style is averting the responsibility of making a decision. In this style, the individual would not make a decision. Therefore, the individual would stick with their current job.\nThe spontaneous style is a need to make a decision as soon as possible rather than waiting to make a decision. In this style, the individual would either reject or accept the job as soon as it is offered.\n\n\n== Organizational vs. individual level ==\nThere are a few characteristics that differentiate organizational decision-making from individual decision-making as studied in lab experiments:1. Unlike most lab studies of individual decision-making, ambiguity is pervasive in organizations. There is often only ambiguous information, and there is ambiguity about preferences as well as about interpreting the history of decisions.\n2. Decision-making in and by organizations is embedded in a longitudinal context, meaning that participants in organizational decision-making are a part of ongoing processes. Even if they don't take on active roles in all phases of decision-making, they are part of the Decision Process and its consequences. Decisions in organizations are made in a sequential manner, and commitment may be more important in such processes than judgmental accuracy. In contrast, most lab studies of individual decision-making are conducted in artificial settings (lab) that are not connected to the subjects\u2019 ongoing activities.\n3. Incentives play an important role in organizational decision-making. Incentives, penalties, and their ramifications are real and may have long-lasting effects. These effects are intensified due to the longitudinal nature of decision-making in organizational settings. Incentives and penalties are very salient in organizations, and often they command managerial attention.\n4. Many executives, especially in middle management, may make repeated decisions on similar issues. Managers may develop a sense of using his/her skills (which may be faulty) and a sense of having control and using one's skills are pervasive in managerial thinking about risk taking. Several repeated decisions are made by following rules rather than by using pure information processing modes.\n5. Conflict is pervasive in organizational decision-making. Many times power considerations and agenda setting determine decisions rather than calculations based on the decision's parameters. The nature of authority relations may have a large impact on the way decisions are made in organizations, which are basically political systems.\n\n\n== See also ==\n\n\n== References ==", {"entities": [[3, 13, "TRAINED_CATEGORY"], [15, 30, "TRAINED_CATEGORY"], [45, 60, "TRAINED_CATEGORY"], [96, 117, "TRAINED_CATEGORY"], [131, 144, "TRAINED_CATEGORY"], [148, 156, "TRAINED_CATEGORY"], [172, 178, "TRAINED_CATEGORY"], [185, 221, "TRAINED_CATEGORY"], [242, 253, "TRAINED_CATEGORY"], [282, 294, "TRAINED_CATEGORY"], [304, 314, "TRAINED_CATEGORY"], [316, 327, "TRAINED_CATEGORY"], [332, 339, "TRAINED_CATEGORY"], [343, 361, "TRAINED_CATEGORY"], [363, 392, "TRAINED_CATEGORY"], [402, 416, "TRAINED_CATEGORY"], [446, 452, "TRAINED_CATEGORY"], [454, 462, "TRAINED_CATEGORY"], [469, 484, "TRAINED_CATEGORY"], [509, 526, "TRAINED_CATEGORY"], [552, 583, "TRAINED_CATEGORY"], [602, 617, "TRAINED_CATEGORY"], [637, 663, "TRAINED_CATEGORY"], [673, 683, "TRAINED_CATEGORY"], [732, 734, "TRAINED_CATEGORY"], [748, 757, "TRAINED_CATEGORY"], [827, 854, "TRAINED_CATEGORY"], [859, 866, "TRAINED_CATEGORY"], [868, 883, "TRAINED_CATEGORY"], [906, 914, "TRAINED_CATEGORY"], [918, 951, "TRAINED_CATEGORY"], [969, 980, "TRAINED_CATEGORY"], [984, 993, "TRAINED_CATEGORY"], [1036, 1063, "TRAINED_CATEGORY"], [1065, 1082, "TRAINED_CATEGORY"], [1092, 1103, "TRAINED_CATEGORY"], [1107, 1122, "TRAINED_CATEGORY"], [1128, 1148, "TRAINED_CATEGORY"], [1176, 1196, "TRAINED_CATEGORY"], [1200, 1211, "TRAINED_CATEGORY"], [1215, 1220, "TRAINED_CATEGORY"], [1224, 1229, "TRAINED_CATEGORY"], [1231, 1242, "TRAINED_CATEGORY"], [1254, 1268, "TRAINED_CATEGORY"], [1283, 1292, "TRAINED_CATEGORY"], [1294, 1321, "TRAINED_CATEGORY"], [1334, 1354, "TRAINED_CATEGORY"], [1369, 1384, "TRAINED_CATEGORY"], [1390, 1405, "TRAINED_CATEGORY"], [1407, 1416, "TRAINED_CATEGORY"], [1418, 1430, "TRAINED_CATEGORY"], [1434, 1454, "TRAINED_CATEGORY"], [1470, 1479, "TRAINED_CATEGORY"], [1483, 1498, "TRAINED_CATEGORY"], [1503, 1528, "TRAINED_CATEGORY"], [1534, 1554, "TRAINED_CATEGORY"], [1555, 1557, "TRAINED_CATEGORY"], [1567, 1579, "TRAINED_CATEGORY"], [1583, 1598, "TRAINED_CATEGORY"], [1608, 1620, "TRAINED_CATEGORY"], [1624, 1636, "TRAINED_CATEGORY"], [1640, 1652, "TRAINED_CATEGORY"], [1666, 1671, "TRAINED_CATEGORY"], [1675, 1694, "TRAINED_CATEGORY"], [1701, 1709, "TRAINED_CATEGORY"], [1727, 1745, "TRAINED_CATEGORY"], [1749, 1754, "TRAINED_CATEGORY"], [1773, 1777, "TRAINED_CATEGORY"], [1785, 1805, "TRAINED_CATEGORY"], [1812, 1828, "TRAINED_CATEGORY"], [1860, 1872, "TRAINED_CATEGORY"], [1890, 1910, "TRAINED_CATEGORY"], [1927, 1954, "TRAINED_CATEGORY"], [1958, 1974, "TRAINED_CATEGORY"], [1980, 1988, "TRAINED_CATEGORY"], [1993, 2005, "TRAINED_CATEGORY"], [2016, 2024, "TRAINED_CATEGORY"], [2039, 2044, "TRAINED_CATEGORY"], [2051, 2067, "TRAINED_CATEGORY"], [2107, 2120, "TRAINED_CATEGORY"], [2124, 2133, "TRAINED_CATEGORY"], [2137, 2172, "TRAINED_CATEGORY"], [2174, 2178, "TRAINED_CATEGORY"], [2181, 2190, "TRAINED_CATEGORY"], [2194, 2209, "TRAINED_CATEGORY"], [2244, 2256, "TRAINED_CATEGORY"], [2260, 2276, "TRAINED_CATEGORY"], [2281, 2294, "TRAINED_CATEGORY"], [2336, 2353, "TRAINED_CATEGORY"], [2370, 2392, "TRAINED_CATEGORY"], [2398, 2402, "TRAINED_CATEGORY"], [2418, 2439, "TRAINED_CATEGORY"], [2455, 2470, "TRAINED_CATEGORY"], [2474, 2499, "TRAINED_CATEGORY"], [2501, 2524, "TRAINED_CATEGORY"], [2528, 2545, "TRAINED_CATEGORY"], [2549, 2578, "TRAINED_CATEGORY"], [2586, 2597, "TRAINED_CATEGORY"], [2604, 2619, "TRAINED_CATEGORY"], [2623, 2635, "TRAINED_CATEGORY"], [2644, 2662, "TRAINED_CATEGORY"], [2668, 2675, "TRAINED_CATEGORY"], [2677, 2700, "TRAINED_CATEGORY"], [2716, 2727, "TRAINED_CATEGORY"], [2732, 2745, "TRAINED_CATEGORY"], [2749, 2770, "TRAINED_CATEGORY"], [2805, 2813, "TRAINED_CATEGORY"], [2828, 2838, "TRAINED_CATEGORY"], [2844, 2864, "TRAINED_CATEGORY"], [2866, 2879, "TRAINED_CATEGORY"], [2884, 2905, "TRAINED_CATEGORY"], [2907, 2914, "TRAINED_CATEGORY"], [2923, 2948, "TRAINED_CATEGORY"], [2961, 2982, "TRAINED_CATEGORY"], [2984, 2988, "TRAINED_CATEGORY"], [3000, 3029, "TRAINED_CATEGORY"], [3040, 3056, "TRAINED_CATEGORY"], [3071, 3079, "TRAINED_CATEGORY"], [3083, 3089, "TRAINED_CATEGORY"], [3107, 3119, "TRAINED_CATEGORY"], [3120, 3152, "TRAINED_CATEGORY"], [3162, 3168, "TRAINED_CATEGORY"], [3172, 3199, "TRAINED_CATEGORY"], [3205, 3212, "TRAINED_CATEGORY"], [3214, 3238, "TRAINED_CATEGORY"], [3242, 3250, "TRAINED_CATEGORY"], [3267, 3285, "TRAINED_CATEGORY"], [3287, 3308, "TRAINED_CATEGORY"], [3312, 3326, "TRAINED_CATEGORY"], [3332, 3346, "TRAINED_CATEGORY"], [3350, 3375, "TRAINED_CATEGORY"], [3399, 3403, "TRAINED_CATEGORY"], [3405, 3412, "TRAINED_CATEGORY"], [3421, 3435, "TRAINED_CATEGORY"], [3439, 3447, "TRAINED_CATEGORY"], [3464, 3489, "TRAINED_CATEGORY"], [3505, 3530, "TRAINED_CATEGORY"], [3549, 3559, "TRAINED_CATEGORY"], [3581, 3593, "TRAINED_CATEGORY"], [3595, 3609, "TRAINED_CATEGORY"], [3619, 3629, "TRAINED_CATEGORY"], [3633, 3639, "TRAINED_CATEGORY"], [3643, 3653, "TRAINED_CATEGORY"], [3657, 3670, "TRAINED_CATEGORY"], [3695, 3708, "TRAINED_CATEGORY"], [3721, 3733, "TRAINED_CATEGORY"], [3735, 3753, "TRAINED_CATEGORY"], [3778, 3796, "TRAINED_CATEGORY"], [3800, 3824, "TRAINED_CATEGORY"], [3832, 3834, "TRAINED_CATEGORY"], [3857, 3870, "TRAINED_CATEGORY"], [3880, 3897, "TRAINED_CATEGORY"], [3904, 3911, "TRAINED_CATEGORY"], [3943, 3945, "TRAINED_CATEGORY"], [3984, 3991, "TRAINED_CATEGORY"], [4043, 4050, "TRAINED_CATEGORY"], [4062, 4073, "TRAINED_CATEGORY"], [4091, 4112, "TRAINED_CATEGORY"], [4125, 4147, "TRAINED_CATEGORY"], [4156, 4165, "TRAINED_CATEGORY"], [4169, 4178, "TRAINED_CATEGORY"], [4195, 4197, "TRAINED_CATEGORY"], [4213, 4220, "TRAINED_CATEGORY"], [4232, 4238, "TRAINED_CATEGORY"], [4247, 4262, "TRAINED_CATEGORY"], [4272, 4287, "TRAINED_CATEGORY"], [4300, 4312, "TRAINED_CATEGORY"], [4333, 4348, "TRAINED_CATEGORY"], [4350, 4365, "TRAINED_CATEGORY"], [4369, 4376, "TRAINED_CATEGORY"], [4385, 4393, "TRAINED_CATEGORY"], [4405, 4415, "TRAINED_CATEGORY"], [4421, 4442, "TRAINED_CATEGORY"], [4443, 4451, "TRAINED_CATEGORY"], [4495, 4503, "TRAINED_CATEGORY"], [4518, 4526, "TRAINED_CATEGORY"], [4532, 4553, "TRAINED_CATEGORY"], [4554, 4563, "TRAINED_CATEGORY"], [4606, 4610, "TRAINED_CATEGORY"], [4643, 4650, "TRAINED_CATEGORY"], [4651, 4657, "TRAINED_CATEGORY"], [4661, 4669, "TRAINED_CATEGORY"], [4690, 4706, "TRAINED_CATEGORY"], [4726, 4737, "TRAINED_CATEGORY"], [4738, 4755, "TRAINED_CATEGORY"], [4759, 4768, "TRAINED_CATEGORY"], [4772, 4779, "TRAINED_CATEGORY"], [4802, 4815, "TRAINED_CATEGORY"], [4830, 4865, "TRAINED_CATEGORY"], [4867, 4897, "TRAINED_CATEGORY"], [4917, 4927, "TRAINED_CATEGORY"], [4954, 4964, "TRAINED_CATEGORY"], [4998, 5003, "TRAINED_CATEGORY"], [5007, 5017, "TRAINED_CATEGORY"], [5018, 5037, "TRAINED_CATEGORY"], [5056, 5072, "TRAINED_CATEGORY"], [5099, 5117, "TRAINED_CATEGORY"], [5118, 5133, "TRAINED_CATEGORY"], [5158, 5176, "TRAINED_CATEGORY"], [5180, 5202, "TRAINED_CATEGORY"], [5203, 5225, "TRAINED_CATEGORY"], [5243, 5269, "TRAINED_CATEGORY"], [5270, 5290, "TRAINED_CATEGORY"], [5306, 5324, "TRAINED_CATEGORY"], [5346, 5370, "TRAINED_CATEGORY"], [5385, 5393, "TRAINED_CATEGORY"], [5407, 5419, "TRAINED_CATEGORY"], [5421, 5437, "TRAINED_CATEGORY"], [5484, 5489, "TRAINED_CATEGORY"], [5518, 5529, "TRAINED_CATEGORY"], [5533, 5549, "TRAINED_CATEGORY"], [5580, 5606, "TRAINED_CATEGORY"], [5610, 5621, "TRAINED_CATEGORY"], [5632, 5640, "TRAINED_CATEGORY"], [5642, 5654, "TRAINED_CATEGORY"], [5685, 5694, "TRAINED_CATEGORY"], [5709, 5725, "TRAINED_CATEGORY"], [5732, 5750, "TRAINED_CATEGORY"], [5761, 5768, "TRAINED_CATEGORY"], [5772, 5782, "TRAINED_CATEGORY"], [5801, 5803, "TRAINED_CATEGORY"], [5812, 5836, "TRAINED_CATEGORY"], [5840, 5847, "TRAINED_CATEGORY"], [5858, 5868, "TRAINED_CATEGORY"], [5870, 5874, "TRAINED_CATEGORY"], [5897, 5915, "TRAINED_CATEGORY"], [5917, 5935, "TRAINED_CATEGORY"], [5939, 5948, "TRAINED_CATEGORY"], [5954, 5962, "TRAINED_CATEGORY"], [5976, 5980, "TRAINED_CATEGORY"], [6000, 6010, "TRAINED_CATEGORY"], [6015, 6021, "TRAINED_CATEGORY"], [6033, 6044, "TRAINED_CATEGORY"], [6054, 6069, "TRAINED_CATEGORY"], [6074, 6092, "TRAINED_CATEGORY"], [6096, 6118, "TRAINED_CATEGORY"], [6122, 6135, "TRAINED_CATEGORY"], [6139, 6151, "TRAINED_CATEGORY"], [6167, 6180, "TRAINED_CATEGORY"], [6184, 6188, "TRAINED_CATEGORY"], [6203, 6214, "TRAINED_CATEGORY"], [6226, 6247, "TRAINED_CATEGORY"], [6251, 6269, "TRAINED_CATEGORY"], [6284, 6310, "TRAINED_CATEGORY"], [6312, 6321, "TRAINED_CATEGORY"], [6325, 6334, "TRAINED_CATEGORY"], [6357, 6375, "TRAINED_CATEGORY"], [6399, 6409, "TRAINED_CATEGORY"], [6418, 6422, "TRAINED_CATEGORY"], [6441, 6456, "TRAINED_CATEGORY"], [6477, 6481, "TRAINED_CATEGORY"], [6492, 6510, "TRAINED_CATEGORY"], [6526, 6554, "TRAINED_CATEGORY"], [6556, 6570, "TRAINED_CATEGORY"], [6594, 6607, "TRAINED_CATEGORY"], [6635, 6655, "TRAINED_CATEGORY"], [6657, 6675, "TRAINED_CATEGORY"], [6686, 6699, "TRAINED_CATEGORY"], [6704, 6715, "TRAINED_CATEGORY"], [6721, 6735, "TRAINED_CATEGORY"], [6755, 6759, "TRAINED_CATEGORY"], [6776, 6797, "TRAINED_CATEGORY"], [6817, 6827, "TRAINED_CATEGORY"], [6842, 6868, "TRAINED_CATEGORY"], [6870, 6884, "TRAINED_CATEGORY"], [6897, 6915, "TRAINED_CATEGORY"], [6935, 6950, "TRAINED_CATEGORY"], [6955, 6970, "TRAINED_CATEGORY"], [6974, 6994, "TRAINED_CATEGORY"], [7019, 7034, "TRAINED_CATEGORY"], [7042, 7052, "TRAINED_CATEGORY"], [7056, 7064, "TRAINED_CATEGORY"], [7072, 7089, "TRAINED_CATEGORY"], [7093, 7111, "TRAINED_CATEGORY"], [7115, 7129, "TRAINED_CATEGORY"], [7151, 7159, "TRAINED_CATEGORY"], [7161, 7171, "TRAINED_CATEGORY"], [7175, 7183, "TRAINED_CATEGORY"], [7187, 7196, "TRAINED_CATEGORY"], [7202, 7210, "TRAINED_CATEGORY"], [7222, 7226, "TRAINED_CATEGORY"], [7232, 7250, "TRAINED_CATEGORY"], [7259, 7276, "TRAINED_CATEGORY"], [7280, 7309, "TRAINED_CATEGORY"], [7311, 7321, "TRAINED_CATEGORY"], [7325, 7333, "TRAINED_CATEGORY"], [7372, 7391, "TRAINED_CATEGORY"], [7398, 7404, "TRAINED_CATEGORY"], [7409, 7417, "TRAINED_CATEGORY"], [7424, 7431, "TRAINED_CATEGORY"], [7435, 7445, "TRAINED_CATEGORY"], [7447, 7465, "TRAINED_CATEGORY"], [7494, 7501, "TRAINED_CATEGORY"], [7504, 7512, "TRAINED_CATEGORY"], [7547, 7566, "TRAINED_CATEGORY"], [7571, 7585, "TRAINED_CATEGORY"], [7586, 7596, "TRAINED_CATEGORY"], [7600, 7608, "TRAINED_CATEGORY"], [7612, 7619, "TRAINED_CATEGORY"], [7628, 7638, "TRAINED_CATEGORY"], [7642, 7660, "TRAINED_CATEGORY"], [7678, 7686, "TRAINED_CATEGORY"], [7690, 7700, "TRAINED_CATEGORY"], [7704, 7712, "TRAINED_CATEGORY"], [7727, 7742, "TRAINED_CATEGORY"], [7744, 7754, "TRAINED_CATEGORY"], [7763, 7770, "TRAINED_CATEGORY"], [7774, 7781, "TRAINED_CATEGORY"], [7806, 7816, "TRAINED_CATEGORY"], [7820, 7829, "TRAINED_CATEGORY"], [7847, 7851, "TRAINED_CATEGORY"], [7855, 7857, "TRAINED_CATEGORY"], [7871, 7879, "TRAINED_CATEGORY"], [7902, 7909, "TRAINED_CATEGORY"], [7920, 7929, "TRAINED_CATEGORY"], [7958, 7969, "TRAINED_CATEGORY"], [7971, 7978, "TRAINED_CATEGORY"], [7988, 7998, "TRAINED_CATEGORY"], [8020, 8034, "TRAINED_CATEGORY"], [8038, 8048, "TRAINED_CATEGORY"], [8052, 8060, "TRAINED_CATEGORY"], [8068, 8088, "TRAINED_CATEGORY"], [8094, 8114, "TRAINED_CATEGORY"], [8119, 8124, "TRAINED_CATEGORY"], [8133, 8143, "TRAINED_CATEGORY"], [8147, 8158, "TRAINED_CATEGORY"], [8163, 8172, "TRAINED_CATEGORY"], [8173, 8175, "TRAINED_CATEGORY"], [8196, 8198, "TRAINED_CATEGORY"], [8200, 8211, "TRAINED_CATEGORY"], [8220, 8235, "TRAINED_CATEGORY"], [8262, 8273, "TRAINED_CATEGORY"], [8275, 8296, "TRAINED_CATEGORY"], [8305, 8323, "TRAINED_CATEGORY"], [8328, 8335, "TRAINED_CATEGORY"], [8351, 8366, "TRAINED_CATEGORY"], [8368, 8403, "TRAINED_CATEGORY"], [8418, 8441, "TRAINED_CATEGORY"], [8468, 8480, "TRAINED_CATEGORY"], [8495, 8511, "TRAINED_CATEGORY"], [8515, 8526, "TRAINED_CATEGORY"], [8528, 8543, "TRAINED_CATEGORY"], [8548, 8558, "TRAINED_CATEGORY"], [8569, 8581, "TRAINED_CATEGORY"], [8585, 8594, "TRAINED_CATEGORY"], [8617, 8628, "TRAINED_CATEGORY"], [8639, 8657, "TRAINED_CATEGORY"], [8658, 8660, "TRAINED_CATEGORY"], [8680, 8693, "TRAINED_CATEGORY"], [8702, 8720, "TRAINED_CATEGORY"], [8722, 8733, "TRAINED_CATEGORY"], [8738, 8758, "TRAINED_CATEGORY"], [8763, 8782, "TRAINED_CATEGORY"], [8784, 8805, "TRAINED_CATEGORY"], [8807, 8817, "TRAINED_CATEGORY"], [8823, 8835, "TRAINED_CATEGORY"], [8843, 8859, "TRAINED_CATEGORY"], [8865, 8881, "TRAINED_CATEGORY"], [8890, 8906, "TRAINED_CATEGORY"], [8935, 8944, "TRAINED_CATEGORY"], [8948, 8970, "TRAINED_CATEGORY"], [8972, 8978, "TRAINED_CATEGORY"], [8979, 8982, "TRAINED_CATEGORY"], [8988, 8997, "TRAINED_CATEGORY"], [9001, 9019, "TRAINED_CATEGORY"], [9023, 9027, "TRAINED_CATEGORY"], [9042, 9055, "TRAINED_CATEGORY"], [9074, 9096, "TRAINED_CATEGORY"], [9098, 9100, "TRAINED_CATEGORY"], [9120, 9136, "TRAINED_CATEGORY"], [9159, 9162, "TRAINED_CATEGORY"], [9171, 9180, "TRAINED_CATEGORY"], [9185, 9203, "TRAINED_CATEGORY"], [9205, 9252, "TRAINED_CATEGORY"], [9257, 9275, "TRAINED_CATEGORY"], [9293, 9309, "TRAINED_CATEGORY"], [9311, 9328, "TRAINED_CATEGORY"], [9354, 9362, "TRAINED_CATEGORY"], [9375, 9394, "TRAINED_CATEGORY"], [9398, 9407, "TRAINED_CATEGORY"], [9409, 9421, "TRAINED_CATEGORY"], [9422, 9426, "TRAINED_CATEGORY"], [9457, 9475, "TRAINED_CATEGORY"], [9484, 9492, "TRAINED_CATEGORY"], [9500, 9513, "TRAINED_CATEGORY"], [9542, 9552, "TRAINED_CATEGORY"], [9554, 9572, "TRAINED_CATEGORY"], [9591, 9609, "TRAINED_CATEGORY"], [9618, 9632, "TRAINED_CATEGORY"], [9651, 9664, "TRAINED_CATEGORY"], [9681, 9699, "TRAINED_CATEGORY"], [9726, 9739, "TRAINED_CATEGORY"], [9776, 9784, "TRAINED_CATEGORY"], [9792, 9814, "TRAINED_CATEGORY"], [9819, 9829, "TRAINED_CATEGORY"], [9834, 9842, "TRAINED_CATEGORY"], [9846, 9860, "TRAINED_CATEGORY"], [9881, 9896, "TRAINED_CATEGORY"], [9907, 9953, "TRAINED_CATEGORY"], [9960, 9972, "TRAINED_CATEGORY"], [9995, 10003, "TRAINED_CATEGORY"], [10007, 10020, "TRAINED_CATEGORY"], [10024, 10034, "TRAINED_CATEGORY"], [10038, 10058, "TRAINED_CATEGORY"], [10064, 10086, "TRAINED_CATEGORY"], [10088, 10112, "TRAINED_CATEGORY"], [10124, 10153, "TRAINED_CATEGORY"], [10155, 10158, "TRAINED_CATEGORY"], [10161, 10181, "TRAINED_CATEGORY"], [10186, 10232, "TRAINED_CATEGORY"], [10264, 10289, "TRAINED_CATEGORY"], [10291, 10311, "TRAINED_CATEGORY"], [10318, 10338, "TRAINED_CATEGORY"], [10342, 10359, "TRAINED_CATEGORY"], [10363, 10376, "TRAINED_CATEGORY"], [10398, 10407, "TRAINED_CATEGORY"], [10421, 10430, "TRAINED_CATEGORY"], [10434, 10461, "TRAINED_CATEGORY"], [10475, 10485, "TRAINED_CATEGORY"], [10491, 10498, "TRAINED_CATEGORY"], [10505, 10513, "TRAINED_CATEGORY"], [10519, 10525, "TRAINED_CATEGORY"], [10529, 10563, "TRAINED_CATEGORY"], [10569, 10579, "TRAINED_CATEGORY"], [10587, 10609, "TRAINED_CATEGORY"], [10610, 10638, "TRAINED_CATEGORY"], [10652, 10674, "TRAINED_CATEGORY"], [10678, 10716, "TRAINED_CATEGORY"], [10718, 10722, "TRAINED_CATEGORY"], [10734, 10743, "TRAINED_CATEGORY"], [10766, 10782, "TRAINED_CATEGORY"], [10790, 10804, "TRAINED_CATEGORY"], [10806, 10813, "TRAINED_CATEGORY"], [10817, 10853, "TRAINED_CATEGORY"], [10864, 10878, "TRAINED_CATEGORY"], [10890, 10897, "TRAINED_CATEGORY"], [10901, 10920, "TRAINED_CATEGORY"], [10940, 10953, "TRAINED_CATEGORY"], [10957, 10967, "TRAINED_CATEGORY"], [10984, 10994, "TRAINED_CATEGORY"], [10998, 11007, "TRAINED_CATEGORY"], [11012, 11023, "TRAINED_CATEGORY"], [11042, 11054, "TRAINED_CATEGORY"], [11056, 11076, "TRAINED_CATEGORY"], [11088, 11095, "TRAINED_CATEGORY"], [11099, 11106, "TRAINED_CATEGORY"], [11110, 11121, "TRAINED_CATEGORY"], [11134, 11158, "TRAINED_CATEGORY"], [11162, 11174, "TRAINED_CATEGORY"], [11178, 11204, "TRAINED_CATEGORY"], [11221, 11228, "TRAINED_CATEGORY"], [11259, 11289, "TRAINED_CATEGORY"], [11302, 11315, "TRAINED_CATEGORY"], [11317, 11329, "TRAINED_CATEGORY"], [11341, 11345, "TRAINED_CATEGORY"], [11350, 11356, "TRAINED_CATEGORY"], [11382, 11407, "TRAINED_CATEGORY"], [11417, 11448, "TRAINED_CATEGORY"], [11456, 11464, "TRAINED_CATEGORY"], [11470, 11477, "TRAINED_CATEGORY"], [11498, 11525, "TRAINED_CATEGORY"], [11559, 11567, "TRAINED_CATEGORY"], [11571, 11582, "TRAINED_CATEGORY"], [11597, 11610, "TRAINED_CATEGORY"], [11650, 11654, "TRAINED_CATEGORY"], [11657, 11686, "TRAINED_CATEGORY"], [11690, 11714, "TRAINED_CATEGORY"], [11722, 11731, "TRAINED_CATEGORY"], [11744, 11752, "TRAINED_CATEGORY"], [11756, 11773, "TRAINED_CATEGORY"], [11775, 11786, "TRAINED_CATEGORY"], [11798, 11812, "TRAINED_CATEGORY"], [11826, 11834, "TRAINED_CATEGORY"], [11839, 11847, "TRAINED_CATEGORY"], [11851, 11864, "TRAINED_CATEGORY"], [11891, 11907, "TRAINED_CATEGORY"], [11911, 11930, "TRAINED_CATEGORY"], [11945, 11962, "TRAINED_CATEGORY"], [11967, 11975, "TRAINED_CATEGORY"], [12018, 12030, "TRAINED_CATEGORY"], [12040, 12052, "TRAINED_CATEGORY"], [12061, 12075, "TRAINED_CATEGORY"], [12140, 12169, "TRAINED_CATEGORY"], [12171, 12200, "TRAINED_CATEGORY"], [12204, 12216, "TRAINED_CATEGORY"], [12222, 12241, "TRAINED_CATEGORY"], [12255, 12269, "TRAINED_CATEGORY"], [12274, 12284, "TRAINED_CATEGORY"], [12294, 12302, "TRAINED_CATEGORY"], [12320, 12341, "TRAINED_CATEGORY"], [12345, 12367, "TRAINED_CATEGORY"], [12374, 12400, "TRAINED_CATEGORY"], [12404, 12430, "TRAINED_CATEGORY"], [12453, 12473, "TRAINED_CATEGORY"], [12475, 12507, "TRAINED_CATEGORY"], [12512, 12549, "TRAINED_CATEGORY"], [12551, 12588, "TRAINED_CATEGORY"], [12618, 12625, "TRAINED_CATEGORY"], [12633, 12638, "TRAINED_CATEGORY"], [12643, 12674, "TRAINED_CATEGORY"], [12684, 12692, "TRAINED_CATEGORY"], [12698, 12705, "TRAINED_CATEGORY"], [12708, 12717, "TRAINED_CATEGORY"], [12732, 12742, "TRAINED_CATEGORY"], [12751, 12765, "TRAINED_CATEGORY"], [12769, 12775, "TRAINED_CATEGORY"], [12786, 12798, "TRAINED_CATEGORY"], [12822, 12832, "TRAINED_CATEGORY"], [12836, 12842, "TRAINED_CATEGORY"], [12847, 12858, "TRAINED_CATEGORY"], [12863, 12875, "TRAINED_CATEGORY"], [12884, 12894, "TRAINED_CATEGORY"], [12898, 12904, "TRAINED_CATEGORY"], [12906, 12915, "TRAINED_CATEGORY"], [12930, 12940, "TRAINED_CATEGORY"], [12944, 12950, "TRAINED_CATEGORY"], [12973, 12995, "TRAINED_CATEGORY"], [12997, 13017, "TRAINED_CATEGORY"], [13019, 13027, "TRAINED_CATEGORY"], [13037, 13044, "TRAINED_CATEGORY"], [13050, 13063, "TRAINED_CATEGORY"], [13067, 13078, "TRAINED_CATEGORY"], [13082, 13091, "TRAINED_CATEGORY"], [13099, 13106, "TRAINED_CATEGORY"], [13111, 13117, "TRAINED_CATEGORY"], [13137, 13146, "TRAINED_CATEGORY"], [13148, 13157, "TRAINED_CATEGORY"], [13165, 13182, "TRAINED_CATEGORY"], [13186, 13193, "TRAINED_CATEGORY"], [13211, 13213, "TRAINED_CATEGORY"], [13229, 13239, "TRAINED_CATEGORY"], [13241, 13257, "TRAINED_CATEGORY"], [13265, 13277, "TRAINED_CATEGORY"], [13286, 13302, "TRAINED_CATEGORY"], [13307, 13316, "TRAINED_CATEGORY"], [13320, 13330, "TRAINED_CATEGORY"], [13335, 13348, "TRAINED_CATEGORY"], [13388, 13396, "TRAINED_CATEGORY"], [13399, 13401, "TRAINED_CATEGORY"], [13412, 13418, "TRAINED_CATEGORY"], [13422, 13436, "TRAINED_CATEGORY"], [13441, 13454, "TRAINED_CATEGORY"], [13456, 13468, "TRAINED_CATEGORY"], [13507, 13528, "TRAINED_CATEGORY"], [13530, 13540, "TRAINED_CATEGORY"], [13546, 13565, "TRAINED_CATEGORY"], [13577, 13588, "TRAINED_CATEGORY"], [13630, 13656, "TRAINED_CATEGORY"], [13663, 13684, "TRAINED_CATEGORY"], [13696, 13702, "TRAINED_CATEGORY"], [13718, 13731, "TRAINED_CATEGORY"], [13735, 13771, "TRAINED_CATEGORY"], [13776, 13782, "TRAINED_CATEGORY"], [13809, 13834, "TRAINED_CATEGORY"], [13862, 13875, "TRAINED_CATEGORY"], [13878, 13888, "TRAINED_CATEGORY"], [13892, 13913, "TRAINED_CATEGORY"], [13929, 13936, "TRAINED_CATEGORY"], [13940, 13953, "TRAINED_CATEGORY"], [13973, 13977, "TRAINED_CATEGORY"], [13982, 13988, "TRAINED_CATEGORY"], [14001, 14013, "TRAINED_CATEGORY"], [14055, 14065, "TRAINED_CATEGORY"], [14069, 14088, "TRAINED_CATEGORY"], [14092, 14097, "TRAINED_CATEGORY"], [14098, 14102, "TRAINED_CATEGORY"], [14120, 14149, "TRAINED_CATEGORY"], [14162, 14174, "TRAINED_CATEGORY"], [14184, 14211, "TRAINED_CATEGORY"], [14215, 14222, "TRAINED_CATEGORY"], [14226, 14232, "TRAINED_CATEGORY"], [14237, 14259, "TRAINED_CATEGORY"], [14261, 14281, "TRAINED_CATEGORY"], [14287, 14299, "TRAINED_CATEGORY"], [14303, 14330, "TRAINED_CATEGORY"], [14340, 14355, "TRAINED_CATEGORY"], [14385, 14409, "TRAINED_CATEGORY"], [14423, 14431, "TRAINED_CATEGORY"], [14433, 14449, "TRAINED_CATEGORY"], [14455, 14471, "TRAINED_CATEGORY"], [14494, 14504, "TRAINED_CATEGORY"], [14509, 14533, "TRAINED_CATEGORY"], [14543, 14557, "TRAINED_CATEGORY"], [14562, 14575, "TRAINED_CATEGORY"], [14577, 14585, "TRAINED_CATEGORY"], [14590, 14595, "TRAINED_CATEGORY"], [14597, 14601, "TRAINED_CATEGORY"], [14606, 14610, "TRAINED_CATEGORY"], [14615, 14626, "TRAINED_CATEGORY"], [14644, 14662, "TRAINED_CATEGORY"], [14670, 14687, "TRAINED_CATEGORY"], [14689, 14716, "TRAINED_CATEGORY"], [14727, 14742, "TRAINED_CATEGORY"], [14748, 14788, "TRAINED_CATEGORY"], [14804, 14822, "TRAINED_CATEGORY"], [14827, 14840, "TRAINED_CATEGORY"], [14871, 14891, "TRAINED_CATEGORY"], [14895, 14917, "TRAINED_CATEGORY"], [14928, 14965, "TRAINED_CATEGORY"], [14967, 14978, "TRAINED_CATEGORY"], [14990, 15002, "TRAINED_CATEGORY"], [15014, 15038, "TRAINED_CATEGORY"], [15049, 15061, "TRAINED_CATEGORY"], [15100, 15124, "TRAINED_CATEGORY"], [15141, 15146, "TRAINED_CATEGORY"], [15155, 15170, "TRAINED_CATEGORY"], [15172, 15181, "TRAINED_CATEGORY"], [15185, 15193, "TRAINED_CATEGORY"], [15197, 15206, "TRAINED_CATEGORY"], [15210, 15220, "TRAINED_CATEGORY"], [15239, 15245, "TRAINED_CATEGORY"], [15248, 15269, "TRAINED_CATEGORY"], [15278, 15302, "TRAINED_CATEGORY"], [15315, 15325, "TRAINED_CATEGORY"], [15329, 15351, "TRAINED_CATEGORY"], [15353, 15360, "TRAINED_CATEGORY"], [15375, 15381, "TRAINED_CATEGORY"], [15391, 15397, "TRAINED_CATEGORY"], [15401, 15408, "TRAINED_CATEGORY"], [15409, 15414, "TRAINED_CATEGORY"], [15531, 15541, "TRAINED_CATEGORY"], [15543, 15555, "TRAINED_CATEGORY"], [15559, 15572, "TRAINED_CATEGORY"], [15574, 15600, "TRAINED_CATEGORY"], [15613, 15621, "TRAINED_CATEGORY"], [15626, 15645, "TRAINED_CATEGORY"], [15647, 15671, "TRAINED_CATEGORY"], [15679, 15703, "TRAINED_CATEGORY"], [15720, 15744, "TRAINED_CATEGORY"], [15765, 15782, "TRAINED_CATEGORY"], [15784, 15794, "TRAINED_CATEGORY"], [15799, 15812, "TRAINED_CATEGORY"], [15825, 15834, "TRAINED_CATEGORY"], [15841, 15846, "TRAINED_CATEGORY"], [15850, 15859, "TRAINED_CATEGORY"], [15863, 15874, "TRAINED_CATEGORY"], [15891, 15917, "TRAINED_CATEGORY"], [15937, 15952, "TRAINED_CATEGORY"], [15960, 15965, "TRAINED_CATEGORY"], [15973, 15982, "TRAINED_CATEGORY"], [15984, 16006, "TRAINED_CATEGORY"], [16011, 16021, "TRAINED_CATEGORY"], [16032, 16057, "TRAINED_CATEGORY"], [16078, 16082, "TRAINED_CATEGORY"], [16093, 16104, "TRAINED_CATEGORY"], [16123, 16131, "TRAINED_CATEGORY"], [16160, 16171, "TRAINED_CATEGORY"], [16173, 16184, "TRAINED_CATEGORY"], [16198, 16224, "TRAINED_CATEGORY"], [16240, 16265, "TRAINED_CATEGORY"], [16267, 16272, "TRAINED_CATEGORY"], [16276, 16286, "TRAINED_CATEGORY"], [16291, 16317, "TRAINED_CATEGORY"], [16319, 16338, "TRAINED_CATEGORY"], [16340, 16353, "TRAINED_CATEGORY"], [16358, 16368, "TRAINED_CATEGORY"], [16399, 16411, "TRAINED_CATEGORY"], [16415, 16434, "TRAINED_CATEGORY"], [16462, 16473, "TRAINED_CATEGORY"], [16492, 16499, "TRAINED_CATEGORY"], [16507, 16545, "TRAINED_CATEGORY"], [16549, 16560, "TRAINED_CATEGORY"], [16562, 16568, "TRAINED_CATEGORY"], [16573, 16587, "TRAINED_CATEGORY"], [16587, 16593, "TRAINED_CATEGORY"], [16608, 16619, "TRAINED_CATEGORY"], [16634, 16638, "TRAINED_CATEGORY"], [16646, 16652, "TRAINED_CATEGORY"], [16666, 16678, "TRAINED_CATEGORY"], [16689, 16705, "TRAINED_CATEGORY"], [16709, 16724, "TRAINED_CATEGORY"], [16736, 16745, "TRAINED_CATEGORY"], [16754, 16765, "TRAINED_CATEGORY"], [16789, 16805, "TRAINED_CATEGORY"], [16807, 16818, "TRAINED_CATEGORY"], [16840, 16860, "TRAINED_CATEGORY"], [16870, 16890, "TRAINED_CATEGORY"], [16913, 16919, "TRAINED_CATEGORY"], [16923, 16929, "TRAINED_CATEGORY"], [16951, 16963, "TRAINED_CATEGORY"], [16968, 16984, "TRAINED_CATEGORY"], [17025, 17034, "TRAINED_CATEGORY"], [17038, 17056, "TRAINED_CATEGORY"], [17060, 17067, "TRAINED_CATEGORY"], [17069, 17074, "TRAINED_CATEGORY"], [17084, 17111, "TRAINED_CATEGORY"], [17117, 17128, "TRAINED_CATEGORY"], [17138, 17146, "TRAINED_CATEGORY"], [17151, 17158, "TRAINED_CATEGORY"], [17160, 17171, "TRAINED_CATEGORY"], [17173, 17180, "TRAINED_CATEGORY"], [17217, 17226, "TRAINED_CATEGORY"], [17231, 17235, "TRAINED_CATEGORY"], [17239, 17255, "TRAINED_CATEGORY"], [17262, 17274, "TRAINED_CATEGORY"], [17293, 17299, "TRAINED_CATEGORY"], [17313, 17315, "TRAINED_CATEGORY"], [17343, 17355, "TRAINED_CATEGORY"], [17365, 17390, "TRAINED_CATEGORY"], [17405, 17425, "TRAINED_CATEGORY"], [17427, 17447, "TRAINED_CATEGORY"], [17451, 17465, "TRAINED_CATEGORY"], [17469, 17477, "TRAINED_CATEGORY"], [17484, 17496, "TRAINED_CATEGORY"], [17500, 17521, "TRAINED_CATEGORY"], [17531, 17539, "TRAINED_CATEGORY"], [17543, 17553, "TRAINED_CATEGORY"], [17568, 17577, "TRAINED_CATEGORY"], [17598, 17615, "TRAINED_CATEGORY"], [17617, 17622, "TRAINED_CATEGORY"], [17628, 17638, "TRAINED_CATEGORY"], [17663, 17671, "TRAINED_CATEGORY"], [17705, 17715, "TRAINED_CATEGORY"], [17722, 17727, "TRAINED_CATEGORY"], [17748, 17763, "TRAINED_CATEGORY"], [17765, 17775, "TRAINED_CATEGORY"], [17792, 17801, "TRAINED_CATEGORY"], [17810, 17824, "TRAINED_CATEGORY"], [17835, 17857, "TRAINED_CATEGORY"], [17862, 17873, "TRAINED_CATEGORY"], [17888, 17899, "TRAINED_CATEGORY"], [17907, 17928, "TRAINED_CATEGORY"], [17953, 17977, "TRAINED_CATEGORY"], [17981, 17990, "TRAINED_CATEGORY"], [17995, 18004, "TRAINED_CATEGORY"], [18052, 18077, "TRAINED_CATEGORY"], [18102, 18121, "TRAINED_CATEGORY"], [18125, 18131, "TRAINED_CATEGORY"], [18166, 18178, "TRAINED_CATEGORY"], [18184, 18230, "TRAINED_CATEGORY"], [18260, 18266, "TRAINED_CATEGORY"], [18281, 18308, "TRAINED_CATEGORY"], [18310, 18320, "TRAINED_CATEGORY"], [18324, 18330, "TRAINED_CATEGORY"], [18332, 18342, "TRAINED_CATEGORY"], [18346, 18352, "TRAINED_CATEGORY"], [18360, 18365, "TRAINED_CATEGORY"], [18390, 18406, "TRAINED_CATEGORY"], [18418, 18429, "TRAINED_CATEGORY"], [18433, 18439, "TRAINED_CATEGORY"], [18467, 18492, "TRAINED_CATEGORY"], [18494, 18505, "TRAINED_CATEGORY"], [18507, 18514, "TRAINED_CATEGORY"], [18524, 18538, "TRAINED_CATEGORY"], [18576, 18584, "TRAINED_CATEGORY"], [18591, 18604, "TRAINED_CATEGORY"], [18626, 18646, "TRAINED_CATEGORY"], [18648, 18661, "TRAINED_CATEGORY"], [18666, 18675, "TRAINED_CATEGORY"], [18683, 18696, "TRAINED_CATEGORY"], [18713, 18715, "TRAINED_CATEGORY"], [18721, 18730, "TRAINED_CATEGORY"], [18732, 18741, "TRAINED_CATEGORY"], [18761, 18775, "TRAINED_CATEGORY"], [18793, 18797, "TRAINED_CATEGORY"], [18799, 18812, "TRAINED_CATEGORY"], [18814, 18821, "TRAINED_CATEGORY"], [18835, 18845, "TRAINED_CATEGORY"], [18858, 18871, "TRAINED_CATEGORY"], [18876, 18878, "TRAINED_CATEGORY"], [18879, 18881, "TRAINED_CATEGORY"], [18908, 18922, "TRAINED_CATEGORY"], [18926, 18933, "TRAINED_CATEGORY"], [18943, 18954, "TRAINED_CATEGORY"], [18958, 18967, "TRAINED_CATEGORY"], [18975, 18987, "TRAINED_CATEGORY"], [18991, 18999, "TRAINED_CATEGORY"], [19032, 19041, "TRAINED_CATEGORY"], [19045, 19058, "TRAINED_CATEGORY"], [19077, 19111, "TRAINED_CATEGORY"], [19113, 19133, "TRAINED_CATEGORY"], [19161, 19173, "TRAINED_CATEGORY"], [19189, 19210, "TRAINED_CATEGORY"], [19215, 19238, "TRAINED_CATEGORY"], [19248, 19264, "TRAINED_CATEGORY"], [19269, 19281, "TRAINED_CATEGORY"], [19297, 19315, "TRAINED_CATEGORY"], [19317, 19337, "TRAINED_CATEGORY"], [19342, 19357, "TRAINED_CATEGORY"], [19366, 19396, "TRAINED_CATEGORY"], [19407, 19435, "TRAINED_CATEGORY"], [19447, 19460, "TRAINED_CATEGORY"], [19497, 19506, "TRAINED_CATEGORY"], [19508, 19510, "TRAINED_CATEGORY"], [19530, 19536, "TRAINED_CATEGORY"], [19567, 19586, "TRAINED_CATEGORY"], [19593, 19597, "TRAINED_CATEGORY"], [19624, 19646, "TRAINED_CATEGORY"], [19648, 19670, "TRAINED_CATEGORY"], [19681, 19689, "TRAINED_CATEGORY"], [19709, 19716, "TRAINED_CATEGORY"], [19730, 19748, "TRAINED_CATEGORY"], [19753, 19760, "TRAINED_CATEGORY"], [19764, 19771, "TRAINED_CATEGORY"], [19785, 19792, "TRAINED_CATEGORY"], [19793, 19821, "TRAINED_CATEGORY"], [19832, 19837, "TRAINED_CATEGORY"], [19842, 19850, "TRAINED_CATEGORY"], [19852, 19867, "TRAINED_CATEGORY"], [19871, 19891, "TRAINED_CATEGORY"], [19900, 19909, "TRAINED_CATEGORY"], [19913, 19917, "TRAINED_CATEGORY"], [19921, 19931, "TRAINED_CATEGORY"], [19932, 19939, "TRAINED_CATEGORY"], [19944, 19954, "TRAINED_CATEGORY"], [19986, 19993, "TRAINED_CATEGORY"], [20005, 20007, "TRAINED_CATEGORY"], [20025, 20032, "TRAINED_CATEGORY"], [20053, 20065, "TRAINED_CATEGORY"], [20078, 20103, "TRAINED_CATEGORY"], [20114, 20120, "TRAINED_CATEGORY"], [20129, 20149, "TRAINED_CATEGORY"], [20156, 20163, "TRAINED_CATEGORY"], [20173, 20194, "TRAINED_CATEGORY"], [20211, 20227, "TRAINED_CATEGORY"], [20238, 20256, "TRAINED_CATEGORY"], [20267, 20281, "TRAINED_CATEGORY"], [20291, 20318, "TRAINED_CATEGORY"], [20322, 20337, "TRAINED_CATEGORY"], [20341, 20381, "TRAINED_CATEGORY"], [20399, 20420, "TRAINED_CATEGORY"], [20424, 20442, "TRAINED_CATEGORY"], [20444, 20462, "TRAINED_CATEGORY"], [20472, 20494, "TRAINED_CATEGORY"], [20498, 20513, "TRAINED_CATEGORY"], [20518, 20544, "TRAINED_CATEGORY"], [20548, 20558, "TRAINED_CATEGORY"], [20559, 20583, "TRAINED_CATEGORY"], [20605, 20615, "TRAINED_CATEGORY"], [20620, 20628, "TRAINED_CATEGORY"], [20650, 20663, "TRAINED_CATEGORY"], [20667, 20693, "TRAINED_CATEGORY"], [20702, 20714, "TRAINED_CATEGORY"], [20729, 20738, "TRAINED_CATEGORY"], [20749, 20770, "TRAINED_CATEGORY"], [20777, 20785, "TRAINED_CATEGORY"], [20787, 20798, "TRAINED_CATEGORY"], [20804, 20810, "TRAINED_CATEGORY"], [20820, 20828, "TRAINED_CATEGORY"], [20833, 20835, "TRAINED_CATEGORY"], [20864, 20870, "TRAINED_CATEGORY"], [20872, 20880, "TRAINED_CATEGORY"], [20905, 20932, "TRAINED_CATEGORY"], [20934, 20951, "TRAINED_CATEGORY"], [20955, 20979, "TRAINED_CATEGORY"], [21032, 21062, "TRAINED_CATEGORY"], [21075, 21085, "TRAINED_CATEGORY"], [21089, 21096, "TRAINED_CATEGORY"], [21112, 21121, "TRAINED_CATEGORY"], [21123, 21156, "TRAINED_CATEGORY"], [21181, 21189, "TRAINED_CATEGORY"], [21230, 21238, "TRAINED_CATEGORY"], [21251, 21255, "TRAINED_CATEGORY"], [21261, 21271, "TRAINED_CATEGORY"], [21272, 21280, "TRAINED_CATEGORY"], [21300, 21321, "TRAINED_CATEGORY"], [21333, 21337, "TRAINED_CATEGORY"], [21343, 21356, "TRAINED_CATEGORY"], [21369, 21377, "TRAINED_CATEGORY"], [21382, 21388, "TRAINED_CATEGORY"], [21406, 21417, "TRAINED_CATEGORY"], [21421, 21448, "TRAINED_CATEGORY"], [21450, 21468, "TRAINED_CATEGORY"], [21482, 21496, "TRAINED_CATEGORY"], [21500, 21518, "TRAINED_CATEGORY"], [21523, 21527, "TRAINED_CATEGORY"], [21531, 21549, "TRAINED_CATEGORY"], [21551, 21559, "TRAINED_CATEGORY"], [21565, 21592, "TRAINED_CATEGORY"], [21623, 21637, "TRAINED_CATEGORY"], [21638, 21642, "TRAINED_CATEGORY"], [21664, 21678, "TRAINED_CATEGORY"], [21682, 21697, "TRAINED_CATEGORY"], [21703, 21705, "TRAINED_CATEGORY"], [21715, 21723, "TRAINED_CATEGORY"], [21727, 21735, "TRAINED_CATEGORY"], [21739, 21754, "TRAINED_CATEGORY"], [21756, 21764, "TRAINED_CATEGORY"], [21769, 21775, "TRAINED_CATEGORY"], [21794, 21802, "TRAINED_CATEGORY"], [21826, 21837, "TRAINED_CATEGORY"], [21841, 21858, "TRAINED_CATEGORY"], [21871, 21883, "TRAINED_CATEGORY"], [21885, 21893, "TRAINED_CATEGORY"], [21898, 21905, "TRAINED_CATEGORY"], [21920, 21931, "TRAINED_CATEGORY"], [21944, 21969, "TRAINED_CATEGORY"], [21971, 21990, "TRAINED_CATEGORY"], [22005, 22028, "TRAINED_CATEGORY"], [22032, 22040, "TRAINED_CATEGORY"], [22044, 22052, "TRAINED_CATEGORY"], [22068, 22106, "TRAINED_CATEGORY"], [22136, 22144, "TRAINED_CATEGORY"], [22162, 22173, "TRAINED_CATEGORY"], [22185, 22207, "TRAINED_CATEGORY"], [22209, 22214, "TRAINED_CATEGORY"], [22229, 22254, "TRAINED_CATEGORY"], [22259, 22273, "TRAINED_CATEGORY"], [22275, 22290, "TRAINED_CATEGORY"], [22316, 22327, "TRAINED_CATEGORY"], [22331, 22350, "TRAINED_CATEGORY"], [22359, 22370, "TRAINED_CATEGORY"], [22375, 22381, "TRAINED_CATEGORY"], [22389, 22404, "TRAINED_CATEGORY"], [22406, 22417, "TRAINED_CATEGORY"], [22438, 22449, "TRAINED_CATEGORY"], [22453, 22468, "TRAINED_CATEGORY"], [22484, 22490, "TRAINED_CATEGORY"], [22494, 22499, "TRAINED_CATEGORY"], [22503, 22512, "TRAINED_CATEGORY"], [22530, 22544, "TRAINED_CATEGORY"], [22548, 22571, "TRAINED_CATEGORY"], [22587, 22602, "TRAINED_CATEGORY"], [22604, 22612, "TRAINED_CATEGORY"], [22616, 22644, "TRAINED_CATEGORY"], [22661, 22676, "TRAINED_CATEGORY"], [22686, 22701, "TRAINED_CATEGORY"], [22703, 22721, "TRAINED_CATEGORY"], [22723, 22744, "TRAINED_CATEGORY"], [22749, 22759, "TRAINED_CATEGORY"], [22763, 22776, "TRAINED_CATEGORY"], [22781, 22789, "TRAINED_CATEGORY"], [22791, 22802, "TRAINED_CATEGORY"], [22821, 22840, "TRAINED_CATEGORY"], [22859, 22871, "TRAINED_CATEGORY"], [22882, 22897, "TRAINED_CATEGORY"], [22910, 22921, "TRAINED_CATEGORY"], [22942, 22948, "TRAINED_CATEGORY"], [22953, 22964, "TRAINED_CATEGORY"], [22974, 22999, "TRAINED_CATEGORY"], [23005, 23016, "TRAINED_CATEGORY"], [23087, 23110, "TRAINED_CATEGORY"], [23127, 23142, "TRAINED_CATEGORY"], [23153, 23179, "TRAINED_CATEGORY"], [23183, 23194, "TRAINED_CATEGORY"], [23202, 23213, "TRAINED_CATEGORY"], [23217, 23229, "TRAINED_CATEGORY"], [23238, 23270, "TRAINED_CATEGORY"], [23275, 23304, "TRAINED_CATEGORY"], [23306, 23329, "TRAINED_CATEGORY"], [23333, 23342, "TRAINED_CATEGORY"], [23353, 23381, "TRAINED_CATEGORY"], [23420, 23437, "TRAINED_CATEGORY"], [23439, 23476, "TRAINED_CATEGORY"], [23480, 23488, "TRAINED_CATEGORY"], [23493, 23508, "TRAINED_CATEGORY"], [23518, 23532, "TRAINED_CATEGORY"], [23536, 23552, "TRAINED_CATEGORY"], [23558, 23568, "TRAINED_CATEGORY"], [23572, 23579, "TRAINED_CATEGORY"], [23590, 23616, "TRAINED_CATEGORY"], [23653, 23682, "TRAINED_CATEGORY"], [23718, 23733, "TRAINED_CATEGORY"], [23737, 23743, "TRAINED_CATEGORY"], [23745, 23774, "TRAINED_CATEGORY"], [23800, 23826, "TRAINED_CATEGORY"], [23849, 23875, "TRAINED_CATEGORY"], [23881, 23904, "TRAINED_CATEGORY"], [23922, 23933, "TRAINED_CATEGORY"], [23949, 23977, "TRAINED_CATEGORY"], [23979, 24007, "TRAINED_CATEGORY"], [24032, 24037, "TRAINED_CATEGORY"], [24041, 24050, "TRAINED_CATEGORY"], [24063, 24080, "TRAINED_CATEGORY"], [24090, 24095, "TRAINED_CATEGORY"], [24107, 24114, "TRAINED_CATEGORY"], [24118, 24124, "TRAINED_CATEGORY"], [24130, 24151, "TRAINED_CATEGORY"], [24153, 24169, "TRAINED_CATEGORY"], [24204, 24214, "TRAINED_CATEGORY"], [24228, 24266, "TRAINED_CATEGORY"], [24268, 24273, "TRAINED_CATEGORY"], [24297, 24311, "TRAINED_CATEGORY"], [24320, 24324, "TRAINED_CATEGORY"], [24332, 24344, "TRAINED_CATEGORY"], [24348, 24355, "TRAINED_CATEGORY"], [24377, 24379, "TRAINED_CATEGORY"], [24392, 24420, "TRAINED_CATEGORY"], [24433, 24444, "TRAINED_CATEGORY"], [24452, 24456, "TRAINED_CATEGORY"], [24458, 24472, "TRAINED_CATEGORY"], [24487, 24498, "TRAINED_CATEGORY"], [24504, 24516, "TRAINED_CATEGORY"], [24538, 24545, "TRAINED_CATEGORY"], [24549, 24557, "TRAINED_CATEGORY"], [24561, 24569, "TRAINED_CATEGORY"], [24592, 24599, "TRAINED_CATEGORY"], [24606, 24620, "TRAINED_CATEGORY"], [24624, 24630, "TRAINED_CATEGORY"], [24636, 24640, "TRAINED_CATEGORY"], [24674, 24680, "TRAINED_CATEGORY"], [24684, 24697, "TRAINED_CATEGORY"], [24707, 24714, "TRAINED_CATEGORY"], [24718, 24726, "TRAINED_CATEGORY"], [24730, 24739, "TRAINED_CATEGORY"], [24754, 24768, "TRAINED_CATEGORY"], [24788, 24807, "TRAINED_CATEGORY"], [24815, 24821, "TRAINED_CATEGORY"], [24826, 24832, "TRAINED_CATEGORY"], [24870, 24887, "TRAINED_CATEGORY"], [24896, 24926, "TRAINED_CATEGORY"], [24949, 24958, "TRAINED_CATEGORY"], [24965, 24967, "TRAINED_CATEGORY"], [24980, 25006, "TRAINED_CATEGORY"], [25016, 25027, "TRAINED_CATEGORY"], [25031, 25043, "TRAINED_CATEGORY"], [25052, 25075, "TRAINED_CATEGORY"], [25095, 25101, "TRAINED_CATEGORY"], [25126, 25136, "TRAINED_CATEGORY"], [25140, 25150, "TRAINED_CATEGORY"], [25161, 25165, "TRAINED_CATEGORY"], [25172, 25184, "TRAINED_CATEGORY"], [25190, 25197, "TRAINED_CATEGORY"], [25199, 25204, "TRAINED_CATEGORY"], [25234, 25239, "TRAINED_CATEGORY"], [25240, 25243, "TRAINED_CATEGORY"], [25258, 25262, "TRAINED_CATEGORY"], [25274, 25280, "TRAINED_CATEGORY"], [25288, 25294, "TRAINED_CATEGORY"], [25317, 25326, "TRAINED_CATEGORY"], [25330, 25344, "TRAINED_CATEGORY"], [25351, 25380, "TRAINED_CATEGORY"], [25384, 25390, "TRAINED_CATEGORY"], [25406, 25431, "TRAINED_CATEGORY"], [25433, 25437, "TRAINED_CATEGORY"], [25455, 25468, "TRAINED_CATEGORY"], [25473, 25486, "TRAINED_CATEGORY"], [25502, 25513, "TRAINED_CATEGORY"], [25521, 25525, "TRAINED_CATEGORY"], [25552, 25558, "TRAINED_CATEGORY"], [25562, 25585, "TRAINED_CATEGORY"], [25589, 25597, "TRAINED_CATEGORY"], [25602, 25617, "TRAINED_CATEGORY"], [25620, 25636, "TRAINED_CATEGORY"], [25641, 25649, "TRAINED_CATEGORY"], [25665, 25682, "TRAINED_CATEGORY"], [25685, 25691, "TRAINED_CATEGORY"], [25721, 25726, "TRAINED_CATEGORY"], [25740, 25759, "TRAINED_CATEGORY"], [25764, 25785, "TRAINED_CATEGORY"], [25799, 25820, "TRAINED_CATEGORY"], [25822, 25833, "TRAINED_CATEGORY"], [25834, 25837, "TRAINED_CATEGORY"], [25862, 25873, "TRAINED_CATEGORY"], [25879, 25932, "TRAINED_CATEGORY"], [25948, 25951, "TRAINED_CATEGORY"], [25960, 25986, "TRAINED_CATEGORY"], [25988, 26009, "TRAINED_CATEGORY"], [26013, 26019, "TRAINED_CATEGORY"], [26024, 26032, "TRAINED_CATEGORY"], [26034, 26040, "TRAINED_CATEGORY"], [26056, 26077, "TRAINED_CATEGORY"], [26094, 26096, "TRAINED_CATEGORY"], [26109, 26126, "TRAINED_CATEGORY"], [26130, 26147, "TRAINED_CATEGORY"], [26158, 26183, "TRAINED_CATEGORY"], [26187, 26195, "TRAINED_CATEGORY"], [26199, 26216, "TRAINED_CATEGORY"], [26240, 26246, "TRAINED_CATEGORY"], [26267, 26278, "TRAINED_CATEGORY"], [26284, 26288, "TRAINED_CATEGORY"], [26325, 26334, "TRAINED_CATEGORY"], [26340, 26357, "TRAINED_CATEGORY"], [26361, 26372, "TRAINED_CATEGORY"], [26389, 26398, "TRAINED_CATEGORY"], [26436, 26440, "TRAINED_CATEGORY"], [26483, 26503, "TRAINED_CATEGORY"], [26507, 26530, "TRAINED_CATEGORY"], [26532, 26548, "TRAINED_CATEGORY"], [26552, 26562, "TRAINED_CATEGORY"], [26578, 26584, "TRAINED_CATEGORY"], [26588, 26624, "TRAINED_CATEGORY"], [26644, 26654, "TRAINED_CATEGORY"], [26659, 26667, "TRAINED_CATEGORY"], [26669, 26691, "TRAINED_CATEGORY"], [26704, 26710, "TRAINED_CATEGORY"], [26719, 26733, "TRAINED_CATEGORY"], [26737, 26764, "TRAINED_CATEGORY"], [26773, 26791, "TRAINED_CATEGORY"], [26823, 26829, "TRAINED_CATEGORY"], [26844, 26858, "TRAINED_CATEGORY"], [26862, 26885, "TRAINED_CATEGORY"], [26914, 26938, "TRAINED_CATEGORY"], [26944, 26960, "TRAINED_CATEGORY"], [26963, 26982, "TRAINED_CATEGORY"], [26986, 26999, "TRAINED_CATEGORY"], [27003, 27007, "TRAINED_CATEGORY"], [27011, 27028, "TRAINED_CATEGORY"], [27055, 27070, "TRAINED_CATEGORY"], [27074, 27087, "TRAINED_CATEGORY"], [27099, 27103, "TRAINED_CATEGORY"], [27104, 27107, "TRAINED_CATEGORY"], [27140, 27159, "TRAINED_CATEGORY"], [27163, 27180, "TRAINED_CATEGORY"], [27208, 27217, "TRAINED_CATEGORY"], [27243, 27262, "TRAINED_CATEGORY"], [27275, 27283, "TRAINED_CATEGORY"], [27287, 27309, "TRAINED_CATEGORY"], [27311, 27321, "TRAINED_CATEGORY"], [27325, 27338, "TRAINED_CATEGORY"], [27353, 27365, "TRAINED_CATEGORY"], [27374, 27383, "TRAINED_CATEGORY"], [27385, 27408, "TRAINED_CATEGORY"], [27412, 27422, "TRAINED_CATEGORY"], [27433, 27453, "TRAINED_CATEGORY"], [27457, 27466, "TRAINED_CATEGORY"], [27470, 27476, "TRAINED_CATEGORY"], [27485, 27495, "TRAINED_CATEGORY"], [27497, 27509, "TRAINED_CATEGORY"], [27514, 27519, "TRAINED_CATEGORY"], [27529, 27539, "TRAINED_CATEGORY"], [27549, 27555, "TRAINED_CATEGORY"], [27578, 27588, "TRAINED_CATEGORY"], [27592, 27598, "TRAINED_CATEGORY"], [27604, 27608, "TRAINED_CATEGORY"], [27624, 27633, "TRAINED_CATEGORY"], [27636, 27689, "TRAINED_CATEGORY"], [27691, 27697, "TRAINED_CATEGORY"], [27706, 27716, "TRAINED_CATEGORY"], [27720, 27732, "TRAINED_CATEGORY"], [27736, 27745, "TRAINED_CATEGORY"], [27776, 27784, "TRAINED_CATEGORY"], [27788, 27805, "TRAINED_CATEGORY"], [27835, 27861, "TRAINED_CATEGORY"], [27867, 27881, "TRAINED_CATEGORY"], [27907, 27913, "TRAINED_CATEGORY"], [27932, 27949, "TRAINED_CATEGORY"], [27953, 27969, "TRAINED_CATEGORY"], [27981, 27990, "TRAINED_CATEGORY"], [27995, 28002, "TRAINED_CATEGORY"], [28016, 28030, "TRAINED_CATEGORY"], [28034, 28039, "TRAINED_CATEGORY"], [28043, 28059, "TRAINED_CATEGORY"], [28068, 28076, "TRAINED_CATEGORY"], [28078, 28094, "TRAINED_CATEGORY"], [28109, 28115, "TRAINED_CATEGORY"], [28124, 28139, "TRAINED_CATEGORY"], [28143, 28150, "TRAINED_CATEGORY"], [28152, 28168, "TRAINED_CATEGORY"], [28172, 28182, "TRAINED_CATEGORY"], [28197, 28233, "TRAINED_CATEGORY"], [28251, 28262, "TRAINED_CATEGORY"], [28267, 28279, "TRAINED_CATEGORY"], [28283, 28290, "TRAINED_CATEGORY"], [28292, 28298, "TRAINED_CATEGORY"], [28321, 28339, "TRAINED_CATEGORY"], [28351, 28361, "TRAINED_CATEGORY"], [28373, 28377, "TRAINED_CATEGORY"], [28383, 28395, "TRAINED_CATEGORY"], [28401, 28407, "TRAINED_CATEGORY"], [28413, 28417, "TRAINED_CATEGORY"], [28478, 28486, "TRAINED_CATEGORY"], [28502, 28506, "TRAINED_CATEGORY"], [28510, 28525, "TRAINED_CATEGORY"], [28531, 28538, "TRAINED_CATEGORY"], [28546, 28598, "TRAINED_CATEGORY"], [28602, 28617, "TRAINED_CATEGORY"], [28621, 28635, "TRAINED_CATEGORY"], [28649, 28664, "TRAINED_CATEGORY"], [28666, 28668, "TRAINED_CATEGORY"], [28678, 28691, "TRAINED_CATEGORY"], [28699, 28709, "TRAINED_CATEGORY"], [28716, 28735, "TRAINED_CATEGORY"], [28745, 28749, "TRAINED_CATEGORY"], [28750, 28754, "TRAINED_CATEGORY"], [28783, 28796, "TRAINED_CATEGORY"], [28798, 28808, "TRAINED_CATEGORY"], [28826, 28839, "TRAINED_CATEGORY"], [28873, 28880, "TRAINED_CATEGORY"], [28886, 28890, "TRAINED_CATEGORY"], [28923, 28931, "TRAINED_CATEGORY"], [28937, 28941, "TRAINED_CATEGORY"], [28957, 28961, "TRAINED_CATEGORY"], [28972, 28984, "TRAINED_CATEGORY"], [28988, 28998, "TRAINED_CATEGORY"], [29009, 29024, "TRAINED_CATEGORY"], [29034, 29042, "TRAINED_CATEGORY"], [29064, 29087, "TRAINED_CATEGORY"], [29089, 29102, "TRAINED_CATEGORY"], [29129, 29135, "TRAINED_CATEGORY"], [29152, 29168, "TRAINED_CATEGORY"], [29199, 29204, "TRAINED_CATEGORY"], [29221, 29236, "TRAINED_CATEGORY"], [29292, 29305, "TRAINED_CATEGORY"], [29314, 29322, "TRAINED_CATEGORY"], [29327, 29338, "TRAINED_CATEGORY"], [29340, 29353, "TRAINED_CATEGORY"], [29357, 29367, "TRAINED_CATEGORY"], [29384, 29398, "TRAINED_CATEGORY"], [29402, 29417, "TRAINED_CATEGORY"], [29431, 29441, "TRAINED_CATEGORY"], [29460, 29474, "TRAINED_CATEGORY"], [29478, 29498, "TRAINED_CATEGORY"], [29500, 29524, "TRAINED_CATEGORY"], [29557, 29565, "TRAINED_CATEGORY"], [29569, 29585, "TRAINED_CATEGORY"], [29594, 29604, "TRAINED_CATEGORY"], [29617, 29640, "TRAINED_CATEGORY"], [29642, 29658, "TRAINED_CATEGORY"], [29669, 29684, "TRAINED_CATEGORY"], [29689, 29704, "TRAINED_CATEGORY"], [29708, 29720, "TRAINED_CATEGORY"], [29735, 29742, "TRAINED_CATEGORY"], [29746, 29752, "TRAINED_CATEGORY"], [29754, 29781, "TRAINED_CATEGORY"], [29819, 29835, "TRAINED_CATEGORY"], [29839, 29854, "TRAINED_CATEGORY"], [29861, 29882, "TRAINED_CATEGORY"], [29886, 29892, "TRAINED_CATEGORY"], [29900, 29906, "TRAINED_CATEGORY"], [29908, 29914, "TRAINED_CATEGORY"], [29924, 29933, "TRAINED_CATEGORY"], [29942, 29970, "TRAINED_CATEGORY"], [29972, 29982, "TRAINED_CATEGORY"], [29995, 30006, "TRAINED_CATEGORY"], [30008, 30027, "TRAINED_CATEGORY"], [30045, 30052, "TRAINED_CATEGORY"], [30054, 30065, "TRAINED_CATEGORY"], [30069, 30078, "TRAINED_CATEGORY"], [30101, 30112, "TRAINED_CATEGORY"], [30124, 30141, "TRAINED_CATEGORY"], [30152, 30163, "TRAINED_CATEGORY"], [30172, 30183, "TRAINED_CATEGORY"], [30193, 30208, "TRAINED_CATEGORY"], [30227, 30238, "TRAINED_CATEGORY"], [30249, 30260, "TRAINED_CATEGORY"], [30286, 30296, "TRAINED_CATEGORY"], [30320, 30353, "TRAINED_CATEGORY"], [30364, 30368, "TRAINED_CATEGORY"], [30372, 30382, "TRAINED_CATEGORY"], [30386, 30390, "TRAINED_CATEGORY"], [30394, 30402, "TRAINED_CATEGORY"], [30409, 30414, "TRAINED_CATEGORY"], [30418, 30429, "TRAINED_CATEGORY"], [30437, 30453, "TRAINED_CATEGORY"], [30478, 30489, "TRAINED_CATEGORY"], [30495, 30511, "TRAINED_CATEGORY"], [30519, 30529, "TRAINED_CATEGORY"], [30530, 30550, "TRAINED_CATEGORY"], [30563, 30571, "TRAINED_CATEGORY"], [30577, 30598, "TRAINED_CATEGORY"], [30613, 30634, "TRAINED_CATEGORY"], [30636, 30650, "TRAINED_CATEGORY"], [30655, 30696, "TRAINED_CATEGORY"], [30698, 30728, "TRAINED_CATEGORY"], [30744, 30766, "TRAINED_CATEGORY"], [30775, 30795, "TRAINED_CATEGORY"], [30797, 30807, "TRAINED_CATEGORY"], [30820, 30839, "TRAINED_CATEGORY"], [30849, 30860, "TRAINED_CATEGORY"], [30880, 30890, "TRAINED_CATEGORY"], [30914, 30924, "TRAINED_CATEGORY"], [30952, 30961, "TRAINED_CATEGORY"], [30969, 30977, "TRAINED_CATEGORY"], [30990, 31001, "TRAINED_CATEGORY"], [31009, 31022, "TRAINED_CATEGORY"], [31032, 31041, "TRAINED_CATEGORY"], [31053, 31057, "TRAINED_CATEGORY"], [31089, 31104, "TRAINED_CATEGORY"], [31122, 31126, "TRAINED_CATEGORY"], [31146, 31157, "TRAINED_CATEGORY"], [31176, 31186, "TRAINED_CATEGORY"], [31252, 31268, "TRAINED_CATEGORY"], [31269, 31284, "TRAINED_CATEGORY"], [31295, 31300, "TRAINED_CATEGORY"], [31324, 31341, "TRAINED_CATEGORY"], [31342, 31357, "TRAINED_CATEGORY"], [31362, 31374, "TRAINED_CATEGORY"], [31395, 31421, "TRAINED_CATEGORY"], [31425, 31435, "TRAINED_CATEGORY"], [31439, 31451, "TRAINED_CATEGORY"], [31460, 31469, "TRAINED_CATEGORY"], [31473, 31492, "TRAINED_CATEGORY"], [31494, 31523, "TRAINED_CATEGORY"], [31548, 31576, "TRAINED_CATEGORY"], [31598, 31604, "TRAINED_CATEGORY"], [31610, 31648, "TRAINED_CATEGORY"], [31652, 31667, "TRAINED_CATEGORY"], [31675, 31681, "TRAINED_CATEGORY"], [31687, 31697, "TRAINED_CATEGORY"], [31709, 31724, "TRAINED_CATEGORY"], [31728, 31743, "TRAINED_CATEGORY"], [31745, 31751, "TRAINED_CATEGORY"], [31763, 31780, "TRAINED_CATEGORY"], [31784, 31792, "TRAINED_CATEGORY"], [31797, 31805, "TRAINED_CATEGORY"], [31960, 31970, "TRAINED_CATEGORY"], [31975, 31981, "TRAINED_CATEGORY"], [31986, 31993, "TRAINED_CATEGORY"], [32032, 32053, "TRAINED_CATEGORY"], [32055, 32066, "TRAINED_CATEGORY"], [32088, 32094, "TRAINED_CATEGORY"], [32099, 32111, "TRAINED_CATEGORY"], [32115, 32121, "TRAINED_CATEGORY"], [32126, 32133, "TRAINED_CATEGORY"], [32135, 32151, "TRAINED_CATEGORY"], [32164, 32172, "TRAINED_CATEGORY"], [32176, 32181, "TRAINED_CATEGORY"], [32196, 32201, "TRAINED_CATEGORY"], [32216, 32231, "TRAINED_CATEGORY"], [32235, 32244, "TRAINED_CATEGORY"], [32246, 32266, "TRAINED_CATEGORY"], [32270, 32292, "TRAINED_CATEGORY"], [32320, 32347, "TRAINED_CATEGORY"], [32389, 32400, "TRAINED_CATEGORY"], [32430, 32441, "TRAINED_CATEGORY"], [32443, 32456, "TRAINED_CATEGORY"], [32477, 32488, "TRAINED_CATEGORY"], [32501, 32517, "TRAINED_CATEGORY"], [32549, 32560, "TRAINED_CATEGORY"], [32577, 32585, "TRAINED_CATEGORY"], [32589, 32594, "TRAINED_CATEGORY"], [32609, 32625, "TRAINED_CATEGORY"], [32627, 32641, "TRAINED_CATEGORY"], [32650, 32670, "TRAINED_CATEGORY"], [32674, 32685, "TRAINED_CATEGORY"], [32687, 32721, "TRAINED_CATEGORY"], [32727, 32760, "TRAINED_CATEGORY"], [32763, 32792, "TRAINED_CATEGORY"], [32796, 32810, "TRAINED_CATEGORY"], [32815, 32828, "TRAINED_CATEGORY"], [32830, 32853, "TRAINED_CATEGORY"], [32876, 32931, "TRAINED_CATEGORY"], [32937, 32946, "TRAINED_CATEGORY"], [32958, 32978, "TRAINED_CATEGORY"], [32984, 33001, "TRAINED_CATEGORY"], [33014, 33037, "TRAINED_CATEGORY"], [33041, 33046, "TRAINED_CATEGORY"], [33048, 33064, "TRAINED_CATEGORY"], [33073, 33096, "TRAINED_CATEGORY"], [33106, 33144, "TRAINED_CATEGORY"], [33146, 33164, "TRAINED_CATEGORY"], [33168, 33176, "TRAINED_CATEGORY"], [33178, 33206, "TRAINED_CATEGORY"], [33210, 33226, "TRAINED_CATEGORY"], [33229, 33242, "TRAINED_CATEGORY"], [33285, 33295, "TRAINED_CATEGORY"], [33316, 33321, "TRAINED_CATEGORY"], [33340, 33352, "TRAINED_CATEGORY"], [33357, 33363, "TRAINED_CATEGORY"], [33365, 33378, "TRAINED_CATEGORY"], [33386, 33396, "TRAINED_CATEGORY"], [33401, 33413, "TRAINED_CATEGORY"], [33423, 33448, "TRAINED_CATEGORY"], [33456, 33466, "TRAINED_CATEGORY"], [33476, 33492, "TRAINED_CATEGORY"], [33496, 33515, "TRAINED_CATEGORY"], [33526, 33547, "TRAINED_CATEGORY"], [33566, 33576, "TRAINED_CATEGORY"], [33599, 33614, "TRAINED_CATEGORY"], [33616, 33629, "TRAINED_CATEGORY"], [33633, 33641, "TRAINED_CATEGORY"], [33645, 33660, "TRAINED_CATEGORY"], [33665, 33688, "TRAINED_CATEGORY"], [33692, 33696, "TRAINED_CATEGORY"], [33697, 33717, "TRAINED_CATEGORY"], [33740, 33757, "TRAINED_CATEGORY"], [33763, 33774, "TRAINED_CATEGORY"], [33778, 33800, "TRAINED_CATEGORY"], [33809, 33825, "TRAINED_CATEGORY"], [33830, 33843, "TRAINED_CATEGORY"], [33878, 33899, "TRAINED_CATEGORY"], [33938, 33953, "TRAINED_CATEGORY"], [33957, 33969, "TRAINED_CATEGORY"], [33986, 33989, "TRAINED_CATEGORY"], [34004, 34022, "TRAINED_CATEGORY"], [34035, 34055, "TRAINED_CATEGORY"], [34057, 34067, "TRAINED_CATEGORY"], [34082, 34116, "TRAINED_CATEGORY"], [34120, 34141, "TRAINED_CATEGORY"], [34147, 34167, "TRAINED_CATEGORY"], [34174, 34184, "TRAINED_CATEGORY"], [34185, 34200, "TRAINED_CATEGORY"], [34212, 34222, "TRAINED_CATEGORY"], [34229, 34231, "TRAINED_CATEGORY"], [34254, 34267, "TRAINED_CATEGORY"], [34278, 34293, "TRAINED_CATEGORY"], [34301, 34315, "TRAINED_CATEGORY"], [34319, 34340, "TRAINED_CATEGORY"], [34343, 34345, "TRAINED_CATEGORY"], [34352, 34355, "TRAINED_CATEGORY"], [34393, 34397, "TRAINED_CATEGORY"], [34398, 34414, "TRAINED_CATEGORY"], [34419, 34441, "TRAINED_CATEGORY"], [34443, 34462, "TRAINED_CATEGORY"], [34466, 34482, "TRAINED_CATEGORY"], [34486, 34501, "TRAINED_CATEGORY"], [34529, 34545, "TRAINED_CATEGORY"], [34565, 34581, "TRAINED_CATEGORY"], [34585, 34607, "TRAINED_CATEGORY"], [34611, 34623, "TRAINED_CATEGORY"], [34632, 34647, "TRAINED_CATEGORY"], [34651, 34664, "TRAINED_CATEGORY"], [34673, 34694, "TRAINED_CATEGORY"], [34698, 34709, "TRAINED_CATEGORY"], [34721, 34741, "TRAINED_CATEGORY"], [34745, 34764, "TRAINED_CATEGORY"], [34772, 34781, "TRAINED_CATEGORY"], [34785, 34802, "TRAINED_CATEGORY"], [34820, 34839, "TRAINED_CATEGORY"], [34841, 34875, "TRAINED_CATEGORY"], [34887, 34907, "TRAINED_CATEGORY"], [34911, 34932, "TRAINED_CATEGORY"], [34934, 34939, "TRAINED_CATEGORY"], [34950, 34955, "TRAINED_CATEGORY"], [34959, 34983, "TRAINED_CATEGORY"], [35025, 35029, "TRAINED_CATEGORY"], [35032, 35051, "TRAINED_CATEGORY"], [35055, 35071, "TRAINED_CATEGORY"], [35090, 35097, "TRAINED_CATEGORY"], [35099, 35111, "TRAINED_CATEGORY"], [35116, 35128, "TRAINED_CATEGORY"], [35130, 35138, "TRAINED_CATEGORY"], [35143, 35153, "TRAINED_CATEGORY"], [35159, 35166, "TRAINED_CATEGORY"], [35171, 35180, "TRAINED_CATEGORY"], [35182, 35185, "TRAINED_CATEGORY"], [35199, 35231, "TRAINED_CATEGORY"], [35257, 35261, "TRAINED_CATEGORY"], [35271, 35292, "TRAINED_CATEGORY"], [35298, 35305, "TRAINED_CATEGORY"], [35307, 35314, "TRAINED_CATEGORY"], [35315, 35318, "TRAINED_CATEGORY"], [35331, 35343, "TRAINED_CATEGORY"], [35389, 35403, "TRAINED_CATEGORY"], [35423, 35502, "TRAINED_CATEGORY"], [35513, 35531, "TRAINED_CATEGORY"], [35541, 35549, "TRAINED_CATEGORY"], [35556, 35567, "TRAINED_CATEGORY"], [35572, 35580, "TRAINED_CATEGORY"], [35607, 35620, "TRAINED_CATEGORY"], [35634, 35678, "TRAINED_CATEGORY"], [35682, 35697, "TRAINED_CATEGORY"], [35711, 35727, "TRAINED_CATEGORY"], [35733, 35740, "TRAINED_CATEGORY"], [35742, 35758, "TRAINED_CATEGORY"], [35774, 35821, "TRAINED_CATEGORY"], [35835, 35863, "TRAINED_CATEGORY"], [35867, 35882, "TRAINED_CATEGORY"], [35883, 35908, "TRAINED_CATEGORY"], [35918, 35929, "TRAINED_CATEGORY"], [35933, 35942, "TRAINED_CATEGORY"], [35953, 35985, "TRAINED_CATEGORY"], [35993, 36022, "TRAINED_CATEGORY"], [36024, 36028, "TRAINED_CATEGORY"], [36037, 36082, "TRAINED_CATEGORY"], [36096, 36109, "TRAINED_CATEGORY"], [36114, 36128, "TRAINED_CATEGORY"], [36140, 36167, "TRAINED_CATEGORY"], [36228, 36271, "TRAINED_CATEGORY"], [36292, 36303, "TRAINED_CATEGORY"], [36308, 36317, "TRAINED_CATEGORY"], [36323, 36332, "TRAINED_CATEGORY"], [36378, 36390, "TRAINED_CATEGORY"], [36398, 36412, "TRAINED_CATEGORY"], [36428, 36437, "TRAINED_CATEGORY"], [36453, 36458, "TRAINED_CATEGORY"], [36464, 36483, "TRAINED_CATEGORY"], [36486, 36504, "TRAINED_CATEGORY"], [36508, 36526, "TRAINED_CATEGORY"], [36536, 36558, "TRAINED_CATEGORY"], [36563, 36576, "TRAINED_CATEGORY"], [36584, 36595, "TRAINED_CATEGORY"], [36612, 36622, "TRAINED_CATEGORY"], [36627, 36637, "TRAINED_CATEGORY"], [36639, 36653, "TRAINED_CATEGORY"], [36669, 36680, "TRAINED_CATEGORY"], [36703, 36720, "TRAINED_CATEGORY"], [36734, 36742, "TRAINED_CATEGORY"], [36747, 36751, "TRAINED_CATEGORY"], [36762, 36773, "TRAINED_CATEGORY"], [36794, 36815, "TRAINED_CATEGORY"], [36817, 36836, "TRAINED_CATEGORY"], [36840, 36850, "TRAINED_CATEGORY"], [36854, 36876, "TRAINED_CATEGORY"], [36881, 36894, "TRAINED_CATEGORY"], [36899, 36909, "TRAINED_CATEGORY"], [36914, 36928, "TRAINED_CATEGORY"], [36947, 36958, "TRAINED_CATEGORY"], [36967, 36971, "TRAINED_CATEGORY"], [36977, 36986, "TRAINED_CATEGORY"], [36992, 37012, "TRAINED_CATEGORY"], [37034, 37038, "TRAINED_CATEGORY"], [37045, 37049, "TRAINED_CATEGORY"], [37071, 37082, "TRAINED_CATEGORY"], [37084, 37098, "TRAINED_CATEGORY"], [37114, 37127, "TRAINED_CATEGORY"], [37139, 37146, "TRAINED_CATEGORY"], [37159, 37178, "TRAINED_CATEGORY"], [37193, 37213, "TRAINED_CATEGORY"], [37218, 37230, "TRAINED_CATEGORY"], [37234, 37247, "TRAINED_CATEGORY"], [37267, 37277, "TRAINED_CATEGORY"], [37279, 37293, "TRAINED_CATEGORY"], [37304, 37311, "TRAINED_CATEGORY"], [37313, 37319, "TRAINED_CATEGORY"], [37321, 37330, "TRAINED_CATEGORY"], [37342, 37356, "TRAINED_CATEGORY"], [37378, 37390, "TRAINED_CATEGORY"], [37392, 37410, "TRAINED_CATEGORY"], [37423, 37441, "TRAINED_CATEGORY"], [37452, 37462, "TRAINED_CATEGORY"], [37467, 37477, "TRAINED_CATEGORY"], [37479, 37493, "TRAINED_CATEGORY"], [37509, 37519, "TRAINED_CATEGORY"], [37532, 37546, "TRAINED_CATEGORY"], [37564, 37581, "TRAINED_CATEGORY"], [37583, 37604, "TRAINED_CATEGORY"], [37608, 37614, "TRAINED_CATEGORY"], [37623, 37633, "TRAINED_CATEGORY"], [37682, 37692, "TRAINED_CATEGORY"], [37697, 37707, "TRAINED_CATEGORY"], [37709, 37723, "TRAINED_CATEGORY"], [37754, 37761, "TRAINED_CATEGORY"], [37773, 37775, "TRAINED_CATEGORY"], [37812, 37828, "TRAINED_CATEGORY"], [37842, 37863, "TRAINED_CATEGORY"], [37883, 37913, "TRAINED_CATEGORY"], [37919, 37945, "TRAINED_CATEGORY"], [37960, 37963, "TRAINED_CATEGORY"], [37986, 38002, "TRAINED_CATEGORY"], [38006, 38032, "TRAINED_CATEGORY"], [38034, 38043, "TRAINED_CATEGORY"], [38060, 38073, "TRAINED_CATEGORY"], [38090, 38116, "TRAINED_CATEGORY"], [38131, 38140, "TRAINED_CATEGORY"], [38147, 38158, "TRAINED_CATEGORY"], [38189, 38200, "TRAINED_CATEGORY"], [38204, 38213, "TRAINED_CATEGORY"], [38244, 38257, "TRAINED_CATEGORY"], [38273, 38295, "TRAINED_CATEGORY"], [38310, 38322, "TRAINED_CATEGORY"], [38326, 38356, "TRAINED_CATEGORY"], [38361, 38367, "TRAINED_CATEGORY"], [38371, 38388, "TRAINED_CATEGORY"], [38398, 38402, "TRAINED_CATEGORY"], [38417, 38429, "TRAINED_CATEGORY"], [38433, 38443, "TRAINED_CATEGORY"], [38447, 38462, "TRAINED_CATEGORY"], [38464, 38468, "TRAINED_CATEGORY"], [38473, 38477, "TRAINED_CATEGORY"], [38481, 38501, "TRAINED_CATEGORY"], [38506, 38522, "TRAINED_CATEGORY"], [38524, 38533, "TRAINED_CATEGORY"], [38537, 38550, "TRAINED_CATEGORY"], [38563, 38582, "TRAINED_CATEGORY"], [38588, 38598, "TRAINED_CATEGORY"], [38624, 38638, "TRAINED_CATEGORY"], [38644, 38663, "TRAINED_CATEGORY"], [38668, 38676, "TRAINED_CATEGORY"], [38678, 38694, "TRAINED_CATEGORY"], [38698, 38724, "TRAINED_CATEGORY"], [38742, 38761, "TRAINED_CATEGORY"], [38762, 38766, "TRAINED_CATEGORY"], [38794, 38826, "TRAINED_CATEGORY"], [38831, 38841, "TRAINED_CATEGORY"], [38847, 38864, "TRAINED_CATEGORY"], [38868, 38898, "TRAINED_CATEGORY"], [38900, 38910, "TRAINED_CATEGORY"], [38912, 38921, "TRAINED_CATEGORY"], [38927, 38946, "TRAINED_CATEGORY"], [38969, 38989, "TRAINED_CATEGORY"], [38991, 39004, "TRAINED_CATEGORY"], [39028, 39051, "TRAINED_CATEGORY"], [39055, 39070, "TRAINED_CATEGORY"], [39074, 39097, "TRAINED_CATEGORY"], [39099, 39109, "TRAINED_CATEGORY"], [39114, 39123, "TRAINED_CATEGORY"], [39144, 39157, "TRAINED_CATEGORY"], [39169, 39173, "TRAINED_CATEGORY"], [39182, 39202, "TRAINED_CATEGORY"], [39207, 39222, "TRAINED_CATEGORY"], [39238, 39255, "TRAINED_CATEGORY"], [39266, 39284, "TRAINED_CATEGORY"], [39288, 39302, "TRAINED_CATEGORY"], [39304, 39312, "TRAINED_CATEGORY"], [39325, 39332, "TRAINED_CATEGORY"], [39342, 39356, "TRAINED_CATEGORY"], [39383, 39390, "TRAINED_CATEGORY"], [39401, 39408, "TRAINED_CATEGORY"], [39419, 39431, "TRAINED_CATEGORY"], [39449, 39468, "TRAINED_CATEGORY"], [39475, 39486, "TRAINED_CATEGORY"], [39488, 39514, "TRAINED_CATEGORY"], [39537, 39542, "TRAINED_CATEGORY"], [39564, 39597, "TRAINED_CATEGORY"], [39602, 39610, "TRAINED_CATEGORY"], [39627, 39657, "TRAINED_CATEGORY"], [39659, 39690, "TRAINED_CATEGORY"], [39720, 39729, "TRAINED_CATEGORY"], [39742, 39754, "TRAINED_CATEGORY"], [39764, 39789, "TRAINED_CATEGORY"], [39791, 39801, "TRAINED_CATEGORY"], [39805, 39824, "TRAINED_CATEGORY"], [39834, 39848, "TRAINED_CATEGORY"], [39852, 39859, "TRAINED_CATEGORY"], [39860, 39869, "TRAINED_CATEGORY"], [39882, 39895, "TRAINED_CATEGORY"], [39917, 39934, "TRAINED_CATEGORY"], [39958, 39968, "TRAINED_CATEGORY"], [552, 560, "NORP"], [590, 598, "GPE"], [2341, 2345, "ORG"], [3421, 3447, "ORG"], [3595, 3598, "CARDINAL"], [4867, 4872, "ORG"], [4933, 4938, "ORDINAL"], [5732, 5740, "ORG"], [6203, 6214, "PERSON"], [6226, 6231, "CARDINAL"], [6275, 6280, "ORDINAL"], [6377, 6380, "CARDINAL"], [6516, 6522, "ORDINAL"], [6598, 6603, "ORDINAL"], [6833, 6838, "ORDINAL"], [7727, 7742, "PERSON"], [8368, 8380, "NORP"], [8381, 8403, "PERSON"], [8528, 8543, "PERSON"], [8843, 8851, "ORG"], [9257, 9260, "CARDINAL"], [9907, 9913, "ORG"], [9960, 9972, "ORG"], [10155, 10158, "ORG"], [10682, 10685, "CARDINAL"], [10766, 10769, "CARDINAL"], [10819, 10822, "CARDINAL"], [11103, 11106, "ORG"], [11225, 11228, "ORG"], [11319, 11323, "DATE"], [12204, 12207, "CARDINAL"], [12255, 12269, "PERSON"], [12453, 12456, "CARDINAL"], [12633, 12638, "ORG"], [12643, 12652, "ORG"], [13050, 13063, "PERCENT"], [13492, 13495, "CARDINAL"], [13641, 13649, "PERSON"], [13718, 13724, "PERSON"], [13878, 13888, "PERSON"], [13961, 13971, "ORG"], [14644, 14649, "ORG"], [14670, 14687, "PERSON"], [15018, 15023, "ORDINAL"], [15172, 15181, "PERSON"], [15973, 15982, "DATE"], [15997, 16006, "PERSON"], [16065, 16070, "PRODUCT"], [16132, 16171, "WORK_OF_ART"], [16253, 16265, "PERSON"], [16267, 16272, "ORG"], [16291, 16295, "CARDINAL"], [16660, 16664, "DATE"], [16666, 16678, "PERSON"], [16736, 16739, "CARDINAL"], [16779, 16788, "PERSON"], [16891, 16898, "PERSON"], [16930, 16938, "PERSON"], [17019, 17023, "DATE"], [17025, 17034, "PERSON"], [17038, 17056, "ORG"], [17060, 17067, "GPE"], [17069, 17074, "GPE"], [17117, 17122, "CARDINAL"], [17160, 17166, "PERSON"], [17173, 17180, "PERSON"], [17359, 17363, "DATE"], [17375, 17390, "PERSON"], [17405, 17425, "ORG"], [17451, 17477, "ORG"], [17484, 17489, "CARDINAL"], [17543, 17553, "PERSON"], [18360, 18365, "ORG"], [18390, 18406, "PERSON"], [18418, 18422, "CARDINAL"], [18528, 18533, "ORDINAL"], [19467, 19475, "ORG"], [20238, 20241, "CARDINAL"], [20267, 20273, "GPE"], [20284, 20287, "CARDINAL"], [20777, 20785, "PRODUCT"], [20820, 20828, "PRODUCT"], [20934, 20937, "CARDINAL"], [21196, 21201, "FAC"], [21920, 21931, "DATE"], [22185, 22207, "DATE"], [25351, 25360, "ORG"], [25384, 25390, "PRODUCT"], [25948, 25951, "ORG"], [26060, 26065, "ORDINAL"], [26340, 26343, "CARDINAL"], [26410, 26413, "CARDINAL"], [26990, 26995, "ORDINAL"], [27835, 27839, "CARDINAL"], [29009, 29017, "ORG"], [29861, 29870, "ORG"], [29972, 29975, "CARDINAL"], [29995, 30000, "CARDINAL"], [30437, 30446, "ORG"], [30495, 30511, "PERSON"], [30775, 30778, "CARDINAL"], [30823, 30830, "GPE"], [31269, 31284, "PERSON"], [31342, 31357, "PERSON"], [31362, 31374, "PERSON"], [31460, 31463, "CARDINAL"], [31533, 31541, "WORK_OF_ART"], [31586, 31594, "WORK_OF_ART"], [31682, 31683, "CARDINAL"], [31752, 31753, "CARDINAL"], [31942, 31955, "ORG"], [32032, 32053, "PERSON"], [32135, 32151, "PERSON"], [32501, 32504, "CARDINAL"], [32609, 32625, "PERSON"], [32631, 32634, "CARDINAL"], [32650, 32653, "CARDINAL"], [32763, 32779, "PERSON"], [32800, 32803, "CARDINAL"], [33048, 33064, "PERSON"], [33913, 33918, "ORDINAL"], [34772, 34797, "ORG"], [34820, 34839, "PERSON"], [34934, 34939, "PERSON"], [34959, 34963, "CARDINAL"], [34996, 35001, "PERSON"], [35277, 35281, "CARDINAL"], [35545, 35549, "PERSON"], [35742, 35758, "PERSON"], [35774, 35782, "NORP"], [35784, 35792, "NORP"], [35797, 35804, "NORP"], [35887, 35892, "PERSON"], [35893, 35899, "PERSON"], [36024, 36028, "ORG"], [36072, 36076, "ORG"], [36096, 36109, "PERSON"], [36114, 36128, "PERSON"], [36140, 36144, "CARDINAL"], [36234, 36238, "CARDINAL"], [36323, 36326, "CARDINAL"], [37793, 37807, "ORG"], [38215, 38216, "CARDINAL"], [38481, 38501, "ORG"], [38828, 38829, "CARDINAL"], [39204, 39205, "CARDINAL"], [39599, 39600, "CARDINAL"]]}], ["The decision-making paradox relates to decision-making and the quest for determining reliable decision-making methods. It was first described in 1989, and has been recognized in the related literature as a fundamental paradox in multi-criteria decision analysis (MCDA), multi-criteria decision making (MCDM) and decision analysis since then.\n\n\n== Description ==\nThe decision-making paradox was first described in 1989,  and further elaborated in the 2000 book by Triantaphyllou on multi-criteria decision analysis (MCDA) / multi-criteria decision making (MCDM).\nIt arises from the observation that different decision-making methods, both normative and descriptive, yield different results, when fed with exactly the same decision problem and data.\nIt has been recognized in the related literature as a fundamental paradox in multi-criteria decision analysis (MCDA) / multi-criteria decision making (MCDM),  and decision analysis since then.\nTo find the best decision-making method a decision problem needs to be formulated, for which different decision-making methods are the alternatives. In order to select the best method from the available ones, the best method needs to be known a-priori.In a study reported in International Journal of Decision Support Systems and Multi-Criteria Decision Making: A Comparative Study, the following investigation was undertaken. Since in the beginning it was assumed that the best method is not known, the problem of selecting the best method was solved by successively using different methods. The methods used in that study were the weighted sum model (WSM), the weighted product model (WPM), and two variants of the analytic hierarchy process (AHP). It was found that when a method was used, say method X (which is one of the previous four methods), the conclusion was that another method was best (say, method Y). When method Y was used, then another method, say method Z, was suggested as being the best one, and so on.\nTwo evaluative criteria were used to formulate the previous decision-making problem, actually, an MCDM problem. The first criterion was based on the premise that a method which claims to be accurate in multi-dimensional problems (for which different units of measurement are used to describe the alternatives), should also be accurate in single-dimensional problems. For such problems, the weighted sum model (WSM) is the widely accepted approach, thus their results were compared with the ones derived from the WSM. \nThe second evaluative criterion was based on the situation: alternative A, is evaluated as the best alternative, compared to the non-optimal alternative B. If B is replaced by a worse one, one should expect that alternative A remains the best alternative, under normal conditions where the weights of the two evaluative criteria in all possible combinations always add equal to 1. If not it is known as a \"ranking reversal\".\n\n\n== Methods affected ==\nThe following multi-criteria decision-making methods have been confirmed to exhibit this paradox:The analytic hierarchy process (AHP) and some of its variants, the weighted product model  (WPM),  the ELECTRE (outranking) method and its variants and the TOPSIS method.\n\n\n== Other methods ==\nOther methods that have not been tested yet but may exhibit the same phenomenon include the following:\n\nThe analytic network process (ANP).\nThe PROMETHEE (outranking) method.\nMulti-attribute utility theory (MAUT).\nDominance-based rough set approach (DRSA)\nAggregated indices randomization method (AIRM)\nNonstructural fuzzy decision support system (NSFDSS)\nGrey relational analysis (GRA)\nSuperiority and inferiority ranking method (SIR method)\nPotentially all pairwise rankings of all possible alternatives (PAPRIKA)\nValue analysis (VA)A key role in this quest is played by the study of rank reversals in decision making.\n\n\n== References ==", {"entities": [[0, 27, "TRAINED_CATEGORY"], [39, 54, "TRAINED_CATEGORY"], [59, 68, "TRAINED_CATEGORY"], [85, 117, "TRAINED_CATEGORY"], [119, 121, "TRAINED_CATEGORY"], [178, 200, "TRAINED_CATEGORY"], [204, 225, "TRAINED_CATEGORY"], [229, 261, "TRAINED_CATEGORY"], [263, 267, "TRAINED_CATEGORY"], [302, 306, "TRAINED_CATEGORY"], [347, 358, "TRAINED_CATEGORY"], [362, 389, "TRAINED_CATEGORY"], [446, 459, "TRAINED_CATEGORY"], [463, 477, "TRAINED_CATEGORY"], [481, 513, "TRAINED_CATEGORY"], [515, 519, "TRAINED_CATEGORY"], [523, 553, "TRAINED_CATEGORY"], [555, 559, "TRAINED_CATEGORY"], [562, 564, "TRAINED_CATEGORY"], [577, 592, "TRAINED_CATEGORY"], [598, 631, "TRAINED_CATEGORY"], [671, 688, "TRAINED_CATEGORY"], [704, 737, "TRAINED_CATEGORY"], [742, 746, "TRAINED_CATEGORY"], [748, 750, "TRAINED_CATEGORY"], [774, 796, "TRAINED_CATEGORY"], [800, 821, "TRAINED_CATEGORY"], [825, 857, "TRAINED_CATEGORY"], [859, 863, "TRAINED_CATEGORY"], [899, 903, "TRAINED_CATEGORY"], [949, 980, "TRAINED_CATEGORY"], [981, 999, "TRAINED_CATEGORY"], [1034, 1067, "TRAINED_CATEGORY"], [1072, 1088, "TRAINED_CATEGORY"], [1093, 1098, "TRAINED_CATEGORY"], [1109, 1124, "TRAINED_CATEGORY"], [1130, 1148, "TRAINED_CATEGORY"], [1150, 1165, "TRAINED_CATEGORY"], [1196, 1203, "TRAINED_CATEGORY"], [1216, 1237, "TRAINED_CATEGORY"], [1241, 1265, "TRAINED_CATEGORY"], [1270, 1300, "TRAINED_CATEGORY"], [1302, 1321, "TRAINED_CATEGORY"], [1323, 1350, "TRAINED_CATEGORY"], [1376, 1389, "TRAINED_CATEGORY"], [1390, 1392, "TRAINED_CATEGORY"], [1410, 1425, "TRAINED_CATEGORY"], [1440, 1451, "TRAINED_CATEGORY"], [1465, 1480, "TRAINED_CATEGORY"], [1514, 1531, "TRAINED_CATEGORY"], [1533, 1544, "TRAINED_CATEGORY"], [1553, 1563, "TRAINED_CATEGORY"], [1569, 1591, "TRAINED_CATEGORY"], [1593, 1596, "TRAINED_CATEGORY"], [1599, 1625, "TRAINED_CATEGORY"], [1627, 1630, "TRAINED_CATEGORY"], [1637, 1649, "TRAINED_CATEGORY"], [1653, 1683, "TRAINED_CATEGORY"], [1684, 1688, "TRAINED_CATEGORY"], [1691, 1693, "TRAINED_CATEGORY"], [1714, 1722, "TRAINED_CATEGORY"], [1737, 1745, "TRAINED_CATEGORY"], [1763, 1788, "TRAINED_CATEGORY"], [1791, 1805, "TRAINED_CATEGORY"], [1815, 1829, "TRAINED_CATEGORY"], [1845, 1853, "TRAINED_CATEGORY"], [1861, 1869, "TRAINED_CATEGORY"], [1878, 1899, "TRAINED_CATEGORY"], [1905, 1913, "TRAINED_CATEGORY"], [1938, 1950, "TRAINED_CATEGORY"], [1963, 1986, "TRAINED_CATEGORY"], [2010, 2046, "TRAINED_CATEGORY"], [2075, 2094, "TRAINED_CATEGORY"], [2108, 2119, "TRAINED_CATEGORY"], [2125, 2133, "TRAINED_CATEGORY"], [2165, 2191, "TRAINED_CATEGORY"], [2203, 2218, "TRAINED_CATEGORY"], [2222, 2233, "TRAINED_CATEGORY"], [2255, 2271, "TRAINED_CATEGORY"], [2301, 2328, "TRAINED_CATEGORY"], [2334, 2347, "TRAINED_CATEGORY"], [2349, 2371, "TRAINED_CATEGORY"], [2373, 2376, "TRAINED_CATEGORY"], [2381, 2409, "TRAINED_CATEGORY"], [2416, 2429, "TRAINED_CATEGORY"], [2449, 2457, "TRAINED_CATEGORY"], [2471, 2478, "TRAINED_CATEGORY"], [2481, 2512, "TRAINED_CATEGORY"], [2526, 2539, "TRAINED_CATEGORY"], [2541, 2554, "TRAINED_CATEGORY"], [2572, 2592, "TRAINED_CATEGORY"], [2606, 2633, "TRAINED_CATEGORY"], [2640, 2641, "TRAINED_CATEGORY"], [2670, 2673, "TRAINED_CATEGORY"], [2715, 2735, "TRAINED_CATEGORY"], [2743, 2760, "TRAINED_CATEGORY"], [2767, 2778, "TRAINED_CATEGORY"], [2782, 2809, "TRAINED_CATEGORY"], [2813, 2838, "TRAINED_CATEGORY"], [2869, 2871, "TRAINED_CATEGORY"], [2884, 2903, "TRAINED_CATEGORY"], [2911, 2918, "TRAINED_CATEGORY"], [2931, 2983, "TRAINED_CATEGORY"], [3015, 3027, "TRAINED_CATEGORY"], [3028, 3058, "TRAINED_CATEGORY"], [3060, 3063, "TRAINED_CATEGORY"], [3077, 3089, "TRAINED_CATEGORY"], [3091, 3117, "TRAINED_CATEGORY"], [3119, 3123, "TRAINED_CATEGORY"], [3139, 3150, "TRAINED_CATEGORY"], [3163, 3175, "TRAINED_CATEGORY"], [3180, 3197, "TRAINED_CATEGORY"], [3204, 3217, "TRAINED_CATEGORY"], [3221, 3234, "TRAINED_CATEGORY"], [3281, 3300, "TRAINED_CATEGORY"], [3325, 3353, "TRAINED_CATEGORY"], [3355, 3358, "TRAINED_CATEGORY"], [3375, 3386, "TRAINED_CATEGORY"], [3396, 3426, "TRAINED_CATEGORY"], [3428, 3432, "TRAINED_CATEGORY"], [3435, 3469, "TRAINED_CATEGORY"], [3471, 3475, "TRAINED_CATEGORY"], [3477, 3487, "TRAINED_CATEGORY"], [3496, 3516, "TRAINED_CATEGORY"], [3518, 3522, "TRAINED_CATEGORY"], [3524, 3567, "TRAINED_CATEGORY"], [3569, 3575, "TRAINED_CATEGORY"], [3577, 3601, "TRAINED_CATEGORY"], [3603, 3606, "TRAINED_CATEGORY"], [3636, 3650, "TRAINED_CATEGORY"], [3664, 3688, "TRAINED_CATEGORY"], [3689, 3697, "TRAINED_CATEGORY"], [3701, 3726, "TRAINED_CATEGORY"], [3728, 3735, "TRAINED_CATEGORY"], [3737, 3751, "TRAINED_CATEGORY"], [3753, 3766, "TRAINED_CATEGORY"], [3770, 3780, "TRAINED_CATEGORY"], [3794, 3803, "TRAINED_CATEGORY"], [3807, 3821, "TRAINED_CATEGORY"], [3825, 3840, "TRAINED_CATEGORY"], [3847, 3857, "TRAINED_CATEGORY"], [145, 149, "DATE"], [394, 399, "ORDINAL"], [413, 417, "DATE"], [450, 454, "DATE"], [463, 477, "ORG"], [1216, 1265, "ORG"], [1270, 1301, "ORG"], [1627, 1630, "ORG"], [1637, 1640, "CARDINAL"], [1756, 1759, "CARDINAL"], [1776, 1780, "CARDINAL"], [1963, 1966, "CARDINAL"], [2079, 2084, "ORDINAL"], [2485, 2491, "ORDINAL"], [2634, 2641, "PERSON"], [2786, 2789, "CARDINAL"], [2859, 2860, "CARDINAL"], [3060, 3063, "ORG"], [3120, 3123, "ORG"], [3131, 3138, "WORK_OF_ART"], [3184, 3190, "ORG"], [3355, 3358, "ORG"], [3396, 3401, "ORG"], [3428, 3432, "ORG"], [3471, 3475, "ORG"], [3577, 3581, "PERSON"], [3728, 3735, "ORG"], [3753, 3757, "PRODUCT"]]}], ["Decision-making software (DM software) is software for computer applications that help individuals and organisations make choices and take decisions, typically by ranking, prioritizing or choosing from a number of options.\nAn early example of DM software was described in 1973. Before the advent of the World Wide Web, most DM software was spreadsheet-based, with the first web-based DM software appearing in the mid-1990s. Nowadays, many DM software products (mostly web-based) are available \u2013 e.g. see the comparison table below.\nMost DM software focuses on ranking, prioritizing or choosing from among alternatives characterized on multiple criteria or attributes. Thus most DM software is based on decision analysis, usually multi-criteria decision-making, and so is often referred to as \"decision analysis\" or \"multi-criteria decision-making\" software \u2013 commonly shortened to \"decision-making software\". Some decision support systems include a DM software component.\n\n\n== Purpose ==\nDM software can assist decision-makers \"at various stages of the decision-making process, including problem exploration and formulation, identification of decision alternatives and solution constraints, structuring of preferences, and tradeoff judgements.\"The purpose of DM software is to support the analysis involved at these various stages of the decision-making process, not to replace it. DM software \"should be used to support the process, not as the driving or dominating force.\"DM software frees users \"from the technical implementation details [of the decision-making method employed], allowing them to focus on the fundamental value judgements\". Nonetheless, DM software should not be employed blindly. \"Before using a software, it is necessary to have a sound knowledge of the adopted methodology and of the decision problem at hand.\"\n\n\n== Methods and features ==\n\n\n=== Decision-making methods ===\nAs mentioned earlier, most DM software is based on multi-criteria decision making (MCDM). MCDM involves evaluating and combining alternatives' characteristics on two or more criteria or attributes in order to rank, prioritize or choose from among the alternatives.DM software employs a variety of MCDM methods; popular examples include:\n\nAggregated Indices Randomization Method (AIRM)\nAnalytic Hierarchy Process (AHP)\nAnalytic network process (ANP, an extension of AHP)\nDEX (Decision EXpert)\nElimination and Choice Expressing Reality (ELECTRE)\nMeasuring Attractiveness by a Categorical Based Evaluation Technique (MACBETH)\nMulti-attribute global inference of quality (MAGIQ)\nPotentially All Pairwise RanKings of all possible Alternatives (PAPRIKA)\nPreference Ranking Organization Method for Enrichment Evaluation (PROMETHEE)\nEvidential reasoning approach for MCDM under hybrid uncertaintyThere are significant differences between these methods and, accordingly, the DM software implementing them. Such differences include:\n\nThe extent to which the decision problem is broken into a hierarchy of sub-problems;\nWhether or not pairwise comparisons of alternatives and/or criteria are used to elicit decision-makers' preferences;\nThe use of interval scale or ratio scale measurements of decision-makers' preferences;\nThe number of criteria included;\nThe number of alternatives evaluated, ranging from a few (finite) to infinite;\nThe extent to which numerical scores are used to value and/or rank alternatives;\nThe extent to which incomplete rankings (relative to complete rankings) of alternatives are produced;\nThe extent to which uncertainty is modeled and analyzed.\n\n\n=== Software features ===\nIn the process of helping decision-makers to rank, prioritize or choose from among alternatives, DM software products often include a variety of features and tools; common examples include:\n\nPairwise comparison\nSensitivity analysis\nGroup evaluation (teamwork)\nWeb-based implementation\n\n\n=== Comparison of decision-making software ===\nDM software includes the following notable examples.\n\n\n== See also ==\nCollaborative decision-making software\nList of concept- and mind-mapping software\nProject management software\nStrategic planning software\n\n\n== References ==", {"entities": [[0, 24, "TRAINED_CATEGORY"], [26, 37, "TRAINED_CATEGORY"], [42, 50, "TRAINED_CATEGORY"], [55, 76, "TRAINED_CATEGORY"], [87, 98, "TRAINED_CATEGORY"], [103, 116, "TRAINED_CATEGORY"], [122, 129, "TRAINED_CATEGORY"], [139, 148, "TRAINED_CATEGORY"], [172, 184, "TRAINED_CATEGORY"], [202, 210, "TRAINED_CATEGORY"], [214, 221, "TRAINED_CATEGORY"], [223, 239, "TRAINED_CATEGORY"], [243, 254, "TRAINED_CATEGORY"], [285, 295, "TRAINED_CATEGORY"], [299, 317, "TRAINED_CATEGORY"], [319, 335, "TRAINED_CATEGORY"], [364, 395, "TRAINED_CATEGORY"], [409, 422, "TRAINED_CATEGORY"], [434, 459, "TRAINED_CATEGORY"], [504, 524, "TRAINED_CATEGORY"], [532, 548, "TRAINED_CATEGORY"], [569, 581, "TRAINED_CATEGORY"], [605, 617, "TRAINED_CATEGORY"], [635, 652, "TRAINED_CATEGORY"], [656, 666, "TRAINED_CATEGORY"], [673, 689, "TRAINED_CATEGORY"], [702, 719, "TRAINED_CATEGORY"], [721, 759, "TRAINED_CATEGORY"], [793, 810, "TRAINED_CATEGORY"], [815, 856, "TRAINED_CATEGORY"], [882, 906, "TRAINED_CATEGORY"], [909, 938, "TRAINED_CATEGORY"], [947, 970, "TRAINED_CATEGORY"], [977, 984, "TRAINED_CATEGORY"], [988, 999, "TRAINED_CATEGORY"], [1011, 1026, "TRAINED_CATEGORY"], [1031, 1045, "TRAINED_CATEGORY"], [1049, 1076, "TRAINED_CATEGORY"], [1088, 1107, "TRAINED_CATEGORY"], [1112, 1123, "TRAINED_CATEGORY"], [1125, 1139, "TRAINED_CATEGORY"], [1143, 1164, "TRAINED_CATEGORY"], [1169, 1189, "TRAINED_CATEGORY"], [1206, 1217, "TRAINED_CATEGORY"], [1223, 1242, "TRAINED_CATEGORY"], [1248, 1255, "TRAINED_CATEGORY"], [1259, 1270, "TRAINED_CATEGORY"], [1285, 1297, "TRAINED_CATEGORY"], [1310, 1330, "TRAINED_CATEGORY"], [1334, 1361, "TRAINED_CATEGORY"], [1378, 1380, "TRAINED_CATEGORY"], [1382, 1393, "TRAINED_CATEGORY"], [1421, 1432, "TRAINED_CATEGORY"], [1441, 1472, "TRAINED_CATEGORY"], [1477, 1485, "TRAINED_CATEGORY"], [1492, 1497, "TRAINED_CATEGORY"], [1504, 1540, "TRAINED_CATEGORY"], [1545, 1571, "TRAINED_CATEGORY"], [1592, 1596, "TRAINED_CATEGORY"], [1609, 1641, "TRAINED_CATEGORY"], [1657, 1668, "TRAINED_CATEGORY"], [1715, 1725, "TRAINED_CATEGORY"], [1727, 1729, "TRAINED_CATEGORY"], [1751, 1768, "TRAINED_CATEGORY"], [1772, 1795, "TRAINED_CATEGORY"], [1803, 1823, "TRAINED_CATEGORY"], [1827, 1831, "TRAINED_CATEGORY"], [1839, 1846, "TRAINED_CATEGORY"], [1869, 1892, "TRAINED_CATEGORY"], [1919, 1935, "TRAINED_CATEGORY"], [1948, 1978, "TRAINED_CATEGORY"], [1980, 1984, "TRAINED_CATEGORY"], [1987, 1991, "TRAINED_CATEGORY"], [2026, 2055, "TRAINED_CATEGORY"], [2059, 2079, "TRAINED_CATEGORY"], [2083, 2093, "TRAINED_CATEGORY"], [2097, 2102, "TRAINED_CATEGORY"], [2144, 2160, "TRAINED_CATEGORY"], [2161, 2172, "TRAINED_CATEGORY"], [2181, 2190, "TRAINED_CATEGORY"], [2194, 2206, "TRAINED_CATEGORY"], [2208, 2224, "TRAINED_CATEGORY"], [2246, 2274, "TRAINED_CATEGORY"], [2276, 2280, "TRAINED_CATEGORY"], [2282, 2308, "TRAINED_CATEGORY"], [2309, 2313, "TRAINED_CATEGORY"], [2315, 2339, "TRAINED_CATEGORY"], [2341, 2344, "TRAINED_CATEGORY"], [2346, 2358, "TRAINED_CATEGORY"], [2362, 2365, "TRAINED_CATEGORY"], [2372, 2387, "TRAINED_CATEGORY"], [2405, 2430, "TRAINED_CATEGORY"], [2432, 2439, "TRAINED_CATEGORY"], [2451, 2465, "TRAINED_CATEGORY"], [2469, 2509, "TRAINED_CATEGORY"], [2511, 2518, "TRAINED_CATEGORY"], [2520, 2552, "TRAINED_CATEGORY"], [2556, 2563, "TRAINED_CATEGORY"], [2564, 2570, "TRAINED_CATEGORY"], [2572, 2605, "TRAINED_CATEGORY"], [2609, 2634, "TRAINED_CATEGORY"], [2636, 2643, "TRAINED_CATEGORY"], [2645, 2683, "TRAINED_CATEGORY"], [2688, 2709, "TRAINED_CATEGORY"], [2711, 2720, "TRAINED_CATEGORY"], [2722, 2751, "TRAINED_CATEGORY"], [2756, 2760, "TRAINED_CATEGORY"], [2795, 2818, "TRAINED_CATEGORY"], [2827, 2840, "TRAINED_CATEGORY"], [2859, 2874, "TRAINED_CATEGORY"], [2888, 2892, "TRAINED_CATEGORY"], [2894, 2910, "TRAINED_CATEGORY"], [2921, 2931, "TRAINED_CATEGORY"], [2941, 2961, "TRAINED_CATEGORY"], [2977, 2988, "TRAINED_CATEGORY"], [2992, 3004, "TRAINED_CATEGORY"], [3030, 3041, "TRAINED_CATEGORY"], [3045, 3057, "TRAINED_CATEGORY"], [3065, 3073, "TRAINED_CATEGORY"], [3093, 3121, "TRAINED_CATEGORY"], [3123, 3130, "TRAINED_CATEGORY"], [3134, 3148, "TRAINED_CATEGORY"], [3152, 3176, "TRAINED_CATEGORY"], [3180, 3208, "TRAINED_CATEGORY"], [3210, 3220, "TRAINED_CATEGORY"], [3224, 3232, "TRAINED_CATEGORY"], [3243, 3253, "TRAINED_CATEGORY"], [3257, 3269, "TRAINED_CATEGORY"], [3294, 3307, "TRAINED_CATEGORY"], [3322, 3332, "TRAINED_CATEGORY"], [3342, 3358, "TRAINED_CATEGORY"], [3384, 3401, "TRAINED_CATEGORY"], [3403, 3413, "TRAINED_CATEGORY"], [3456, 3473, "TRAINED_CATEGORY"], [3478, 3490, "TRAINED_CATEGORY"], [3505, 3515, "TRAINED_CATEGORY"], [3525, 3536, "TRAINED_CATEGORY"], [3568, 3576, "TRAINED_CATEGORY"], [3593, 3604, "TRAINED_CATEGORY"], [3616, 3631, "TRAINED_CATEGORY"], [3673, 3685, "TRAINED_CATEGORY"], [3687, 3707, "TRAINED_CATEGORY"], [3722, 3731, "TRAINED_CATEGORY"], [3735, 3743, "TRAINED_CATEGORY"], [3748, 3753, "TRAINED_CATEGORY"], [3755, 3770, "TRAINED_CATEGORY"], [3781, 3800, "TRAINED_CATEGORY"], [3801, 3821, "TRAINED_CATEGORY"], [3822, 3838, "TRAINED_CATEGORY"], [3840, 3848, "TRAINED_CATEGORY"], [3850, 3874, "TRAINED_CATEGORY"], [3881, 3891, "TRAINED_CATEGORY"], [3895, 3919, "TRAINED_CATEGORY"], [3924, 3935, "TRAINED_CATEGORY"], [3945, 3975, "TRAINED_CATEGORY"], [3994, 4032, "TRAINED_CATEGORY"], [4033, 4037, "TRAINED_CATEGORY"], [4041, 4075, "TRAINED_CATEGORY"], [4076, 4103, "TRAINED_CATEGORY"], [4104, 4131, "TRAINED_CATEGORY"], [4137, 4147, "TRAINED_CATEGORY"], [26, 28, "ORG"], [243, 245, "ORG"], [272, 276, "DATE"], [299, 317, "WORK_OF_ART"], [324, 326, "ORG"], [368, 373, "ORDINAL"], [384, 386, "ORG"], [409, 422, "DATE"], [439, 441, "ORG"], [537, 539, "ORG"], [678, 680, "ORG"], [949, 951, "ORG"], [977, 984, "ORG"], [988, 990, "ORG"], [1259, 1261, "ORG"], [1382, 1384, "ORG"], [1657, 1659, "ORG"], [1924, 1926, "ORG"], [2059, 2062, "CARDINAL"], [2161, 2163, "ORG"], [2315, 2323, "ORG"], [2341, 2344, "ORG"], [2362, 2365, "ORG"], [2367, 2370, "PERSON"], [2511, 2518, "PERSON"], [2520, 2525, "ORG"], [2622, 2634, "NORP"], [2636, 2643, "ORG"], [2645, 2676, "ORG"], [2863, 2865, "ORG"], [3687, 3689, "ORG"], [3801, 3812, "ORG"], [3924, 3926, "ORG"]]}], ["The analytic hierarchy process (AHP) is a structured technique for organizing and analyzing complex decisions, based on mathematics and psychology. It was developed by Thomas L. Saaty in the 1970s who partnered with Ernest Forman to develop Expert Choice in 1983, and has been extensively studied and refined since then. It represents an accurate approach for quantifying the weights of decision criteria. Individual experts\u2019 experiences are utilized to estimate the relative magnitudes of factors through pair-wise comparisons. Each of the respondents has to compare the relative importance between the two items under special designed questionnaire (note that while most of the surveys adopted the five point likert scale, AHP's questionnaire is 9 to 1 to 9, see Li et al. (2019)  )\n\n\n== Uses and applications ==\nAHP has particular application in group decision making, and is used around the world in a wide variety of decision situations, in fields such as government, business, industry, healthcare, shipbuilding and education.\nRather than prescribing a \"correct\" decision, the AHP helps decision makers find one that best suits their goal and their understanding of the problem. It provides a comprehensive and rational framework for structuring a decision problem, for representing and quantifying its elements, for relating those elements to overall goals, and for evaluating alternative solutions.\nUsers of the AHP first decompose their decision problem into a hierarchy of more easily comprehended sub-problems, each of which can be analyzed independently. The elements of the hierarchy can relate to any aspect of the decision problem\u2014tangible or intangible, carefully measured or roughly estimated, well or poorly understood\u2014anything at all that applies to the decision at hand.\nOnce the hierarchy is built, the decision makers systematically evaluate its various elements by comparing them to each other two at a time, with respect to their impact on an element above them in the hierarchy. In making the comparisons, the decision makers can use concrete data about the elements, but they typically use their judgments about the elements' relative meaning and importance. It is the essence of the AHP that human judgments, and not just the underlying information, can be used in performing the evaluations.The AHP converts these evaluations to numerical values that can be processed and compared over the entire range of the problem. A numerical weight or priority is derived for each element of the hierarchy, allowing diverse and often incommensurable elements to be compared to one another in a rational and consistent way. This capability distinguishes the AHP from other decision making techniques.\nIn the final step of the process, numerical priorities are calculated for each of the decision alternatives. These numbers represent the alternatives' relative ability to achieve the decision goal, so they allow a straightforward consideration of the various courses of action.\nSeveral firms supply computer software to assist in using the process.\nWhile it can be used by individuals working on straightforward decisions, the Analytic Hierarchy Process (AHP) is most useful where teams of people are working on complex problems, especially those with high stakes, involving human perceptions and judgments, whose resolutions have long-term repercussions.\nIt has unique advantages when important elements of the decision are difficult to quantify or compare, or where communication among team members is impeded by their different specializations, terminologies, or perspectives.\nDecision situations to which the AHP can be applied include:\nChoice \u2013 The selection of one alternative from a given set of alternatives, usually where there are multiple decision criteria involved.\nRanking \u2013 Putting a set of alternatives in order from most to least desirable.\nPrioritization \u2013 Determining the relative merit of members of a set of alternatives, as opposed to selecting a single one or merely ranking them\nResource allocation \u2013 Apportioning resources among a set of alternatives\nBenchmarking \u2013 Comparing the processes in one's own organization with those of other best-of-breed organizations\nQuality management \u2013 Dealing with the multidimensional aspects of quality and quality improvement\nConflict resolution \u2013 Settling disputes between parties with apparently incompatible goals or positionsThe applications of AHP to complex decision situations have numbered in the thousands, and have produced extensive results in problems involving planning, resource allocation, priority setting, and selection among alternatives. Other areas have included forecasting, total quality management, business process reengineering, quality function deployment, and the balanced scorecard. Many AHP applications are never reported to the world at large, because they take place at high levels of large organizations where security and privacy considerations prohibit their disclosure. But some uses of AHP are discussed in the literature. Recently these have included:\n\nSelect a type of nuclear reactors (Politecnico di Milano)\nDeciding how best to reduce the impact of global climate change (Fondazione Eni Enrico Mattei)\nQuantifying the overall quality of software systems (Microsoft Corporation)\nSelecting university faculty (Bloomsburg University of Pennsylvania)\nDeciding where to locate offshore manufacturing plants (University of Cambridge)\nAssessing risk in operating cross-country petroleum pipelines (American Society of Civil Engineers)\nDeciding how best to manage U.S. watersheds (U.S. Department of Agriculture)\nMore Effectively Define and Evaluate SAP Implementation Approaches (SAP Experts)\nAccelerated Bridge Construction Decision Making Tool to assist in determining the viability of accelerated bridge construction (ABC) over traditional construction methods and in selecting appropriate construction and contracting strategies on a case-by-case basis.AHP is sometimes used in designing highly specific procedures for particular situations, such as the rating of buildings by historic significance. It was recently applied to a project that uses video footage to assess the condition of highways in Virginia. Highway engineers first used it to determine the optimum scope of the project, then to justify its budget to lawmakers.\n\n\n== Education and scholarly research ==\nThough using the analytic hierarchy process requires no specialized academic training, it is considered an important subject in many institutions of higher learning, including schools of engineering and graduate schools of business. It is a particularly important subject in the quality field, and is taught in many specialized courses including Six Sigma, Lean Six Sigma, and QFD.The value of the AHP is recognized in developed and developing countries around the world. China is an example\u2014nearly a hundred Chinese universities offer courses in AHP, and many doctoral students choose AHP as the subject of their research and dissertations. Over 900 papers have been published on the subject in China, and there is at least one Chinese scholarly journal devoted exclusively to AHP.The International Symposium on the Analytic Hierarchy Process (ISAHP) holds biennial meetings of academics and practitioners interested in the field. A wide range of topics are covered. Those in 2005 ranged from \"Establishing Payment Standards for Surgical Specialists\", to \"Strategic Technology Roadmapping\", to \"Infrastructure Reconstruction in Devastated Countries\".\nAt the 2007 meeting in Valpara\u00edso, Chile, over 90 papers were presented from 19 countries, including the US, Germany, Japan, Chile, Malaysia, and Nepal. A similar number of papers were presented at the 2009 symposium in Pittsburgh, Pennsylvania, when 28 countries were represented. Subjects of the papers included Economic Stabilization in Latvia, Portfolio Selection in the Banking Sector, Wildfire Management to Help Mitigate Global Warming, and Rural Microprojects in Nepal.\n\n\n== Use ==\nAs can be seen in the material that follows, using the AHP involves the mathematical synthesis of numerous judgments about the decision problem at hand. It is not uncommon for these judgments to number in the dozens or even the hundreds. While the math can be done by hand or with a calculator, it is far more common to use one of several computerized methods for entering and synthesizing the judgments. The simplest of these involve standard spreadsheet software, while the most complex use custom software, often augmented by special devices for acquiring the judgments of decision makers gathered in a meeting room.\nThe procedure for using the AHP can be summarized as:\n\nModel the problem as a hierarchy containing the decision goal, the alternatives for reaching it, and the criteria for evaluating the alternatives.\nEstablish priorities among the elements of the hierarchy by making a series of judgments based on pairwise comparisons of the elements. For example, when comparing potential purchases of commercial real estate, the investors might say they prefer location over price and price over timing.\nSynthesize these judgments to yield a set of overall priorities for the hierarchy. This would combine the investors' judgments about location, price and timing for properties A, B, C, and D into overall priorities for each property.\nCheck the consistency of the judgments.\nCome to a final decision based on the results of this process.These steps are more fully described below.\n\n\n=== Model the problem as a hierarchy ===\nThe first step in the analytic hierarchy process is to model the problem as a hierarchy. In doing this, participants explore the aspects of the problem at levels from general to detailed, then express it in the multileveled way that the AHP requires. As they work to build the hierarchy, they increase their understanding of the problem, of its context, and of each other's thoughts and feelings about both.\n\n\n==== Hierarchies defined ====\nA hierarchy is a stratified system of ranking and organizing people, things, ideas, etc., where each element of the system, except for the top one, is subordinate to one or more other elements. Though the concept of hierarchy is easily grasped intuitively, it can also be described mathematically. Diagrams of hierarchies are often shaped roughly like pyramids, but other than having a single element at the top, there is nothing necessarily pyramid-shaped about a hierarchy.\nHuman organizations are often structured as hierarchies, where the hierarchical system is used for assigning responsibilities, exercising leadership, and facilitating communication. Familiar hierarchies of \"things\" include a desktop computer's tower unit at the \"top\", with its subordinate monitor, keyboard, and mouse \"below.\"\nIn the world of ideas, we use hierarchies to help us acquire detailed knowledge of complex reality: we structure the reality into its constituent parts, and these in turn into their own constituent parts, proceeding down the hierarchy as many levels as we care to. At each step, we focus on understanding a single component of the whole, temporarily disregarding the other components at this and all other levels. As we go through this process, we increase our global understanding of whatever complex reality we are studying.\nThink of the hierarchy that medical students use while learning anatomy\u2014they separately consider the musculoskeletal system (including parts and subparts like the hand and its constituent muscles and bones), the circulatory system (and its many levels and branches), the nervous system (and its numerous components and subsystems), etc., until they've covered all the systems and the important subdivisions of each. Advanced students continue the subdivision all the way to the level of the cell or molecule. In the end, the students understand the \"big picture\" and a considerable number of its details. Not only that, but they understand the relation of the individual parts to the whole. By working hierarchically, they've gained a comprehensive understanding of anatomy.\nSimilarly, when we approach a complex decision problem, we can use a hierarchy to integrate large amounts of information into our understanding of the situation. As we build this information structure, we form a better and better picture of the problem as a whole.\n\n\n==== Hierarchies in the AHP ====\nAn AHP hierarchy is a structured means of modeling the decision at hand. It consists of an overall goal, a group of options or alternatives for reaching the goal, and a group of factors or criteria that relate the alternatives to the goal. The criteria can be further broken down into subcriteria, sub-subcriteria, and so on, in as many levels as the problem requires. A criterion may not apply uniformly, but may have graded differences like a little sweetness is enjoyable but too much sweetness can be harmful. In that case the criterion is divided into subcriteria indicating different intensities of the criterion, like: little, medium, high and these intensities are prioritized through comparisons under the parent criterion, sweetness.\nPublished descriptions of AHP applications often include diagrams and descriptions of their hierarchies; some simple ones are shown throughout this article. More complex AHP hierarchies have been collected and reprinted in at least one book. More complex hierarchies can be found in a special talk page for this article.\nThe design of any AHP hierarchy will depend not only on the nature of the problem at hand, but also on the knowledge, judgments, values, opinions, needs, wants, etc. of the participants in the decision-making process. Constructing a hierarchy typically involves significant discussion, research, and discovery by those involved. Even after its initial construction, it can be changed to accommodate newly-thought-of criteria or criteria not originally considered to be important; alternatives can also be added, deleted, or changed.To better understand AHP hierarchies, consider a decision problem with a goal to be reached, three alternative ways of reaching the goal, and four criteria against which the alternatives need to be measured.\nSuch a hierarchy can be visualized as a diagram like the one immediately below, with the goal at the top, the three alternatives at the bottom, and the four criteria in between. There are useful terms for describing the parts of such diagrams: Each box is called a node. A node that is connected to one or more nodes in a level below it is called a parent node. The nodes to which it is so connected are called its children.\nApplying these definitions to the diagram below, the goal is the parent of the four criteria, and the four criteria are children of the goal. Each criterion is a parent of the three Alternatives. Note that there are only three Alternatives, but in the diagram, each of them is repeated under each of its parents.\n\nTo reduce the size of the drawing required, it is common to represent AHP hierarchies as shown in the diagram below, with only one node for each alternative, and with multiple lines connecting the alternatives and the criteria that apply to them. To avoid clutter, these lines are sometimes omitted or reduced in number. Regardless of any such simplifications in the diagram, in the actual hierarchy each criterion is individually connected to the alternatives. The lines may be thought of as being directed downward from the parent in one level to its children in the level below.\n\n\n=== Evaluate the hierarchy ===\nOnce the hierarchy has been constructed, the participants analyze it through a series of pairwise comparisons that derive numerical scales of measurement for the nodes. The criteria are pairwise compared against the goal for importance. The alternatives are pairwise compared against each of the criteria for preference. The comparisons are processed mathematically, and priorities are derived for each node.\nConsider the \"Choose a Leader\" example above. An important task of the decision makers is to determine the weight to be given each criterion in making the choice of a leader. Another important task is to determine the weight to be given to each candidate with regard to each of the criteria. The AHP not only lets them do that, but it lets them put a meaningful and objective numerical value on each of the four criteria.\n\n\n=== Establish priorities ===\nThis section explains priorities, shows how they are established, and provides a simple example.\n\n\n==== Priorities defined and explained ====\nPriorities are numbers associated with the nodes of an AHP hierarchy. They represent the relative weights of the nodes in any group.\nLike probabilities, priorities are absolute numbers between zero and one, without units or dimensions. A node with priority .200 has twice the weight in reaching the goal as one with priority .100, ten times the weight of one with priority .020, and so forth. Depending on the problem at hand, \"weight\" can refer to importance, or preference, or likelihood, or whatever factor is being considered by the decision makers.\nPriorities are distributed over a hierarchy according to its architecture, and their values depend on the information entered by users of the process. Priorities of the Goal, the Criteria, and the Alternatives are intimately related, but need to be considered separately.\nBy definition, the priority of the Goal is 1.000. The priorities of the alternatives always add up to 1.000. Things can become complicated with multiple levels of Criteria, but if there is only one level, their priorities also add to 1.000. All this is illustrated by the priorities in the example below.\n\nObserve that the priorities on each level of the example\u2014the goal, the criteria, and the alternatives\u2014all add up to 1.000.\nThe priorities shown are those that exist before any information has been entered about weights of the criteria or alternatives, so the priorities within each level are all equal. They are called the hierarchy's default priorities. If a fifth Criterion were added to this hierarchy, the default priority for each Criterion would be .200. If there were only two Alternatives, each would have a default priority of .500.\nTwo additional concepts apply when a hierarchy has more than one level of criteria: local priorities and global priorities. Consider the hierarchy shown below, which has several Subcriteria under each Criterion.\n\nThe local priorities, shown in gray, represent the relative weights of the nodes within a group of siblings with respect to their parent. The local priorities of each group of Criteria and their sibling Subcriteria add up to 1.000. The global priorities, shown in black, are obtained by multiplying the local priorities of the siblings by their parent's global priority. The global priorities for all the subcriteria in the level add up to 1.000.\nThe rule is this: Within a hierarchy, the global priorities of child nodes always add up to the global priority of their parent. Within a group of children, the local priorities add up to 1.000.\nSo far, we have looked only at default priorities. As the Analytical Hierarchy Process moves forward, the priorities will change from their default values as the decision makers input information about the importance of the various nodes. They do this by making a series of pairwise comparisons.\n\n\n== Practical examples ==\nExperienced practitioners know that the best way to understand the AHP is to work through cases and examples. Two detailed case studies, specifically designed as in-depth teaching examples, are provided as appendices to this article:\n\nSimple step-by-step example with four Criteria and three Alternatives: Choosing a leader for an organization.\nMore complex step-by-step example with ten Criteria/Subcriteria and six Alternatives: Buying a family car and Machinery Selection Example.Some of the books on AHP contain practical examples of its use, though they are not typically intended to be step-by-step learning aids. One of them contains a handful of expanded examples, plus about 400 AHP hierarchies briefly described and illustrated with figures. Many examples are discussed, mostly for professional audiences, in papers published by the International Symposium on the Analytic Hierarchy Process.\n\n\n== Criticisms ==\nThe AHP is included in most operations research and management science textbooks, and is taught in numerous universities; it is used extensively in organizations that have carefully investigated its theoretical underpinnings. While the general consensus is that it is both technically valid and practically useful, the method does have its critics. \nIn the early 1990s a series of debates between critics and proponents of AHP was published in Management Science and The Journal of the Operational Research Society. These debates seem to have been settled in favor of AHP: \n\nAn in-depth paper discussing and rebutting the academic criticisms of AHP was published in Operations Research in 2001.\nA  2008 Management Science paper reviewing 15 years of progress in all areas of Multicriteria Decision Making showed that AHP publications have far outnumbered those in any other area, characterizing their growth as \"enormous.\"\nAlso in 2008, the major society for operations research, the Institute for Operations Research and the Management Sciences formally recognized AHP's broad impact on its fields.Occasional criticisms still appear. A 1997 paper examined possible flaws in the verbal (vs. numerical) scale often used in AHP pairwise comparisons. Another from the same year claimed that innocuous changes to the AHP model can introduce order where no order exists. A 2006 paper found that the addition of criteria for which all alternatives perform equally can alter the priorities of alternatives.\n\n\n== Rank reversal ==\nDecision making involves ranking alternatives in terms of criteria or attributes of those alternatives. It is an axiom of some decision theories that when new alternatives are added to a decision problem, the ranking of the old alternatives must not change \u2014 that \"rank reversal\" must not occur.\nThere are two schools of thought about rank reversal. One maintains that new alternatives that introduce no additional attributes should not cause rank reversal under any circumstances. The other maintains that there are some situations in which rank reversal can reasonably be expected. The original formulation of AHP allowed rank reversals.  In 1993, Forman introduced a second AHP synthesis mode, called the ideal synthesis mode, to address choice situations in which the addition or removal of an 'irrelevant' alternative should not and will not cause a change in the ranks of existing alternatives. The current version of the AHP can accommodate both these schools\u2014its ideal mode preserves rank, while its distributive mode allows the ranks to change. Either mode is selected according to the problem at hand.\nRank reversal and AHP are extensively discussed in a 2001 paper in Operations Research, as well as a chapter entitled Rank Preservation and Reversal, in the current basic book on AHP. The latter presents published examples of rank reversal due to adding copies and near copies of an alternative, due to intransitivity of decision rules, due to adding phantom and decoy alternatives, and due to the switching phenomenon in utility functions. It also discusses the Distributive and Ideal Modes of AHP.\nA new form of rank reversal of AHP was found in 2014 in which AHP produces rank order reversal when eliminating irrelevant data, this is data that do not differentiate alternatives.\nThere are different types of rank reversals.  Also, other methods besides the AHP may exhibit such rank reversals.  More discussion on rank reversals with the AHP and other MCDM methods is provided in the rank reversals in decision-making page.\n\n\n== Non-monotonicity of some weight extraction methods ==\nWithin a comparison matrix one may replace a judgement with a less favorable judgment and then check to see if the indication of the new priority becomes less favorable then the original priority. In the context of tournament matrices, it has been proven by Oskar Perron that the principal right eigenvector method is not monotonic. This behaviour can also be demonstrated for reciprocal n x n matrices, where n > 3. Alternative approaches are discussed elsewhere.\n\n\n== See also ==\nAnalytic network process\nArrow's impossibility theorem\nDecision making\nDecision-making paradox\nDecision-making software\nHierarchical decision process\nL. L. Thurstone\nLaw of comparative judgment\nMulti-criteria decision analysis\nPairwise comparison\nPreference\nPrincipal component analysis\nRank reversals in decision-making\n\n\n== References ==\n\n\n== Further reading ==\nSaaty, Thomas L. Decision Making for Leaders: The Analytical Hierarchy Process for Decisions in a Complex World (1982). Belmont, California: Wadsworth. ISBN 0-534-97959-9; Paperback, Pittsburgh: RWS. ISBN 0-9620317-0-4. \"Focuses on practical application of the AHP; briefly covers theory.\"\nSaaty, Thomas L. Fundamentals of Decision Making and Priority Theory with the Analytic Hierarchy Process (1994). Pittsburgh: RWS. ISBN 0-9620317-6-3. \"A thorough exposition of the theoretical aspects of AHP.\"\nSaaty, Thomas L. Mathematical Principles of Decision Making (Principia Mathematica Decernendi) (2009). Pittsburgh: RWS. ISBN 1-888603-10-0. \"Comprehensive coverage of the AHP, its successor the ANP, and further developments of their underlying concepts.\"\nSaaty, Thomas L., with Ernest H. Forman. The Hierarchon: A Dictionary of Hierarchies. (1992) Pittsburgh: RWS. ISBN 0-9620317-5-5. \"Dozens of illustrations and examples of AHP hierarchies. A beginning classification of ideas relating to planning, conflict resolution, and decision making.\"\nSaaty, Thomas L., with Luis G. Vargas The Logic of Priorities: Applications in Business, Energy, Health, and Transportation (1982). Boston: Kluwer-Nijhoff. ISBN 0-89838-071-5 (Hardcover) ISBN 0-89838-078-2 (Paperback). Republished 1991 by RWS, ISBN 1-888603-07-0.\nKardi Teknomo. Analytic Hierarchy Process Tutorial (2012). Revoledu.\nKearns, Kevin P.; Saaty, Thomas L. Analytical Planning: The Organization of Systems (1985). Oxford: Pergamon Press. ISBN 0-08-032599-8. Republished 1991 by RWS, ISBN 1-888603-07-0.\nwith Joyce Alexander. Conflict Resolution: The Analytic Hierarchy Process (1989). New York: Praeger. ISBN 0-275-93229-X\nVargas, Luis L.; Saaty, Thomas L. Prediction, Projection and Forecasting: Applications of the Analytic Hierarchy Process in Economics, Finance, Politics, Games and Sports (1991). Boston: Kluwer Academic. ISBN 0-7923-9104-7\nVargas, Luis L.; Saaty, Thomas L. Decision Making in Economic, Social and Technological Environments (1994). Pittsburgh: RWS. ISBN 0-9620317-7-1\nVargas, Luis L.; Saaty, Thomas L. Models, Methods, Concepts & Applications of the Analytic Hierarchy Process (2001). Boston: Kluwer Academic. ISBN 0-7923-7267-0\nPeniwati, Kirti; Vargas, Luis L. Group Decision Making: Drawing Out and Reconciling Differences (2007). Pittsburgh: RWS. ISBN 1-888603-08-9\n\n\n== External links ==\nInternational Journal of the Analytic Hierarchy Process An online journal about multi-criteria decision making using the AHP.\neasyAHP Online tool to make collaborative decisions using AHP easyAHP is a free online tool to make decisions in a collaborative or individual way. easy AHP uses AHP methodology: Analytic hierarchy process.\nAHP video. (9:17 YouTube clip) Very thorough exposition of AHP by Dr. Klaus G\u00f6pel\nAnalytic Hierarchy Process (AHP) Example with Simulations using Matlab \u2013 Waqqas Farooq \u2013 AHP example for college selection using matlab.\nAn illustrated guide (pdf) \u2013 Dr. Oliver Meixner University of Wien \u2013 \"Analytic Hierarchy Process\", a very easy to understand summary of the mathematical theory\nAHP example with Matlab implementation \u2013 AHP explanation with an example and matlab code.\nR ahp package \u2013 An AHP open source package.\nIntroductory Mathematics of the Analytic Hierarchy Process \u2013 An introduction to the mathematics of the Analytic Hierarchy Process.\nHow to use AHP for Project Prioritization by Dr. James Brown (webinar)\nGuide to use AHP in Excel A guide to using AHP in Excel by Dr. Richard Hodgett\nUse the AHP Methodology to More Effectively Define and Evaluate Your SAP Implementation Approach by Jeetendra Kumar", {"entities": [[0, 30, "TRAINED_CATEGORY"], [32, 35, "TRAINED_CATEGORY"], [40, 62, "TRAINED_CATEGORY"], [92, 109, "TRAINED_CATEGORY"], [120, 131, "TRAINED_CATEGORY"], [136, 146, "TRAINED_CATEGORY"], [148, 150, "TRAINED_CATEGORY"], [168, 183, "TRAINED_CATEGORY"], [187, 196, "TRAINED_CATEGORY"], [197, 200, "TRAINED_CATEGORY"], [216, 229, "TRAINED_CATEGORY"], [241, 254, "TRAINED_CATEGORY"], [321, 323, "TRAINED_CATEGORY"], [335, 355, "TRAINED_CATEGORY"], [372, 383, "TRAINED_CATEGORY"], [387, 404, "TRAINED_CATEGORY"], [406, 437, "TRAINED_CATEGORY"], [463, 486, "TRAINED_CATEGORY"], [490, 497, "TRAINED_CATEGORY"], [506, 527, "TRAINED_CATEGORY"], [537, 552, "TRAINED_CATEGORY"], [568, 591, "TRAINED_CATEGORY"], [600, 613, "TRAINED_CATEGORY"], [620, 650, "TRAINED_CATEGORY"], [676, 687, "TRAINED_CATEGORY"], [696, 723, "TRAINED_CATEGORY"], [725, 744, "TRAINED_CATEGORY"], [765, 773, "TRAINED_CATEGORY"], [790, 794, "TRAINED_CATEGORY"], [799, 811, "TRAINED_CATEGORY"], [815, 818, "TRAINED_CATEGORY"], [823, 845, "TRAINED_CATEGORY"], [849, 870, "TRAINED_CATEGORY"], [891, 900, "TRAINED_CATEGORY"], [904, 918, "TRAINED_CATEGORY"], [922, 941, "TRAINED_CATEGORY"], [946, 952, "TRAINED_CATEGORY"], [961, 971, "TRAINED_CATEGORY"], [973, 981, "TRAINED_CATEGORY"], [983, 991, "TRAINED_CATEGORY"], [993, 1003, "TRAINED_CATEGORY"], [1005, 1017, "TRAINED_CATEGORY"], [1022, 1031, "TRAINED_CATEGORY"], [1057, 1077, "TRAINED_CATEGORY"], [1079, 1086, "TRAINED_CATEGORY"], [1093, 1108, "TRAINED_CATEGORY"], [1114, 1117, "TRAINED_CATEGORY"], [1134, 1144, "TRAINED_CATEGORY"], [1149, 1168, "TRAINED_CATEGORY"], [1172, 1183, "TRAINED_CATEGORY"], [1185, 1187, "TRAINED_CATEGORY"], [1197, 1235, "TRAINED_CATEGORY"], [1252, 1270, "TRAINED_CATEGORY"], [1305, 1317, "TRAINED_CATEGORY"], [1332, 1346, "TRAINED_CATEGORY"], [1350, 1363, "TRAINED_CATEGORY"], [1384, 1405, "TRAINED_CATEGORY"], [1407, 1412, "TRAINED_CATEGORY"], [1416, 1423, "TRAINED_CATEGORY"], [1440, 1462, "TRAINED_CATEGORY"], [1468, 1479, "TRAINED_CATEGORY"], [1483, 1520, "TRAINED_CATEGORY"], [1567, 1579, "TRAINED_CATEGORY"], [1583, 1596, "TRAINED_CATEGORY"], [1611, 1621, "TRAINED_CATEGORY"], [1625, 1645, "TRAINED_CATEGORY"], [1737, 1745, "TRAINED_CATEGORY"], [1769, 1781, "TRAINED_CATEGORY"], [1785, 1789, "TRAINED_CATEGORY"], [1796, 1809, "TRAINED_CATEGORY"], [1820, 1839, "TRAINED_CATEGORY"], [1864, 1884, "TRAINED_CATEGORY"], [1898, 1902, "TRAINED_CATEGORY"], [1924, 1930, "TRAINED_CATEGORY"], [1937, 1944, "TRAINED_CATEGORY"], [1948, 1960, "TRAINED_CATEGORY"], [1964, 1974, "TRAINED_CATEGORY"], [1981, 1985, "TRAINED_CATEGORY"], [1989, 2002, "TRAINED_CATEGORY"], [2014, 2029, "TRAINED_CATEGORY"], [2031, 2050, "TRAINED_CATEGORY"], [2059, 2072, "TRAINED_CATEGORY"], [2079, 2091, "TRAINED_CATEGORY"], [2097, 2101, "TRAINED_CATEGORY"], [2116, 2131, "TRAINED_CATEGORY"], [2138, 2168, "TRAINED_CATEGORY"], [2173, 2183, "TRAINED_CATEGORY"], [2185, 2187, "TRAINED_CATEGORY"], [2191, 2202, "TRAINED_CATEGORY"], [2206, 2213, "TRAINED_CATEGORY"], [2214, 2234, "TRAINED_CATEGORY"], [2240, 2275, "TRAINED_CATEGORY"], [2303, 2318, "TRAINED_CATEGORY"], [2319, 2326, "TRAINED_CATEGORY"], [2336, 2353, "TRAINED_CATEGORY"], [2357, 2373, "TRAINED_CATEGORY"], [2414, 2430, "TRAINED_CATEGORY"], [2434, 2445, "TRAINED_CATEGORY"], [2447, 2465, "TRAINED_CATEGORY"], [2469, 2477, "TRAINED_CATEGORY"], [2493, 2505, "TRAINED_CATEGORY"], [2509, 2522, "TRAINED_CATEGORY"], [2533, 2575, "TRAINED_CATEGORY"], [2609, 2638, "TRAINED_CATEGORY"], [2640, 2655, "TRAINED_CATEGORY"], [2670, 2677, "TRAINED_CATEGORY"], [2683, 2697, "TRAINED_CATEGORY"], [2705, 2715, "TRAINED_CATEGORY"], [2720, 2734, "TRAINED_CATEGORY"], [2738, 2749, "TRAINED_CATEGORY"], [2751, 2771, "TRAINED_CATEGORY"], [2799, 2824, "TRAINED_CATEGORY"], [2826, 2839, "TRAINED_CATEGORY"], [2850, 2884, "TRAINED_CATEGORY"], [2896, 2913, "TRAINED_CATEGORY"], [2918, 2922, "TRAINED_CATEGORY"], [2929, 2960, "TRAINED_CATEGORY"], [2964, 2983, "TRAINED_CATEGORY"], [2987, 2993, "TRAINED_CATEGORY"], [2995, 3008, "TRAINED_CATEGORY"], [3016, 3033, "TRAINED_CATEGORY"], [3053, 3064, "TRAINED_CATEGORY"], [3072, 3074, "TRAINED_CATEGORY"], [3090, 3101, "TRAINED_CATEGORY"], [3113, 3138, "TRAINED_CATEGORY"], [3140, 3170, "TRAINED_CATEGORY"], [3172, 3175, "TRAINED_CATEGORY"], [3198, 3203, "TRAINED_CATEGORY"], [3207, 3213, "TRAINED_CATEGORY"], [3229, 3245, "TRAINED_CATEGORY"], [3269, 3280, "TRAINED_CATEGORY"], [3292, 3309, "TRAINED_CATEGORY"], [3314, 3323, "TRAINED_CATEGORY"], [3325, 3342, "TRAINED_CATEGORY"], [3348, 3371, "TRAINED_CATEGORY"], [3373, 3375, "TRAINED_CATEGORY"], [3380, 3397, "TRAINED_CATEGORY"], [3403, 3421, "TRAINED_CATEGORY"], [3425, 3437, "TRAINED_CATEGORY"], [3485, 3498, "TRAINED_CATEGORY"], [3505, 3517, "TRAINED_CATEGORY"], [3532, 3563, "TRAINED_CATEGORY"], [3565, 3578, "TRAINED_CATEGORY"], [3583, 3595, "TRAINED_CATEGORY"], [3597, 3616, "TRAINED_CATEGORY"], [3626, 3633, "TRAINED_CATEGORY"], [3658, 3664, "TRAINED_CATEGORY"], [3667, 3680, "TRAINED_CATEGORY"], [3684, 3699, "TRAINED_CATEGORY"], [3705, 3716, "TRAINED_CATEGORY"], [3720, 3732, "TRAINED_CATEGORY"], [3758, 3784, "TRAINED_CATEGORY"], [3795, 3802, "TRAINED_CATEGORY"], [3813, 3818, "TRAINED_CATEGORY"], [3822, 3834, "TRAINED_CATEGORY"], [3838, 3843, "TRAINED_CATEGORY"], [3874, 3888, "TRAINED_CATEGORY"], [3903, 3921, "TRAINED_CATEGORY"], [3925, 3932, "TRAINED_CATEGORY"], [3936, 3941, "TRAINED_CATEGORY"], [3945, 3957, "TRAINED_CATEGORY"], [4014, 4018, "TRAINED_CATEGORY"], [4019, 4038, "TRAINED_CATEGORY"], [4054, 4063, "TRAINED_CATEGORY"], [4070, 4075, "TRAINED_CATEGORY"], [4079, 4091, "TRAINED_CATEGORY"], [4092, 4104, "TRAINED_CATEGORY"], [4117, 4130, "TRAINED_CATEGORY"], [4134, 4156, "TRAINED_CATEGORY"], [4185, 4190, "TRAINED_CATEGORY"], [4205, 4223, "TRAINED_CATEGORY"], [4239, 4267, "TRAINED_CATEGORY"], [4271, 4302, "TRAINED_CATEGORY"], [4303, 4322, "TRAINED_CATEGORY"], [4334, 4342, "TRAINED_CATEGORY"], [4351, 4358, "TRAINED_CATEGORY"], [4364, 4393, "TRAINED_CATEGORY"], [4397, 4422, "TRAINED_CATEGORY"], [4426, 4429, "TRAINED_CATEGORY"], [4433, 4460, "TRAINED_CATEGORY"], [4478, 4491, "TRAINED_CATEGORY"], [4511, 4528, "TRAINED_CATEGORY"], [4532, 4540, "TRAINED_CATEGORY"], [4551, 4559, "TRAINED_CATEGORY"], [4561, 4580, "TRAINED_CATEGORY"], [4582, 4598, "TRAINED_CATEGORY"], [4604, 4613, "TRAINED_CATEGORY"], [4620, 4632, "TRAINED_CATEGORY"], [4634, 4645, "TRAINED_CATEGORY"], [4660, 4671, "TRAINED_CATEGORY"], [4673, 4697, "TRAINED_CATEGORY"], [4699, 4715, "TRAINED_CATEGORY"], [4731, 4758, "TRAINED_CATEGORY"], [4764, 4786, "TRAINED_CATEGORY"], [4788, 4809, "TRAINED_CATEGORY"], [4832, 4841, "TRAINED_CATEGORY"], [4860, 4864, "TRAINED_CATEGORY"], [4870, 4875, "TRAINED_CATEGORY"], [4879, 4890, "TRAINED_CATEGORY"], [4894, 4913, "TRAINED_CATEGORY"], [4920, 4928, "TRAINED_CATEGORY"], [4933, 4940, "TRAINED_CATEGORY"], [4941, 4955, "TRAINED_CATEGORY"], [4965, 4981, "TRAINED_CATEGORY"], [4987, 4996, "TRAINED_CATEGORY"], [5000, 5003, "TRAINED_CATEGORY"], [5021, 5035, "TRAINED_CATEGORY"], [5075, 5081, "TRAINED_CATEGORY"], [5085, 5101, "TRAINED_CATEGORY"], [5103, 5124, "TRAINED_CATEGORY"], [5154, 5164, "TRAINED_CATEGORY"], [5168, 5189, "TRAINED_CATEGORY"], [5233, 5252, "TRAINED_CATEGORY"], [5256, 5272, "TRAINED_CATEGORY"], [5273, 5295, "TRAINED_CATEGORY"], [5297, 5306, "TRAINED_CATEGORY"], [5307, 5325, "TRAINED_CATEGORY"], [5327, 5348, "TRAINED_CATEGORY"], [5352, 5364, "TRAINED_CATEGORY"], [5391, 5420, "TRAINED_CATEGORY"], [5422, 5432, "TRAINED_CATEGORY"], [5436, 5445, "TRAINED_CATEGORY"], [5457, 5461, "TRAINED_CATEGORY"], [5465, 5508, "TRAINED_CATEGORY"], [5510, 5526, "TRAINED_CATEGORY"], [5530, 5545, "TRAINED_CATEGORY"], [5575, 5590, "TRAINED_CATEGORY"], [5592, 5607, "TRAINED_CATEGORY"], [5611, 5622, "TRAINED_CATEGORY"], [5661, 5690, "TRAINED_CATEGORY"], [5691, 5703, "TRAINED_CATEGORY"], [5705, 5757, "TRAINED_CATEGORY"], [5783, 5796, "TRAINED_CATEGORY"], [5800, 5831, "TRAINED_CATEGORY"], [5832, 5836, "TRAINED_CATEGORY"], [5843, 5875, "TRAINED_CATEGORY"], [5893, 5917, "TRAINED_CATEGORY"], [5922, 5944, "TRAINED_CATEGORY"], [5958, 5962, "TRAINED_CATEGORY"], [5969, 5972, "TRAINED_CATEGORY"], [6004, 6030, "TRAINED_CATEGORY"], [6035, 6056, "TRAINED_CATEGORY"], [6066, 6076, "TRAINED_CATEGORY"], [6080, 6089, "TRAINED_CATEGORY"], [6093, 6114, "TRAINED_CATEGORY"], [6116, 6118, "TRAINED_CATEGORY"], [6143, 6152, "TRAINED_CATEGORY"], [6163, 6176, "TRAINED_CATEGORY"], [6187, 6200, "TRAINED_CATEGORY"], [6204, 6212, "TRAINED_CATEGORY"], [6216, 6224, "TRAINED_CATEGORY"], [6226, 6243, "TRAINED_CATEGORY"], [6255, 6257, "TRAINED_CATEGORY"], [6271, 6288, "TRAINED_CATEGORY"], [6292, 6303, "TRAINED_CATEGORY"], [6321, 6331, "TRAINED_CATEGORY"], [6335, 6344, "TRAINED_CATEGORY"], [6349, 6360, "TRAINED_CATEGORY"], [6365, 6383, "TRAINED_CATEGORY"], [6400, 6430, "TRAINED_CATEGORY"], [6440, 6472, "TRAINED_CATEGORY"], [6474, 6476, "TRAINED_CATEGORY"], [6515, 6532, "TRAINED_CATEGORY"], [6536, 6551, "TRAINED_CATEGORY"], [6563, 6570, "TRAINED_CATEGORY"], [6574, 6606, "TRAINED_CATEGORY"], [6610, 6618, "TRAINED_CATEGORY"], [6620, 6622, "TRAINED_CATEGORY"], [6626, 6658, "TRAINED_CATEGORY"], [6662, 6679, "TRAINED_CATEGORY"], [6698, 6722, "TRAINED_CATEGORY"], [6733, 6742, "TRAINED_CATEGORY"], [6744, 6758, "TRAINED_CATEGORY"], [6764, 6777, "TRAINED_CATEGORY"], [6781, 6788, "TRAINED_CATEGORY"], [6806, 6840, "TRAINED_CATEGORY"], [6848, 6857, "TRAINED_CATEGORY"], [6859, 6864, "TRAINED_CATEGORY"], [6868, 6878, "TRAINED_CATEGORY"], [6879, 6916, "TRAINED_CATEGORY"], [6923, 6930, "TRAINED_CATEGORY"], [6934, 6937, "TRAINED_CATEGORY"], [6943, 6965, "TRAINED_CATEGORY"], [6973, 6976, "TRAINED_CATEGORY"], [6980, 6991, "TRAINED_CATEGORY"], [6995, 7009, "TRAINED_CATEGORY"], [7014, 7027, "TRAINED_CATEGORY"], [7029, 7044, "TRAINED_CATEGORY"], [7068, 7079, "TRAINED_CATEGORY"], [7083, 7088, "TRAINED_CATEGORY"], [7103, 7141, "TRAINED_CATEGORY"], [7165, 7196, "TRAINED_CATEGORY"], [7200, 7230, "TRAINED_CATEGORY"], [7232, 7237, "TRAINED_CATEGORY"], [7245, 7262, "TRAINED_CATEGORY"], [7266, 7275, "TRAINED_CATEGORY"], [7280, 7293, "TRAINED_CATEGORY"], [7308, 7317, "TRAINED_CATEGORY"], [7319, 7331, "TRAINED_CATEGORY"], [7335, 7341, "TRAINED_CATEGORY"], [7382, 7394, "TRAINED_CATEGORY"], [7395, 7412, "TRAINED_CATEGORY"], [7417, 7437, "TRAINED_CATEGORY"], [7444, 7476, "TRAINED_CATEGORY"], [7483, 7512, "TRAINED_CATEGORY"], [7516, 7536, "TRAINED_CATEGORY"], [7542, 7558, "TRAINED_CATEGORY"], [7562, 7572, "TRAINED_CATEGORY"], [7574, 7579, "TRAINED_CATEGORY"], [7581, 7595, "TRAINED_CATEGORY"], [7616, 7628, "TRAINED_CATEGORY"], [7640, 7646, "TRAINED_CATEGORY"], [7648, 7655, "TRAINED_CATEGORY"], [7657, 7662, "TRAINED_CATEGORY"], [7664, 7669, "TRAINED_CATEGORY"], [7671, 7679, "TRAINED_CATEGORY"], [7685, 7690, "TRAINED_CATEGORY"], [7692, 7708, "TRAINED_CATEGORY"], [7712, 7718, "TRAINED_CATEGORY"], [7737, 7755, "TRAINED_CATEGORY"], [7759, 7769, "TRAINED_CATEGORY"], [7771, 7783, "TRAINED_CATEGORY"], [7790, 7802, "TRAINED_CATEGORY"], [7821, 7829, "TRAINED_CATEGORY"], [7833, 7843, "TRAINED_CATEGORY"], [7853, 7875, "TRAINED_CATEGORY"], [7879, 7885, "TRAINED_CATEGORY"], [7887, 7906, "TRAINED_CATEGORY"], [7910, 7928, "TRAINED_CATEGORY"], [7930, 7949, "TRAINED_CATEGORY"], [7967, 7981, "TRAINED_CATEGORY"], [7987, 8006, "TRAINED_CATEGORY"], [8010, 8015, "TRAINED_CATEGORY"], [8020, 8025, "TRAINED_CATEGORY"], [8047, 8059, "TRAINED_CATEGORY"], [8080, 8087, "TRAINED_CATEGORY"], [8097, 8123, "TRAINED_CATEGORY"], [8127, 8145, "TRAINED_CATEGORY"], [8152, 8172, "TRAINED_CATEGORY"], [8176, 8180, "TRAINED_CATEGORY"], [8182, 8184, "TRAINED_CATEGORY"], [8205, 8220, "TRAINED_CATEGORY"], [8234, 8244, "TRAINED_CATEGORY"], [8248, 8265, "TRAINED_CATEGORY"], [8273, 8281, "TRAINED_CATEGORY"], [8297, 8301, "TRAINED_CATEGORY"], [8310, 8322, "TRAINED_CATEGORY"], [8324, 8326, "TRAINED_CATEGORY"], [8360, 8388, "TRAINED_CATEGORY"], [8419, 8432, "TRAINED_CATEGORY"], [8464, 8493, "TRAINED_CATEGORY"], [8558, 8573, "TRAINED_CATEGORY"], [8588, 8601, "TRAINED_CATEGORY"], [8605, 8620, "TRAINED_CATEGORY"], [8633, 8647, "TRAINED_CATEGORY"], [8649, 8662, "TRAINED_CATEGORY"], [8673, 8680, "TRAINED_CATEGORY"], [8710, 8721, "TRAINED_CATEGORY"], [8725, 8736, "TRAINED_CATEGORY"], [8748, 8765, "TRAINED_CATEGORY"], [8767, 8783, "TRAINED_CATEGORY"], [8797, 8799, "TRAINED_CATEGORY"], [8805, 8817, "TRAINED_CATEGORY"], [8833, 8849, "TRAINED_CATEGORY"], [8861, 8871, "TRAINED_CATEGORY"], [8878, 8890, "TRAINED_CATEGORY"], [8894, 8907, "TRAINED_CATEGORY"], [8918, 8926, "TRAINED_CATEGORY"], [8930, 8939, "TRAINED_CATEGORY"], [8949, 8969, "TRAINED_CATEGORY"], [8973, 8985, "TRAINED_CATEGORY"], [8991, 8998, "TRAINED_CATEGORY"], [9015, 9034, "TRAINED_CATEGORY"], [9038, 9060, "TRAINED_CATEGORY"], [9062, 9075, "TRAINED_CATEGORY"], [9086, 9090, "TRAINED_CATEGORY"], [9098, 9106, "TRAINED_CATEGORY"], [9112, 9117, "TRAINED_CATEGORY"], [9122, 9127, "TRAINED_CATEGORY"], [9133, 9139, "TRAINED_CATEGORY"], [9152, 9167, "TRAINED_CATEGORY"], [9177, 9182, "TRAINED_CATEGORY"], [9186, 9204, "TRAINED_CATEGORY"], [9209, 9222, "TRAINED_CATEGORY"], [9243, 9267, "TRAINED_CATEGORY"], [9274, 9282, "TRAINED_CATEGORY"], [9284, 9289, "TRAINED_CATEGORY"], [9294, 9300, "TRAINED_CATEGORY"], [9305, 9317, "TRAINED_CATEGORY"], [9317, 9323, "TRAINED_CATEGORY"], [9329, 9330, "TRAINED_CATEGORY"], [9336, 9354, "TRAINED_CATEGORY"], [9359, 9372, "TRAINED_CATEGORY"], [9380, 9395, "TRAINED_CATEGORY"], [9399, 9412, "TRAINED_CATEGORY"], [9422, 9438, "TRAINED_CATEGORY"], [9448, 9459, "TRAINED_CATEGORY"], [9463, 9475, "TRAINED_CATEGORY"], [9476, 9487, "TRAINED_CATEGORY"], [9532, 9543, "TRAINED_CATEGORY"], [9547, 9558, "TRAINED_CATEGORY"], [9563, 9577, "TRAINED_CATEGORY"], [9581, 9611, "TRAINED_CATEGORY"], [9624, 9635, "TRAINED_CATEGORY"], [9639, 9650, "TRAINED_CATEGORY"], [9667, 9679, "TRAINED_CATEGORY"], [9688, 9699, "TRAINED_CATEGORY"], [9703, 9714, "TRAINED_CATEGORY"], [9718, 9724, "TRAINED_CATEGORY"], [9764, 9766, "TRAINED_CATEGORY"], [9770, 9790, "TRAINED_CATEGORY"], [9796, 9803, "TRAINED_CATEGORY"], [9817, 9821, "TRAINED_CATEGORY"], [9836, 9849, "TRAINED_CATEGORY"], [9851, 9855, "TRAINED_CATEGORY"], [9865, 9884, "TRAINED_CATEGORY"], [9888, 9899, "TRAINED_CATEGORY"], [9904, 9915, "TRAINED_CATEGORY"], [9924, 9945, "TRAINED_CATEGORY"], [9950, 9958, "TRAINED_CATEGORY"], [9978, 9989, "TRAINED_CATEGORY"], [10003, 10014, "TRAINED_CATEGORY"], [10018, 10037, "TRAINED_CATEGORY"], [10064, 10070, "TRAINED_CATEGORY"], [10072, 10078, "TRAINED_CATEGORY"], [10080, 10085, "TRAINED_CATEGORY"], [10099, 10111, "TRAINED_CATEGORY"], [10115, 10125, "TRAINED_CATEGORY"], [10138, 10149, "TRAINED_CATEGORY"], [10169, 10195, "TRAINED_CATEGORY"], [10204, 10215, "TRAINED_CATEGORY"], [10219, 10228, "TRAINED_CATEGORY"], [10260, 10262, "TRAINED_CATEGORY"], [10301, 10309, "TRAINED_CATEGORY"], [10313, 10324, "TRAINED_CATEGORY"], [10355, 10363, "TRAINED_CATEGORY"], [10387, 10403, "TRAINED_CATEGORY"], [10407, 10414, "TRAINED_CATEGORY"], [10425, 10432, "TRAINED_CATEGORY"], [10466, 10477, "TRAINED_CATEGORY"], [10479, 10498, "TRAINED_CATEGORY"], [10523, 10534, "TRAINED_CATEGORY"], [10542, 10565, "TRAINED_CATEGORY"], [10588, 10604, "TRAINED_CATEGORY"], [10617, 10627, "TRAINED_CATEGORY"], [10646, 10659, "TRAINED_CATEGORY"], [10661, 10681, "TRAINED_CATEGORY"], [10685, 10692, "TRAINED_CATEGORY"], [10702, 10733, "TRAINED_CATEGORY"], [10753, 10776, "TRAINED_CATEGORY"], [10778, 10786, "TRAINED_CATEGORY"], [10792, 10797, "TRAINED_CATEGORY"], [10810, 10819, "TRAINED_CATEGORY"], [10823, 10828, "TRAINED_CATEGORY"], [10830, 10832, "TRAINED_CATEGORY"], [10837, 10848, "TRAINED_CATEGORY"], [10857, 10859, "TRAINED_CATEGORY"], [10868, 10886, "TRAINED_CATEGORY"], [10890, 10905, "TRAINED_CATEGORY"], [10907, 10909, "TRAINED_CATEGORY"], [10920, 10931, "TRAINED_CATEGORY"], [10937, 10958, "TRAINED_CATEGORY"], [10973, 10977, "TRAINED_CATEGORY"], [10983, 11010, "TRAINED_CATEGORY"], [11028, 11041, "TRAINED_CATEGORY"], [11042, 11056, "TRAINED_CATEGORY"], [11060, 11062, "TRAINED_CATEGORY"], [11075, 11084, "TRAINED_CATEGORY"], [11086, 11088, "TRAINED_CATEGORY"], [11112, 11130, "TRAINED_CATEGORY"], [11134, 11143, "TRAINED_CATEGORY"], [11170, 11190, "TRAINED_CATEGORY"], [11203, 11219, "TRAINED_CATEGORY"], [11224, 11226, "TRAINED_CATEGORY"], [11238, 11250, "TRAINED_CATEGORY"], [11252, 11254, "TRAINED_CATEGORY"], [11264, 11288, "TRAINED_CATEGORY"], [11292, 11316, "TRAINED_CATEGORY"], [11317, 11319, "TRAINED_CATEGORY"], [11343, 11356, "TRAINED_CATEGORY"], [11362, 11378, "TRAINED_CATEGORY"], [11398, 11405, "TRAINED_CATEGORY"], [11406, 11410, "TRAINED_CATEGORY"], [11431, 11457, "TRAINED_CATEGORY"], [11469, 11474, "TRAINED_CATEGORY"], [11479, 11487, "TRAINED_CATEGORY"], [11493, 11501, "TRAINED_CATEGORY"], [11506, 11529, "TRAINED_CATEGORY"], [11534, 11539, "TRAINED_CATEGORY"], [11542, 11564, "TRAINED_CATEGORY"], [11570, 11585, "TRAINED_CATEGORY"], [11590, 11598, "TRAINED_CATEGORY"], [11601, 11619, "TRAINED_CATEGORY"], [11625, 11648, "TRAINED_CATEGORY"], [11653, 11663, "TRAINED_CATEGORY"], [11678, 11682, "TRAINED_CATEGORY"], [11694, 11709, "TRAINED_CATEGORY"], [11714, 11740, "TRAINED_CATEGORY"], [11750, 11767, "TRAINED_CATEGORY"], [11777, 11792, "TRAINED_CATEGORY"], [11808, 11817, "TRAINED_CATEGORY"], [11821, 11829, "TRAINED_CATEGORY"], [11833, 11841, "TRAINED_CATEGORY"], [11846, 11853, "TRAINED_CATEGORY"], [11855, 11867, "TRAINED_CATEGORY"], [11879, 11895, "TRAINED_CATEGORY"], [11901, 11922, "TRAINED_CATEGORY"], [11926, 11937, "TRAINED_CATEGORY"], [11958, 11962, "TRAINED_CATEGORY"], [11974, 11986, "TRAINED_CATEGORY"], [11990, 12010, "TRAINED_CATEGORY"], [12014, 12023, "TRAINED_CATEGORY"], [12052, 12056, "TRAINED_CATEGORY"], [12067, 12096, "TRAINED_CATEGORY"], [12100, 12107, "TRAINED_CATEGORY"], [12125, 12127, "TRAINED_CATEGORY"], [12137, 12163, "TRAINED_CATEGORY"], [12165, 12167, "TRAINED_CATEGORY"], [12176, 12187, "TRAINED_CATEGORY"], [12201, 12214, "TRAINED_CATEGORY"], [12218, 12229, "TRAINED_CATEGORY"], [12235, 12252, "TRAINED_CATEGORY"], [12256, 12269, "TRAINED_CATEGORY"], [12274, 12276, "TRAINED_CATEGORY"], [12283, 12309, "TRAINED_CATEGORY"], [12311, 12313, "TRAINED_CATEGORY"], [12319, 12346, "TRAINED_CATEGORY"], [12350, 12361, "TRAINED_CATEGORY"], [12365, 12372, "TRAINED_CATEGORY"], [12381, 12392, "TRAINED_CATEGORY"], [12396, 12403, "TRAINED_CATEGORY"], [12409, 12425, "TRAINED_CATEGORY"], [12429, 12447, "TRAINED_CATEGORY"], [12460, 12472, "TRAINED_CATEGORY"], [12476, 12480, "TRAINED_CATEGORY"], [12482, 12484, "TRAINED_CATEGORY"], [12497, 12512, "TRAINED_CATEGORY"], [12514, 12521, "TRAINED_CATEGORY"], [12525, 12532, "TRAINED_CATEGORY"], [12536, 12548, "TRAINED_CATEGORY"], [12562, 12570, "TRAINED_CATEGORY"], [12576, 12583, "TRAINED_CATEGORY"], [12587, 12594, "TRAINED_CATEGORY"], [12598, 12606, "TRAINED_CATEGORY"], [12619, 12635, "TRAINED_CATEGORY"], [12639, 12647, "TRAINED_CATEGORY"], [12649, 12661, "TRAINED_CATEGORY"], [12738, 12752, "TRAINED_CATEGORY"], [12756, 12767, "TRAINED_CATEGORY"], [12778, 12789, "TRAINED_CATEGORY"], [12835, 12846, "TRAINED_CATEGORY"], [12852, 12870, "TRAINED_CATEGORY"], [12888, 12906, "TRAINED_CATEGORY"], [12926, 12935, "TRAINED_CATEGORY"], [12936, 12949, "TRAINED_CATEGORY"], [12966, 12977, "TRAINED_CATEGORY"], [12989, 13010, "TRAINED_CATEGORY"], [13014, 13027, "TRAINED_CATEGORY"], [13060, 13077, "TRAINED_CATEGORY"], [13102, 13113, "TRAINED_CATEGORY"], [13120, 13140, "TRAINED_CATEGORY"], [13142, 13151, "TRAINED_CATEGORY"], [13153, 13175, "TRAINED_CATEGORY"], [13179, 13195, "TRAINED_CATEGORY"], [13210, 13218, "TRAINED_CATEGORY"], [13223, 13235, "TRAINED_CATEGORY"], [13239, 13256, "TRAINED_CATEGORY"], [13258, 13274, "TRAINED_CATEGORY"], [13296, 13308, "TRAINED_CATEGORY"], [13310, 13338, "TRAINED_CATEGORY"], [13376, 13393, "TRAINED_CATEGORY"], [13395, 13419, "TRAINED_CATEGORY"], [13436, 13455, "TRAINED_CATEGORY"], [13460, 13472, "TRAINED_CATEGORY"], [13474, 13484, "TRAINED_CATEGORY"], [13488, 13505, "TRAINED_CATEGORY"], [13530, 13540, "TRAINED_CATEGORY"], [13544, 13555, "TRAINED_CATEGORY"], [13559, 13563, "TRAINED_CATEGORY"], [13577, 13590, "TRAINED_CATEGORY"], [13592, 13601, "TRAINED_CATEGORY"], [13603, 13609, "TRAINED_CATEGORY"], [13611, 13619, "TRAINED_CATEGORY"], [13621, 13626, "TRAINED_CATEGORY"], [13643, 13659, "TRAINED_CATEGORY"], [13663, 13690, "TRAINED_CATEGORY"], [13705, 13716, "TRAINED_CATEGORY"], [13736, 13758, "TRAINED_CATEGORY"], [13760, 13768, "TRAINED_CATEGORY"], [13774, 13783, "TRAINED_CATEGORY"], [13814, 13838, "TRAINED_CATEGORY"], [13840, 13842, "TRAINED_CATEGORY"], [13873, 13898, "TRAINED_CATEGORY"], [13902, 13910, "TRAINED_CATEGORY"], [13954, 13966, "TRAINED_CATEGORY"], [14027, 14042, "TRAINED_CATEGORY"], [14053, 14071, "TRAINED_CATEGORY"], [14077, 14083, "TRAINED_CATEGORY"], [14099, 14121, "TRAINED_CATEGORY"], [14134, 14142, "TRAINED_CATEGORY"], [14148, 14161, "TRAINED_CATEGORY"], [14176, 14192, "TRAINED_CATEGORY"], [14214, 14230, "TRAINED_CATEGORY"], [14252, 14261, "TRAINED_CATEGORY"], [14267, 14274, "TRAINED_CATEGORY"], [14299, 14307, "TRAINED_CATEGORY"], [14311, 14318, "TRAINED_CATEGORY"], [14320, 14342, "TRAINED_CATEGORY"], [14346, 14356, "TRAINED_CATEGORY"], [14362, 14379, "TRAINED_CATEGORY"], [14402, 14414, "TRAINED_CATEGORY"], [14430, 14439, "TRAINED_CATEGORY"], [14443, 14456, "TRAINED_CATEGORY"], [14458, 14466, "TRAINED_CATEGORY"], [14485, 14491, "TRAINED_CATEGORY"], [14513, 14530, "TRAINED_CATEGORY"], [14534, 14541, "TRAINED_CATEGORY"], [14548, 14550, "TRAINED_CATEGORY"], [14576, 14585, "TRAINED_CATEGORY"], [14595, 14597, "TRAINED_CATEGORY"], [14648, 14665, "TRAINED_CATEGORY"], [14669, 14680, "TRAINED_CATEGORY"], [14688, 14696, "TRAINED_CATEGORY"], [14700, 14710, "TRAINED_CATEGORY"], [14714, 14731, "TRAINED_CATEGORY"], [14737, 14754, "TRAINED_CATEGORY"], [14759, 14767, "TRAINED_CATEGORY"], [14771, 14779, "TRAINED_CATEGORY"], [14781, 14795, "TRAINED_CATEGORY"], [14799, 14807, "TRAINED_CATEGORY"], [14811, 14833, "TRAINED_CATEGORY"], [14855, 14878, "TRAINED_CATEGORY"], [14887, 14898, "TRAINED_CATEGORY"], [14908, 14912, "TRAINED_CATEGORY"], [14939, 14950, "TRAINED_CATEGORY"], [14963, 14971, "TRAINED_CATEGORY"], [14975, 14986, "TRAINED_CATEGORY"], [14997, 14999, "TRAINED_CATEGORY"], [15023, 15038, "TRAINED_CATEGORY"], [15051, 15062, "TRAINED_CATEGORY"], [15075, 15088, "TRAINED_CATEGORY"], [15093, 15109, "TRAINED_CATEGORY"], [15120, 15134, "TRAINED_CATEGORY"], [15146, 15162, "TRAINED_CATEGORY"], [15167, 15179, "TRAINED_CATEGORY"], [15194, 15198, "TRAINED_CATEGORY"], [15209, 15216, "TRAINED_CATEGORY"], [15218, 15229, "TRAINED_CATEGORY"], [15266, 15272, "TRAINED_CATEGORY"], [15288, 15312, "TRAINED_CATEGORY"], [15316, 15327, "TRAINED_CATEGORY"], [15332, 15352, "TRAINED_CATEGORY"], [15353, 15367, "TRAINED_CATEGORY"], [15397, 15413, "TRAINED_CATEGORY"], [15415, 15424, "TRAINED_CATEGORY"], [15475, 15485, "TRAINED_CATEGORY"], [15489, 15498, "TRAINED_CATEGORY"], [15502, 15514, "TRAINED_CATEGORY"], [15518, 15527, "TRAINED_CATEGORY"], [15550, 15563, "TRAINED_CATEGORY"], [15573, 15586, "TRAINED_CATEGORY"], [15609, 15625, "TRAINED_CATEGORY"], [15634, 15636, "TRAINED_CATEGORY"], [15645, 15653, "TRAINED_CATEGORY"], [15657, 15677, "TRAINED_CATEGORY"], [15690, 15706, "TRAINED_CATEGORY"], [15710, 15721, "TRAINED_CATEGORY"], [15726, 15735, "TRAINED_CATEGORY"], [15737, 15749, "TRAINED_CATEGORY"], [15780, 15788, "TRAINED_CATEGORY"], [15793, 15803, "TRAINED_CATEGORY"], [15805, 15821, "TRAINED_CATEGORY"], [15860, 15872, "TRAINED_CATEGORY"], [15877, 15887, "TRAINED_CATEGORY"], [15889, 15904, "TRAINED_CATEGORY"], [15939, 15949, "TRAINED_CATEGORY"], [15966, 15975, "TRAINED_CATEGORY"], [15986, 16015, "TRAINED_CATEGORY"], [16023, 16040, "TRAINED_CATEGORY"], [16044, 16063, "TRAINED_CATEGORY"], [16080, 16090, "TRAINED_CATEGORY"], [16103, 16117, "TRAINED_CATEGORY"], [16128, 16138, "TRAINED_CATEGORY"], [16142, 16150, "TRAINED_CATEGORY"], [16152, 16174, "TRAINED_CATEGORY"], [16191, 16201, "TRAINED_CATEGORY"], [16217, 16231, "TRAINED_CATEGORY"], [16237, 16243, "TRAINED_CATEGORY"], [16255, 16267, "TRAINED_CATEGORY"], [16269, 16276, "TRAINED_CATEGORY"], [16291, 16295, "TRAINED_CATEGORY"], [16309, 16311, "TRAINED_CATEGORY"], [16317, 16321, "TRAINED_CATEGORY"], [16326, 16368, "TRAINED_CATEGORY"], [16380, 16397, "TRAINED_CATEGORY"], [16415, 16425, "TRAINED_CATEGORY"], [16430, 16442, "TRAINED_CATEGORY"], [16452, 16462, "TRAINED_CATEGORY"], [16474, 16478, "TRAINED_CATEGORY"], [16509, 16525, "TRAINED_CATEGORY"], [16534, 16544, "TRAINED_CATEGORY"], [16572, 16582, "TRAINED_CATEGORY"], [16587, 16594, "TRAINED_CATEGORY"], [16611, 16620, "TRAINED_CATEGORY"], [16624, 16640, "TRAINED_CATEGORY"], [16642, 16646, "TRAINED_CATEGORY"], [16657, 16677, "TRAINED_CATEGORY"], [16681, 16690, "TRAINED_CATEGORY"], [16694, 16703, "TRAINED_CATEGORY"], [16710, 16723, "TRAINED_CATEGORY"], [16725, 16735, "TRAINED_CATEGORY"], [16740, 16756, "TRAINED_CATEGORY"], [16787, 16792, "TRAINED_CATEGORY"], [16796, 16806, "TRAINED_CATEGORY"], [16808, 16814, "TRAINED_CATEGORY"], [16820, 16828, "TRAINED_CATEGORY"], [16838, 16854, "TRAINED_CATEGORY"], [16867, 16875, "TRAINED_CATEGORY"], [16978, 16989, "TRAINED_CATEGORY"], [16993, 16997, "TRAINED_CATEGORY"], [17000, 17006, "TRAINED_CATEGORY"], [17021, 17031, "TRAINED_CATEGORY"], [17036, 17046, "TRAINED_CATEGORY"], [17051, 17061, "TRAINED_CATEGORY"], [17066, 17081, "TRAINED_CATEGORY"], [17105, 17124, "TRAINED_CATEGORY"], [17126, 17136, "TRAINED_CATEGORY"], [17158, 17169, "TRAINED_CATEGORY"], [17183, 17199, "TRAINED_CATEGORY"], [17205, 17217, "TRAINED_CATEGORY"], [17228, 17243, "TRAINED_CATEGORY"], [17255, 17260, "TRAINED_CATEGORY"], [17264, 17275, "TRAINED_CATEGORY"], [17277, 17287, "TRAINED_CATEGORY"], [17291, 17299, "TRAINED_CATEGORY"], [17301, 17313, "TRAINED_CATEGORY"], [17319, 17335, "TRAINED_CATEGORY"], [17401, 17411, "TRAINED_CATEGORY"], [17413, 17425, "TRAINED_CATEGORY"], [17429, 17437, "TRAINED_CATEGORY"], [17448, 17462, "TRAINED_CATEGORY"], [17466, 17482, "TRAINED_CATEGORY"], [17507, 17513, "TRAINED_CATEGORY"], [17542, 17557, "TRAINED_CATEGORY"], [17561, 17569, "TRAINED_CATEGORY"], [17587, 17601, "TRAINED_CATEGORY"], [17603, 17619, "TRAINED_CATEGORY"], [17666, 17680, "TRAINED_CATEGORY"], [17684, 17695, "TRAINED_CATEGORY"], [17717, 17731, "TRAINED_CATEGORY"], [17735, 17745, "TRAINED_CATEGORY"], [17749, 17760, "TRAINED_CATEGORY"], [17761, 17769, "TRAINED_CATEGORY"], [17771, 17783, "TRAINED_CATEGORY"], [17789, 17805, "TRAINED_CATEGORY"], [17827, 17841, "TRAINED_CATEGORY"], [17876, 17891, "TRAINED_CATEGORY"], [17915, 17922, "TRAINED_CATEGORY"], [17926, 17938, "TRAINED_CATEGORY"], [17942, 17954, "TRAINED_CATEGORY"], [17959, 17973, "TRAINED_CATEGORY"], [17981, 17991, "TRAINED_CATEGORY"], [18007, 18011, "TRAINED_CATEGORY"], [18062, 18079, "TRAINED_CATEGORY"], [18094, 18108, "TRAINED_CATEGORY"], [18110, 18130, "TRAINED_CATEGORY"], [18135, 18149, "TRAINED_CATEGORY"], [18179, 18200, "TRAINED_CATEGORY"], [18218, 18236, "TRAINED_CATEGORY"], [18246, 18269, "TRAINED_CATEGORY"], [18281, 18292, "TRAINED_CATEGORY"], [18297, 18316, "TRAINED_CATEGORY"], [18320, 18328, "TRAINED_CATEGORY"], [18330, 18346, "TRAINED_CATEGORY"], [18351, 18368, "TRAINED_CATEGORY"], [18379, 18392, "TRAINED_CATEGORY"], [18416, 18435, "TRAINED_CATEGORY"], [18442, 18456, "TRAINED_CATEGORY"], [18459, 18479, "TRAINED_CATEGORY"], [18506, 18526, "TRAINED_CATEGORY"], [18530, 18539, "TRAINED_CATEGORY"], [18547, 18554, "TRAINED_CATEGORY"], [18558, 18566, "TRAINED_CATEGORY"], [18572, 18579, "TRAINED_CATEGORY"], [18583, 18595, "TRAINED_CATEGORY"], [18597, 18617, "TRAINED_CATEGORY"], [18621, 18631, "TRAINED_CATEGORY"], [18635, 18643, "TRAINED_CATEGORY"], [18648, 18673, "TRAINED_CATEGORY"], [18691, 18712, "TRAINED_CATEGORY"], [18723, 18728, "TRAINED_CATEGORY"], [18758, 18778, "TRAINED_CATEGORY"], [18782, 18794, "TRAINED_CATEGORY"], [18798, 18828, "TRAINED_CATEGORY"], [18830, 18851, "TRAINED_CATEGORY"], [18856, 18875, "TRAINED_CATEGORY"], [18879, 18888, "TRAINED_CATEGORY"], [18906, 18914, "TRAINED_CATEGORY"], [18931, 18942, "TRAINED_CATEGORY"], [18944, 18965, "TRAINED_CATEGORY"], [18969, 18980, "TRAINED_CATEGORY"], [18998, 19017, "TRAINED_CATEGORY"], [19021, 19033, "TRAINED_CATEGORY"], [19042, 19049, "TRAINED_CATEGORY"], [19053, 19061, "TRAINED_CATEGORY"], [19063, 19083, "TRAINED_CATEGORY"], [19109, 19111, "TRAINED_CATEGORY"], [19132, 19150, "TRAINED_CATEGORY"], [19155, 19187, "TRAINED_CATEGORY"], [19203, 19217, "TRAINED_CATEGORY"], [19235, 19255, "TRAINED_CATEGORY"], [19259, 19278, "TRAINED_CATEGORY"], [19285, 19296, "TRAINED_CATEGORY"], [19303, 19317, "TRAINED_CATEGORY"], [19321, 19338, "TRAINED_CATEGORY"], [19340, 19344, "TRAINED_CATEGORY"], [19363, 19371, "TRAINED_CATEGORY"], [19375, 19395, "TRAINED_CATEGORY"], [19402, 19420, "TRAINED_CATEGORY"], [19424, 19449, "TRAINED_CATEGORY"], [19460, 19472, "TRAINED_CATEGORY"], [19487, 19494, "TRAINED_CATEGORY"], [19514, 19519, "TRAINED_CATEGORY"], [19524, 19532, "TRAINED_CATEGORY"], [19534, 19559, "TRAINED_CATEGORY"], [19589, 19594, "TRAINED_CATEGORY"], [19630, 19640, "TRAINED_CATEGORY"], [19644, 19656, "TRAINED_CATEGORY"], [19674, 19678, "TRAINED_CATEGORY"], [19692, 19705, "TRAINED_CATEGORY"], [19710, 19728, "TRAINED_CATEGORY"], [19739, 19747, "TRAINED_CATEGORY"], [19752, 19767, "TRAINED_CATEGORY"], [19790, 19794, "TRAINED_CATEGORY"], [19808, 19832, "TRAINED_CATEGORY"], [19837, 19853, "TRAINED_CATEGORY"], [19862, 19874, "TRAINED_CATEGORY"], [19879, 19906, "TRAINED_CATEGORY"], [19915, 19924, "TRAINED_CATEGORY"], [19928, 19931, "TRAINED_CATEGORY"], [19940, 19958, "TRAINED_CATEGORY"], [19962, 19969, "TRAINED_CATEGORY"], [19978, 19982, "TRAINED_CATEGORY"], [20024, 20028, "TRAINED_CATEGORY"], [20051, 20055, "TRAINED_CATEGORY"], [20065, 20074, "TRAINED_CATEGORY"], [20078, 20095, "TRAINED_CATEGORY"], [20102, 20127, "TRAINED_CATEGORY"], [20167, 20174, "TRAINED_CATEGORY"], [20176, 20189, "TRAINED_CATEGORY"], [20216, 20238, "TRAINED_CATEGORY"], [20243, 20249, "TRAINED_CATEGORY"], [20263, 20290, "TRAINED_CATEGORY"], [20294, 20324, "TRAINED_CATEGORY"], [20331, 20341, "TRAINED_CATEGORY"], [20345, 20352, "TRAINED_CATEGORY"], [20368, 20425, "TRAINED_CATEGORY"], [20444, 20465, "TRAINED_CATEGORY"], [20467, 20469, "TRAINED_CATEGORY"], [20493, 20506, "TRAINED_CATEGORY"], [20540, 20569, "TRAINED_CATEGORY"], [20577, 20598, "TRAINED_CATEGORY"], [20607, 20609, "TRAINED_CATEGORY"], [20660, 20670, "TRAINED_CATEGORY"], [20681, 20692, "TRAINED_CATEGORY"], [20698, 20713, "TRAINED_CATEGORY"], [20714, 20722, "TRAINED_CATEGORY"], [20726, 20733, "TRAINED_CATEGORY"], [20742, 20749, "TRAINED_CATEGORY"], [20754, 20764, "TRAINED_CATEGORY"], [20768, 20771, "TRAINED_CATEGORY"], [20789, 20807, "TRAINED_CATEGORY"], [20812, 20823, "TRAINED_CATEGORY"], [20827, 20859, "TRAINED_CATEGORY"], [20861, 20874, "TRAINED_CATEGORY"], [20904, 20909, "TRAINED_CATEGORY"], [20913, 20916, "TRAINED_CATEGORY"], [20926, 20931, "TRAINED_CATEGORY"], [20963, 20986, "TRAINED_CATEGORY"], [20990, 20993, "TRAINED_CATEGORY"], [21011, 21030, "TRAINED_CATEGORY"], [21040, 21072, "TRAINED_CATEGORY"], [21083, 21091, "TRAINED_CATEGORY"], [21095, 21103, "TRAINED_CATEGORY"], [21107, 21116, "TRAINED_CATEGORY"], [21120, 21149, "TRAINED_CATEGORY"], [21162, 21178, "TRAINED_CATEGORY"], [21209, 21223, "TRAINED_CATEGORY"], [21240, 21252, "TRAINED_CATEGORY"], [21282, 21299, "TRAINED_CATEGORY"], [21304, 21323, "TRAINED_CATEGORY"], [21325, 21338, "TRAINED_CATEGORY"], [21343, 21362, "TRAINED_CATEGORY"], [21367, 21390, "TRAINED_CATEGORY"], [21411, 21429, "TRAINED_CATEGORY"], [21433, 21443, "TRAINED_CATEGORY"], [21444, 21465, "TRAINED_CATEGORY"], [21480, 21492, "TRAINED_CATEGORY"], [21502, 21516, "TRAINED_CATEGORY"], [21520, 21552, "TRAINED_CATEGORY"], [21567, 21570, "TRAINED_CATEGORY"], [21571, 21591, "TRAINED_CATEGORY"], [21606, 21619, "TRAINED_CATEGORY"], [21633, 21650, "TRAINED_CATEGORY"], [21654, 21667, "TRAINED_CATEGORY"], [21682, 21687, "TRAINED_CATEGORY"], [21694, 21702, "TRAINED_CATEGORY"], [21711, 21723, "TRAINED_CATEGORY"], [21735, 21747, "TRAINED_CATEGORY"], [21751, 21759, "TRAINED_CATEGORY"], [21770, 21786, "TRAINED_CATEGORY"], [21813, 21827, "TRAINED_CATEGORY"], [21831, 21843, "TRAINED_CATEGORY"], [21850, 21863, "TRAINED_CATEGORY"], [21867, 21882, "TRAINED_CATEGORY"], [21892, 21912, "TRAINED_CATEGORY"], [21916, 21921, "TRAINED_CATEGORY"], [21925, 21933, "TRAINED_CATEGORY"], [21937, 21947, "TRAINED_CATEGORY"], [21951, 21969, "TRAINED_CATEGORY"], [21971, 21973, "TRAINED_CATEGORY"], [21977, 21985, "TRAINED_CATEGORY"], [21989, 22011, "TRAINED_CATEGORY"], [22022, 22038, "TRAINED_CATEGORY"], [22052, 22070, "TRAINED_CATEGORY"], [22072, 22083, "TRAINED_CATEGORY"], [22087, 22107, "TRAINED_CATEGORY"], [22131, 22145, "TRAINED_CATEGORY"], [22173, 22184, "TRAINED_CATEGORY"], [22188, 22195, "TRAINED_CATEGORY"], [22202, 22215, "TRAINED_CATEGORY"], [22217, 22220, "TRAINED_CATEGORY"], [22231, 22252, "TRAINED_CATEGORY"], [22268, 22292, "TRAINED_CATEGORY"], [22310, 22323, "TRAINED_CATEGORY"], [22330, 22347, "TRAINED_CATEGORY"], [22384, 22399, "TRAINED_CATEGORY"], [22409, 22422, "TRAINED_CATEGORY"], [22451, 22475, "TRAINED_CATEGORY"], [22479, 22482, "TRAINED_CATEGORY"], [22491, 22505, "TRAINED_CATEGORY"], [22517, 22523, "TRAINED_CATEGORY"], [22535, 22562, "TRAINED_CATEGORY"], [22608, 22625, "TRAINED_CATEGORY"], [22635, 22647, "TRAINED_CATEGORY"], [22651, 22658, "TRAINED_CATEGORY"], [22662, 22689, "TRAINED_CATEGORY"], [22720, 22728, "TRAINED_CATEGORY"], [22732, 22741, "TRAINED_CATEGORY"], [22745, 22766, "TRAINED_CATEGORY"], [22768, 22787, "TRAINED_CATEGORY"], [22791, 22798, "TRAINED_CATEGORY"], [22815, 22833, "TRAINED_CATEGORY"], [22834, 22863, "TRAINED_CATEGORY"], [22871, 22892, "TRAINED_CATEGORY"], [22900, 22909, "TRAINED_CATEGORY"], [22921, 22932, "TRAINED_CATEGORY"], [22958, 22969, "TRAINED_CATEGORY"], [22973, 22977, "TRAINED_CATEGORY"], [22979, 22992, "TRAINED_CATEGORY"], [22997, 23000, "TRAINED_CATEGORY"], [23030, 23042, "TRAINED_CATEGORY"], [23046, 23065, "TRAINED_CATEGORY"], [23078, 23087, "TRAINED_CATEGORY"], [23097, 23114, "TRAINED_CATEGORY"], [23119, 23127, "TRAINED_CATEGORY"], [23132, 23154, "TRAINED_CATEGORY"], [23158, 23161, "TRAINED_CATEGORY"], [23163, 23182, "TRAINED_CATEGORY"], [23193, 23201, "TRAINED_CATEGORY"], [23205, 23218, "TRAINED_CATEGORY"], [23233, 23239, "TRAINED_CATEGORY"], [23249, 23255, "TRAINED_CATEGORY"], [23259, 23273, "TRAINED_CATEGORY"], [23282, 23296, "TRAINED_CATEGORY"], [23300, 23314, "TRAINED_CATEGORY"], [23330, 23360, "TRAINED_CATEGORY"], [23373, 23397, "TRAINED_CATEGORY"], [23401, 23418, "TRAINED_CATEGORY"], [23420, 23422, "TRAINED_CATEGORY"], [23438, 23470, "TRAINED_CATEGORY"], [23474, 23477, "TRAINED_CATEGORY"], [23479, 23489, "TRAINED_CATEGORY"], [23493, 23506, "TRAINED_CATEGORY"], [23510, 23513, "TRAINED_CATEGORY"], [23541, 23544, "TRAINED_CATEGORY"], [23554, 23573, "TRAINED_CATEGORY"], [23591, 23606, "TRAINED_CATEGORY"], [23616, 23620, "TRAINED_CATEGORY"], [23647, 23659, "TRAINED_CATEGORY"], [23671, 23686, "TRAINED_CATEGORY"], [23690, 23704, "TRAINED_CATEGORY"], [23713, 23726, "TRAINED_CATEGORY"], [23735, 23742, "TRAINED_CATEGORY"], [23755, 23774, "TRAINED_CATEGORY"], [23777, 23792, "TRAINED_CATEGORY"], [23796, 23810, "TRAINED_CATEGORY"], [23816, 23823, "TRAINED_CATEGORY"], [23828, 23846, "TRAINED_CATEGORY"], [23862, 23880, "TRAINED_CATEGORY"], [23884, 23904, "TRAINED_CATEGORY"], [23911, 23927, "TRAINED_CATEGORY"], [23931, 23961, "TRAINED_CATEGORY"], [23972, 23991, "TRAINED_CATEGORY"], [23992, 23995, "TRAINED_CATEGORY"], [24008, 24019, "TRAINED_CATEGORY"], [24025, 24050, "TRAINED_CATEGORY"], [24076, 24090, "TRAINED_CATEGORY"], [24094, 24110, "TRAINED_CATEGORY"], [24165, 24176, "TRAINED_CATEGORY"], [24180, 24199, "TRAINED_CATEGORY"], [24201, 24203, "TRAINED_CATEGORY"], [24223, 24235, "TRAINED_CATEGORY"], [24241, 24279, "TRAINED_CATEGORY"], [24298, 24312, "TRAINED_CATEGORY"], [24342, 24367, "TRAINED_CATEGORY"], [24382, 24404, "TRAINED_CATEGORY"], [24447, 24471, "TRAINED_CATEGORY"], [24472, 24493, "TRAINED_CATEGORY"], [24518, 24541, "TRAINED_CATEGORY"], [24542, 24566, "TRAINED_CATEGORY"], [24567, 24596, "TRAINED_CATEGORY"], [24597, 24602, "TRAINED_CATEGORY"], [24603, 24612, "TRAINED_CATEGORY"], [24613, 24616, "TRAINED_CATEGORY"], [24620, 24640, "TRAINED_CATEGORY"], [24641, 24673, "TRAINED_CATEGORY"], [24674, 24693, "TRAINED_CATEGORY"], [24694, 24733, "TRAINED_CATEGORY"], [24734, 24748, "TRAINED_CATEGORY"], [24773, 24783, "TRAINED_CATEGORY"], [24792, 24807, "TRAINED_CATEGORY"], [24811, 24816, "TRAINED_CATEGORY"], [24848, 24855, "TRAINED_CATEGORY"], [24857, 24889, "TRAINED_CATEGORY"], [24894, 24903, "TRAINED_CATEGORY"], [24907, 24922, "TRAINED_CATEGORY"], [24931, 24938, "TRAINED_CATEGORY"], [24952, 24961, "TRAINED_CATEGORY"], [24963, 24967, "TRAINED_CATEGORY"], [24983, 24992, "TRAINED_CATEGORY"], [24994, 25004, "TRAINED_CATEGORY"], [25006, 25009, "TRAINED_CATEGORY"], [25011, 25015, "TRAINED_CATEGORY"], [25043, 25064, "TRAINED_CATEGORY"], [25068, 25075, "TRAINED_CATEGORY"], [25092, 25098, "TRAINED_CATEGORY"], [25101, 25106, "TRAINED_CATEGORY"], [25108, 25130, "TRAINED_CATEGORY"], [25134, 25149, "TRAINED_CATEGORY"], [25154, 25169, "TRAINED_CATEGORY"], [25175, 25205, "TRAINED_CATEGORY"], [25214, 25224, "TRAINED_CATEGORY"], [25226, 25229, "TRAINED_CATEGORY"], [25231, 25235, "TRAINED_CATEGORY"], [25252, 25273, "TRAINED_CATEGORY"], [25277, 25300, "TRAINED_CATEGORY"], [25304, 25307, "TRAINED_CATEGORY"], [25310, 25315, "TRAINED_CATEGORY"], [25317, 25350, "TRAINED_CATEGORY"], [25354, 25369, "TRAINED_CATEGORY"], [25370, 25403, "TRAINED_CATEGORY"], [25413, 25423, "TRAINED_CATEGORY"], [25425, 25428, "TRAINED_CATEGORY"], [25430, 25434, "TRAINED_CATEGORY"], [25451, 25473, "TRAINED_CATEGORY"], [25477, 25484, "TRAINED_CATEGORY"], [25486, 25499, "TRAINED_CATEGORY"], [25500, 25507, "TRAINED_CATEGORY"], [25513, 25533, "TRAINED_CATEGORY"], [25537, 25562, "TRAINED_CATEGORY"], [25565, 25570, "TRAINED_CATEGORY"], [25572, 25581, "TRAINED_CATEGORY"], [25588, 25604, "TRAINED_CATEGORY"], [25606, 25620, "TRAINED_CATEGORY"], [25622, 25634, "TRAINED_CATEGORY"], [25638, 25649, "TRAINED_CATEGORY"], [25651, 25668, "TRAINED_CATEGORY"], [25670, 25673, "TRAINED_CATEGORY"], [25675, 25679, "TRAINED_CATEGORY"], [25695, 25702, "TRAINED_CATEGORY"], [25706, 25719, "TRAINED_CATEGORY"], [25724, 25732, "TRAINED_CATEGORY"], [25736, 25751, "TRAINED_CATEGORY"], [25753, 25779, "TRAINED_CATEGORY"], [25783, 25788, "TRAINED_CATEGORY"], [25801, 25809, "TRAINED_CATEGORY"], [25811, 25830, "TRAINED_CATEGORY"], [25836, 25851, "TRAINED_CATEGORY"], [25854, 25859, "TRAINED_CATEGORY"], [25861, 25870, "TRAINED_CATEGORY"], [25877, 25891, "TRAINED_CATEGORY"], [25892, 25901, "TRAINED_CATEGORY"], [25905, 25915, "TRAINED_CATEGORY"], [25917, 25929, "TRAINED_CATEGORY"], [25933, 25941, "TRAINED_CATEGORY"], [25943, 25949, "TRAINED_CATEGORY"], [25951, 25957, "TRAINED_CATEGORY"], [25963, 25977, "TRAINED_CATEGORY"], [25986, 25992, "TRAINED_CATEGORY"], [25994, 26008, "TRAINED_CATEGORY"], [26010, 26014, "TRAINED_CATEGORY"], [26016, 26045, "TRAINED_CATEGORY"], [26047, 26070, "TRAINED_CATEGORY"], [26093, 26096, "TRAINED_CATEGORY"], [26098, 26102, "TRAINED_CATEGORY"], [26118, 26131, "TRAINED_CATEGORY"], [26133, 26168, "TRAINED_CATEGORY"], [26177, 26185, "TRAINED_CATEGORY"], [26187, 26193, "TRAINED_CATEGORY"], [26195, 26203, "TRAINED_CATEGORY"], [26205, 26210, "TRAINED_CATEGORY"], [26212, 26241, "TRAINED_CATEGORY"], [26243, 26259, "TRAINED_CATEGORY"], [26263, 26270, "TRAINED_CATEGORY"], [26279, 26285, "TRAINED_CATEGORY"], [26303, 26307, "TRAINED_CATEGORY"], [26343, 26346, "TRAINED_CATEGORY"], [26348, 26352, "TRAINED_CATEGORY"], [26373, 26388, "TRAINED_CATEGORY"], [26390, 26409, "TRAINED_CATEGORY"], [26411, 26441, "TRAINED_CATEGORY"], [26450, 26458, "TRAINED_CATEGORY"], [26460, 26467, "TRAINED_CATEGORY"], [26469, 26473, "TRAINED_CATEGORY"], [26488, 26494, "TRAINED_CATEGORY"], [26496, 26503, "TRAINED_CATEGORY"], [26505, 26510, "TRAINED_CATEGORY"], [26512, 26532, "TRAINED_CATEGORY"], [26534, 26544, "TRAINED_CATEGORY"], [26549, 26560, "TRAINED_CATEGORY"], [26562, 26574, "TRAINED_CATEGORY"], [26578, 26608, "TRAINED_CATEGORY"], [26612, 26621, "TRAINED_CATEGORY"], [26623, 26630, "TRAINED_CATEGORY"], [26632, 26640, "TRAINED_CATEGORY"], [26642, 26647, "TRAINED_CATEGORY"], [26652, 26658, "TRAINED_CATEGORY"], [26667, 26673, "TRAINED_CATEGORY"], [26675, 26690, "TRAINED_CATEGORY"], [26692, 26696, "TRAINED_CATEGORY"], [26698, 26717, "TRAINED_CATEGORY"], [26719, 26726, "TRAINED_CATEGORY"], [26728, 26733, "TRAINED_CATEGORY"], [26735, 26760, "TRAINED_CATEGORY"], [26764, 26811, "TRAINED_CATEGORY"], [26820, 26830, "TRAINED_CATEGORY"], [26832, 26835, "TRAINED_CATEGORY"], [26837, 26841, "TRAINED_CATEGORY"], [26843, 26862, "TRAINED_CATEGORY"], [26864, 26871, "TRAINED_CATEGORY"], [26873, 26878, "TRAINED_CATEGORY"], [26880, 26896, "TRAINED_CATEGORY"], [26898, 26905, "TRAINED_CATEGORY"], [26907, 26915, "TRAINED_CATEGORY"], [26918, 26930, "TRAINED_CATEGORY"], [26934, 26964, "TRAINED_CATEGORY"], [26973, 26979, "TRAINED_CATEGORY"], [26981, 26996, "TRAINED_CATEGORY"], [26998, 27002, "TRAINED_CATEGORY"], [27004, 27025, "TRAINED_CATEGORY"], [27027, 27032, "TRAINED_CATEGORY"], [27034, 27040, "TRAINED_CATEGORY"], [27042, 27071, "TRAINED_CATEGORY"], [27089, 27112, "TRAINED_CATEGORY"], [27121, 27131, "TRAINED_CATEGORY"], [27133, 27136, "TRAINED_CATEGORY"], [27138, 27142, "TRAINED_CATEGORY"], [27162, 27176, "TRAINED_CATEGORY"], [27180, 27201, "TRAINED_CATEGORY"], [27205, 27235, "TRAINED_CATEGORY"], [27236, 27253, "TRAINED_CATEGORY"], [27297, 27304, "TRAINED_CATEGORY"], [27306, 27313, "TRAINED_CATEGORY"], [27314, 27325, "TRAINED_CATEGORY"], [27334, 27357, "TRAINED_CATEGORY"], [27364, 27375, "TRAINED_CATEGORY"], [27379, 27397, "TRAINED_CATEGORY"], [27406, 27415, "TRAINED_CATEGORY"], [27419, 27452, "TRAINED_CATEGORY"], [27454, 27462, "TRAINED_CATEGORY"], [27468, 27483, "TRAINED_CATEGORY"], [27485, 27511, "TRAINED_CATEGORY"], [27513, 27522, "TRAINED_CATEGORY"], [27524, 27542, "TRAINED_CATEGORY"], [27544, 27568, "TRAINED_CATEGORY"], [27572, 27575, "TRAINED_CATEGORY"], [27579, 27594, "TRAINED_CATEGORY"], [27595, 27621, "TRAINED_CATEGORY"], [27622, 27626, "TRAINED_CATEGORY"], [27628, 27635, "TRAINED_CATEGORY"], [27641, 27652, "TRAINED_CATEGORY"], [27659, 27665, "TRAINED_CATEGORY"], [27668, 27681, "TRAINED_CATEGORY"], [27682, 27695, "TRAINED_CATEGORY"], [27700, 27717, "TRAINED_CATEGORY"], [27724, 27730, "TRAINED_CATEGORY"], [27732, 27752, "TRAINED_CATEGORY"], [27754, 27757, "TRAINED_CATEGORY"], [27761, 27790, "TRAINED_CATEGORY"], [27794, 27798, "TRAINED_CATEGORY"], [27801, 27828, "TRAINED_CATEGORY"], [27857, 27864, "TRAINED_CATEGORY"], [27868, 27891, "TRAINED_CATEGORY"], [27892, 27903, "TRAINED_CATEGORY"], [27909, 27930, "TRAINED_CATEGORY"], [27954, 27980, "TRAINED_CATEGORY"], [27982, 27995, "TRAINED_CATEGORY"], [27998, 28024, "TRAINED_CATEGORY"], [28026, 28050, "TRAINED_CATEGORY"], [28054, 28084, "TRAINED_CATEGORY"], [28087, 28102, "TRAINED_CATEGORY"], [28106, 28121, "TRAINED_CATEGORY"], [28125, 28155, "TRAINED_CATEGORY"], [28168, 28171, "TRAINED_CATEGORY"], [28176, 28198, "TRAINED_CATEGORY"], [28202, 28217, "TRAINED_CATEGORY"], [28218, 28226, "TRAINED_CATEGORY"], [28228, 28233, "TRAINED_CATEGORY"], [28241, 28244, "TRAINED_CATEGORY"], [28248, 28261, "TRAINED_CATEGORY"], [28271, 28274, "TRAINED_CATEGORY"], [28278, 28283, "TRAINED_CATEGORY"], [28287, 28306, "TRAINED_CATEGORY"], [28311, 28330, "TRAINED_CATEGORY"], [28371, 28403, "TRAINED_CATEGORY"], [28407, 28422, "TRAINED_CATEGORY"], [32, 35, "ORG"], [168, 183, "PERSON"], [187, 196, "DATE"], [216, 229, "PERSON"], [241, 254, "ORG"], [258, 262, "DATE"], [604, 607, "CARDINAL"], [700, 704, "CARDINAL"], [725, 728, "ORG"], [748, 749, "CARDINAL"], [753, 754, "CARDINAL"], [758, 759, "CARDINAL"], [765, 773, "PERSON"], [776, 780, "DATE"], [815, 818, "ORG"], [1083, 1086, "ORG"], [1420, 1423, "ORG"], [1917, 1920, "CARDINAL"], [2210, 2213, "ORG"], [2323, 2326, "ORG"], [2674, 2677, "ORG"], [3140, 3175, "ORG"], [3630, 3633, "ORG"], [3684, 3687, "CARDINAL"], [4426, 4429, "ORG"], [4482, 4491, "CARDINAL"], [4793, 4796, "ORG"], [5000, 5003, "ORG"], [5103, 5114, "ORG"], [5118, 5124, "PERSON"], [5191, 5219, "ORG"], [5274, 5295, "ORG"], [5327, 5364, "ORG"], [5422, 5445, "ORG"], [5510, 5545, "ORG"], [5575, 5579, "GPE"], [5592, 5622, "ORG"], [5833, 5836, "ORG"], [5969, 5972, "ORG"], [6216, 6224, "GPE"], [6244, 6249, "ORDINAL"], [6351, 6360, "ORG"], [6733, 6742, "LOC"], [6744, 6758, "PERSON"], [6764, 6771, "CARDINAL"], [6785, 6788, "ORG"], [6859, 6864, "GPE"], [6879, 6895, "CARDINAL"], [6896, 6903, "NORP"], [6934, 6937, "ORG"], [6973, 6976, "ORG"], [7083, 7088, "GPE"], [7103, 7115, "CARDINAL"], [7116, 7123, "NORP"], [7165, 7232, "ORG"], [7364, 7368, "DATE"], [7382, 7437, "WORK_OF_ART"], [7483, 7536, "WORK_OF_ART"], [7546, 7550, "DATE"], [7562, 7572, "GPE"], [7574, 7579, "GPE"], [7581, 7588, "CARDINAL"], [7616, 7618, "CARDINAL"], [7644, 7646, "GPE"], [7648, 7655, "GPE"], [7657, 7662, "GPE"], [7664, 7669, "GPE"], [7671, 7679, "GPE"], [7685, 7690, "GPE"], [7741, 7745, "DATE"], [7759, 7769, "GPE"], [7771, 7783, "GPE"], [7790, 7792, "CARDINAL"], [7879, 7885, "GPE"], [7987, 8006, "ORG"], [8010, 8015, "GPE"], [8084, 8087, "ORG"], [8238, 8244, "CARDINAL"], [8257, 8265, "CARDINAL"], [8353, 8356, "CARDINAL"], [8677, 8680, "ORG"], [9526, 9531, "PRODUCT"], [9567, 9572, "ORDINAL"], [9800, 9803, "ORG"], [12400, 12403, "ORG"], [12412, 12415, "ORG"], [13179, 13182, "ORG"], [13323, 13326, "ORG"], [13376, 13388, "CARDINAL"], [13492, 13495, "ORG"], [14027, 14030, "ORG"], [14099, 14104, "CARDINAL"], [14148, 14152, "CARDINAL"], [14271, 14274, "CARDINAL"], [14324, 14329, "CARDINAL"], [14366, 14370, "CARDINAL"], [14513, 14516, "CARDINAL"], [14718, 14722, "CARDINAL"], [14741, 14745, "CARDINAL"], [14815, 14820, "CARDINAL"], [14855, 14865, "CARDINAL"], [15023, 15026, "ORG"], [15075, 15083, "CARDINAL"], [15489, 15492, "CARDINAL"], [16273, 16276, "ORG"], [16384, 16388, "CARDINAL"], [16405, 16414, "NORP"], [16534, 16544, "ORG"], [16627, 16630, "ORG"], [16757, 16777, "CARDINAL"], [16879, 16882, "CARDINAL"], [16903, 16906, "CARDINAL"], [16927, 16930, "CARDINAL"], [16945, 16949, "CARDINAL"], [17305, 17313, "ORG"], [17323, 17335, "NORP"], [17433, 17437, "LOC"], [17441, 17446, "CARDINAL"], [17500, 17505, "CARDINAL"], [17561, 17569, "ORG"], [17632, 17637, "CARDINAL"], [17820, 17825, "CARDINAL"], [18064, 18069, "ORDINAL"], [18179, 18187, "CARDINAL"], [18188, 18200, "NORP"], [18240, 18244, "CARDINAL"], [18246, 18249, "CARDINAL"], [18297, 18310, "CARDINAL"], [18424, 18435, "NORP"], [18635, 18643, "ORG"], [18662, 18673, "NORP"], [18684, 18689, "CARDINAL"], [18899, 18904, "CARDINAL"], [19094, 19099, "CARDINAL"], [19402, 19411, "ORG"], [19491, 19494, "ORG"], [19534, 19537, "CARDINAL"], [19692, 19696, "CARDINAL"], [19710, 19715, "CARDINAL"], [19808, 19811, "CARDINAL"], [19812, 19832, "ORG"], [19837, 19840, "CARDINAL"], [19928, 19931, "ORG"], [20044, 20047, "CARDINAL"], [20102, 20111, "CARDINAL"], [20112, 20115, "ORG"], [20263, 20324, "EVENT"], [20331, 20341, "ORG"], [20349, 20352, "ORG"], [20698, 20713, "DATE"], [20768, 20771, "ORG"], [20789, 20859, "ORG"], [20913, 20916, "ORG"], [20990, 20993, "ORG"], [21011, 21030, "ORG"], [21034, 21038, "DATE"], [21043, 21047, "DATE"], [21048, 21066, "ORG"], [21083, 21091, "DATE"], [21120, 21149, "ORG"], [21162, 21165, "ORG"], [21276, 21280, "DATE"], [21325, 21362, "ORG"], [21367, 21390, "ORG"], [21411, 21414, "ORG"], [21482, 21486, "DATE"], [21567, 21570, "ORG"], [21606, 21619, "DATE"], [21658, 21661, "ORG"], [21713, 21717, "DATE"], [21850, 21854, "ORG"], [22173, 22176, "CARDINAL"], [22217, 22220, "CARDINAL"], [22479, 22482, "ORG"], [22511, 22515, "DATE"], [22517, 22523, "ORG"], [22537, 22543, "ORDINAL"], [22544, 22547, "ORG"], [22795, 22798, "ORG"], [22997, 23000, "ORG"], [23032, 23036, "DATE"], [23046, 23065, "ORG"], [23097, 23114, "ORG"], [23119, 23127, "PERSON"], [23158, 23161, "ORG"], [23438, 23477, "ORG"], [23510, 23513, "ORG"], [23527, 23531, "DATE"], [23541, 23544, "ORG"], [23739, 23742, "ORG"], [23820, 23823, "ORG"], [24223, 24235, "PERSON"], [24377, 24380, "DATE"], [24447, 24455, "ORG"], [24472, 24477, "ORG"], [24567, 24579, "ORG"], [24597, 24602, "PERSON"], [24641, 24646, "ORG"], [24734, 24738, "PRODUCT"], [24818, 24836, "PERSON"], [24924, 24928, "DATE"], [24931, 24938, "GPE"], [24940, 24950, "GPE"], [24952, 24961, "PERSON"], [24983, 24992, "GPE"], [24994, 25004, "GPE"], [25006, 25009, "ORG"], [25072, 25075, "ORG"], [25108, 25130, "PERSON"], [25134, 25169, "ORG"], [25207, 25211, "DATE"], [25214, 25224, "GPE"], [25226, 25229, "ORG"], [25304, 25307, "ORG"], [25317, 25339, "PERSON"], [25371, 25403, "PERSON"], [25406, 25410, "DATE"], [25413, 25423, "GPE"], [25425, 25428, "ORG"], [25435, 25436, "CARDINAL"], [25481, 25484, "ORG"], [25504, 25507, "ORG"], [25572, 25581, "PERSON"], [25588, 25604, "PERSON"], [25610, 25620, "PERSON"], [25652, 25656, "DATE"], [25658, 25668, "GPE"], [25696, 25702, "CARDINAL"], [25736, 25739, "ORG"], [25861, 25870, "PERSON"], [25877, 25891, "PERSON"], [25892, 25915, "PERSON"], [25979, 25983, "DATE"], [25986, 25992, "GPE"], [25994, 26008, "ORG"], [26085, 26089, "DATE"], [26093, 26096, "ORG"], [26098, 26102, "ORG"], [26118, 26131, "PERSON"], [26170, 26174, "DATE"], [26187, 26193, "PERSON"], [26195, 26203, "PERSON"], [26212, 26242, "PERSON"], [26243, 26270, "ORG"], [26272, 26276, "DATE"], [26287, 26301, "ORG"], [26335, 26339, "DATE"], [26343, 26346, "ORG"], [26348, 26352, "ORG"], [26373, 26388, "PERSON"], [26443, 26447, "DATE"], [26450, 26458, "GPE"], [26460, 26467, "ORG"], [26488, 26494, "GPE"], [26496, 26503, "PERSON"], [26512, 26532, "PERSON"], [26660, 26664, "DATE"], [26667, 26673, "GPE"], [26711, 26717, "GPE"], [26719, 26726, "PERSON"], [26735, 26760, "PERSON"], [26813, 26817, "DATE"], [26820, 26830, "GPE"], [26832, 26835, "ORG"], [26856, 26862, "GPE"], [26864, 26871, "PERSON"], [26880, 26896, "PERSON"], [26898, 26964, "ORG"], [26966, 26970, "DATE"], [26973, 26979, "GPE"], [27017, 27025, "GPE"], [27027, 27032, "GPE"], [27034, 27040, "GPE"], [27042, 27055, "PERSON"], [27114, 27118, "DATE"], [27121, 27131, "GPE"], [27133, 27136, "ORG"], [27143, 27144, "CARDINAL"], [27162, 27170, "ORG"], [27180, 27235, "ORG"], [27301, 27304, "ORG"], [27364, 27367, "ORG"], [27459, 27462, "ORG"], [27468, 27471, "ORG"], [27513, 27516, "ORG"], [27525, 27537, "CARDINAL"], [27572, 27575, "ORG"], [27583, 27594, "PERSON"], [27659, 27665, "PERSON"], [27684, 27687, "ORG"], [27765, 27779, "PERSON"], [27802, 27829, "WORK_OF_ART"], [27892, 27895, "ORG"], [27933, 27936, "ORG"], [28001, 28004, "ORG"], [28168, 28171, "ORG"], [28206, 28217, "PERSON"], [28241, 28244, "ORG"], [28248, 28253, "PRODUCT"], [28271, 28274, "ORG"], [28278, 28283, "PRODUCT"], [28291, 28306, "PERSON"], [28407, 28422, "PERSON"]]}], ["Louis Leon Thurstone (29 May 1887 \u2013 30 September 1955) was a U.S. pioneer in the fields of psychometrics and psychophysics. He conceived the approach to measurement known as the law of comparative judgment, and is well known for his contributions to factor analysis. A Review of General Psychology survey, published in 2002, ranked Thurstone as the 88th most cited psychologist of the 20th century, tied with John Garcia, James J. Gibson, David Rumelhart, Margaret Floy Washburn, and Robert S. Woodworth.\n\n\n== Background and history ==\nLouis Leon Thurstone was born in Chicago, Illinois, to Swedish immigrant parents. Thurstone originally received a masters in mechanical engineering from Cornell University in 1912. Thurstone was offered a brief assistantship in the laboratory of Thomas Edison. In 1914, after two years as an instructor of geometry and drafting at the University of Minnesota, he enrolled as a graduate student in psychology at the University of Chicago (PhD, 1917). He later returned to the University of Chicago (1924\u20131952) where he taught and conducted research. In 1952, he established the L. L. Thurstone Psychometric Laboratory at the University of North Carolina at Chapel Hill.\n\n\n== Factor analysis and work on intelligence ==\nThurstone was responsible for the standardized mean and standard deviation of IQ scores used today, as opposed to the Intelligence Test system originally used by Alfred Binet. He is also known for the development of the Thurstone scale.Thurstone's work in factor analysis led him to formulate a model of intelligence centered on \"Primary Mental Abilities\" (PMAs), which were independent group factors of intelligence that different individuals possessed in varying degrees. He opposed the notion of a singular general intelligence that factored into the scores of all psychometric tests and was expressed as a mental age. In 1935 Thurstone, together with EL Thorndike and JP Guilford, founded the journal Psychometrika and also the Psychometric Society, going on to become the society's first president in 1936. Thurstone's contributions to methods of factor analysis have proved valuable in establishing and verifying later psychometric factor structures, and have influenced the hierarchical models of intelligence in use in intelligence tests such as WAIS and the modern Stanford-Binet IQ test.The seven primary mental abilities in Thurstone's model were verbal comprehension, word fluency, number facility, spatial visualization, associative memory, perceptual speed, and reasoning.\n\n\n== Contributions to measurement ==\nDespite his contributions to factor analysis, Thurstone (1959, p. 267) cautioned: \"When a problem is so involved that no rational formulation is available, then some quantification is still possible by the coefficients of correlation of contingency and the like. But such statistical procedures constitute an acknowledgement of failure to rationalize the problem and to establish functions that underlie the data. We want to measure the separation between the two opinions on the attitude continuum and we want to test the validity of the assumed continuum by means of its internal consistency\". Thurstone's approach to measurement was termed the law of comparative judgment. He applied the approach in psychophysics, and later to the measurement of psychological values. The so-called 'Law', which can be regarded as a measurement model, involves subjects making a comparison between each of a number of pairs of stimuli with respect to magnitude of a property, attribute, or attitude. Methods based on the approach to measurement can be used to estimate such scale values.Thurstone's Law of comparative judgment has important links to modern approaches to social and psychological measurement. In particular, the approach bears a close conceptual relation to the Rasch model (Andrich, 1978), although Thurstone typically employed the normal distribution in applications of the Law of comparative judgment whereas the Rasch model is a simple logistic function. Thurstone anticipated a key epistemological requirement of measurement later articulated by Rasch, which is that relative scale locations must 'transcend' the group measured; i.e. scale locations must be invariant to (or independent of) the particular group of persons instrumental to comparisons between the stimuli. Thurstone (1929) also articulated what he referred to as the additivity criterion for scale differences, a criterion which must be satisfied in order to obtain interval-level measurements.\n\n\n== Awards and honors ==\nThurstone received numerous awards, including:  Best Article, American Psychological Association (1949); Centennial Award, Northwestern University (1951); Honorary Doctorate, University of G\u00f6teborg (1954). Thurstone was President of American Psychological Association (1933) and first President of the American Psychometric Society (1936).\n\n\n== Selected works ==\nThe Nature of Intelligence   (London:  Routledge. 1924)\nThe Effect of Motion Pictures on the Social Attitudes of High School Children Ruth C. Peterson & L.L. Thurstone, MacMillan, 1932\nMotion Pictures and the Social Attitudes of Children Ruth C. Peterson & L.L. Thurstone, MacMillan, 1933\nThe Vectors of Mind. Address of the president before the American Psychological Association, Chicago meeting, September, 1933  ( Psychological Review, 41, 1\u201332. 1934)\nThe Vectors of Mind (Chicago, IL, US: University of Chicago Press 1935)\nPrimary mental abilities  (Chicago: University of Chicago Press. 1938)\nMultiple-Factor Analysis (Chicago:  University of Chicago Press. 1947)\nThe Fundamentals of Statistics (MacMillan: Norwood Press. 1925)\n\n\n== See also ==\nL. L. Thurstone Psychometric Laboratory\nLaw of comparative judgment\n\n\n== References ==\n\n\n== Sources ==\nMartin, O (1997). \"Psychological measurement from Binet to Thurstone, (1900\u20131930)\". Revue de Synthese (in French). 118 (4): 457\u201393. doi:10.1007/BF03181359. PMID 11625304.\nThurstone, LL (1987). \"Psychophysical analysis. by L. L. Thurstone, 1927\" (PDF). The American Journal of Psychology. 100 (3\u20134): 587\u2013609. doi:10.2307/1422696. JSTOR 1422696. PMID 3322058.\nGulliksen, H (1968). \"Louis Leon Thurstone, experimental and mathematical psychologist\". The American Psychologist. 23 (11): 786\u2013802. doi:10.1037/h0026696. PMID 4881041.\nWolfle, D (1956). \"Louis Leon Thurstone, 1887\u20131955\". The American Journal of Psychology. 69 (1): 131\u20134. PMID 13302517.\nHorst, P (1955). \"L.L. Thurstone and the science of human behavior\". Science. 122 (3183): 1259\u201360. doi:10.1126/science.122.3183.1259. PMID 13274085.\nAndrich, D. (1978). \"Relationships Between the Thurstone and Rasch Approaches to Item Scaling\". Applied Psychological Measurement. 2 (3): 451\u2013462. doi:10.1177/014662167800200319.\nThurstone, L. L. (1927). \"A law of comparative judgement\". Psychological Review. 34 (4): 278\u2013286. doi:10.1037/h0070288.\nGordon, Kate; Smith, Thomas Vernor, eds. (1929). Essays in Philosophy: by Seventeen Doctors of Philosophy of the University of Chicago. Chicago: Open Court. OCLC 257229209.\nThurstone, L. L. (1974). The Measurement of Values. Chicago: The University of Chicago Press. ISBN 978-0-226-80114-8. OCLC 5723850.\n\n\n== External links ==\nThe Vectors of Mind 1934\nHistory of  L. L. Thurstone Psychometric Laboratory", {"entities": [[0, 20, "TRAINED_CATEGORY"], [22, 28, "TRAINED_CATEGORY"], [36, 48, "TRAINED_CATEGORY"], [59, 73, "TRAINED_CATEGORY"], [77, 87, "TRAINED_CATEGORY"], [91, 104, "TRAINED_CATEGORY"], [109, 122, "TRAINED_CATEGORY"], [124, 126, "TRAINED_CATEGORY"], [137, 149, "TRAINED_CATEGORY"], [153, 164, "TRAINED_CATEGORY"], [174, 181, "TRAINED_CATEGORY"], [185, 205, "TRAINED_CATEGORY"], [229, 246, "TRAINED_CATEGORY"], [257, 265, "TRAINED_CATEGORY"], [267, 275, "TRAINED_CATEGORY"], [279, 304, "TRAINED_CATEGORY"], [332, 341, "TRAINED_CATEGORY"], [345, 377, "TRAINED_CATEGORY"], [381, 397, "TRAINED_CATEGORY"], [409, 420, "TRAINED_CATEGORY"], [422, 437, "TRAINED_CATEGORY"], [439, 454, "TRAINED_CATEGORY"], [456, 478, "TRAINED_CATEGORY"], [484, 503, "TRAINED_CATEGORY"], [510, 520, "TRAINED_CATEGORY"], [525, 532, "TRAINED_CATEGORY"], [536, 556, "TRAINED_CATEGORY"], [569, 576, "TRAINED_CATEGORY"], [578, 586, "TRAINED_CATEGORY"], [591, 616, "TRAINED_CATEGORY"], [618, 627, "TRAINED_CATEGORY"], [648, 657, "TRAINED_CATEGORY"], [661, 683, "TRAINED_CATEGORY"], [689, 707, "TRAINED_CATEGORY"], [717, 726, "TRAINED_CATEGORY"], [739, 760, "TRAINED_CATEGORY"], [764, 778, "TRAINED_CATEGORY"], [782, 795, "TRAINED_CATEGORY"], [812, 821, "TRAINED_CATEGORY"], [825, 838, "TRAINED_CATEGORY"], [842, 850, "TRAINED_CATEGORY"], [867, 881, "TRAINED_CATEGORY"], [885, 894, "TRAINED_CATEGORY"], [896, 898, "TRAINED_CATEGORY"], [911, 929, "TRAINED_CATEGORY"], [933, 943, "TRAINED_CATEGORY"], [947, 961, "TRAINED_CATEGORY"], [965, 972, "TRAINED_CATEGORY"], [974, 977, "TRAINED_CATEGORY"], [986, 988, "TRAINED_CATEGORY"], [1007, 1021, "TRAINED_CATEGORY"], [1025, 1032, "TRAINED_CATEGORY"], [1051, 1053, "TRAINED_CATEGORY"], [1075, 1083, "TRAINED_CATEGORY"], [1094, 1096, "TRAINED_CATEGORY"], [1109, 1152, "TRAINED_CATEGORY"], [1156, 1170, "TRAINED_CATEGORY"], [1174, 1188, "TRAINED_CATEGORY"], [1192, 1203, "TRAINED_CATEGORY"], [1210, 1225, "TRAINED_CATEGORY"], [1230, 1234, "TRAINED_CATEGORY"], [1238, 1250, "TRAINED_CATEGORY"], [1254, 1263, "TRAINED_CATEGORY"], [1284, 1328, "TRAINED_CATEGORY"], [1332, 1341, "TRAINED_CATEGORY"], [1368, 1396, "TRAINED_CATEGORY"], [1416, 1428, "TRAINED_CATEGORY"], [1430, 1432, "TRAINED_CATEGORY"], [1451, 1466, "TRAINED_CATEGORY"], [1470, 1489, "TRAINED_CATEGORY"], [1490, 1506, "TRAINED_CATEGORY"], [1510, 1525, "TRAINED_CATEGORY"], [1530, 1533, "TRAINED_CATEGORY"], [1547, 1554, "TRAINED_CATEGORY"], [1558, 1570, "TRAINED_CATEGORY"], [1583, 1608, "TRAINED_CATEGORY"], [1611, 1615, "TRAINED_CATEGORY"], [1629, 1654, "TRAINED_CATEGORY"], [1658, 1670, "TRAINED_CATEGORY"], [1676, 1697, "TRAINED_CATEGORY"], [1711, 1726, "TRAINED_CATEGORY"], [1728, 1730, "TRAINED_CATEGORY"], [1739, 1749, "TRAINED_CATEGORY"], [1753, 1784, "TRAINED_CATEGORY"], [1804, 1814, "TRAINED_CATEGORY"], [1818, 1840, "TRAINED_CATEGORY"], [1862, 1874, "TRAINED_CATEGORY"], [1884, 1893, "TRAINED_CATEGORY"], [1909, 1921, "TRAINED_CATEGORY"], [1926, 1937, "TRAINED_CATEGORY"], [1947, 1958, "TRAINED_CATEGORY"], [1959, 1972, "TRAINED_CATEGORY"], [1977, 2006, "TRAINED_CATEGORY"], [2027, 2056, "TRAINED_CATEGORY"], [2066, 2091, "TRAINED_CATEGORY"], [2095, 2102, "TRAINED_CATEGORY"], [2106, 2121, "TRAINED_CATEGORY"], [2173, 2209, "TRAINED_CATEGORY"], [2231, 2254, "TRAINED_CATEGORY"], [2258, 2270, "TRAINED_CATEGORY"], [2274, 2277, "TRAINED_CATEGORY"], [2281, 2299, "TRAINED_CATEGORY"], [2308, 2312, "TRAINED_CATEGORY"], [2317, 2350, "TRAINED_CATEGORY"], [2351, 2385, "TRAINED_CATEGORY"], [2389, 2406, "TRAINED_CATEGORY"], [2412, 2432, "TRAINED_CATEGORY"], [2434, 2446, "TRAINED_CATEGORY"], [2448, 2463, "TRAINED_CATEGORY"], [2465, 2486, "TRAINED_CATEGORY"], [2488, 2506, "TRAINED_CATEGORY"], [2508, 2524, "TRAINED_CATEGORY"], [2530, 2539, "TRAINED_CATEGORY"], [2546, 2559, "TRAINED_CATEGORY"], [2586, 2603, "TRAINED_CATEGORY"], [2614, 2622, "TRAINED_CATEGORY"], [2624, 2633, "TRAINED_CATEGORY"], [2641, 2643, "TRAINED_CATEGORY"], [2666, 2675, "TRAINED_CATEGORY"], [2696, 2719, "TRAINED_CATEGORY"], [2739, 2758, "TRAINED_CATEGORY"], [2780, 2796, "TRAINED_CATEGORY"], [2800, 2811, "TRAINED_CATEGORY"], [2815, 2826, "TRAINED_CATEGORY"], [2845, 2872, "TRAINED_CATEGORY"], [2884, 2902, "TRAINED_CATEGORY"], [2906, 2913, "TRAINED_CATEGORY"], [2929, 2940, "TRAINED_CATEGORY"], [2958, 2967, "TRAINED_CATEGORY"], [2982, 2990, "TRAINED_CATEGORY"], [2992, 2994, "TRAINED_CATEGORY"], [3011, 3025, "TRAINED_CATEGORY"], [3034, 3050, "TRAINED_CATEGORY"], [3054, 3076, "TRAINED_CATEGORY"], [3081, 3083, "TRAINED_CATEGORY"], [3097, 3109, "TRAINED_CATEGORY"], [3113, 3134, "TRAINED_CATEGORY"], [3138, 3143, "TRAINED_CATEGORY"], [3147, 3171, "TRAINED_CATEGORY"], [3174, 3194, "TRAINED_CATEGORY"], [3198, 3209, "TRAINED_CATEGORY"], [3232, 3252, "TRAINED_CATEGORY"], [3254, 3256, "TRAINED_CATEGORY"], [3265, 3277, "TRAINED_CATEGORY"], [3281, 3294, "TRAINED_CATEGORY"], [3309, 3324, "TRAINED_CATEGORY"], [3328, 3348, "TRAINED_CATEGORY"], [3350, 3368, "TRAINED_CATEGORY"], [3396, 3415, "TRAINED_CATEGORY"], [3426, 3434, "TRAINED_CATEGORY"], [3442, 3454, "TRAINED_CATEGORY"], [3471, 3479, "TRAINED_CATEGORY"], [3483, 3488, "TRAINED_CATEGORY"], [3492, 3499, "TRAINED_CATEGORY"], [3505, 3512, "TRAINED_CATEGORY"], [3516, 3525, "TRAINED_CATEGORY"], [3529, 3539, "TRAINED_CATEGORY"], [3541, 3550, "TRAINED_CATEGORY"], [3555, 3563, "TRAINED_CATEGORY"], [3565, 3572, "TRAINED_CATEGORY"], [3582, 3594, "TRAINED_CATEGORY"], [3598, 3609, "TRAINED_CATEGORY"], [3634, 3651, "TRAINED_CATEGORY"], [3652, 3667, "TRAINED_CATEGORY"], [3671, 3691, "TRAINED_CATEGORY"], [3696, 3711, "TRAINED_CATEGORY"], [3715, 3732, "TRAINED_CATEGORY"], [3736, 3772, "TRAINED_CATEGORY"], [3789, 3801, "TRAINED_CATEGORY"], [3808, 3835, "TRAINED_CATEGORY"], [3839, 3854, "TRAINED_CATEGORY"], [3856, 3863, "TRAINED_CATEGORY"], [3881, 3890, "TRAINED_CATEGORY"], [3910, 3933, "TRAINED_CATEGORY"], [3937, 3949, "TRAINED_CATEGORY"], [3953, 3960, "TRAINED_CATEGORY"], [3964, 3984, "TRAINED_CATEGORY"], [3993, 4008, "TRAINED_CATEGORY"], [4012, 4038, "TRAINED_CATEGORY"], [4040, 4049, "TRAINED_CATEGORY"], [4062, 4095, "TRAINED_CATEGORY"], [4099, 4110, "TRAINED_CATEGORY"], [4132, 4137, "TRAINED_CATEGORY"], [4153, 4177, "TRAINED_CATEGORY"], [4195, 4204, "TRAINED_CATEGORY"], [4215, 4235, "TRAINED_CATEGORY"], [4277, 4297, "TRAINED_CATEGORY"], [4301, 4308, "TRAINED_CATEGORY"], [4325, 4336, "TRAINED_CATEGORY"], [4345, 4356, "TRAINED_CATEGORY"], [4358, 4367, "TRAINED_CATEGORY"], [4392, 4396, "TRAINED_CATEGORY"], [4397, 4399, "TRAINED_CATEGORY"], [4415, 4439, "TRAINED_CATEGORY"], [4444, 4461, "TRAINED_CATEGORY"], [4463, 4474, "TRAINED_CATEGORY"], [4502, 4507, "TRAINED_CATEGORY"], [4518, 4545, "TRAINED_CATEGORY"], [4552, 4558, "TRAINED_CATEGORY"], [4563, 4569, "TRAINED_CATEGORY"], [4573, 4582, "TRAINED_CATEGORY"], [4592, 4607, "TRAINED_CATEGORY"], [4621, 4633, "TRAINED_CATEGORY"], [4635, 4669, "TRAINED_CATEGORY"], [4678, 4694, "TRAINED_CATEGORY"], [4696, 4719, "TRAINED_CATEGORY"], [4728, 4746, "TRAINED_CATEGORY"], [4748, 4758, "TRAINED_CATEGORY"], [4762, 4770, "TRAINED_CATEGORY"], [4779, 4788, "TRAINED_CATEGORY"], [4793, 4802, "TRAINED_CATEGORY"], [4806, 4840, "TRAINED_CATEGORY"], [4852, 4867, "TRAINED_CATEGORY"], [4871, 4904, "TRAINED_CATEGORY"], [4918, 4932, "TRAINED_CATEGORY"], [4936, 4946, "TRAINED_CATEGORY"], [4950, 4962, "TRAINED_CATEGORY"], [4965, 4972, "TRAINED_CATEGORY"], [4975, 4984, "TRAINED_CATEGORY"], [4992, 5002, "TRAINED_CATEGORY"], [5006, 5021, "TRAINED_CATEGORY"], [5025, 5045, "TRAINED_CATEGORY"], [5049, 5086, "TRAINED_CATEGORY"], [5089, 5103, "TRAINED_CATEGORY"], [5121, 5136, "TRAINED_CATEGORY"], [5141, 5161, "TRAINED_CATEGORY"], [5165, 5190, "TRAINED_CATEGORY"], [5193, 5207, "TRAINED_CATEGORY"], [5225, 5236, "TRAINED_CATEGORY"], [5240, 5244, "TRAINED_CATEGORY"], [5246, 5253, "TRAINED_CATEGORY"], [5257, 5270, "TRAINED_CATEGORY"], [5278, 5316, "TRAINED_CATEGORY"], [5318, 5333, "TRAINED_CATEGORY"], [5352, 5374, "TRAINED_CATEGORY"], [5392, 5403, "TRAINED_CATEGORY"], [5407, 5411, "TRAINED_CATEGORY"], [5413, 5420, "TRAINED_CATEGORY"], [5422, 5424, "TRAINED_CATEGORY"], [5426, 5428, "TRAINED_CATEGORY"], [5430, 5440, "TRAINED_CATEGORY"], [5444, 5457, "TRAINED_CATEGORY"], [5464, 5488, "TRAINED_CATEGORY"], [5490, 5498, "TRAINED_CATEGORY"], [5500, 5510, "TRAINED_CATEGORY"], [5514, 5527, "TRAINED_CATEGORY"], [5535, 5559, "TRAINED_CATEGORY"], [5561, 5568, "TRAINED_CATEGORY"], [5571, 5581, "TRAINED_CATEGORY"], [5585, 5598, "TRAINED_CATEGORY"], [5606, 5622, "TRAINED_CATEGORY"], [5626, 5636, "TRAINED_CATEGORY"], [5637, 5647, "TRAINED_CATEGORY"], [5649, 5662, "TRAINED_CATEGORY"], [5687, 5692, "TRAINED_CATEGORY"], [5693, 5726, "TRAINED_CATEGORY"], [5727, 5730, "TRAINED_CATEGORY"], [5734, 5754, "TRAINED_CATEGORY"], [5760, 5770, "TRAINED_CATEGORY"], [5777, 5786, "TRAINED_CATEGORY"], [5790, 5796, "TRAINED_CATEGORY"], [5809, 5834, "TRAINED_CATEGORY"], [5840, 5845, "TRAINED_CATEGORY"], [5849, 5858, "TRAINED_CATEGORY"], [5874, 5891, "TRAINED_CATEGORY"], [5896, 5902, "TRAINED_CATEGORY"], [5922, 5944, "TRAINED_CATEGORY"], [5946, 5950, "TRAINED_CATEGORY"], [5961, 5970, "TRAINED_CATEGORY"], [5972, 5974, "TRAINED_CATEGORY"], [5984, 6007, "TRAINED_CATEGORY"], [6012, 6027, "TRAINED_CATEGORY"], [6035, 6039, "TRAINED_CATEGORY"], [6042, 6062, "TRAINED_CATEGORY"], [6066, 6076, "TRAINED_CATEGORY"], [6098, 6117, "TRAINED_CATEGORY"], [6119, 6124, "TRAINED_CATEGORY"], [6134, 6138, "TRAINED_CATEGORY"], [6148, 6157, "TRAINED_CATEGORY"], [6159, 6160, "TRAINED_CATEGORY"], [6170, 6190, "TRAINED_CATEGORY"], [6192, 6234, "TRAINED_CATEGORY"], [6237, 6262, "TRAINED_CATEGORY"], [6282, 6302, "TRAINED_CATEGORY"], [6304, 6308, "TRAINED_CATEGORY"], [6318, 6324, "TRAINED_CATEGORY"], [6337, 6357, "TRAINED_CATEGORY"], [6371, 6391, "TRAINED_CATEGORY"], [6395, 6405, "TRAINED_CATEGORY"], [6422, 6426, "TRAINED_CATEGORY"], [6437, 6442, "TRAINED_CATEGORY"], [6444, 6445, "TRAINED_CATEGORY"], [6455, 6469, "TRAINED_CATEGORY"], [6474, 6485, "TRAINED_CATEGORY"], [6489, 6503, "TRAINED_CATEGORY"], [6506, 6513, "TRAINED_CATEGORY"], [6525, 6534, "TRAINED_CATEGORY"], [6536, 6569, "TRAINED_CATEGORY"], [6571, 6575, "TRAINED_CATEGORY"], [6586, 6593, "TRAINED_CATEGORY"], [6595, 6597, "TRAINED_CATEGORY"], [6607, 6620, "TRAINED_CATEGORY"], [6629, 6642, "TRAINED_CATEGORY"], [6647, 6652, "TRAINED_CATEGORY"], [6682, 6689, "TRAINED_CATEGORY"], [6690, 6715, "TRAINED_CATEGORY"], [6733, 6763, "TRAINED_CATEGORY"], [6765, 6774, "TRAINED_CATEGORY"], [6776, 6781, "TRAINED_CATEGORY"], [6791, 6796, "TRAINED_CATEGORY"], [6800, 6821, "TRAINED_CATEGORY"], [6824, 6844, "TRAINED_CATEGORY"], [6863, 6874, "TRAINED_CATEGORY"], [6874, 6883, "TRAINED_CATEGORY"], [6885, 6891, "TRAINED_CATEGORY"], [6893, 6897, "TRAINED_CATEGORY"], [6899, 6904, "TRAINED_CATEGORY"], [6906, 6919, "TRAINED_CATEGORY"], [6921, 6924, "TRAINED_CATEGORY"], [6934, 6940, "TRAINED_CATEGORY"], [6944, 6954, "TRAINED_CATEGORY"], [6959, 6976, "TRAINED_CATEGORY"], [6980, 6990, "TRAINED_CATEGORY"], [6994, 7008, "TRAINED_CATEGORY"], [7012, 7019, "TRAINED_CATEGORY"], [7021, 7028, "TRAINED_CATEGORY"], [7030, 7040, "TRAINED_CATEGORY"], [7042, 7046, "TRAINED_CATEGORY"], [7058, 7067, "TRAINED_CATEGORY"], [7069, 7074, "TRAINED_CATEGORY"], [7083, 7098, "TRAINED_CATEGORY"], [7102, 7108, "TRAINED_CATEGORY"], [7110, 7117, "TRAINED_CATEGORY"], [7119, 7133, "TRAINED_CATEGORY"], [7137, 7150, "TRAINED_CATEGORY"], [7152, 7156, "TRAINED_CATEGORY"], [7176, 7180, "TRAINED_CATEGORY"], [7195, 7209, "TRAINED_CATEGORY"], [7213, 7224, "TRAINED_CATEGORY"], [7228, 7232, "TRAINED_CATEGORY"], [7238, 7245, "TRAINED_CATEGORY"], [7250, 7289, "TRAINED_CATEGORY"], [0, 20, "PERSON"], [22, 24, "CARDINAL"], [25, 33, "DATE"], [36, 53, "DATE"], [61, 65, "GPE"], [319, 323, "DATE"], [332, 341, "PERSON"], [349, 353, "ORDINAL"], [381, 397, "DATE"], [409, 420, "PERSON"], [422, 437, "PERSON"], [439, 454, "PERSON"], [456, 478, "PERSON"], [484, 503, "PERSON"], [510, 520, "ORG"], [536, 556, "PERSON"], [569, 576, "GPE"], [578, 586, "GPE"], [591, 598, "NORP"], [689, 707, "ORG"], [711, 715, "DATE"], [717, 726, "PERSON"], [782, 795, "PERSON"], [800, 804, "DATE"], [812, 821, "DATE"], [867, 894, "ORG"], [947, 972, "ORG"], [974, 977, "GPE"], [979, 983, "DATE"], [1007, 1032, "ORG"], [1088, 1092, "DATE"], [1109, 1118, "PERSON"], [1142, 1152, "PRODUCT"], [1156, 1188, "ORG"], [1192, 1203, "FAC"], [1254, 1263, "PERSON"], [1416, 1428, "PERSON"], [1474, 1483, "PERSON"], [1490, 1499, "PERSON"], [1879, 1883, "DATE"], [1959, 1972, "PERSON"], [1982, 2006, "ORG"], [2041, 2046, "ORDINAL"], [2060, 2064, "DATE"], [2066, 2075, "PERSON"], [2308, 2312, "ORG"], [2328, 2342, "ORG"], [2355, 2360, "CARDINAL"], [2389, 2398, "PERSON"], [2624, 2633, "PERSON"], [2635, 2639, "DATE"], [2644, 2647, "CARDINAL"], [3038, 3041, "CARDINAL"], [3174, 3183, "PERSON"], [3652, 3661, "PERSON"], [3843, 3848, "PERSON"], [3856, 3863, "PERSON"], [3865, 3869, "DATE"], [3881, 3890, "PERSON"], [3997, 4002, "PERSON"], [4040, 4049, "PERSON"], [4132, 4137, "PERSON"], [4369, 4373, "DATE"], [4552, 4558, "ORG"], [4573, 4582, "PERSON"], [4621, 4633, "ORG"], [4635, 4669, "ORG"], [4671, 4675, "DATE"], [4678, 4719, "ORG"], [4721, 4725, "DATE"], [4728, 4746, "PERSON"], [4748, 4770, "ORG"], [4772, 4776, "DATE"], [4779, 4788, "PERSON"], [4806, 4840, "ORG"], [4842, 4846, "DATE"], [4852, 4857, "ORDINAL"], [4871, 4904, "ORG"], [4906, 4910, "DATE"], [4936, 4962, "WORK_OF_ART"], [4966, 4972, "GPE"], [4975, 4984, "FAC"], [4992, 5021, "WORK_OF_ART"], [5070, 5086, "PERSON"], [5089, 5103, "PERSON"], [5105, 5114, "ORG"], [5116, 5120, "DATE"], [5121, 5136, "ORG"], [5141, 5161, "ORG"], [5174, 5190, "PERSON"], [5193, 5207, "PERSON"], [5209, 5218, "ORG"], [5220, 5224, "DATE"], [5225, 5244, "WORK_OF_ART"], [5278, 5316, "ORG"], [5318, 5325, "GPE"], [5335, 5344, "DATE"], [5352, 5374, "ORG"], [5376, 5378, "DATE"], [5392, 5411, "WORK_OF_ART"], [5413, 5420, "GPE"], [5422, 5424, "GPE"], [5426, 5428, "GPE"], [5430, 5457, "ORG"], [5458, 5462, "DATE"], [5491, 5527, "ORG"], [5561, 5568, "GPE"], [5571, 5598, "ORG"], [5638, 5647, "ORG"], [5649, 5662, "ORG"], [5664, 5668, "DATE"], [5687, 5702, "PERSON"], [5790, 5796, "PERSON"], [5840, 5845, "NORP"], [5849, 5858, "PERSON"], [5874, 5891, "PERSON"], [5896, 5902, "NORP"], [5905, 5908, "CARDINAL"], [5910, 5911, "CARDINAL"], [5914, 5920, "CARDINAL"], [5934, 5944, "PRODUCT"], [5946, 5950, "PRODUCT"], [5976, 5980, "DATE"], [6012, 6027, "PERSON"], [6029, 6033, "DATE"], [6042, 6076, "ORG"], [6078, 6081, "CARDINAL"], [6083, 6086, "CARDINAL"], [6089, 6096, "CARDINAL"], [6119, 6132, "PERSON"], [6134, 6146, "PRODUCT"], [6148, 6157, "PERSON"], [6170, 6190, "PERSON"], [6241, 6249, "NORP"], [6250, 6262, "NORP"], [6264, 6266, "CARDINAL"], [6268, 6270, "CARDINAL"], [6273, 6280, "CARDINAL"], [6304, 6316, "PRODUCT"], [6337, 6357, "PERSON"], [6371, 6405, "ORG"], [6407, 6409, "CARDINAL"], [6411, 6412, "CARDINAL"], [6415, 6420, "CARDINAL"], [6422, 6435, "PRODUCT"], [6455, 6469, "PERSON"], [6515, 6518, "CARDINAL"], [6520, 6524, "DATE"], [6571, 6575, "PRODUCT"], [6576, 6584, "DATE"], [6586, 6593, "PERSON"], [6595, 6597, "NORP"], [6599, 6603, "DATE"], [6633, 6642, "PERSON"], [6682, 6715, "ORG"], [6717, 6718, "CARDINAL"], [6720, 6721, "CARDINAL"], [6724, 6731, "CARDINAL"], [6776, 6781, "PERSON"], [6783, 6787, "DATE"], [6824, 6844, "ORG"], [6846, 6848, "CARDINAL"], [6850, 6851, "CARDINAL"], [6854, 6861, "CARDINAL"], [6885, 6891, "PERSON"], [6893, 6897, "PERSON"], [6899, 6904, "PERSON"], [6906, 6919, "PERSON"], [6921, 6924, "DATE"], [6927, 6931, "DATE"], [6959, 6968, "ORG"], [6994, 7019, "ORG"], [7021, 7028, "GPE"], [7047, 7056, "DATE"], [7058, 7067, "PERSON"], [7076, 7080, "DATE"], [7083, 7108, "WORK_OF_ART"], [7110, 7117, "GPE"], [7119, 7150, "ORG"], [7157, 7160, "CARDINAL"], [7195, 7203, "ORG"], [7213, 7237, "WORK_OF_ART"]]}], ["The law of comparative judgment was conceived by L. L. Thurstone. In modern-day terminology, it is more aptly described as a model that is used to obtain measurements from any process of pairwise comparison. Examples of such processes are the comparison of perceived intensity of physical stimuli, such as the weights of objects, and comparisons of the extremity of an attitude expressed within statements, such as statements about capital punishment. The measurements represent how we perceive objects, rather than being measurements of actual physical properties. This kind of measurement is the focus of psychometrics and psychophysics.\nIn somewhat more technical terms, the law of comparative judgment is a mathematical representation of a discriminal process, which is any process in which a comparison is made between pairs of a collection of entities with respect to magnitudes of an attribute, trait, attitude, and so on. The theoretical basis for the model is closely related to item response theory and the theory underlying the Rasch model, which are used in psychology and education to analyse data from questionnaires and tests.\n\n\n== Background ==\nThurstone published a paper on the law of comparative judgment in 1927. In this paper he introduced the underlying concept of a psychological continuum for a particular 'project in measurement' involving the comparison between a series of stimuli, such as weights and handwriting specimens, in pairs. He soon extended the domain of application of the law of comparative judgment to things that have no obvious physical counterpart, such as attitudes and values (Thurstone, 1929). For example, in one experiment, people compared statements about capital punishment to judge which of each pair expressed a stronger positive (or negative) attitude.\nThe essential idea behind Thurstone's process and model is that it can be used to scale a collection of stimuli based on simple comparisons between stimuli two at a time: that is, based on a series of pairwise comparisons. For example, suppose that someone wishes to measure the perceived weights of a series of five objects of varying masses. By having people compare the weights of the objects in pairs, data can be obtained and the law of comparative judgment applied to estimate scale values of the perceived weights. This is the perceptual counterpart to the physical weight of the objects. That is, the scale represents how heavy people perceive the objects to be based on the comparisons.\nAlthough Thurstone referred to it as a law, as stated above, in terms of modern psychometric theory the 'law' of comparative judgment is more aptly described as a measurement model.  It represents a general theoretical model which, applied in a particular empirical context, constitutes a scientific hypothesis regarding the outcomes of comparisons between some collection of objects. If data agree with the model, it is possible to produce a scale from the data.\n\n\n=== Relationships to pre-existing psychophysical theory ===\nThurstone showed that in terms of his conceptual framework, Weber's law and the so-called Weber-Fechner law, which are sometimes (and misleadingly) regarded as one and the same, are independent, in the sense that one may be applicable but not the other to a given collection of experimental data.  In particular, Thurstone showed that if Fechner's law applies and the discriminal dispersions associated with stimuli are constant (as in Case 5 of the LCJ outlined below), then Weber's law will also be verified. He considered that the Weber-Fechner law and the LCJ both involve a linear measurement on a psychological continuum whereas Weber's law does not.\nWeber's law essentially states that how much people perceive physical stimulus intensity to change depends on that intensity. For example, if someone compares a light object of 1 kg with one slightly heavier, one notices a relatively small difference, perhaps when the second object is 1.2 kg. On the other hand, if someone compares a heavy object of 30 kg with a second, the second must be quite a bit larger for a person to notice the difference, perhaps when the second object is 36 kg. People tend to perceive differences that are proportional to the size rather than noticing a specific difference irrespective of the size. The same applies to brightness, pressure, warmth, loudness, and so on.\nThurstone stated Weber's law as follows: \"The stimulus increase which is correctly discriminated in any specified proportion of attempts (except 0 and 100 per cent) is a constant fraction of the stimulus magnitude\" (Thurstone, 1959, p. 61). He considered that Weber's law said nothing directly about sensation intensities at all. In terms of Thurstone's conceptual framework, the association posited between perceived stimulus intensity and the physical magnitude of the stimulus in the Weber-Fechner law will only hold when Weber's law holds and the just noticeable difference (JND) is treated as a unit of measurement.  Importantly, this is not simply given a priori (Michell, 1997, p. 355), as is implied by purely mathematical derivations of the one law from the other. It is, rather, an empirical question whether measurements have been obtained; one which requires justification through the process of stating and testing a well-defined hypothesis in order to ascertain whether specific theoretical criteria for measurement have been satisfied. Some of the relevant criteria were articulated by Thurstone, in a preliminary fashion, including what he termed the additivity criterion. Accordingly, from the point of view of Thurstone's approach, treating the JND as a unit is justifiable provided only that the discriminal dispersions are uniform for all stimuli considered in a given experimental context. Similar issues are associated with Stevens' power law.\nIn addition, Thurstone employed the approach to clarify other similarities and differences between Weber's law, the Weber-Fechner law, and the LCJ.  An important clarification is that the LCJ does not necessarily involve a physical stimulus, whereas the other 'laws' do.  Another key difference is that Weber's law and the LCJ involve proportions of comparisons in which one stimulus is judged greater than another whereas the so-called Weber-Fechner law does not.\n\n\n== The general form ==\nThe most general form of the LCJ is\n\n  \n    \n      \n        \n          S\n          \n            i\n          \n        \n        \u2212\n        \n          S\n          \n            j\n          \n        \n        =\n        \n          x\n          \n            i\n            j\n          \n        \n        \n          \n            \n              \u03c3\n              \n                i\n              \n              \n                2\n              \n            \n            +\n            \n              \u03c3\n              \n                j\n              \n              \n                2\n              \n            \n            \u2212\n            2\n            \n              r\n              \n                i\n                j\n              \n            \n            \n              \u03c3\n              \n                i\n              \n            \n            \n              \u03c3\n              \n                j\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle S_{i}-S_{j}=x_{ij}{\\sqrt {\\sigma _{i}^{2}+\\sigma _{j}^{2}-2r_{ij}\\sigma _{i}\\sigma _{j}}},}\n  in which:\n\n  \n    \n      \n        \n          S\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle S_{i}}\n   is the psychological scale value of stimuli i\n\n  \n    \n      \n        \n          x\n          \n            i\n            j\n          \n        \n      \n    \n    {\\displaystyle x_{ij}}\n   is the sigma corresponding with the proportion of occasions on which the magnitude of stimulus i is judged to exceed the magnitude of stimulus j\n\n  \n    \n      \n        \n          \u03c3\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle \\sigma _{i}}\n   is the discriminal dispersion of a stimulus \n  \n    \n      \n        \n          R\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle R_{i}}\n  \n\n  \n    \n      \n        \n          r\n          \n            i\n            j\n          \n        \n      \n    \n    {\\displaystyle r_{ij}}\n   is the correlation between the discriminal deviations of stimuli i and jThe discriminal dispersion of a stimulus i is the dispersion of fluctuations of the discriminal process for a uniform repeated stimulus, denoted \n  \n    \n      \n        \n          R\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle R_{i}}\n  , where \n  \n    \n      \n        \n          S\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle S_{i}}\n   represents the mode of such values.  Thurstone (1959, p. 20) used the term discriminal process to refer to the \"psychological values of psychophysics\"; that is, the values on a psychological continuum associated with a given stimulus.\n\n\n== Case 5 ==\nThurstone specified five particular cases of the 'law', or measurement model.  An important case of the model is Case 5, in which the discriminal dispersions are specified to be uniform and uncorrelated.  This form of the model can be represented as follows:\n\n  \n    \n      \n        \n          x\n          \n            i\n            j\n          \n        \n        =\n        \n          \n            \n              \n                S\n                \n                  i\n                \n              \n              \u2212\n              \n                S\n                \n                  j\n                \n              \n            \n            \u03c3\n          \n        \n        \n      \n    \n    {\\displaystyle x_{ij}={\\frac {S_{i}-S_{j}}{\\sigma }}\\,}\n  where\n\n  \n    \n      \n        \n          \u03c3\n        \n        =\n        \n          \n            \n              \u03c3\n              \n                i\n              \n              \n                2\n              \n            \n            +\n            \n              \u03c3\n              \n                j\n              \n              \n                2\n              \n            \n          \n        \n        .\n        \n      \n    \n    {\\displaystyle {\\sigma }={\\sqrt {\\sigma _{i}^{2}+\\sigma _{j}^{2}}}.\\,}\n  In this case of the model, the difference \n  \n    \n      \n        \n          \n            S\n            \n              i\n            \n          \n          \u2212\n          \n            S\n            \n              j\n            \n          \n        \n      \n    \n    {\\displaystyle {S_{i}-S_{j}}}\n   can be inferred directly from the proportion of instances in which j is judged greater than i if it is hypothesised that \n  \n    \n      \n        \n          x\n          \n            i\n            j\n          \n        \n      \n    \n    {\\displaystyle x_{ij}}\n   is distributed according to some density function, such as the normal distribution or logistic function.  In order to do so, it is necessary to let \n  \n    \n      \n        \u03c3\n        =\n        1\n      \n    \n    {\\displaystyle \\sigma =1}\n  , which is in effect an arbitrary choice of the unit of measurement.  Letting \n  \n    \n      \n        \n          P\n          \n            i\n            j\n          \n        \n      \n    \n    {\\displaystyle P_{ij}}\n   be the proportion of occasions on which i is judged greater than j, if, for example, \n  \n    \n      \n        \n          P\n          \n            i\n            j\n          \n        \n        =\n        0.84\n      \n    \n    {\\displaystyle P_{ij}=0.84}\n   and it is hypothesised that \n  \n    \n      \n        \n          x\n          \n            i\n            j\n          \n        \n      \n    \n    {\\displaystyle x_{ij}}\n   is normally distributed, then it would be inferred that \n  \n    \n      \n        \n          S\n          \n            i\n          \n        \n        \u2212\n        \n          S\n          \n            j\n          \n        \n        \u2245\n        1\n      \n    \n    {\\displaystyle S_{i}-S_{j}\\cong 1}\n  .\nWhen a simple logistic function is employed instead of the normal density function, then the model has the structure of the Bradley-Terry-Luce model (BTL model) (Bradley & Terry, 1952; Luce, 1959). In turn, the Rasch model for dichotomous data (Rasch, 1960/1980) is identical to the BTL model after the person parameter of the Rasch model has been eliminated, as is achieved through statistical conditioning during the process of Conditional Maximum Likelihood estimation. With this in mind, the specification of uniform discriminal dispersions is equivalent to the requirement of parallel Item Characteristic Curves (ICCs) in the Rasch model. Accordingly, as shown by Andrich (1978), the Rasch model should, in principle, yield essentially the same results as those obtained from a Thurstone scale. Like the Rasch model, when applied in a given empirical context, Case 5 of the LCJ constitutes a mathematized hypothesis which embodies theoretical criteria for measurement.\n\n\n== Applications ==\nOne important application involving the law of comparative judgment is the widely used Analytic Hierarchy Process, a structured technique for helping people deal with complex decisions. It uses pairwise comparisons of tangible and intangible factors to construct ratio scales that are useful in making important decisions.\n\n\n== References ==\n\nAndrich, D. (1978b).  Relationships between the Thurstone and Rasch approaches to item scaling.  Applied Psychological Measurement, 2, 449-460.\nBradley, R.A. and Terry, M.E. (1952). Rank analysis of incomplete block designs, I. the method of paired comparisons. Biometrika, 39, 324-345.\nKrus, D.J., & Kennedy, P.H. (1977) Normal scaling of dominance matrices: The domain-referenced model. Educational and Psychological Measurement, 37, 189-193 (Request reprint).\nLuce, R.D. (1959). Individual Choice Behaviours: A Theoretical Analysis. New York: J. Wiley.\nMichell, J. (1997). Quantitative science and the definition of measurement in psychology. British Journal of Psychology, 88, 355-383.\nRasch, G. (1960/1980). Probabilistic models for some intelligence and attainment tests. (Copenhagen, Danish Institute for Educational Research), expanded edition (1980) with foreword and afterword by B.D. Wright.  Chicago: The University of Chicago Press.\nThurstone, L.L. (1927).  A law of comparative judgement. Psychological Review, 34, 273-286.\nThurstone, L.L. (1929).  The Measurement of Psychological Value.  In T.V. Smith and W.K. Wright (Eds.), Essays in Philosophy by Seventeen Doctors of Philosophy of the \tUniversity of Chicago.  Chicago: Open Court.\nThurstone, L.L. (1959).  The Measurement of Values.  Chicago: The University of Chicago Press.\n\n\n== External links ==\n\"The Measurement of Psychological Value\"\nHow to Analyze Paired Comparisons (tutorial on using Thurstone's Law of Comparative Judgement)\nL.L. Thurstone psychometric laboratory", {"entities": [[0, 7, "TRAINED_CATEGORY"], [11, 31, "TRAINED_CATEGORY"], [49, 64, "TRAINED_CATEGORY"], [69, 91, "TRAINED_CATEGORY"], [93, 95, "TRAINED_CATEGORY"], [123, 130, "TRAINED_CATEGORY"], [154, 166, "TRAINED_CATEGORY"], [172, 183, "TRAINED_CATEGORY"], [187, 206, "TRAINED_CATEGORY"], [208, 216, "TRAINED_CATEGORY"], [220, 234, "TRAINED_CATEGORY"], [239, 253, "TRAINED_CATEGORY"], [257, 276, "TRAINED_CATEGORY"], [280, 296, "TRAINED_CATEGORY"], [306, 317, "TRAINED_CATEGORY"], [321, 328, "TRAINED_CATEGORY"], [334, 345, "TRAINED_CATEGORY"], [349, 362, "TRAINED_CATEGORY"], [366, 377, "TRAINED_CATEGORY"], [395, 405, "TRAINED_CATEGORY"], [415, 425, "TRAINED_CATEGORY"], [432, 450, "TRAINED_CATEGORY"], [452, 468, "TRAINED_CATEGORY"], [483, 485, "TRAINED_CATEGORY"], [495, 502, "TRAINED_CATEGORY"], [522, 534, "TRAINED_CATEGORY"], [538, 564, "TRAINED_CATEGORY"], [566, 575, "TRAINED_CATEGORY"], [579, 590, "TRAINED_CATEGORY"], [594, 603, "TRAINED_CATEGORY"], [607, 620, "TRAINED_CATEGORY"], [625, 638, "TRAINED_CATEGORY"], [643, 672, "TRAINED_CATEGORY"], [674, 681, "TRAINED_CATEGORY"], [685, 705, "TRAINED_CATEGORY"], [709, 738, "TRAINED_CATEGORY"], [742, 763, "TRAINED_CATEGORY"], [774, 785, "TRAINED_CATEGORY"], [795, 807, "TRAINED_CATEGORY"], [824, 829, "TRAINED_CATEGORY"], [833, 845, "TRAINED_CATEGORY"], [849, 857, "TRAINED_CATEGORY"], [863, 870, "TRAINED_CATEGORY"], [874, 884, "TRAINED_CATEGORY"], [888, 900, "TRAINED_CATEGORY"], [902, 907, "TRAINED_CATEGORY"], [909, 917, "TRAINED_CATEGORY"], [930, 951, "TRAINED_CATEGORY"], [956, 965, "TRAINED_CATEGORY"], [988, 1008, "TRAINED_CATEGORY"], [1013, 1023, "TRAINED_CATEGORY"], [1035, 1050, "TRAINED_CATEGORY"], [1070, 1080, "TRAINED_CATEGORY"], [1085, 1094, "TRAINED_CATEGORY"], [1106, 1110, "TRAINED_CATEGORY"], [1116, 1130, "TRAINED_CATEGORY"], [1135, 1140, "TRAINED_CATEGORY"], [1147, 1157, "TRAINED_CATEGORY"], [1161, 1170, "TRAINED_CATEGORY"], [1181, 1188, "TRAINED_CATEGORY"], [1192, 1199, "TRAINED_CATEGORY"], [1203, 1223, "TRAINED_CATEGORY"], [1236, 1246, "TRAINED_CATEGORY"], [1247, 1249, "TRAINED_CATEGORY"], [1261, 1283, "TRAINED_CATEGORY"], [1287, 1312, "TRAINED_CATEGORY"], [1317, 1338, "TRAINED_CATEGORY"], [1342, 1353, "TRAINED_CATEGORY"], [1365, 1379, "TRAINED_CATEGORY"], [1388, 1396, "TRAINED_CATEGORY"], [1400, 1407, "TRAINED_CATEGORY"], [1417, 1424, "TRAINED_CATEGORY"], [1429, 1440, "TRAINED_CATEGORY"], [1441, 1450, "TRAINED_CATEGORY"], [1455, 1460, "TRAINED_CATEGORY"], [1462, 1464, "TRAINED_CATEGORY"], [1479, 1489, "TRAINED_CATEGORY"], [1493, 1504, "TRAINED_CATEGORY"], [1508, 1515, "TRAINED_CATEGORY"], [1519, 1539, "TRAINED_CATEGORY"], [1543, 1549, "TRAINED_CATEGORY"], [1560, 1591, "TRAINED_CATEGORY"], [1601, 1610, "TRAINED_CATEGORY"], [1615, 1621, "TRAINED_CATEGORY"], [1623, 1632, "TRAINED_CATEGORY"], [1645, 1652, "TRAINED_CATEGORY"], [1657, 1671, "TRAINED_CATEGORY"], [1673, 1679, "TRAINED_CATEGORY"], [1689, 1699, "TRAINED_CATEGORY"], [1706, 1724, "TRAINED_CATEGORY"], [1743, 1752, "TRAINED_CATEGORY"], [1763, 1805, "TRAINED_CATEGORY"], [1807, 1825, "TRAINED_CATEGORY"], [1833, 1852, "TRAINED_CATEGORY"], [1857, 1862, "TRAINED_CATEGORY"], [1871, 1873, "TRAINED_CATEGORY"], [1895, 1907, "TRAINED_CATEGORY"], [1911, 1918, "TRAINED_CATEGORY"], [1928, 1946, "TRAINED_CATEGORY"], [1955, 1962, "TRAINED_CATEGORY"], [1970, 1976, "TRAINED_CATEGORY"], [1996, 2004, "TRAINED_CATEGORY"], [2008, 2028, "TRAINED_CATEGORY"], [2034, 2041, "TRAINED_CATEGORY"], [2056, 2063, "TRAINED_CATEGORY"], [2082, 2103, "TRAINED_CATEGORY"], [2107, 2115, "TRAINED_CATEGORY"], [2119, 2131, "TRAINED_CATEGORY"], [2135, 2149, "TRAINED_CATEGORY"], [2161, 2167, "TRAINED_CATEGORY"], [2176, 2187, "TRAINED_CATEGORY"], [2191, 2202, "TRAINED_CATEGORY"], [2206, 2211, "TRAINED_CATEGORY"], [2213, 2217, "TRAINED_CATEGORY"], [2238, 2245, "TRAINED_CATEGORY"], [2249, 2269, "TRAINED_CATEGORY"], [2290, 2302, "TRAINED_CATEGORY"], [2306, 2327, "TRAINED_CATEGORY"], [2337, 2363, "TRAINED_CATEGORY"], [2367, 2386, "TRAINED_CATEGORY"], [2390, 2401, "TRAINED_CATEGORY"], [2412, 2421, "TRAINED_CATEGORY"], [2433, 2449, "TRAINED_CATEGORY"], [2459, 2470, "TRAINED_CATEGORY"], [2486, 2501, "TRAINED_CATEGORY"], [2512, 2521, "TRAINED_CATEGORY"], [2534, 2536, "TRAINED_CATEGORY"], [2540, 2545, "TRAINED_CATEGORY"], [2567, 2572, "TRAINED_CATEGORY"], [2576, 2602, "TRAINED_CATEGORY"], [2603, 2611, "TRAINED_CATEGORY"], [2616, 2636, "TRAINED_CATEGORY"], [2664, 2683, "TRAINED_CATEGORY"], [2686, 2688, "TRAINED_CATEGORY"], [2700, 2727, "TRAINED_CATEGORY"], [2746, 2776, "TRAINED_CATEGORY"], [2790, 2813, "TRAINED_CATEGORY"], [2824, 2836, "TRAINED_CATEGORY"], [2840, 2851, "TRAINED_CATEGORY"], [2860, 2875, "TRAINED_CATEGORY"], [2879, 2886, "TRAINED_CATEGORY"], [2891, 2895, "TRAINED_CATEGORY"], [2907, 2916, "TRAINED_CATEGORY"], [2918, 2920, "TRAINED_CATEGORY"], [2944, 2951, "TRAINED_CATEGORY"], [2957, 2965, "TRAINED_CATEGORY"], [2973, 2986, "TRAINED_CATEGORY"], [2990, 3024, "TRAINED_CATEGORY"], [3029, 3038, "TRAINED_CATEGORY"], [3054, 3059, "TRAINED_CATEGORY"], [3063, 3087, "TRAINED_CATEGORY"], [3089, 3100, "TRAINED_CATEGORY"], [3105, 3136, "TRAINED_CATEGORY"], [3227, 3236, "TRAINED_CATEGORY"], [3242, 3245, "TRAINED_CATEGORY"], [3285, 3303, "TRAINED_CATEGORY"], [3307, 3324, "TRAINED_CATEGORY"], [3342, 3351, "TRAINED_CATEGORY"], [3367, 3380, "TRAINED_CATEGORY"], [3393, 3420, "TRAINED_CATEGORY"], [3437, 3444, "TRAINED_CATEGORY"], [3465, 3469, "TRAINED_CATEGORY"], [3475, 3482, "TRAINED_CATEGORY"], [3505, 3516, "TRAINED_CATEGORY"], [3540, 3542, "TRAINED_CATEGORY"], [3559, 3580, "TRAINED_CATEGORY"], [3585, 3592, "TRAINED_CATEGORY"], [3606, 3626, "TRAINED_CATEGORY"], [3630, 3655, "TRAINED_CATEGORY"], [3664, 3675, "TRAINED_CATEGORY"], [3686, 3697, "TRAINED_CATEGORY"], [3722, 3737, "TRAINED_CATEGORY"], [3747, 3774, "TRAINED_CATEGORY"], [3796, 3810, "TRAINED_CATEGORY"], [3816, 3823, "TRAINED_CATEGORY"], [3828, 3835, "TRAINED_CATEGORY"], [3845, 3859, "TRAINED_CATEGORY"], [3863, 3867, "TRAINED_CATEGORY"], [3907, 3936, "TRAINED_CATEGORY"], [3951, 3968, "TRAINED_CATEGORY"], [3972, 3978, "TRAINED_CATEGORY"], [3983, 3997, "TRAINED_CATEGORY"], [4002, 4009, "TRAINED_CATEGORY"], [4019, 4033, "TRAINED_CATEGORY"], [4037, 4042, "TRAINED_CATEGORY"], [4100, 4108, "TRAINED_CATEGORY"], [4119, 4133, "TRAINED_CATEGORY"], [4148, 4165, "TRAINED_CATEGORY"], [4169, 4174, "TRAINED_CATEGORY"], [4176, 4182, "TRAINED_CATEGORY"], [4200, 4211, "TRAINED_CATEGORY"], [4237, 4245, "TRAINED_CATEGORY"], [4267, 4288, "TRAINED_CATEGORY"], [4305, 4313, "TRAINED_CATEGORY"], [4335, 4345, "TRAINED_CATEGORY"], [4347, 4355, "TRAINED_CATEGORY"], [4357, 4363, "TRAINED_CATEGORY"], [4365, 4373, "TRAINED_CATEGORY"], [4386, 4395, "TRAINED_CATEGORY"], [4403, 4414, "TRAINED_CATEGORY"], [4428, 4449, "TRAINED_CATEGORY"], [4486, 4510, "TRAINED_CATEGORY"], [4514, 4522, "TRAINED_CATEGORY"], [4545, 4549, "TRAINED_CATEGORY"], [4554, 4573, "TRAINED_CATEGORY"], [4577, 4599, "TRAINED_CATEGORY"], [4602, 4611, "TRAINED_CATEGORY"], [4627, 4629, "TRAINED_CATEGORY"], [4646, 4657, "TRAINED_CATEGORY"], [4663, 4670, "TRAINED_CATEGORY"], [4686, 4707, "TRAINED_CATEGORY"], [4719, 4724, "TRAINED_CATEGORY"], [4728, 4760, "TRAINED_CATEGORY"], [4762, 4777, "TRAINED_CATEGORY"], [4794, 4822, "TRAINED_CATEGORY"], [4827, 4849, "TRAINED_CATEGORY"], [4853, 4865, "TRAINED_CATEGORY"], [4869, 4890, "TRAINED_CATEGORY"], [4911, 4922, "TRAINED_CATEGORY"], [4965, 4968, "TRAINED_CATEGORY"], [4984, 4990, "TRAINED_CATEGORY"], [4994, 5005, "TRAINED_CATEGORY"], [5056, 5063, "TRAINED_CATEGORY"], [5071, 5073, "TRAINED_CATEGORY"], [5097, 5128, "TRAINED_CATEGORY"], [5132, 5143, "TRAINED_CATEGORY"], [5160, 5162, "TRAINED_CATEGORY"], [5175, 5196, "TRAINED_CATEGORY"], [5205, 5217, "TRAINED_CATEGORY"], [5257, 5270, "TRAINED_CATEGORY"], [5279, 5290, "TRAINED_CATEGORY"], [5314, 5339, "TRAINED_CATEGORY"], [5343, 5348, "TRAINED_CATEGORY"], [5370, 5399, "TRAINED_CATEGORY"], [5404, 5415, "TRAINED_CATEGORY"], [5445, 5466, "TRAINED_CATEGORY"], [5487, 5496, "TRAINED_CATEGORY"], [5501, 5522, "TRAINED_CATEGORY"], [5534, 5538, "TRAINED_CATEGORY"], [5539, 5541, "TRAINED_CATEGORY"], [5593, 5602, "TRAINED_CATEGORY"], [5606, 5610, "TRAINED_CATEGORY"], [5614, 5634, "TRAINED_CATEGORY"], [5645, 5652, "TRAINED_CATEGORY"], [5656, 5662, "TRAINED_CATEGORY"], [5697, 5724, "TRAINED_CATEGORY"], [5741, 5752, "TRAINED_CATEGORY"], [5767, 5795, "TRAINED_CATEGORY"], [5797, 5811, "TRAINED_CATEGORY"], [5832, 5850, "TRAINED_CATEGORY"], [5855, 5863, "TRAINED_CATEGORY"], [5865, 5874, "TRAINED_CATEGORY"], [5884, 5896, "TRAINED_CATEGORY"], [5908, 5926, "TRAINED_CATEGORY"], [5931, 5942, "TRAINED_CATEGORY"], [5951, 5962, "TRAINED_CATEGORY"], [5964, 5985, "TRAINED_CATEGORY"], [5991, 5998, "TRAINED_CATEGORY"], [6001, 6027, "TRAINED_CATEGORY"], [6036, 6043, "TRAINED_CATEGORY"], [6073, 6092, "TRAINED_CATEGORY"], [6112, 6117, "TRAINED_CATEGORY"], [6124, 6146, "TRAINED_CATEGORY"], [6155, 6166, "TRAINED_CATEGORY"], [6171, 6178, "TRAINED_CATEGORY"], [6187, 6198, "TRAINED_CATEGORY"], [6202, 6213, "TRAINED_CATEGORY"], [6223, 6235, "TRAINED_CATEGORY"], [6275, 6306, "TRAINED_CATEGORY"], [6322, 6338, "TRAINED_CATEGORY"], [6342, 6363, "TRAINED_CATEGORY"], [6367, 6374, "TRAINED_CATEGORY"], [6413, 6414, "TRAINED_CATEGORY"], [6438, 6439, "TRAINED_CATEGORY"], [6468, 6469, "TRAINED_CATEGORY"], [6489, 6490, "TRAINED_CATEGORY"], [6514, 6515, "TRAINED_CATEGORY"], [6590, 6591, "TRAINED_CATEGORY"], [6604, 6605, "TRAINED_CATEGORY"], [6673, 6674, "TRAINED_CATEGORY"], [6706, 6707, "TRAINED_CATEGORY"], [6825, 6826, "TRAINED_CATEGORY"], [6858, 6859, "TRAINED_CATEGORY"], [6906, 6907, "TRAINED_CATEGORY"], [6948, 6949, "TRAINED_CATEGORY"], [6962, 6992, "TRAINED_CATEGORY"], [7024, 7025, "TRAINED_CATEGORY"], [7042, 7043, "TRAINED_CATEGORY"], [7099, 7100, "TRAINED_CATEGORY"], [7132, 7133, "TRAINED_CATEGORY"], [7189, 7190, "TRAINED_CATEGORY"], [7222, 7223, "TRAINED_CATEGORY"], [7299, 7337, "TRAINED_CATEGORY"], [7339, 7347, "TRAINED_CATEGORY"], [7347, 7363, "TRAINED_CATEGORY"], [7364, 7386, "TRAINED_CATEGORY"], [7386, 7399, "TRAINED_CATEGORY"], [7452, 7453, "TRAINED_CATEGORY"], [7477, 7478, "TRAINED_CATEGORY"], [7515, 7534, "TRAINED_CATEGORY"], [7543, 7572, "TRAINED_CATEGORY"], [7576, 7583, "TRAINED_CATEGORY"], [7584, 7585, "TRAINED_CATEGORY"], [7646, 7647, "TRAINED_CATEGORY"], [7660, 7661, "TRAINED_CATEGORY"], [7713, 7718, "TRAINED_CATEGORY"], [7756, 7770, "TRAINED_CATEGORY"], [7774, 7783, "TRAINED_CATEGORY"], [7793, 7806, "TRAINED_CATEGORY"], [7810, 7818, "TRAINED_CATEGORY"], [7819, 7820, "TRAINED_CATEGORY"], [7841, 7854, "TRAINED_CATEGORY"], [7858, 7866, "TRAINED_CATEGORY"], [7904, 7905, "TRAINED_CATEGORY"], [7929, 7930, "TRAINED_CATEGORY"], [7991, 7992, "TRAINED_CATEGORY"], [8001, 8027, "TRAINED_CATEGORY"], [8031, 8041, "TRAINED_CATEGORY"], [8077, 8078, "TRAINED_CATEGORY"], [8102, 8103, "TRAINED_CATEGORY"], [8141, 8159, "TRAINED_CATEGORY"], [8225, 8226, "TRAINED_CATEGORY"], [8239, 8240, "TRAINED_CATEGORY"], [8292, 8297, "TRAINED_CATEGORY"], [8306, 8321, "TRAINED_CATEGORY"], [8330, 8356, "TRAINED_CATEGORY"], [8360, 8367, "TRAINED_CATEGORY"], [8368, 8369, "TRAINED_CATEGORY"], [8374, 8401, "TRAINED_CATEGORY"], [8405, 8415, "TRAINED_CATEGORY"], [8416, 8417, "TRAINED_CATEGORY"], [8421, 8435, "TRAINED_CATEGORY"], [8439, 8451, "TRAINED_CATEGORY"], [8455, 8478, "TRAINED_CATEGORY"], [8483, 8510, "TRAINED_CATEGORY"], [8555, 8556, "TRAINED_CATEGORY"], [8580, 8581, "TRAINED_CATEGORY"], [8619, 8637, "TRAINED_CATEGORY"], [8685, 8686, "TRAINED_CATEGORY"], [8710, 8711, "TRAINED_CATEGORY"], [8748, 8767, "TRAINED_CATEGORY"], [8784, 8792, "TRAINED_CATEGORY"], [8796, 8807, "TRAINED_CATEGORY"], [8810, 8819, "TRAINED_CATEGORY"], [8839, 8867, "TRAINED_CATEGORY"], [8880, 8905, "TRAINED_CATEGORY"], [8909, 8922, "TRAINED_CATEGORY"], [8948, 8973, "TRAINED_CATEGORY"], [8990, 9006, "TRAINED_CATEGORY"], [9013, 9017, "TRAINED_CATEGORY"], [9023, 9032, "TRAINED_CATEGORY"], [9043, 9064, "TRAINED_CATEGORY"], [9068, 9076, "TRAINED_CATEGORY"], [9082, 9099, "TRAINED_CATEGORY"], [9102, 9119, "TRAINED_CATEGORY"], [9123, 9132, "TRAINED_CATEGORY"], [9136, 9140, "TRAINED_CATEGORY"], [9153, 9180, "TRAINED_CATEGORY"], [9228, 9237, "TRAINED_CATEGORY"], [9241, 9250, "TRAINED_CATEGORY"], [9342, 9343, "TRAINED_CATEGORY"], [9356, 9357, "TRAINED_CATEGORY"], [9452, 9453, "TRAINED_CATEGORY"], [9489, 9490, "TRAINED_CATEGORY"], [9537, 9538, "TRAINED_CATEGORY"], [9570, 9571, "TRAINED_CATEGORY"], [9666, 9667, "TRAINED_CATEGORY"], [9880, 9881, "TRAINED_CATEGORY"], [9913, 9914, "TRAINED_CATEGORY"], [10032, 10033, "TRAINED_CATEGORY"], [10065, 10066, "TRAINED_CATEGORY"], [10274, 10283, "TRAINED_CATEGORY"], [10287, 10296, "TRAINED_CATEGORY"], [10361, 10362, "TRAINED_CATEGORY"], [10390, 10391, "TRAINED_CATEGORY"], [10426, 10427, "TRAINED_CATEGORY"], [10451, 10481, "TRAINED_CATEGORY"], [10546, 10557, "TRAINED_CATEGORY"], [10594, 10608, "TRAINED_CATEGORY"], [10612, 10621, "TRAINED_CATEGORY"], [10631, 10632, "TRAINED_CATEGORY"], [10656, 10657, "TRAINED_CATEGORY"], [10661, 10663, "TRAINED_CATEGORY"], [10745, 10746, "TRAINED_CATEGORY"], [10759, 10760, "TRAINED_CATEGORY"], [10851, 10872, "TRAINED_CATEGORY"], [10882, 10905, "TRAINED_CATEGORY"], [10909, 10926, "TRAINED_CATEGORY"], [10932, 10937, "TRAINED_CATEGORY"], [10948, 10950, "TRAINED_CATEGORY"], [11075, 11081, "TRAINED_CATEGORY"], [11082, 11101, "TRAINED_CATEGORY"], [11105, 11113, "TRAINED_CATEGORY"], [11117, 11128, "TRAINED_CATEGORY"], [11174, 11175, "TRAINED_CATEGORY"], [11199, 11200, "TRAINED_CATEGORY"], [11213, 11214, "TRAINED_CATEGORY"], [11266, 11271, "TRAINED_CATEGORY"], [11280, 11294, "TRAINED_CATEGORY"], [11298, 11307, "TRAINED_CATEGORY"], [11317, 11318, "TRAINED_CATEGORY"], [11342, 11343, "TRAINED_CATEGORY"], [11353, 11360, "TRAINED_CATEGORY"], [11422, 11423, "TRAINED_CATEGORY"], [11436, 11437, "TRAINED_CATEGORY"], [11532, 11534, "TRAINED_CATEGORY"], [11616, 11617, "TRAINED_CATEGORY"], [11630, 11631, "TRAINED_CATEGORY"], [11724, 11726, "TRAINED_CATEGORY"], [11810, 11811, "TRAINED_CATEGORY"], [11840, 11841, "TRAINED_CATEGORY"], [11861, 11862, "TRAINED_CATEGORY"], [11886, 11887, "TRAINED_CATEGORY"], [11916, 11917, "TRAINED_CATEGORY"], [11945, 11975, "TRAINED_CATEGORY"], [11988, 12014, "TRAINED_CATEGORY"], [12038, 12065, "TRAINED_CATEGORY"], [12072, 12081, "TRAINED_CATEGORY"], [12086, 12099, "TRAINED_CATEGORY"], [12103, 12131, "TRAINED_CATEGORY"], [12133, 12142, "TRAINED_CATEGORY"], [12168, 12172, "TRAINED_CATEGORY"], [12184, 12188, "TRAINED_CATEGORY"], [12190, 12205, "TRAINED_CATEGORY"], [12210, 12226, "TRAINED_CATEGORY"], [12228, 12233, "TRAINED_CATEGORY"], [12262, 12275, "TRAINED_CATEGORY"], [12282, 12292, "TRAINED_CATEGORY"], [12306, 12321, "TRAINED_CATEGORY"], [12366, 12390, "TRAINED_CATEGORY"], [12398, 12409, "TRAINED_CATEGORY"], [12413, 12454, "TRAINED_CATEGORY"], [12469, 12473, "TRAINED_CATEGORY"], [12475, 12492, "TRAINED_CATEGORY"], [12496, 12527, "TRAINED_CATEGORY"], [12545, 12560, "TRAINED_CATEGORY"], [12564, 12599, "TRAINED_CATEGORY"], [12601, 12605, "TRAINED_CATEGORY"], [12610, 12625, "TRAINED_CATEGORY"], [12652, 12659, "TRAINED_CATEGORY"], [12668, 12683, "TRAINED_CATEGORY"], [12695, 12704, "TRAINED_CATEGORY"], [12712, 12740, "TRAINED_CATEGORY"], [12764, 12781, "TRAINED_CATEGORY"], [12788, 12803, "TRAINED_CATEGORY"], [12821, 12846, "TRAINED_CATEGORY"], [12848, 12852, "TRAINED_CATEGORY"], [12858, 12865, "TRAINED_CATEGORY"], [12878, 12903, "TRAINED_CATEGORY"], [12919, 12939, "TRAINED_CATEGORY"], [12944, 12955, "TRAINED_CATEGORY"], [12962, 12974, "TRAINED_CATEGORY"], [12978, 13003, "TRAINED_CATEGORY"], [13014, 13021, "TRAINED_CATEGORY"], [13025, 13045, "TRAINED_CATEGORY"], [13049, 13091, "TRAINED_CATEGORY"], [13093, 13115, "TRAINED_CATEGORY"], [13128, 13134, "TRAINED_CATEGORY"], [13145, 13162, "TRAINED_CATEGORY"], [13164, 13166, "TRAINED_CATEGORY"], [13181, 13192, "TRAINED_CATEGORY"], [13196, 13227, "TRAINED_CATEGORY"], [13241, 13253, "TRAINED_CATEGORY"], [13280, 13299, "TRAINED_CATEGORY"], [13306, 13316, "TRAINED_CATEGORY"], [13321, 13328, "TRAINED_CATEGORY"], [13330, 13332, "TRAINED_CATEGORY"], [13343, 13356, "TRAINED_CATEGORY"], [13365, 13378, "TRAINED_CATEGORY"], [13383, 13388, "TRAINED_CATEGORY"], [13403, 13415, "TRAINED_CATEGORY"], [13418, 13451, "TRAINED_CATEGORY"], [13465, 13472, "TRAINED_CATEGORY"], [13474, 13478, "TRAINED_CATEGORY"], [13483, 13488, "TRAINED_CATEGORY"], [13490, 13494, "TRAINED_CATEGORY"], [13503, 13516, "TRAINED_CATEGORY"], [13520, 13544, "TRAINED_CATEGORY"], [13546, 13548, "TRAINED_CATEGORY"], [13549, 13559, "TRAINED_CATEGORY"], [13563, 13581, "TRAINED_CATEGORY"], [13583, 13593, "TRAINED_CATEGORY"], [13608, 13612, "TRAINED_CATEGORY"], [13614, 13618, "TRAINED_CATEGORY"], [13622, 13629, "TRAINED_CATEGORY"], [13631, 13635, "TRAINED_CATEGORY"], [13643, 13657, "TRAINED_CATEGORY"], [13661, 13679, "TRAINED_CATEGORY"], [13681, 13708, "TRAINED_CATEGORY"], [13710, 13751, "TRAINED_CATEGORY"], [13765, 13781, "TRAINED_CATEGORY"], [13784, 13788, "TRAINED_CATEGORY"], [13790, 13794, "TRAINED_CATEGORY"], [13803, 13831, "TRAINED_CATEGORY"], [13833, 13855, "TRAINED_CATEGORY"], [13857, 13865, "TRAINED_CATEGORY"], [13867, 13875, "TRAINED_CATEGORY"], [13877, 13884, "TRAINED_CATEGORY"], [13897, 13917, "TRAINED_CATEGORY"], [13922, 13936, "TRAINED_CATEGORY"], [13940, 13951, "TRAINED_CATEGORY"], [13955, 13965, "TRAINED_CATEGORY"], [13967, 13982, "TRAINED_CATEGORY"], [13986, 13996, "TRAINED_CATEGORY"], [14011, 14016, "TRAINED_CATEGORY"], [14018, 14020, "TRAINED_CATEGORY"], [14034, 14054, "TRAINED_CATEGORY"], [14059, 14097, "TRAINED_CATEGORY"], [14100, 14110, "TRAINED_CATEGORY"], [14112, 14128, "TRAINED_CATEGORY"], [14133, 14153, "TRAINED_CATEGORY"], [14165, 14172, "TRAINED_CATEGORY"], [14185, 14193, "TRAINED_CATEGORY"], [14211, 14222, "TRAINED_CATEGORY"], [14225, 14232, "TRAINED_CATEGORY"], [14234, 14248, "TRAINED_CATEGORY"], [14252, 14265, "TRAINED_CATEGORY"], [14267, 14276, "TRAINED_CATEGORY"], [14278, 14282, "TRAINED_CATEGORY"], [14292, 14297, "TRAINED_CATEGORY"], [14301, 14322, "TRAINED_CATEGORY"], [14324, 14344, "TRAINED_CATEGORY"], [14359, 14368, "TRAINED_CATEGORY"], [14370, 14374, "TRAINED_CATEGORY"], [14384, 14399, "TRAINED_CATEGORY"], [14403, 14422, "TRAINED_CATEGORY"], [14428, 14438, "TRAINED_CATEGORY"], [14443, 14454, "TRAINED_CATEGORY"], [14455, 14459, "TRAINED_CATEGORY"], [14461, 14469, "TRAINED_CATEGORY"], [14473, 14483, "TRAINED_CATEGORY"], [14487, 14504, "TRAINED_CATEGORY"], [14508, 14518, "TRAINED_CATEGORY"], [14522, 14537, "TRAINED_CATEGORY"], [14541, 14548, "TRAINED_CATEGORY"], [14551, 14558, "TRAINED_CATEGORY"], [14560, 14570, "TRAINED_CATEGORY"], [14572, 14581, "TRAINED_CATEGORY"], [14583, 14587, "TRAINED_CATEGORY"], [14597, 14612, "TRAINED_CATEGORY"], [14616, 14622, "TRAINED_CATEGORY"], [14625, 14632, "TRAINED_CATEGORY"], [14634, 14648, "TRAINED_CATEGORY"], [14652, 14665, "TRAINED_CATEGORY"], [14672, 14686, "TRAINED_CATEGORY"], [14690, 14706, "TRAINED_CATEGORY"], [14710, 14729, "TRAINED_CATEGORY"], [14738, 14764, "TRAINED_CATEGORY"], [14765, 14774, "TRAINED_CATEGORY"], [14784, 14799, "TRAINED_CATEGORY"], [14803, 14824, "TRAINED_CATEGORY"], [14826, 14830, "TRAINED_CATEGORY"], [14831, 14864, "TRAINED_CATEGORY"], [49, 64, "PERSON"], [69, 79, "DATE"], [1039, 1044, "PERSON"], [1147, 1157, "ORG"], [1161, 1170, "PERSON"], [1227, 1231, "DATE"], [1657, 1660, "CARDINAL"], [1833, 1842, "PERSON"], [1963, 1966, "CARDINAL"], [2119, 2123, "CARDINAL"], [2512, 2521, "PERSON"], [3029, 3038, "PERSON"], [3089, 3094, "ORG"], [3119, 3132, "WORK_OF_ART"], [3342, 3351, "PERSON"], [3367, 3374, "PERSON"], [3470, 3471, "CARDINAL"], [3505, 3510, "ORG"], [3664, 3669, "ORG"], [3686, 3691, "DATE"], [3863, 3867, "QUANTITY"], [3873, 3876, "CARDINAL"], [3955, 3961, "ORDINAL"], [3972, 3978, "QUANTITY"], [4037, 4042, "QUANTITY"], [4050, 4056, "ORDINAL"], [4062, 4068, "ORDINAL"], [4152, 4158, "ORDINAL"], [4169, 4174, "QUANTITY"], [4386, 4395, "PERSON"], [4403, 4408, "ORG"], [4531, 4532, "CARDINAL"], [4537, 4549, "MONEY"], [4613, 4617, "DATE"], [4622, 4624, "CARDINAL"], [4646, 4651, "ORG"], [4728, 4737, "PERSON"], [4911, 4916, "ORG"], [4965, 4968, "ORG"], [5056, 5063, "ORG"], [5065, 5069, "DATE"], [5074, 5077, "CARDINAL"], [5136, 5139, "CARDINAL"], [5238, 5241, "CARDINAL"], [5487, 5496, "PERSON"], [5614, 5623, "PERSON"], [5649, 5652, "ORG"], [5832, 5839, "PERSON"], [5865, 5874, "PERSON"], [5951, 5956, "DATE"], [6040, 6043, "ORG"], [6155, 6160, "ORG"], [6223, 6226, "CARDINAL"], [6289, 6302, "WORK_OF_ART"], [6371, 6374, "ORG"], [6468, 6489, "PERSON"], [6754, 6755, "CARDINAL"], [6906, 6907, "CARDINAL"], [6948, 6949, "ORG"], [6962, 6963, "CARDINAL"], [7299, 7339, "ORG"], [7339, 7345, "PRODUCT"], [7362, 7364, "MONEY"], [7982, 7988, "PRODUCT"], [8278, 8291, "WORK_OF_ART"], [8619, 8642, "WORK_OF_ART"], [8749, 8773, "WORK_OF_ART"], [8810, 8819, "PERSON"], [8821, 8825, "DATE"], [8830, 8832, "CARDINAL"], [9018, 9019, "CARDINAL"], [9043, 9047, "CARDINAL"], [9141, 9142, "CARDINAL"], [9961, 9962, "CARDINAL"], [10113, 10114, "CARDINAL"], [10214, 10220, "PRODUCT"], [10231, 10237, "PRODUCT"], [10254, 10255, "CARDINAL"], [10361, 10390, "ORG"], [11015, 11016, "CARDINAL"], [11034, 11054, "WORK_OF_ART"], [11056, 11057, "CARDINAL"], [11476, 11480, "CARDINAL"], [11498, 11528, "WORK_OF_ART"], [11840, 11861, "PERSON"], [11926, 11944, "DATE"], [11945, 11981, "WORK_OF_ART"], [12107, 12125, "PRODUCT"], [12133, 12136, "ORG"], [12145, 12160, "ORG"], [12162, 12166, "DATE"], [12168, 12172, "ORG"], [12174, 12178, "DATE"], [12194, 12199, "PERSON"], [12235, 12244, "DATE"], [12266, 12269, "ORG"], [12310, 12315, "PERSON"], [12413, 12443, "ORG"], [12573, 12599, "ORG"], [12614, 12619, "PERSON"], [12652, 12659, "PERSON"], [12661, 12665, "DATE"], [12672, 12677, "PERSON"], [12766, 12775, "PERSON"], [12792, 12797, "PERSON"], [12853, 12854, "CARDINAL"], [12862, 12865, "ORG"], [12978, 12981, "CARDINAL"], [13321, 13328, "PERSON"], [13330, 13332, "NORP"], [13334, 13339, "DATE"], [13369, 13378, "PERSON"], [13418, 13451, "ORG"], [13453, 13454, "CARDINAL"], [13456, 13459, "CARDINAL"], [13465, 13472, "GPE"], [13474, 13478, "GPE"], [13483, 13488, "GPE"], [13490, 13494, "GPE"], [13496, 13500, "DATE"], [13546, 13548, "NORP"], [13583, 13593, "PERSON"], [13595, 13597, "DATE"], [13599, 13602, "CARDINAL"], [13608, 13612, "GPE"], [13614, 13618, "GPE"], [13622, 13629, "GPE"], [13631, 13635, "GPE"], [13637, 13641, "DATE"], [13726, 13751, "PERSON"], [13753, 13755, "DATE"], [13757, 13760, "CARDINAL"], [13790, 13794, "GPE"], [13796, 13800, "DATE"], [13857, 13865, "GPE"], [13867, 13875, "PERSON"], [13877, 13884, "PERSON"], [13886, 13888, "PERSON"], [13890, 13894, "DATE"], [13967, 14000, "ORG"], [14002, 14005, "CARDINAL"], [14018, 14020, "PERSON"], [14022, 14031, "DATE"], [14100, 14153, "ORG"], [14174, 14178, "DATE"], [14211, 14222, "PERSON"], [14225, 14232, "GPE"], [14234, 14265, "ORG"], [14278, 14282, "PERSON"], [14284, 14288, "DATE"], [14324, 14344, "ORG"], [14346, 14348, "DATE"], [14350, 14353, "CARDINAL"], [14359, 14368, "GPE"], [14370, 14374, "GPE"], [14376, 14380, "DATE"], [14384, 14422, "WORK_OF_ART"], [14428, 14438, "PERSON"], [14443, 14454, "PERSON"], [14583, 14587, "PERSON"], [14589, 14593, "DATE"], [14597, 14622, "WORK_OF_ART"], [14625, 14632, "GPE"], [14634, 14665, "ORG"], [14672, 14680, "ORG"], [14691, 14729, "WORK_OF_ART"], [14738, 14764, "ORG"], [14784, 14824, "LAW"], [14826, 14830, "PERSON"]]}], ["Multiple-criteria decision-making (MCDM) or multiple-criteria decision analysis (MCDA) is a sub-discipline of operations research that explicitly evaluates multiple conflicting criteria in decision making (both in daily life and in settings such as business, government and medicine). Conflicting criteria are typical in evaluating options: cost or price is usually one of the main criteria, and some measure of quality is typically another criterion, easily in conflict with the cost. In purchasing a car, cost, comfort, safety, and fuel economy may be some of the main criteria we consider \u2013 it is unusual that the cheapest car is the most comfortable and the safest one. In portfolio management, we are interested in getting high returns while simultaneously reducing risks; however, the stocks that have the potential of bringing high returns typically carry high risk of losing money. In a service industry, customer satisfaction and the cost of providing service are fundamental conflicting criteria.\nIn our daily lives, we usually weigh multiple criteria implicitly and we may be comfortable with the consequences of such decisions that are made based on only intuition. On the other hand, when stakes are high, it is important to properly structure the problem and explicitly evaluate multiple criteria. In making the decision of whether to build a nuclear power plant or not, and where to build it, there are not only very complex issues involving multiple criteria, but there are also multiple parties who are deeply affected by the consequences.\nStructuring complex problems well and considering multiple criteria explicitly leads to more informed and better decisions.  There have been important advances in this field since the start of the modern multiple-criteria decision-making discipline in the early 1960s. A variety of approaches and methods, many implemented by specialized decision-making software, have been developed for their application in an array of disciplines, ranging from politics and business to the environment and energy.\n\n\n== Foundations, concepts, definitions ==\nMCDM or MCDA are well-known acronyms for multiple-criteria decision-making and multiple-criteria decision analysis; Stanley Zionts helped popularizing the acronym with his 1979 article \"MCDM \u2013 If not a Roman Numeral, then What?\", intended for an entrepreneurial audience. \nMCDM is concerned with structuring and solving decision and planning problems involving multiple criteria. The purpose is to support decision-makers facing such problems. Typically, there does not exist a unique optimal solution for such problems and it is necessary to use decision-maker's preferences to differentiate between solutions.\n\"Solving\" can be interpreted in different ways. It could correspond to choosing the \"best\" alternative from a set of available alternatives (where \"best\" can be interpreted as \"the most preferred alternative\" of a decision-maker).  Another interpretation of \"solving\" could be choosing a small set of good alternatives, or grouping alternatives into different preference sets. An extreme interpretation could be to find all \"efficient\" or \"nondominated\" alternatives (which we will define shortly).\nThe difficulty of the problem originates from the presence of more than one criterion. There is no longer a unique optimal solution to an MCDM problem that can be obtained without incorporating preference information. The concept of an optimal solution is often replaced by the set of nondominated solutions. A nondominated solution has the property that it is not possible to move away from it to any other solution without sacrificing in at least one criterion.  Therefore, it makes sense for the decision-maker to choose a solution from the nondominated set. Otherwise, she/he could do better in terms of some or all of the criteria, and not do worse in any of them. Generally, however, the set of nondominated solutions is too large to be presented to the decision-maker for the final choice. Hence we need tools that help the decision-maker focus on the preferred solutions (or alternatives). Normally one has to \"tradeoff\" certain criteria for others.\nMCDM has been an active area of research since the 1970s. There are several MCDM-related organizations including the International Society on Multi-criteria Decision Making, Euro Working Group on MCDA, and INFORMS Section on MCDM. For a history see: K\u00f6ksalan, Wallenius and Zionts (2011).\nMCDM draws upon knowledge in many fields including:\n\nMathematics\nDecision analysis\nEconomics\nComputer technology\nSoftware engineering\nInformation systems\n\n\n=== A typology ===\nThere are different classifications of MCDM problems and methods.  A major distinction between MCDM problems is based on whether the solutions are explicitly or implicitly defined.\n\nMultiple-criteria evaluation problems: These problems consist of a finite number of alternatives, explicitly known in the beginning of the solution process.  Each alternative is represented by its performance in multiple criteria.  The problem may be defined as finding the best alternative for a decision-maker (DM), or finding a set of good alternatives.  One may also be interested in \"sorting\" or \"classifying\" alternatives.  Sorting refers to placing alternatives in a set of preference-ordered classes (such as assigning credit-ratings to countries), and classifying refers to assigning alternatives to non-ordered sets (such as diagnosing patients based on their symptoms). Some of the MCDM methods in this category have been studied in a comparative manner in the book by Triantaphyllou on this subject, 2000.\nMultiple-criteria design problems (multiple objective mathematical programming problems):  In these problems, the alternatives are not explicitly known. An alternative (solution) can be found by solving a mathematical model.  The number of alternatives is either infinite and not countable (when some variables are continuous) or typically very large if countable (when all variables are discrete).Whether it is an evaluation problem or a design problem, preference information of DMs is required in order to differentiate between solutions.  The solution methods for MCDM problems are commonly classified based on the timing of preference information obtained from the DM.\nThere are methods that require the DM's preference information at the start of the process, transforming the problem into essentially a single criterion problem.  These methods are said to operate by \"prior articulation of preferences\".  Methods based on estimating a value function or using the concept of \"outranking relations\", analytical hierarchy process, and some decision rule-based methods try to solve multiple criteria evaluation problems utilizing prior articulation of preferences.  Similarly, there are methods developed to solve multiple-criteria design problems using prior articulation of preferences by constructing a value function.  Perhaps the most well-known of these methods is goal programming.  Once the value function is constructed, the resulting single objective mathematical program is solved to obtain a preferred solution.\nSome methods require preference information from the DM throughout the solution process.  These are referred to as interactive methods or methods that require \"progressive articulation of preferences\". These methods have been well-developed for both the multiple criteria evaluation (see for example Geoffrion, Dyer and Feinberg, 1972, and K\u00f6ksalan and Sagala, 1995 ) and design problems (see Steuer, 1986).\nMultiple-criteria design problems typically require the solution of a series of mathematical programming models in order to reveal implicitly defined solutions.  For these problems, a representation or approximation of \"efficient solutions\" may also be of interest.  This category is referred to as \"posterior articulation of preferences\", implying that the DM's involvement starts posterior to the explicit revelation of \"interesting\" solutions (see for example Karasakal and K\u00f6ksalan, 2009).\nWhen the mathematical programming models contain integer variables, the design problems become harder to solve.  Multiobjective Combinatorial Optimization (MOCO) constitutes a special category of such problems posing substantial computational difficulty (see Ehrgott and Gandibleux, 2002, for a review).\n\n\n=== Representations and definitions ===\nThe MCDM problem can be represented in the criterion space or the decision space.  Alternatively, if different criteria are combined by a weighted linear function, it is also possible to represent the problem in the weight space.  Below are the demonstrations of the criterion and weight spaces as well as some formal definitions.\n\n\n==== Criterion space representation ====\nLet us assume that we evaluate solutions in a specific problem situation using several criteria.  Let us further assume that more is better in each criterion.  Then, among all possible solutions, we are ideally interested in those solutions that perform well in all considered criteria.  However, it is unlikely to have a single solution that performs well in all considered criteria.  Typically, some solutions perform well in some criteria and some perform well in others.  Finding a way of trading off between criteria is one of the main endeavors in the MCDM literature.\nMathematically, the MCDM problem corresponding to the above arguments can be represented as\n\n\"max\" qsubject toq \u2208 Qwhere q is the vector of k criterion functions (objective functions) and Q is the feasible set, Q \u2286 Rk.\nIf Q is defined explicitly (by a set of alternatives), the resulting problem is called a multiple-criteria evaluation problem.\nIf Q is defined implicitly (by a set of constraints), the resulting problem is called a multiple-criteria design problem.\nThe quotation marks are used to indicate that the maximization of a vector is not a well-defined mathematical operation.  This corresponds to the argument that we will have to find a way to resolve the trade-off between criteria (typically based on the preferences of a decision maker) when a solution that performs well in all criteria does not exist.\n\n\n==== Decision space representation ====\nThe decision space corresponds to the set of possible decisions that are available to us.  The criteria values will be consequences of the decisions we make.  Hence, we can define a corresponding problem in the decision space.  For example, in designing a product, we decide on the design parameters (decision variables) each of which affects the performance measures (criteria) with which we evaluate our product.\nMathematically, a multiple-criteria design problem can be represented in the decision space as follows:\n\n  \n    \n      \n        \n          \n            \n              \n                max\n                q\n              \n              \n                \n                =\n                f\n                (\n                x\n                )\n                =\n                f\n                (\n                \n                  x\n                  \n                    1\n                  \n                \n                ,\n                \u2026\n                ,\n                \n                  x\n                  \n                    n\n                  \n                \n                )\n              \n            \n            \n              \n                \n                  subject to\n                \n              \n            \n            \n              \n                q\n                \u2208\n                Q\n              \n              \n                \n                =\n                {\n                f\n                (\n                x\n                )\n                :\n                x\n                \u2208\n                X\n                ,\n                \n                X\n                \u2286\n                \n                  \n                    R\n                  \n                  \n                    n\n                  \n                \n                }\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}\\max q&=f(x)=f(x_{1},\\ldots ,x_{n})\\\\{\\text{subject to}}\\\\q\\in Q&=\\{f(x):x\\in X,\\,X\\subseteq \\mathbb {R} ^{n}\\}\\end{aligned}}}\n  where X is the feasible set and x is the decision variable vector of size n.\nA well-developed special case is obtained when X is a polyhedron defined by linear inequalities and equalities. If all the objective functions are linear in terms of the decision variables, this variation leads to multiple objective linear programming (MOLP), an important subclass of MCDM problems.\nThere are several definitions that are central in MCDM.  Two closely related definitions are those of nondominance (defined based on the criterion space representation) and efficiency (defined based on the decision variable representation).\nDefinition 1.  q* \u2208 Q is nondominated if there does not exist another q \u2208 Q such that q \u2265 q* and q \u2260 q*.\nRoughly speaking, a solution is nondominated so long as it is not inferior to any other available solution in all the considered criteria.\nDefinition 2.  x* \u2208 X is efficient if there does not exist another x \u2208 X such that f(x) \u2265 f(x*) and f(x) \u2260 f(x*).\nIf an MCDM problem represents a decision situation well, then the most preferred solution of a DM has to be an efficient solution in the decision space, and its image is a nondominated point in the criterion space.  Following definitions are also important.\nDefinition 3.  q* \u2208 Q is weakly nondominated if there does not exist another q \u2208 Q such that q > q*.\nDefinition 4.  x* \u2208 X is weakly efficient if there does not exist another x \u2208 X such that f(x) > f(x*).\nWeakly nondominated points include all nondominated points and some special dominated points.  The importance of these special dominated points comes from the fact that they commonly appear in practice and special care is necessary to distinguish them from nondominated points.  If, for example, we maximize a single objective, we may end up with a weakly nondominated point that is dominated. The dominated points of the weakly nondominated set are located either on vertical or horizontal planes (hyperplanes) in the criterion space.\nIdeal point: (in criterion space) represents the best (the maximum for maximization problems and the minimum for minimization problems) of each objective function and typically corresponds to an infeasible solution.\nNadir point: (in criterion space) represents the worst (the minimum for maximization problems and the maximum for minimization problems) of each objective function among the points in the nondominated set and is typically a dominated point.\nThe ideal point and the nadir point are useful to the DM to get the \"feel\" of the range of solutions (although it is not straightforward to find the nadir point for design problems having more than two criteria).\n\n\n==== Illustrations of the decision and criterion spaces ====\nThe following two-variable MOLP problem in the decision variable space will help demonstrate some of the key concepts graphically.\n\n  \n    \n      \n        \n          \n            \n              \n                max\n                \n                  f\n                  \n                    1\n                  \n                \n                (\n                \n                  x\n                \n                )\n              \n              \n                \n                =\n                \u2212\n                \n                  x\n                  \n                    1\n                  \n                \n                +\n                2\n                \n                  x\n                  \n                    2\n                  \n                \n              \n            \n            \n              \n                max\n                \n                  f\n                  \n                    2\n                  \n                \n                (\n                \n                  x\n                \n                )\n              \n              \n                \n                =\n                2\n                \n                  x\n                  \n                    1\n                  \n                \n                \u2212\n                \n                  x\n                  \n                    2\n                  \n                \n              \n            \n            \n              \n                \n                  subject to\n                \n              \n            \n            \n              \n                \n                  x\n                  \n                    1\n                  \n                \n              \n              \n                \n                \u2264\n                4\n              \n            \n            \n              \n                \n                  x\n                  \n                    2\n                  \n                \n              \n              \n                \n                \u2264\n                4\n              \n            \n            \n              \n                \n                  x\n                  \n                    1\n                  \n                \n                +\n                \n                  x\n                  \n                    2\n                  \n                \n              \n              \n                \n                \u2264\n                7\n              \n            \n            \n              \n                \u2212\n                \n                  x\n                  \n                    1\n                  \n                \n                +\n                \n                  x\n                  \n                    2\n                  \n                \n              \n              \n                \n                \u2264\n                3\n              \n            \n            \n              \n                \n                  x\n                  \n                    1\n                  \n                \n                \u2212\n                \n                  x\n                  \n                    2\n                  \n                \n              \n              \n                \n                \u2264\n                3\n              \n            \n            \n              \n                \n                  x\n                  \n                    1\n                  \n                \n                ,\n                \n                  x\n                  \n                    2\n                  \n                \n              \n              \n                \n                \u2265\n                0\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}\\max f_{1}(\\mathbf {x} )&=-x_{1}+2x_{2}\\\\\\max f_{2}(\\mathbf {x} )&=2x_{1}-x_{2}\\\\{\\text{subject to}}\\\\x_{1}&\\leq 4\\\\x_{2}&\\leq 4\\\\x_{1}+x_{2}&\\leq 7\\\\-x_{1}+x_{2}&\\leq 3\\\\x_{1}-x_{2}&\\leq 3\\\\x_{1},x_{2}&\\geq 0\\end{aligned}}}\n  In Figure 1, the extreme points \"e\" and \"b\" maximize the first and second objectives, respectively. The red boundary between those two extreme points represents the efficient set. It can be seen from the figure that, for any feasible solution outside the efficient set, it is possible to improve both objectives by some points on the efficient set. Conversely, for any point on the efficient set, it is not possible to improve both objectives by moving to any other feasible solution.  At these solutions, one has to sacrifice from one of the objectives in order to improve the other objective.\nDue to its simplicity, the above problem can be represented in criterion space by replacing the  x's with the  f 's as follows:\n\nMax f1Max f2subject to f1 + 2f2 \u2264 12 2f1 + f2 \u2264 12 f1 + f2 \u2264 7 f1 \u2013 f2 \u2264 9 \u2212f1 + f2 \u2264 9 f1 + 2f2 \u2265 0 2f1 + f2 \u2265 0We present the criterion space graphically in Figure 2.  It is easier to detect the nondominated points (corresponding to efficient solutions in the decision space) in the criterion space. The north-east region of the feasible space constitutes the set of nondominated points (for maximization problems).\n\n\n=== Generating nondominated solutions ===\nThere are several ways to generate nondominated solutions.  We will discuss two of these.  The first approach can generate a special class of nondominated solutions whereas the second approach can generate any nondominated solution.\n\nWeighted sums (Gass & Saaty, 1955)If we combine the multiple criteria into a single criterion by multiplying each criterion with a positive weight and summing up the weighted criteria, then the solution to the resulting single criterion problem is a special efficient solution.  These special efficient solutions appear at corner points of the set of available solutions.  Efficient solutions that are not at corner points have special characteristics and this method is not capable of finding such points.  Mathematically, we can represent this situation as\n\nmax  wT.q =  wT.f(x), w> 0subject tox \u2208 XBy varying the weights, weighted sums can be used for generating efficient extreme point solutions for design problems, and supported (convex nondominated) points for evaluation problems.\n\nAchievement scalarizing function (Wierzbicki, 1980)\nAchievement scalarizing functions also combine multiple criteria into a single criterion by weighting them in a very special way.  They create rectangular contours going away from a reference point towards the available efficient solutions.  This special structure empower achievement scalarizing functions to reach any efficient solution.  This is a powerful property that makes these functions very useful for MCDM problems.\nMathematically, we can represent the corresponding problem as\n\nMin s(g, q, w, \u03c1) =  Min  {maxi [(gi \u2212 qi)/wi ] + \u03c1 \u2211i (gi \u2212 qi)},subject toq \u2208 QThe achievement scalarizing function can be used to project any point (feasible or infeasible) on the efficient frontier. Any point (supported or not) can be reached. The second term in the objective function is required to avoid generating inefficient solutions. Figure 3 demonstrates how a feasible point, g1, and an infeasible point, g2, are projected onto the nondominated points, q1 and q2, respectively, along the direction w using an achievement scalarizing function.  The dashed and solid contours correspond to the objective function contours with and without the second term of the objective function, respectively.\n\n\n=== Solving MCDM problems ===\nDifferent schools of thought have developed for solving MCDM problems (both of the design and evaluation type). For a bibliometric study showing their development over time, see Bragge, Korhonen, H. Wallenius and J. Wallenius [2010].Multiple objective mathematical programming school\n(1) Vector maximization: The purpose of vector maximization is to approximate the nondominated set; originally developed for Multiple Objective Linear Programming problems (Evans and Steuer, 1973; Yu and Zeleny, 1975).\n(2) Interactive programming: Phases of computation alternate with phases of decision-making (Benayoun et al., 1971; Geoffrion, Dyer and Feinberg, 1972; Zionts and Wallenius, 1976; Korhonen and Wallenius, 1988). No explicit knowledge of the DM's value function is assumed.\nGoal programming school\nThe purpose is to set apriori target values for goals, and to minimize weighted deviations from these goals. Both importance weights as well as lexicographic pre-emptive weights have been used (Charnes and Cooper, 1961).\nFuzzy-set theorists\nFuzzy sets were introduced by Zadeh (1965) as an extension of the classical notion of sets. This idea is used in many MCDM algorithms to model and solve fuzzy problems.\nMulti-attribute utility theorists\nMulti-attribute utility or value functions are elicited and used to identify the most preferred alternative or to rank order the alternatives. Elaborate interview techniques, which exist for eliciting linear additive utility functions and multiplicative nonlinear utility functions, are used (Keeney and Raiffa, 1976).\nFrench school\nThe French school focuses on decision aiding, in particular the ELECTRE family of outranking methods that originated in France during the mid-1960s. The method was first proposed by Bernard Roy (Roy, 1968).\nEvolutionary multiobjective optimization school (EMO)\nEMO algorithms start with an initial population, and update it by using processes designed to mimic natural survival-of-the-fittest principles and genetic variation operators to improve the average population from one generation to the next. The goal is to converge to a population of solutions which represent the nondominated set (Schaffer, 1984; Srinivas and Deb, 1994).  More recently, there are efforts to incorporate preference information into the solution process of EMO algorithms (see Deb and K\u00f6ksalan, 2010).\nAnalytic hierarchy process (AHP)\nThe AHP first decomposes the decision problem into a hierarchy of subproblems. Then the decision-maker evaluates the relative importance of its various elements by pairwise comparisons. The AHP converts these evaluations to numerical values (weights or priorities), which are used to calculate a score for each alternative (Saaty, 1980). A consistency index measures the extent to which the decision-maker has been consistent in her responses. AHP is one of the more controversial techniques listed here, with some researchers in the MCDA community believing it to be flawed. The underlying mathematics is also more complicated, though it has gained some popularity as a result of commercially available software.\nSeveral papers reviewed the application of MCDM techniques in various disciplines such as fuzzy MCDM, classic MCDM, sustainable and renewable energy, VIKOR technique, transportation systems, service quality, TOPSIS method, energy management problems, e-learning, tourism and hospitality, SWARA and WASPAS methods.\n\n\n=== MCDM methods ===\nThe following MCDM methods are available, many of which are implemented by specialized decision-making software:\nAggregated Indices Randomization Method (AIRM)\nAnalytic hierarchy process (AHP)\nAnalytic network process (ANP)\nBalance Beam process\nBase-criterion method (BCM)\nBest worst method (BWM)\nBrown\u2013Gibson model\nCharacteristic Objects METhod (COMET)\nChoosing By Advantages (CBA)\nData envelopment analysis\nDecision EXpert (DEX)\nDisaggregation \u2013 Aggregation Approaches (UTA*, UTAII, UTADIS)\nRough set (Rough set approach)\nDominance-based rough set approach (DRSA)\nELECTRE (Outranking)\nEvaluation Based on Distance from Average Solution (EDAS)\nEvidential reasoning approach (ER)\nGoal programming (GP)\nGrey relational analysis (GRA)\nInner product of vectors (IPV)\nMeasuring Attractiveness by a categorical Based Evaluation Technique (MACBETH)\nSimple Multi-Attribute Rating Technique (SMART) \nStratified Multi Criteria Decision Making (SMCDM)\nMulti-Attribute Global Inference of Quality (MAGIQ)\nMulti-attribute utility theory (MAUT)\nMulti-attribute value theory (MAVT)\nMarkovian Multi Criteria Decision Making\nNew Approach to Appraisal (NATA)\nNonstructural Fuzzy Decision Support System (NSFDSS)\nPotentially All Pairwise RanKings of all possible Alternatives (PAPRIKA)\nPROMETHEE (Outranking)\nRanking based on optimal points (RBOP)\nStochastic Multicriteria Acceptability Analysis (SMAA)\nSuperiority and inferiority ranking method (SIR method)\nTechnique for the Order of Prioritisation by Similarity to Ideal Solution (TOPSIS)\nValue analysis (VA)\nValue engineering (VE)\nVIKOR method\nWeighted product model (WPM)\nWeighted sum model (WSM)\nModelo Integrado de Valor para Estructuras Sostenibles (MIVES)\n\n\n== See also ==\nArchitecture tradeoff analysis method\nDecision-making\nDecision-making software\nDecision-making paradox\nDecisional balance sheet\nMulticriteria classification problems\nRank reversals in decision-making\nSuperiority and inferiority ranking method\n\n\n== References ==\n\n\n== Further reading ==\nMaliene, V. (2011). \"Specialised property valuation: Multiple criteria decision analysis\". Journal of Retail & Leisure Property. 9 (5): 443\u201350. doi:10.1057/rlp.2011.7.\nMulliner E, Smallbone K, Maliene V (2013). \"An assessment of sustainable housing affordability using a multiple criteria decision making method\" (PDF). Omega. 41 (2): 270\u201379. doi:10.1016/j.omega.2012.05.002.\nMaliene, V.;  et al. (2002). \"Application of a new multiple criteria analysis method in the valuation of property\" (PDF). FIG XXII International Congress: 19\u201326.\nA Brief History prepared by Steuer and Zionts\nMalakooti, B. (2013). Operations and Production Systems with Multiple Objectives. John Wiley & Sons.", {"entities": [[0, 33, "TRAINED_CATEGORY"], [35, 39, "TRAINED_CATEGORY"], [44, 79, "TRAINED_CATEGORY"], [81, 85, "TRAINED_CATEGORY"], [90, 106, "TRAINED_CATEGORY"], [110, 129, "TRAINED_CATEGORY"], [156, 185, "TRAINED_CATEGORY"], [189, 204, "TRAINED_CATEGORY"], [214, 224, "TRAINED_CATEGORY"], [232, 240, "TRAINED_CATEGORY"], [249, 257, "TRAINED_CATEGORY"], [259, 269, "TRAINED_CATEGORY"], [274, 282, "TRAINED_CATEGORY"], [285, 305, "TRAINED_CATEGORY"], [332, 339, "TRAINED_CATEGORY"], [341, 345, "TRAINED_CATEGORY"], [349, 354, "TRAINED_CATEGORY"], [373, 390, "TRAINED_CATEGORY"], [396, 408, "TRAINED_CATEGORY"], [412, 419, "TRAINED_CATEGORY"], [433, 450, "TRAINED_CATEGORY"], [462, 470, "TRAINED_CATEGORY"], [476, 484, "TRAINED_CATEGORY"], [500, 505, "TRAINED_CATEGORY"], [507, 511, "TRAINED_CATEGORY"], [513, 520, "TRAINED_CATEGORY"], [522, 528, "TRAINED_CATEGORY"], [534, 546, "TRAINED_CATEGORY"], [562, 579, "TRAINED_CATEGORY"], [580, 582, "TRAINED_CATEGORY"], [594, 596, "TRAINED_CATEGORY"], [613, 629, "TRAINED_CATEGORY"], [677, 697, "TRAINED_CATEGORY"], [699, 701, "TRAINED_CATEGORY"], [728, 740, "TRAINED_CATEGORY"], [771, 776, "TRAINED_CATEGORY"], [787, 797, "TRAINED_CATEGORY"], [808, 821, "TRAINED_CATEGORY"], [834, 846, "TRAINED_CATEGORY"], [863, 872, "TRAINED_CATEGORY"], [883, 888, "TRAINED_CATEGORY"], [893, 911, "TRAINED_CATEGORY"], [913, 934, "TRAINED_CATEGORY"], [939, 947, "TRAINED_CATEGORY"], [961, 968, "TRAINED_CATEGORY"], [973, 1005, "TRAINED_CATEGORY"], [1010, 1025, "TRAINED_CATEGORY"], [1027, 1029, "TRAINED_CATEGORY"], [1044, 1061, "TRAINED_CATEGORY"], [1077, 1079, "TRAINED_CATEGORY"], [1104, 1120, "TRAINED_CATEGORY"], [1124, 1138, "TRAINED_CATEGORY"], [1162, 1176, "TRAINED_CATEGORY"], [1181, 1195, "TRAINED_CATEGORY"], [1202, 1208, "TRAINED_CATEGORY"], [1219, 1221, "TRAINED_CATEGORY"], [1257, 1268, "TRAINED_CATEGORY"], [1293, 1310, "TRAINED_CATEGORY"], [1322, 1334, "TRAINED_CATEGORY"], [1355, 1376, "TRAINED_CATEGORY"], [1404, 1406, "TRAINED_CATEGORY"], [1427, 1446, "TRAINED_CATEGORY"], [1457, 1474, "TRAINED_CATEGORY"], [1495, 1511, "TRAINED_CATEGORY"], [1512, 1515, "TRAINED_CATEGORY"], [1539, 1555, "TRAINED_CATEGORY"], [1569, 1585, "TRAINED_CATEGORY"], [1607, 1624, "TRAINED_CATEGORY"], [1645, 1679, "TRAINED_CATEGORY"], [1698, 1716, "TRAINED_CATEGORY"], [1720, 1730, "TRAINED_CATEGORY"], [1737, 1746, "TRAINED_CATEGORY"], [1750, 1805, "TRAINED_CATEGORY"], [1809, 1824, "TRAINED_CATEGORY"], [1826, 1835, "TRAINED_CATEGORY"], [1839, 1849, "TRAINED_CATEGORY"], [1854, 1861, "TRAINED_CATEGORY"], [1883, 1919, "TRAINED_CATEGORY"], [1945, 1962, "TRAINED_CATEGORY"], [1966, 1974, "TRAINED_CATEGORY"], [1978, 1989, "TRAINED_CATEGORY"], [2004, 2012, "TRAINED_CATEGORY"], [2017, 2025, "TRAINED_CATEGORY"], [2029, 2044, "TRAINED_CATEGORY"], [2049, 2055, "TRAINED_CATEGORY"], [2060, 2061, "TRAINED_CATEGORY"], [2062, 2096, "TRAINED_CATEGORY"], [2100, 2104, "TRAINED_CATEGORY"], [2108, 2112, "TRAINED_CATEGORY"], [2117, 2136, "TRAINED_CATEGORY"], [2141, 2214, "TRAINED_CATEGORY"], [2216, 2230, "TRAINED_CATEGORY"], [2251, 2262, "TRAINED_CATEGORY"], [2268, 2284, "TRAINED_CATEGORY"], [2286, 2290, "TRAINED_CATEGORY"], [2293, 2326, "TRAINED_CATEGORY"], [2343, 2370, "TRAINED_CATEGORY"], [2373, 2377, "TRAINED_CATEGORY"], [2420, 2428, "TRAINED_CATEGORY"], [2433, 2441, "TRAINED_CATEGORY"], [2442, 2450, "TRAINED_CATEGORY"], [2461, 2478, "TRAINED_CATEGORY"], [2480, 2491, "TRAINED_CATEGORY"], [2506, 2521, "TRAINED_CATEGORY"], [2529, 2542, "TRAINED_CATEGORY"], [2576, 2601, "TRAINED_CATEGORY"], [2606, 2619, "TRAINED_CATEGORY"], [2624, 2626, "TRAINED_CATEGORY"], [2647, 2675, "TRAINED_CATEGORY"], [2701, 2710, "TRAINED_CATEGORY"], [2744, 2758, "TRAINED_CATEGORY"], [2760, 2762, "TRAINED_CATEGORY"], [2792, 2814, "TRAINED_CATEGORY"], [2820, 2825, "TRAINED_CATEGORY"], [2829, 2851, "TRAINED_CATEGORY"], [2889, 2919, "TRAINED_CATEGORY"], [2924, 2940, "TRAINED_CATEGORY"], [2944, 2966, "TRAINED_CATEGORY"], [2998, 3009, "TRAINED_CATEGORY"], [3013, 3030, "TRAINED_CATEGORY"], [3044, 3056, "TRAINED_CATEGORY"], [3062, 3087, "TRAINED_CATEGORY"], [3089, 3114, "TRAINED_CATEGORY"], [3151, 3178, "TRAINED_CATEGORY"], [3186, 3188, "TRAINED_CATEGORY"], [3211, 3225, "TRAINED_CATEGORY"], [3257, 3269, "TRAINED_CATEGORY"], [3273, 3296, "TRAINED_CATEGORY"], [3317, 3342, "TRAINED_CATEGORY"], [3346, 3361, "TRAINED_CATEGORY"], [3405, 3427, "TRAINED_CATEGORY"], [3429, 3440, "TRAINED_CATEGORY"], [3444, 3463, "TRAINED_CATEGORY"], [3485, 3492, "TRAINED_CATEGORY"], [3496, 3518, "TRAINED_CATEGORY"], [3520, 3543, "TRAINED_CATEGORY"], [3548, 3560, "TRAINED_CATEGORY"], [3566, 3568, "TRAINED_CATEGORY"], [3603, 3605, "TRAINED_CATEGORY"], [3609, 3627, "TRAINED_CATEGORY"], [3651, 3673, "TRAINED_CATEGORY"], [3687, 3689, "TRAINED_CATEGORY"], [3696, 3701, "TRAINED_CATEGORY"], [3706, 3724, "TRAINED_CATEGORY"], [3735, 3745, "TRAINED_CATEGORY"], [3751, 3771, "TRAINED_CATEGORY"], [3788, 3790, "TRAINED_CATEGORY"], [3810, 3815, "TRAINED_CATEGORY"], [3834, 3846, "TRAINED_CATEGORY"], [3875, 3879, "TRAINED_CATEGORY"], [3901, 3908, "TRAINED_CATEGORY"], [3912, 3934, "TRAINED_CATEGORY"], [3967, 3985, "TRAINED_CATEGORY"], [3990, 4006, "TRAINED_CATEGORY"], [4014, 4016, "TRAINED_CATEGORY"], [4022, 4027, "TRAINED_CATEGORY"], [4038, 4062, "TRAINED_CATEGORY"], [4066, 4089, "TRAINED_CATEGORY"], [4094, 4106, "TRAINED_CATEGORY"], [4118, 4121, "TRAINED_CATEGORY"], [4140, 4156, "TRAINED_CATEGORY"], [4161, 4167, "TRAINED_CATEGORY"], [4169, 4173, "TRAINED_CATEGORY"], [4183, 4197, "TRAINED_CATEGORY"], [4201, 4209, "TRAINED_CATEGORY"], [4237, 4271, "TRAINED_CATEGORY"], [4282, 4307, "TRAINED_CATEGORY"], [4311, 4341, "TRAINED_CATEGORY"], [4343, 4361, "TRAINED_CATEGORY"], [4365, 4369, "TRAINED_CATEGORY"], [4375, 4390, "TRAINED_CATEGORY"], [4394, 4398, "TRAINED_CATEGORY"], [4404, 4413, "TRAINED_CATEGORY"], [4419, 4427, "TRAINED_CATEGORY"], [4429, 4438, "TRAINED_CATEGORY"], [4443, 4449, "TRAINED_CATEGORY"], [4458, 4462, "TRAINED_CATEGORY"], [4474, 4483, "TRAINED_CATEGORY"], [4487, 4498, "TRAINED_CATEGORY"], [4511, 4540, "TRAINED_CATEGORY"], [4541, 4550, "TRAINED_CATEGORY"], [4551, 4570, "TRAINED_CATEGORY"], [4571, 4591, "TRAINED_CATEGORY"], [4592, 4611, "TRAINED_CATEGORY"], [4618, 4628, "TRAINED_CATEGORY"], [4643, 4668, "TRAINED_CATEGORY"], [4672, 4685, "TRAINED_CATEGORY"], [4690, 4697, "TRAINED_CATEGORY"], [4700, 4719, "TRAINED_CATEGORY"], [4728, 4741, "TRAINED_CATEGORY"], [4762, 4775, "TRAINED_CATEGORY"], [4854, 4868, "TRAINED_CATEGORY"], [4880, 4895, "TRAINED_CATEGORY"], [4899, 4911, "TRAINED_CATEGORY"], [4933, 4946, "TRAINED_CATEGORY"], [4950, 4970, "TRAINED_CATEGORY"], [4973, 4989, "TRAINED_CATEGORY"], [5008, 5023, "TRAINED_CATEGORY"], [5027, 5044, "TRAINED_CATEGORY"], [5047, 5058, "TRAINED_CATEGORY"], [5085, 5105, "TRAINED_CATEGORY"], [5110, 5130, "TRAINED_CATEGORY"], [5144, 5149, "TRAINED_CATEGORY"], [5153, 5170, "TRAINED_CATEGORY"], [5230, 5242, "TRAINED_CATEGORY"], [5271, 5283, "TRAINED_CATEGORY"], [5287, 5292, "TRAINED_CATEGORY"], [5296, 5322, "TRAINED_CATEGORY"], [5342, 5356, "TRAINED_CATEGORY"], [5360, 5369, "TRAINED_CATEGORY"], [5388, 5394, "TRAINED_CATEGORY"], [5408, 5420, "TRAINED_CATEGORY"], [5424, 5440, "TRAINED_CATEGORY"], [5450, 5469, "TRAINED_CATEGORY"], [5479, 5493, "TRAINED_CATEGORY"], [5504, 5520, "TRAINED_CATEGORY"], [5524, 5537, "TRAINED_CATEGORY"], [5559, 5579, "TRAINED_CATEGORY"], [5583, 5591, "TRAINED_CATEGORY"], [5595, 5609, "TRAINED_CATEGORY"], [5613, 5625, "TRAINED_CATEGORY"], [5633, 5666, "TRAINED_CATEGORY"], [5668, 5720, "TRAINED_CATEGORY"], [5727, 5741, "TRAINED_CATEGORY"], [5743, 5759, "TRAINED_CATEGORY"], [5786, 5810, "TRAINED_CATEGORY"], [5836, 5856, "TRAINED_CATEGORY"], [5859, 5869, "TRAINED_CATEGORY"], [5873, 5885, "TRAINED_CATEGORY"], [5929, 5943, "TRAINED_CATEGORY"], [6003, 6016, "TRAINED_CATEGORY"], [6021, 6038, "TRAINED_CATEGORY"], [6039, 6041, "TRAINED_CATEGORY"], [6045, 6066, "TRAINED_CATEGORY"], [6070, 6086, "TRAINED_CATEGORY"], [6088, 6110, "TRAINED_CATEGORY"], [6114, 6117, "TRAINED_CATEGORY"], [6133, 6138, "TRAINED_CATEGORY"], [6164, 6173, "TRAINED_CATEGORY"], [6176, 6196, "TRAINED_CATEGORY"], [6201, 6214, "TRAINED_CATEGORY"], [6248, 6258, "TRAINED_CATEGORY"], [6262, 6284, "TRAINED_CATEGORY"], [6299, 6305, "TRAINED_CATEGORY"], [6317, 6324, "TRAINED_CATEGORY"], [6338, 6369, "TRAINED_CATEGORY"], [6373, 6382, "TRAINED_CATEGORY"], [6386, 6397, "TRAINED_CATEGORY"], [6412, 6423, "TRAINED_CATEGORY"], [6429, 6467, "TRAINED_CATEGORY"], [6470, 6483, "TRAINED_CATEGORY"], [6508, 6526, "TRAINED_CATEGORY"], [6530, 6541, "TRAINED_CATEGORY"], [6545, 6552, "TRAINED_CATEGORY"], [6573, 6589, "TRAINED_CATEGORY"], [6599, 6610, "TRAINED_CATEGORY"], [6614, 6635, "TRAINED_CATEGORY"], [6638, 6666, "TRAINED_CATEGORY"], [6672, 6704, "TRAINED_CATEGORY"], [6718, 6755, "TRAINED_CATEGORY"], [6766, 6784, "TRAINED_CATEGORY"], [6788, 6799, "TRAINED_CATEGORY"], [6823, 6830, "TRAINED_CATEGORY"], [6850, 6883, "TRAINED_CATEGORY"], [6890, 6908, "TRAINED_CATEGORY"], [6912, 6923, "TRAINED_CATEGORY"], [6940, 6956, "TRAINED_CATEGORY"], [6990, 7003, "TRAINED_CATEGORY"], [7007, 7023, "TRAINED_CATEGORY"], [7031, 7049, "TRAINED_CATEGORY"], [7066, 7117, "TRAINED_CATEGORY"], [7138, 7158, "TRAINED_CATEGORY"], [7160, 7172, "TRAINED_CATEGORY"], [7181, 7203, "TRAINED_CATEGORY"], [7209, 7215, "TRAINED_CATEGORY"], [7227, 7247, "TRAINED_CATEGORY"], [7275, 7294, "TRAINED_CATEGORY"], [7298, 7305, "TRAINED_CATEGORY"], [7320, 7344, "TRAINED_CATEGORY"], [7348, 7359, "TRAINED_CATEGORY"], [7362, 7375, "TRAINED_CATEGORY"], [7405, 7442, "TRAINED_CATEGORY"], [7452, 7459, "TRAINED_CATEGORY"], [7460, 7469, "TRAINED_CATEGORY"], [7471, 7475, "TRAINED_CATEGORY"], [7480, 7488, "TRAINED_CATEGORY"], [7500, 7508, "TRAINED_CATEGORY"], [7513, 7519, "TRAINED_CATEGORY"], [7553, 7559, "TRAINED_CATEGORY"], [7568, 7601, "TRAINED_CATEGORY"], [7620, 7632, "TRAINED_CATEGORY"], [7636, 7644, "TRAINED_CATEGORY"], [7648, 7679, "TRAINED_CATEGORY"], [7683, 7688, "TRAINED_CATEGORY"], [7699, 7727, "TRAINED_CATEGORY"], [7734, 7748, "TRAINED_CATEGORY"], [7787, 7807, "TRAINED_CATEGORY"], [7824, 7832, "TRAINED_CATEGORY"], [7835, 7848, "TRAINED_CATEGORY"], [7868, 7890, "TRAINED_CATEGORY"], [7894, 7905, "TRAINED_CATEGORY"], [7922, 7942, "TRAINED_CATEGORY"], [7963, 7986, "TRAINED_CATEGORY"], [7990, 8013, "TRAINED_CATEGORY"], [8023, 8030, "TRAINED_CATEGORY"], [8031, 8040, "TRAINED_CATEGORY"], [8045, 8053, "TRAINED_CATEGORY"], [8067, 8102, "TRAINED_CATEGORY"], [8111, 8128, "TRAINED_CATEGORY"], [8130, 8149, "TRAINED_CATEGORY"], [8175, 8216, "TRAINED_CATEGORY"], [8218, 8222, "TRAINED_CATEGORY"], [8236, 8254, "TRAINED_CATEGORY"], [8258, 8271, "TRAINED_CATEGORY"], [8279, 8315, "TRAINED_CATEGORY"], [8321, 8328, "TRAINED_CATEGORY"], [8333, 8343, "TRAINED_CATEGORY"], [8355, 8363, "TRAINED_CATEGORY"], [8370, 8387, "TRAINED_CATEGORY"], [8392, 8403, "TRAINED_CATEGORY"], [8408, 8424, "TRAINED_CATEGORY"], [8447, 8466, "TRAINED_CATEGORY"], [8470, 8488, "TRAINED_CATEGORY"], [8509, 8527, "TRAINED_CATEGORY"], [8544, 8570, "TRAINED_CATEGORY"], [8572, 8574, "TRAINED_CATEGORY"], [8605, 8616, "TRAINED_CATEGORY"], [8620, 8636, "TRAINED_CATEGORY"], [8649, 8667, "TRAINED_CATEGORY"], [8671, 8684, "TRAINED_CATEGORY"], [8689, 8702, "TRAINED_CATEGORY"], [8714, 8737, "TRAINED_CATEGORY"], [8746, 8776, "TRAINED_CATEGORY"], [8786, 8788, "TRAINED_CATEGORY"], [8801, 8803, "TRAINED_CATEGORY"], [8813, 8822, "TRAINED_CATEGORY"], [8826, 8854, "TRAINED_CATEGORY"], [8861, 8877, "TRAINED_CATEGORY"], [8884, 8886, "TRAINED_CATEGORY"], [8925, 8939, "TRAINED_CATEGORY"], [8954, 8976, "TRAINED_CATEGORY"], [8978, 8980, "TRAINED_CATEGORY"], [9007, 9022, "TRAINED_CATEGORY"], [9048, 9067, "TRAINED_CATEGORY"], [9079, 9081, "TRAINED_CATEGORY"], [9102, 9119, "TRAINED_CATEGORY"], [9142, 9165, "TRAINED_CATEGORY"], [9179, 9193, "TRAINED_CATEGORY"], [9210, 9223, "TRAINED_CATEGORY"], [9249, 9255, "TRAINED_CATEGORY"], [9266, 9271, "TRAINED_CATEGORY"], [9275, 9282, "TRAINED_CATEGORY"], [9295, 9303, "TRAINED_CATEGORY"], [9314, 9332, "TRAINED_CATEGORY"], [9336, 9355, "TRAINED_CATEGORY"], [9373, 9389, "TRAINED_CATEGORY"], [9407, 9426, "TRAINED_CATEGORY"], [9450, 9468, "TRAINED_CATEGORY"], [9469, 9470, "TRAINED_CATEGORY"], [9471, 9479, "TRAINED_CATEGORY"], [9483, 9493, "TRAINED_CATEGORY"], [9497, 9518, "TRAINED_CATEGORY"], [9520, 9539, "TRAINED_CATEGORY"], [9545, 9546, "TRAINED_CATEGORY"], [9550, 9566, "TRAINED_CATEGORY"], [9568, 9574, "TRAINED_CATEGORY"], [9579, 9580, "TRAINED_CATEGORY"], [9607, 9612, "TRAINED_CATEGORY"], [9616, 9628, "TRAINED_CATEGORY"], [9631, 9652, "TRAINED_CATEGORY"], [9706, 9707, "TRAINED_CATEGORY"], [9734, 9739, "TRAINED_CATEGORY"], [9743, 9754, "TRAINED_CATEGORY"], [9757, 9778, "TRAINED_CATEGORY"], [9825, 9844, "TRAINED_CATEGORY"], [9871, 9887, "TRAINED_CATEGORY"], [9891, 9899, "TRAINED_CATEGORY"], [9907, 9944, "TRAINED_CATEGORY"], [9967, 9979, "TRAINED_CATEGORY"], [9985, 9987, "TRAINED_CATEGORY"], [10006, 10011, "TRAINED_CATEGORY"], [10023, 10036, "TRAINED_CATEGORY"], [10045, 10053, "TRAINED_CATEGORY"], [10074, 10089, "TRAINED_CATEGORY"], [10093, 10109, "TRAINED_CATEGORY"], [10116, 10126, "TRAINED_CATEGORY"], [10149, 10161, "TRAINED_CATEGORY"], [10185, 10214, "TRAINED_CATEGORY"], [10220, 10238, "TRAINED_CATEGORY"], [10254, 10261, "TRAINED_CATEGORY"], [10265, 10283, "TRAINED_CATEGORY"], [10306, 10308, "TRAINED_CATEGORY"], [10311, 10330, "TRAINED_CATEGORY"], [10339, 10351, "TRAINED_CATEGORY"], [10355, 10368, "TRAINED_CATEGORY"], [10369, 10371, "TRAINED_CATEGORY"], [10386, 10388, "TRAINED_CATEGORY"], [10400, 10423, "TRAINED_CATEGORY"], [10427, 10445, "TRAINED_CATEGORY"], [10452, 10459, "TRAINED_CATEGORY"], [10474, 10483, "TRAINED_CATEGORY"], [10485, 10487, "TRAINED_CATEGORY"], [10498, 10519, "TRAINED_CATEGORY"], [10520, 10539, "TRAINED_CATEGORY"], [10563, 10587, "TRAINED_CATEGORY"], [10589, 10597, "TRAINED_CATEGORY"], [10610, 10612, "TRAINED_CATEGORY"], [10622, 10633, "TRAINED_CATEGORY"], [10651, 10685, "TRAINED_CATEGORY"], [10708, 10726, "TRAINED_CATEGORY"], [10819, 10822, "TRAINED_CATEGORY"], [10839, 10840, "TRAINED_CATEGORY"], [10922, 10923, "TRAINED_CATEGORY"], [11012, 11013, "TRAINED_CATEGORY"], [11523, 11524, "TRAINED_CATEGORY"], [11541, 11542, "TRAINED_CATEGORY"], [11559, 11560, "TRAINED_CATEGORY"], [11786, 11787, "TRAINED_CATEGORY"], [11839, 11840, "TRAINED_CATEGORY"], [11857, 11858, "TRAINED_CATEGORY"], [12095, 12153, "TRAINED_CATEGORY"], [12178, 12188, "TRAINED_CATEGORY"], [12227, 12229, "TRAINED_CATEGORY"], [12261, 12262, "TRAINED_CATEGORY"], [12266, 12282, "TRAINED_CATEGORY"], [12292, 12320, "TRAINED_CATEGORY"], [12324, 12331, "TRAINED_CATEGORY"], [12332, 12361, "TRAINED_CATEGORY"], [12379, 12380, "TRAINED_CATEGORY"], [12384, 12396, "TRAINED_CATEGORY"], [12408, 12427, "TRAINED_CATEGORY"], [12432, 12442, "TRAINED_CATEGORY"], [12447, 12474, "TRAINED_CATEGORY"], [12489, 12494, "TRAINED_CATEGORY"], [12498, 12520, "TRAINED_CATEGORY"], [12522, 12536, "TRAINED_CATEGORY"], [12546, 12583, "TRAINED_CATEGORY"], [12585, 12589, "TRAINED_CATEGORY"], [12592, 12613, "TRAINED_CATEGORY"], [12617, 12630, "TRAINED_CATEGORY"], [12642, 12661, "TRAINED_CATEGORY"], [12682, 12686, "TRAINED_CATEGORY"], [12689, 12720, "TRAINED_CATEGORY"], [12734, 12746, "TRAINED_CATEGORY"], [12765, 12799, "TRAINED_CATEGORY"], [12805, 12815, "TRAINED_CATEGORY"], [12834, 12870, "TRAINED_CATEGORY"], [12873, 12883, "TRAINED_CATEGORY"], [12888, 12889, "TRAINED_CATEGORY"], [12889, 12892, "TRAINED_CATEGORY"], [12893, 12894, "TRAINED_CATEGORY"], [12935, 12948, "TRAINED_CATEGORY"], [12963, 12964, "TRAINED_CATEGORY"], [12966, 12975, "TRAINED_CATEGORY"], [12996, 13006, "TRAINED_CATEGORY"], [13034, 13036, "TRAINED_CATEGORY"], [13056, 13084, "TRAINED_CATEGORY"], [13088, 13115, "TRAINED_CATEGORY"], [13117, 13127, "TRAINED_CATEGORY"], [13133, 13136, "TRAINED_CATEGORY"], [13137, 13138, "TRAINED_CATEGORY"], [13176, 13187, "TRAINED_CATEGORY"], [13188, 13189, "TRAINED_CATEGORY"], [13205, 13210, "TRAINED_CATEGORY"], [13222, 13227, "TRAINED_CATEGORY"], [13234, 13249, "TRAINED_CATEGORY"], [13261, 13281, "TRAINED_CATEGORY"], [13293, 13320, "TRAINED_CATEGORY"], [13324, 13328, "TRAINED_CATEGORY"], [13339, 13360, "TRAINED_CATEGORY"], [13364, 13382, "TRAINED_CATEGORY"], [13388, 13397, "TRAINED_CATEGORY"], [13401, 13421, "TRAINED_CATEGORY"], [13425, 13444, "TRAINED_CATEGORY"], [13447, 13468, "TRAINED_CATEGORY"], [13489, 13499, "TRAINED_CATEGORY"], [13504, 13505, "TRAINED_CATEGORY"], [13505, 13508, "TRAINED_CATEGORY"], [13509, 13510, "TRAINED_CATEGORY"], [13558, 13571, "TRAINED_CATEGORY"], [13586, 13587, "TRAINED_CATEGORY"], [13590, 13600, "TRAINED_CATEGORY"], [13606, 13609, "TRAINED_CATEGORY"], [13610, 13611, "TRAINED_CATEGORY"], [13656, 13667, "TRAINED_CATEGORY"], [13668, 13669, "TRAINED_CATEGORY"], [13701, 13720, "TRAINED_CATEGORY"], [13729, 13752, "TRAINED_CATEGORY"], [13757, 13786, "TRAINED_CATEGORY"], [13789, 13803, "TRAINED_CATEGORY"], [13807, 13837, "TRAINED_CATEGORY"], [13849, 13857, "TRAINED_CATEGORY"], [13863, 13867, "TRAINED_CATEGORY"], [13887, 13895, "TRAINED_CATEGORY"], [13900, 13912, "TRAINED_CATEGORY"], [13941, 13945, "TRAINED_CATEGORY"], [13951, 13970, "TRAINED_CATEGORY"], [13981, 13988, "TRAINED_CATEGORY"], [13990, 13992, "TRAINED_CATEGORY"], [14002, 14020, "TRAINED_CATEGORY"], [14022, 14024, "TRAINED_CATEGORY"], [14041, 14068, "TRAINED_CATEGORY"], [14088, 14108, "TRAINED_CATEGORY"], [14112, 14139, "TRAINED_CATEGORY"], [14162, 14191, "TRAINED_CATEGORY"], [14193, 14204, "TRAINED_CATEGORY"], [14209, 14228, "TRAINED_CATEGORY"], [14230, 14241, "TRAINED_CATEGORY"], [14247, 14262, "TRAINED_CATEGORY"], [14285, 14296, "TRAINED_CATEGORY"], [14301, 14322, "TRAINED_CATEGORY"], [14327, 14338, "TRAINED_CATEGORY"], [14343, 14364, "TRAINED_CATEGORY"], [14369, 14392, "TRAINED_CATEGORY"], [14422, 14444, "TRAINED_CATEGORY"], [14446, 14457, "TRAINED_CATEGORY"], [14463, 14478, "TRAINED_CATEGORY"], [14502, 14513, "TRAINED_CATEGORY"], [14518, 14539, "TRAINED_CATEGORY"], [14544, 14555, "TRAINED_CATEGORY"], [14560, 14581, "TRAINED_CATEGORY"], [14586, 14609, "TRAINED_CATEGORY"], [14616, 14626, "TRAINED_CATEGORY"], [14630, 14650, "TRAINED_CATEGORY"], [14668, 14685, "TRAINED_CATEGORY"], [14687, 14702, "TRAINED_CATEGORY"], [14707, 14722, "TRAINED_CATEGORY"], [14737, 14743, "TRAINED_CATEGORY"], [14765, 14774, "TRAINED_CATEGORY"], [14778, 14787, "TRAINED_CATEGORY"], [14798, 14800, "TRAINED_CATEGORY"], [14832, 14847, "TRAINED_CATEGORY"], [14852, 14867, "TRAINED_CATEGORY"], [14875, 14897, "TRAINED_CATEGORY"], [14907, 14920, "TRAINED_CATEGORY"], [14924, 14957, "TRAINED_CATEGORY"], [14963, 15002, "TRAINED_CATEGORY"], [15006, 15033, "TRAINED_CATEGORY"], [15064, 15080, "TRAINED_CATEGORY"], [15174, 15177, "TRAINED_CATEGORY"], [15213, 15214, "TRAINED_CATEGORY"], [15463, 15464, "TRAINED_CATEGORY"], [15595, 15596, "TRAINED_CATEGORY"], [15801, 15804, "TRAINED_CATEGORY"], [15840, 15841, "TRAINED_CATEGORY"], [16222, 16223, "TRAINED_CATEGORY"], [16429, 16436, "TRAINED_CATEGORY"], [17420, 17421, "TRAINED_CATEGORY"], [17937, 17938, "TRAINED_CATEGORY"], [18501, 18502, "TRAINED_CATEGORY"], [18600, 18634, "TRAINED_CATEGORY"], [18641, 18642, "TRAINED_CATEGORY"], [18642, 18661, "TRAINED_CATEGORY"], [18712, 18728, "TRAINED_CATEGORY"], [18846, 18852, "TRAINED_CATEGORY"], [18856, 18874, "TRAINED_CATEGORY"], [18876, 18877, "TRAINED_CATEGORY"], [18883, 18885, "TRAINED_CATEGORY"], [18896, 18927, "TRAINED_CATEGORY"], [18943, 18959, "TRAINED_CATEGORY"], [18968, 18992, "TRAINED_CATEGORY"], [19004, 19021, "TRAINED_CATEGORY"], [19023, 19025, "TRAINED_CATEGORY"], [19043, 19053, "TRAINED_CATEGORY"], [19064, 19085, "TRAINED_CATEGORY"], [19094, 19111, "TRAINED_CATEGORY"], [19113, 19115, "TRAINED_CATEGORY"], [19139, 19154, "TRAINED_CATEGORY"], [19158, 19169, "TRAINED_CATEGORY"], [19173, 19190, "TRAINED_CATEGORY"], [19208, 19217, "TRAINED_CATEGORY"], [19221, 19238, "TRAINED_CATEGORY"], [19240, 19242, "TRAINED_CATEGORY"], [19270, 19285, "TRAINED_CATEGORY"], [19299, 19326, "TRAINED_CATEGORY"], [19332, 19347, "TRAINED_CATEGORY"], [19349, 19352, "TRAINED_CATEGORY"], [19382, 19396, "TRAINED_CATEGORY"], [19400, 19405, "TRAINED_CATEGORY"], [19417, 19436, "TRAINED_CATEGORY"], [19445, 19459, "TRAINED_CATEGORY"], [19461, 19478, "TRAINED_CATEGORY"], [19501, 19516, "TRAINED_CATEGORY"], [19544, 19550, "TRAINED_CATEGORY"], [19567, 19570, "TRAINED_CATEGORY"], [19577, 19586, "TRAINED_CATEGORY"], [19615, 19620, "TRAINED_CATEGORY"], [19623, 19625, "TRAINED_CATEGORY"], [19628, 19632, "TRAINED_CATEGORY"], [19635, 19657, "TRAINED_CATEGORY"], [19660, 19665, "TRAINED_CATEGORY"], [19674, 19678, "TRAINED_CATEGORY"], [19679, 19682, "TRAINED_CATEGORY"], [19691, 19710, "TRAINED_CATEGORY"], [19726, 19732, "TRAINED_CATEGORY"], [19737, 19739, "TRAINED_CATEGORY"], [19760, 19783, "TRAINED_CATEGORY"], [19802, 19821, "TRAINED_CATEGORY"], [19825, 19843, "TRAINED_CATEGORY"], [19848, 19867, "TRAINED_CATEGORY"], [19869, 19890, "TRAINED_CATEGORY"], [19894, 19912, "TRAINED_CATEGORY"], [19925, 19932, "TRAINED_CATEGORY"], [19936, 19955, "TRAINED_CATEGORY"], [19961, 19982, "TRAINED_CATEGORY"], [19991, 20001, "TRAINED_CATEGORY"], [20002, 20024, "TRAINED_CATEGORY"], [20039, 20051, "TRAINED_CATEGORY"], [20064, 20086, "TRAINED_CATEGORY"], [20089, 20091, "TRAINED_CATEGORY"], [20120, 20138, "TRAINED_CATEGORY"], [20152, 20167, "TRAINED_CATEGORY"], [20171, 20193, "TRAINED_CATEGORY"], [20202, 20221, "TRAINED_CATEGORY"], [20235, 20260, "TRAINED_CATEGORY"], [20272, 20276, "TRAINED_CATEGORY"], [20278, 20282, "TRAINED_CATEGORY"], [20285, 20290, "TRAINED_CATEGORY"], [20300, 20302, "TRAINED_CATEGORY"], [20311, 20332, "TRAINED_CATEGORY"], [20338, 20356, "TRAINED_CATEGORY"], [20372, 20386, "TRAINED_CATEGORY"], [20392, 20409, "TRAINED_CATEGORY"], [20425, 20446, "TRAINED_CATEGORY"], [20453, 20465, "TRAINED_CATEGORY"], [20469, 20507, "TRAINED_CATEGORY"], [20511, 20539, "TRAINED_CATEGORY"], [20542, 20575, "TRAINED_CATEGORY"], [20586, 20599, "TRAINED_CATEGORY"], [20603, 20610, "TRAINED_CATEGORY"], [20614, 20633, "TRAINED_CATEGORY"], [20636, 20655, "TRAINED_CATEGORY"], [20672, 20685, "TRAINED_CATEGORY"], [20691, 20714, "TRAINED_CATEGORY"], [20719, 20730, "TRAINED_CATEGORY"], [20757, 20768, "TRAINED_CATEGORY"], [20787, 20789, "TRAINED_CATEGORY"], [20804, 20818, "TRAINED_CATEGORY"], [20823, 20826, "TRAINED_CATEGORY"], [20836, 20842, "TRAINED_CATEGORY"], [20843, 20846, "TRAINED_CATEGORY"], [20857, 20860, "TRAINED_CATEGORY"], [20861, 20866, "TRAINED_CATEGORY"], [20875, 20886, "TRAINED_CATEGORY"], [20888, 20901, "TRAINED_CATEGORY"], [20929, 20962, "TRAINED_CATEGORY"], [20967, 20982, "TRAINED_CATEGORY"], [20999, 21005, "TRAINED_CATEGORY"], [21020, 21026, "TRAINED_CATEGORY"], [21031, 21050, "TRAINED_CATEGORY"], [21053, 21085, "TRAINED_CATEGORY"], [21087, 21097, "TRAINED_CATEGORY"], [21105, 21138, "TRAINED_CATEGORY"], [21152, 21169, "TRAINED_CATEGORY"], [21175, 21193, "TRAINED_CATEGORY"], [21207, 21211, "TRAINED_CATEGORY"], [21215, 21233, "TRAINED_CATEGORY"], [21236, 21240, "TRAINED_CATEGORY"], [21248, 21268, "TRAINED_CATEGORY"], [21285, 21302, "TRAINED_CATEGORY"], [21311, 21344, "TRAINED_CATEGORY"], [21347, 21411, "TRAINED_CATEGORY"], [21421, 21443, "TRAINED_CATEGORY"], [21454, 21473, "TRAINED_CATEGORY"], [21485, 21500, "TRAINED_CATEGORY"], [21517, 21530, "TRAINED_CATEGORY"], [21548, 21550, "TRAINED_CATEGORY"], [21565, 21590, "TRAINED_CATEGORY"], [21595, 21602, "TRAINED_CATEGORY"], [21604, 21605, "TRAINED_CATEGORY"], [21610, 21611, "TRAINED_CATEGORY"], [21616, 21626, "TRAINED_CATEGORY"], [21629, 21640, "TRAINED_CATEGORY"], [21643, 21646, "TRAINED_CATEGORY"], [21647, 21649, "TRAINED_CATEGORY"], [21651, 21655, "TRAINED_CATEGORY"], [21669, 21672, "TRAINED_CATEGORY"], [21673, 21674, "TRAINED_CATEGORY"], [21675, 21679, "TRAINED_CATEGORY"], [21680, 21712, "TRAINED_CATEGORY"], [21736, 21745, "TRAINED_CATEGORY"], [21774, 21796, "TRAINED_CATEGORY"], [21798, 21807, "TRAINED_CATEGORY"], [21843, 21858, "TRAINED_CATEGORY"], [21862, 21884, "TRAINED_CATEGORY"], [21917, 21938, "TRAINED_CATEGORY"], [21940, 21946, "TRAINED_CATEGORY"], [21966, 21982, "TRAINED_CATEGORY"], [21984, 21986, "TRAINED_CATEGORY"], [21992, 22011, "TRAINED_CATEGORY"], [22013, 22015, "TRAINED_CATEGORY"], [22036, 22059, "TRAINED_CATEGORY"], [22061, 22063, "TRAINED_CATEGORY"], [22068, 22070, "TRAINED_CATEGORY"], [22092, 22105, "TRAINED_CATEGORY"], [22114, 22149, "TRAINED_CATEGORY"], [22196, 22227, "TRAINED_CATEGORY"], [22245, 22260, "TRAINED_CATEGORY"], [22264, 22286, "TRAINED_CATEGORY"], [22316, 22329, "TRAINED_CATEGORY"], [22334, 22351, "TRAINED_CATEGORY"], [22355, 22362, "TRAINED_CATEGORY"], [22390, 22403, "TRAINED_CATEGORY"], [22413, 22443, "TRAINED_CATEGORY"], [22450, 22470, "TRAINED_CATEGORY"], [22479, 22496, "TRAINED_CATEGORY"], [22502, 22506, "TRAINED_CATEGORY"], [22512, 22518, "TRAINED_CATEGORY"], [22520, 22528, "TRAINED_CATEGORY"], [22530, 22542, "TRAINED_CATEGORY"], [22547, 22559, "TRAINED_CATEGORY"], [22561, 22617, "TRAINED_CATEGORY"], [22618, 22641, "TRAINED_CATEGORY"], [22643, 22654, "TRAINED_CATEGORY"], [22658, 22677, "TRAINED_CATEGORY"], [22696, 22716, "TRAINED_CATEGORY"], [22743, 22789, "TRAINED_CATEGORY"], [22791, 22796, "TRAINED_CATEGORY"], [22801, 22807, "TRAINED_CATEGORY"], [22815, 22817, "TRAINED_CATEGORY"], [22822, 22828, "TRAINED_CATEGORY"], [22837, 22864, "TRAINED_CATEGORY"], [22866, 22872, "TRAINED_CATEGORY"], [22876, 22887, "TRAINED_CATEGORY"], [22903, 22909, "TRAINED_CATEGORY"], [22913, 22928, "TRAINED_CATEGORY"], [22929, 22945, "TRAINED_CATEGORY"], [22953, 22962, "TRAINED_CATEGORY"], [22964, 22968, "TRAINED_CATEGORY"], [22973, 22981, "TRAINED_CATEGORY"], [22989, 22995, "TRAINED_CATEGORY"], [23000, 23009, "TRAINED_CATEGORY"], [23017, 23025, "TRAINED_CATEGORY"], [23030, 23039, "TRAINED_CATEGORY"], [23048, 23069, "TRAINED_CATEGORY"], [23073, 23096, "TRAINED_CATEGORY"], [23109, 23132, "TRAINED_CATEGORY"], [23133, 23144, "TRAINED_CATEGORY"], [23155, 23176, "TRAINED_CATEGORY"], [23181, 23186, "TRAINED_CATEGORY"], [23204, 23223, "TRAINED_CATEGORY"], [23229, 23240, "TRAINED_CATEGORY"], [23242, 23257, "TRAINED_CATEGORY"], [23277, 23310, "TRAINED_CATEGORY"], [23327, 23334, "TRAINED_CATEGORY"], [23339, 23345, "TRAINED_CATEGORY"], [23354, 23373, "TRAINED_CATEGORY"], [23374, 23384, "TRAINED_CATEGORY"], [23404, 23409, "TRAINED_CATEGORY"], [23420, 23432, "TRAINED_CATEGORY"], [23436, 23456, "TRAINED_CATEGORY"], [23460, 23464, "TRAINED_CATEGORY"], [23466, 23475, "TRAINED_CATEGORY"], [23487, 23507, "TRAINED_CATEGORY"], [23527, 23541, "TRAINED_CATEGORY"], [23543, 23576, "TRAINED_CATEGORY"], [23577, 23600, "TRAINED_CATEGORY"], [23604, 23619, "TRAINED_CATEGORY"], [23654, 23684, "TRAINED_CATEGORY"], [23696, 23701, "TRAINED_CATEGORY"], [23702, 23718, "TRAINED_CATEGORY"], [23720, 23750, "TRAINED_CATEGORY"], [23768, 23777, "TRAINED_CATEGORY"], [23778, 23784, "TRAINED_CATEGORY"], [23785, 23811, "TRAINED_CATEGORY"], [23816, 23858, "TRAINED_CATEGORY"], [23870, 23876, "TRAINED_CATEGORY"], [23881, 23887, "TRAINED_CATEGORY"], [23896, 23909, "TRAINED_CATEGORY"], [23910, 23927, "TRAINED_CATEGORY"], [23939, 23947, "TRAINED_CATEGORY"], [23956, 23988, "TRAINED_CATEGORY"], [23992, 24010, "TRAINED_CATEGORY"], [24030, 24036, "TRAINED_CATEGORY"], [24044, 24057, "TRAINED_CATEGORY"], [24059, 24069, "TRAINED_CATEGORY"], [24092, 24103, "TRAINED_CATEGORY"], [24104, 24108, "TRAINED_CATEGORY"], [24117, 24164, "TRAINED_CATEGORY"], [24166, 24169, "TRAINED_CATEGORY"], [24171, 24185, "TRAINED_CATEGORY"], [24197, 24218, "TRAINED_CATEGORY"], [24231, 24233, "TRAINED_CATEGORY"], [24243, 24252, "TRAINED_CATEGORY"], [24271, 24313, "TRAINED_CATEGORY"], [24318, 24345, "TRAINED_CATEGORY"], [24357, 24379, "TRAINED_CATEGORY"], [24385, 24399, "TRAINED_CATEGORY"], [24413, 24421, "TRAINED_CATEGORY"], [24440, 24452, "TRAINED_CATEGORY"], [24456, 24465, "TRAINED_CATEGORY"], [24482, 24502, "TRAINED_CATEGORY"], [24504, 24512, "TRAINED_CATEGORY"], [24520, 24528, "TRAINED_CATEGORY"], [24533, 24536, "TRAINED_CATEGORY"], [24571, 24578, "TRAINED_CATEGORY"], [24594, 24616, "TRAINED_CATEGORY"], [24622, 24642, "TRAINED_CATEGORY"], [24646, 24660, "TRAINED_CATEGORY"], [24666, 24669, "TRAINED_CATEGORY"], [24674, 24682, "TRAINED_CATEGORY"], [24691, 24717, "TRAINED_CATEGORY"], [24719, 24722, "TRAINED_CATEGORY"], [24724, 24731, "TRAINED_CATEGORY"], [24749, 24769, "TRAINED_CATEGORY"], [24775, 24786, "TRAINED_CATEGORY"], [24790, 24801, "TRAINED_CATEGORY"], [24808, 24826, "TRAINED_CATEGORY"], [24837, 24860, "TRAINED_CATEGORY"], [24864, 24884, "TRAINED_CATEGORY"], [24888, 24908, "TRAINED_CATEGORY"], [24910, 24917, "TRAINED_CATEGORY"], [24927, 24944, "TRAINED_CATEGORY"], [24948, 24964, "TRAINED_CATEGORY"], [24966, 24973, "TRAINED_CATEGORY"], [24977, 24987, "TRAINED_CATEGORY"], [25018, 25025, "TRAINED_CATEGORY"], [25030, 25046, "TRAINED_CATEGORY"], [25048, 25053, "TRAINED_CATEGORY"], [25062, 25081, "TRAINED_CATEGORY"], [25091, 25101, "TRAINED_CATEGORY"], [25111, 25129, "TRAINED_CATEGORY"], [25153, 25166, "TRAINED_CATEGORY"], [25168, 25171, "TRAINED_CATEGORY"], [25182, 25215, "TRAINED_CATEGORY"], [25234, 25250, "TRAINED_CATEGORY"], [25254, 25272, "TRAINED_CATEGORY"], [25283, 25285, "TRAINED_CATEGORY"], [25300, 25326, "TRAINED_CATEGORY"], [25360, 25362, "TRAINED_CATEGORY"], [25374, 25389, "TRAINED_CATEGORY"], [25393, 25401, "TRAINED_CATEGORY"], [25405, 25436, "TRAINED_CATEGORY"], [25438, 25452, "TRAINED_CATEGORY"], [25462, 25477, "TRAINED_CATEGORY"], [25481, 25496, "TRAINED_CATEGORY"], [25500, 25519, "TRAINED_CATEGORY"], [25528, 25538, "TRAINED_CATEGORY"], [25540, 25552, "TRAINED_CATEGORY"], [25580, 25586, "TRAINED_CATEGORY"], [25588, 25603, "TRAINED_CATEGORY"], [25605, 25627, "TRAINED_CATEGORY"], [25629, 25644, "TRAINED_CATEGORY"], [25646, 25659, "TRAINED_CATEGORY"], [25661, 25687, "TRAINED_CATEGORY"], [25689, 25699, "TRAINED_CATEGORY"], [25701, 25708, "TRAINED_CATEGORY"], [25713, 25724, "TRAINED_CATEGORY"], [25726, 25750, "TRAINED_CATEGORY"], [25758, 25770, "TRAINED_CATEGORY"], [25775, 25801, "TRAINED_CATEGORY"], [25850, 25886, "TRAINED_CATEGORY"], [25888, 25927, "TRAINED_CATEGORY"], [25929, 25933, "TRAINED_CATEGORY"], [25935, 25961, "TRAINED_CATEGORY"], [25963, 25966, "TRAINED_CATEGORY"], [25968, 25992, "TRAINED_CATEGORY"], [25994, 25997, "TRAINED_CATEGORY"], [25999, 26019, "TRAINED_CATEGORY"], [26020, 26041, "TRAINED_CATEGORY"], [26043, 26046, "TRAINED_CATEGORY"], [26048, 26065, "TRAINED_CATEGORY"], [26067, 26070, "TRAINED_CATEGORY"], [26072, 26077, "TRAINED_CATEGORY"], [26078, 26090, "TRAINED_CATEGORY"], [26091, 26113, "TRAINED_CATEGORY"], [26121, 26127, "TRAINED_CATEGORY"], [26129, 26137, "TRAINED_CATEGORY"], [26141, 26151, "TRAINED_CATEGORY"], [26152, 26156, "TRAINED_CATEGORY"], [26158, 26183, "TRAINED_CATEGORY"], [26184, 26199, "TRAINED_CATEGORY"], [26200, 26204, "TRAINED_CATEGORY"], [26206, 26220, "TRAINED_CATEGORY"], [26223, 26245, "TRAINED_CATEGORY"], [26246, 26266, "TRAINED_CATEGORY"], [26268, 26297, "TRAINED_CATEGORY"], [26299, 26333, "TRAINED_CATEGORY"], [26335, 26339, "TRAINED_CATEGORY"], [26341, 26348, "TRAINED_CATEGORY"], [26349, 26360, "TRAINED_CATEGORY"], [26362, 26372, "TRAINED_CATEGORY"], [26382, 26390, "TRAINED_CATEGORY"], [26396, 26412, "TRAINED_CATEGORY"], [26413, 26418, "TRAINED_CATEGORY"], [26420, 26449, "TRAINED_CATEGORY"], [26451, 26453, "TRAINED_CATEGORY"], [26455, 26471, "TRAINED_CATEGORY"], [26473, 26475, "TRAINED_CATEGORY"], [26477, 26501, "TRAINED_CATEGORY"], [26503, 26506, "TRAINED_CATEGORY"], [26508, 26521, "TRAINED_CATEGORY"], [26525, 26532, "TRAINED_CATEGORY"], [26534, 26537, "TRAINED_CATEGORY"], [26549, 26563, "TRAINED_CATEGORY"], [26567, 26607, "TRAINED_CATEGORY"], [26609, 26616, "TRAINED_CATEGORY"], [26618, 26657, "TRAINED_CATEGORY"], [26659, 26664, "TRAINED_CATEGORY"], [26667, 26677, "TRAINED_CATEGORY"], [26678, 26708, "TRAINED_CATEGORY"], [26710, 26715, "TRAINED_CATEGORY"], [26717, 26749, "TRAINED_CATEGORY"], [26753, 26760, "TRAINED_CATEGORY"], [26761, 26767, "TRAINED_CATEGORY"], [26769, 26799, "TRAINED_CATEGORY"], [26801, 26805, "TRAINED_CATEGORY"], [26807, 26835, "TRAINED_CATEGORY"], [26837, 26841, "TRAINED_CATEGORY"], [26843, 26883, "TRAINED_CATEGORY"], [26884, 26896, "TRAINED_CATEGORY"], [26900, 26909, "TRAINED_CATEGORY"], [26911, 26915, "TRAINED_CATEGORY"], [26917, 26960, "TRAINED_CATEGORY"], [26962, 26968, "TRAINED_CATEGORY"], [26970, 27003, "TRAINED_CATEGORY"], [27007, 27032, "TRAINED_CATEGORY"], [27034, 27041, "TRAINED_CATEGORY"], [27043, 27052, "TRAINED_CATEGORY"], [27053, 27064, "TRAINED_CATEGORY"], [27083, 27097, "TRAINED_CATEGORY"], [27105, 27152, "TRAINED_CATEGORY"], [27153, 27158, "TRAINED_CATEGORY"], [27188, 27202, "TRAINED_CATEGORY"], [27216, 27225, "TRAINED_CATEGORY"], [27230, 27239, "TRAINED_CATEGORY"], [27243, 27257, "TRAINED_CATEGORY"], [27261, 27271, "TRAINED_CATEGORY"], [27275, 27289, "TRAINED_CATEGORY"], [27290, 27297, "TRAINED_CATEGORY"], [27299, 27313, "TRAINED_CATEGORY"], [27315, 27317, "TRAINED_CATEGORY"], [27319, 27336, "TRAINED_CATEGORY"], [27337, 27340, "TRAINED_CATEGORY"], [27342, 27354, "TRAINED_CATEGORY"], [27355, 27377, "TRAINED_CATEGORY"], [27379, 27382, "TRAINED_CATEGORY"], [27384, 27402, "TRAINED_CATEGORY"], [27404, 27407, "TRAINED_CATEGORY"], [27409, 27463, "TRAINED_CATEGORY"], [27465, 27470, "TRAINED_CATEGORY"], [27489, 27526, "TRAINED_CATEGORY"], [27543, 27567, "TRAINED_CATEGORY"], [27568, 27591, "TRAINED_CATEGORY"], [27592, 27616, "TRAINED_CATEGORY"], [27617, 27654, "TRAINED_CATEGORY"], [27655, 27669, "TRAINED_CATEGORY"], [27689, 27700, "TRAINED_CATEGORY"], [27705, 27716, "TRAINED_CATEGORY"], [27717, 27731, "TRAINED_CATEGORY"], [27737, 27747, "TRAINED_CATEGORY"], [27756, 27771, "TRAINED_CATEGORY"], [27775, 27782, "TRAINED_CATEGORY"], [27784, 27786, "TRAINED_CATEGORY"], [27796, 27826, "TRAINED_CATEGORY"], [27828, 27863, "TRAINED_CATEGORY"], [27866, 27873, "TRAINED_CATEGORY"], [27877, 27902, "TRAINED_CATEGORY"], [27911, 27941, "TRAINED_CATEGORY"], [27943, 27953, "TRAINED_CATEGORY"], [27955, 27966, "TRAINED_CATEGORY"], [27968, 27977, "TRAINED_CATEGORY"], [27987, 28000, "TRAINED_CATEGORY"], [28004, 28037, "TRAINED_CATEGORY"], [28044, 28086, "TRAINED_CATEGORY"], [28088, 28092, "TRAINED_CATEGORY"], [28095, 28100, "TRAINED_CATEGORY"], [28129, 28149, "TRAINED_CATEGORY"], [28160, 28162, "TRAINED_CATEGORY"], [28165, 28170, "TRAINED_CATEGORY"], [28180, 28192, "TRAINED_CATEGORY"], [28196, 28235, "TRAINED_CATEGORY"], [28239, 28252, "TRAINED_CATEGORY"], [28256, 28264, "TRAINED_CATEGORY"], [28264, 28270, "TRAINED_CATEGORY"], [28273, 28311, "TRAINED_CATEGORY"], [28313, 28328, "TRAINED_CATEGORY"], [28341, 28347, "TRAINED_CATEGORY"], [28352, 28358, "TRAINED_CATEGORY"], [28359, 28368, "TRAINED_CATEGORY"], [28370, 28372, "TRAINED_CATEGORY"], [28381, 28414, "TRAINED_CATEGORY"], [28420, 28439, "TRAINED_CATEGORY"], [28441, 28451, "TRAINED_CATEGORY"], [28454, 28458, "TRAINED_CATEGORY"], [214, 219, "DATE"], [1014, 1019, "DATE"], [1809, 1824, "DATE"], [2062, 2073, "PERSON"], [2216, 2230, "PERSON"], [2272, 2276, "DATE"], [3273, 3286, "CARDINAL"], [3651, 3663, "CARDINAL"], [4216, 4225, "DATE"], [4282, 4316, "ORG"], [4326, 4341, "WORK_OF_ART"], [4343, 4361, "ORG"], [4365, 4369, "ORG"], [4375, 4398, "ORG"], [4419, 4427, "PERSON"], [5128, 5130, "ORG"], [5173, 5176, "CARDINAL"], [5595, 5609, "ORG"], [5627, 5631, "DATE"], [6303, 6305, "ORG"], [6342, 6344, "ORG"], [7213, 7215, "ORG"], [7460, 7488, "WORK_OF_ART"], [7490, 7494, "DATE"], [7500, 7508, "PERSON"], [7513, 7519, "GPE"], [7521, 7525, "DATE"], [7553, 7559, "ORG"], [7561, 7565, "DATE"], [7926, 7928, "ORG"], [8031, 8040, "ORG"], [8045, 8053, "GPE"], [8055, 8059, "DATE"], [8321, 8328, "PERSON"], [8333, 8343, "PERSON"], [8345, 8349, "DATE"], [8746, 8776, "FAC"], [9471, 9479, "PERSON"], [10819, 10822, "PERSON"], [11108, 11109, "CARDINAL"], [12111, 12153, "PERSON"], [12219, 12229, "WORK_OF_ART"], [12682, 12686, "GPE"], [12689, 12692, "CARDINAL"], [12884, 12885, "CARDINAL"], [12970, 12975, "PERSON"], [13117, 13129, "PRODUCT"], [13326, 13328, "ORG"], [13500, 13501, "CARDINAL"], [13601, 13602, "CARDINAL"], [14741, 14743, "ORG"], [14875, 14888, "CARDINAL"], [14977, 14980, "CARDINAL"], [15463, 15464, "ORG"], [15541, 15542, "CARDINAL"], [15613, 15614, "CARDINAL"], [15691, 15692, "CARDINAL"], [15881, 15882, "CARDINAL"], [16090, 16091, "CARDINAL"], [16168, 16169, "CARDINAL"], [16222, 16223, "ORG"], [16300, 16301, "CARDINAL"], [16589, 16590, "CARDINAL"], [16708, 16709, "CARDINAL"], [16842, 16843, "CARDINAL"], [16961, 16962, "CARDINAL"], [17095, 17096, "CARDINAL"], [17227, 17228, "CARDINAL"], [17346, 17347, "CARDINAL"], [17420, 17421, "ORG"], [17498, 17499, "CARDINAL"], [17630, 17631, "CARDINAL"], [17749, 17750, "CARDINAL"], [17883, 17884, "CARDINAL"], [17937, 17938, "ORG"], [18015, 18016, "CARDINAL"], [18134, 18135, "CARDINAL"], [18268, 18269, "CARDINAL"], [18400, 18401, "CARDINAL"], [18519, 18520, "CARDINAL"], [18729, 18742, "ORG"], [18763, 18783, "CARDINAL"], [18784, 18823, "CARDINAL"], [18853, 18854, "CARDINAL"], [18900, 18905, "ORDINAL"], [18910, 18916, "ORDINAL"], [18974, 18977, "CARDINAL"], [19375, 19378, "CARDINAL"], [19567, 19570, "PERSON"], [19590, 19592, "CARDINAL"], [19601, 19603, "CARDINAL"], [19635, 19637, "ORG"], [19640, 19641, "CARDINAL"], [19733, 19734, "CARDINAL"], [19991, 20001, "GPE"], [20105, 20108, "CARDINAL"], [20124, 20129, "ORDINAL"], [20206, 20212, "ORDINAL"], [20278, 20290, "ORG"], [20836, 20842, "DATE"], [21087, 21097, "ORG"], [21099, 21103, "DATE"], [21595, 21602, "PERSON"], [21616, 21619, "PERSON"], [21675, 21679, "PERSON"], [21847, 21853, "ORDINAL"], [21947, 21948, "CARDINAL"], [21984, 21986, "ORG"], [22013, 22015, "PRODUCT"], [22061, 22063, "DATE"], [22068, 22070, "DATE"], [22249, 22255, "ORDINAL"], [22512, 22542, "ORG"], [22547, 22559, "PERSON"], [22619, 22620, "CARDINAL"], [22743, 22780, "ORG"], [22791, 22796, "NORP"], [22801, 22807, "ORG"], [22809, 22813, "DATE"], [22815, 22817, "ORG"], [22822, 22828, "GPE"], [22830, 22834, "DATE"], [22838, 22839, "CARDINAL"], [22930, 22945, "PERSON"], [22947, 22951, "DATE"], [22953, 22962, "ORG"], [22964, 22968, "PERSON"], [22973, 22981, "PERSON"], [22983, 22987, "DATE"], [23000, 23009, "ORG"], [23011, 23015, "DATE"], [23017, 23025, "GPE"], [23030, 23039, "GPE"], [23041, 23045, "DATE"], [23077, 23079, "ORG"], [23327, 23334, "ORG"], [23339, 23345, "PERSON"], [23404, 23409, "PERSON"], [23411, 23415, "DATE"], [23577, 23582, "ORG"], [23870, 23876, "PERSON"], [23881, 23887, "ORG"], [23889, 23893, "DATE"], [23896, 23902, "NORP"], [23914, 23920, "NORP"], [23974, 23981, "PERSON"], [24030, 24036, "GPE"], [24044, 24057, "DATE"], [24092, 24103, "PERSON"], [24105, 24108, "PERSON"], [24110, 24114, "DATE"], [24385, 24388, "CARDINAL"], [24504, 24512, "PERSON"], [24514, 24518, "DATE"], [24520, 24528, "PRODUCT"], [24533, 24536, "GPE"], [24538, 24542, "DATE"], [24666, 24669, "ORG"], [24674, 24682, "GPE"], [24684, 24688, "DATE"], [24691, 24699, "ORG"], [24719, 24722, "ORG"], [24728, 24731, "ORG"], [24914, 24917, "ORG"], [25055, 25059, "DATE"], [25168, 25171, "ORG"], [25258, 25262, "ORG"], [25646, 25652, "ORG"], [25726, 25731, "PERSON"], [25736, 25742, "ORG"], [25963, 25966, "ORG"], [25968, 25976, "ORG"], [25994, 25997, "ORG"], [25999, 26011, "ORG"], [26072, 26077, "PERSON"], [26078, 26084, "PERSON"], [26184, 26199, "WORK_OF_ART"], [26206, 26220, "PERSON"], [26247, 26250, "ORG"], [26253, 26258, "GPE"], [26260, 26266, "ORG"], [26335, 26339, "ORG"], [26477, 26481, "PERSON"], [26508, 26513, "NORP"], [26534, 26537, "ORG"], [26609, 26616, "PERSON"], [26618, 26657, "ORG"], [26659, 26664, "ORG"], [26667, 26708, "ORG"], [26717, 26760, "ORG"], [26762, 26767, "ORG"], [26769, 26774, "ORG"], [26801, 26805, "ORG"], [26807, 26812, "ORG"], [26837, 26841, "ORG"], [26843, 26876, "ORG"], [26911, 26915, "ORG"], [27020, 27032, "NORP"], [27034, 27041, "ORG"], [27099, 27103, "ORG"], [27204, 27207, "ORG"], [27315, 27317, "ORG"], [27409, 27434, "PERSON"], [27440, 27463, "PERSON"], [27775, 27782, "PERSON"], [27784, 27786, "PERSON"], [27788, 27792, "DATE"], [27866, 27902, "ORG"], [27904, 27905, "CARDINAL"], [27907, 27908, "CARDINAL"], [27911, 27917, "CARDINAL"], [27943, 27953, "PERSON"], [27955, 27966, "PERSON"], [27968, 27977, "PERSON"], [27979, 27983, "DATE"], [28102, 28104, "CARDINAL"], [28106, 28107, "CARDINAL"], [28110, 28116, "CARDINAL"], [28160, 28162, "PERSON"], [28173, 28177, "DATE"], [28282, 28304, "ORG"], [28306, 28311, "CARDINAL"], [28341, 28347, "ORG"], [28352, 28372, "ORG"], [28396, 28414, "ORG"], [28420, 28439, "PERSON"], [28441, 28458, "ORG"]]}], ["Pairwise comparison generally is any process of comparing entities in pairs to judge which of each entity is preferred, or has a greater amount of some quantitative property, or whether or not the two entities are identical. The method of pairwise comparison is used in the scientific study of preferences, attitudes, voting systems, social choice, public choice, requirements engineering and multiagent AI systems.  In psychology literature, it is often referred to as paired comparison.\nProminent psychometrician L. L. Thurstone first introduced a scientific approach to using pairwise comparisons for measurement in 1927, which he referred to as the law of comparative judgment. Thurstone linked this approach to psychophysical theory developed by Ernst Heinrich Weber and Gustav Fechner.  Thurstone demonstrated that the method can be used to order items along a dimension such as preference or importance using an interval-type scale.\n\n\n== Overview ==\nIf an individual or organization expresses a preference between two mutually distinct alternatives, this preference can be expressed as a pairwise comparison.  If the two alternatives are x and y, the following are the possible pairwise comparisons:\nThe agent prefers x over y: \"x > y\" or \"xPy\"\nThe agent prefers y over x: \"y > x\" or \"yPx\"\nThe agent is indifferent between both alternatives: \"x = y\" or \"xIy\"\n\n\n== Probabilistic models ==\nIn terms of modern psychometric theory probabilitistic models, which include Thurstone's approach (also called the law of comparative judgment),  the  Bradley\u2013Terry\u2013Luce (BTL) model, and general stochastic transitivity models, are more aptly regarded as a measurement models.  The Bradley\u2013Terry\u2013Luce (BTL) model is often applied to pairwise comparison data to scale preferences. The BTL model is identical to Thurstone's model if the simple logistic function is used. Thurstone used the normal distribution in applications of the model. The simple logistic function varies by less than 0.01 from the cumulative normal ogive across the range, given an arbitrary scale factor.\nIn the BTL model, the probability that object j is judged to have more of an attribute than object i is:\n\n  \n    \n      \n        Pr\n        {\n        \n          X\n          \n            j\n            i\n          \n        \n        =\n        1\n        }\n        =\n        \n          \n            \n              e\n              \n                \n                  \n                    \u03b4\n                    \n                      j\n                    \n                  \n                \n                \u2212\n                \n                  \n                    \u03b4\n                    \n                      i\n                    \n                  \n                \n              \n            \n            \n              1\n              +\n              \n                e\n                \n                  \n                    \n                      \u03b4\n                      \n                        j\n                      \n                    \n                  \n                  \u2212\n                  \n                    \n                      \u03b4\n                      \n                        i\n                      \n                    \n                  \n                \n              \n            \n          \n        \n        =\n        \u03c3\n        (\n        \n          \u03b4\n          \n            j\n          \n        \n        \u2212\n        \n          \u03b4\n          \n            i\n          \n        \n        )\n        ,\n      \n    \n    {\\displaystyle \\Pr\\{X_{ji}=1\\}={\\frac {e^{{\\delta _{j}}-{\\delta _{i}}}}{1+e^{{\\delta _{j}}-{\\delta _{i}}}}}=\\sigma (\\delta _{j}-\\delta _{i}),}\n  where \n  \n    \n      \n        \n          \u03b4\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle \\delta _{i}}\n   is the scale location of object \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  ; \n  \n    \n      \n        \u03c3\n      \n    \n    {\\displaystyle \\sigma }\n   is the logistic function (the inverse of the logit). For example, the scale location might represent the perceived quality of a product, or the perceived weight of an object.\nThe BTL model, the Thurstonian model as well as the Rasch model for measurement are all closely related and belong to the same class of stochastic transitivity.\nThurstone used the method of pairwise comparisons as an approach to measuring perceived intensity of physical stimuli, attitudes, preferences, choices, and values. He also studied implications of the theory he developed for opinion polls and political voting (Thurstone, 1959).\n\n\n== Transitivity ==\nFor a given decision agent, if the information, objective, and alternatives used by the agent remain constant, then it is generally assumed that pairwise comparisons over those alternatives by the decision agent are transitive.  Most agree upon what transitivity is, though there is debate about the transitivity of indifference. The rules of transitivity are as follows for a given decision agent.\n\nIf xPy and yPz, then xPz\nIf xPy and yIz, then xPz\nIf xIy and yPz, then xPz\nIf xIy and yIz, then xIzThis corresponds to (xPy or xIy) being a total preorder, P being the corresponding strict weak order, and I being the corresponding equivalence relation.\nProbabilistic models also give rise to stochastic variants of transitivity, all of which can be verified to satisfy (non-stochastic) transitivity within the bounds of errors of estimates of scale locations of entities. Thus, decisions need not be deterministically transitive in order to apply probabilistic models. However, transitivity will generally hold for a large number of comparisons if models such as the BTL can be effectively applied.\nUsing a transitivity test one can investigate whether a data set of pairwise comparisons contains a higher degree of transitivity than expected by chance.\n\n\n== Argument for intransitivity of indifference ==\nSome contend that indifference is not transitive.  Consider the following example.  Suppose you like apples and you prefer apples that are larger.  Now suppose there exists an apple A, an apple B, and an apple C which have identical intrinsic characteristics except for the following. Suppose B is larger than A, but it is not discernible without an extremely sensitive scale.  Further suppose C is larger than B, but this also is not discernible without an extremely sensitive scale.  However, the difference in sizes between apples A and C is large enough that you can discern that C is larger than A without a sensitive scale. In psychophysical terms, the size difference between A and C is above the just noticeable difference ('jnd') while the size differences between A and B and B and C are below the jnd.\nYou are confronted with the three apples in pairs without the benefit of a sensitive scale.  Therefore, when presented A and B alone, you are indifferent between apple A and apple B; and you are indifferent between apple B and apple C when presented B and C alone.  However, when the pair A and C are shown, you prefer C over A.\n\n\n== Preference orders ==\nIf pairwise comparisons are in fact transitive in respect to the four mentioned rules, then pairwise comparisons for a list of alternatives (A1, A2, A3, ..., An\u22121, and An) can take the form:\n\nA1(>XOR=)A2(>XOR=)A3(>XOR=) ... (>XOR=)An\u22121(>XOR=)AnFor example, if there are three alternatives a, b, and c, then the possible preference orders are:\n\n  \n    \n      \n        a\n        >\n        b\n        >\n        c\n      \n    \n    {\\displaystyle a>b>c}\n  \n\n  \n    \n      \n        a\n        >\n        c\n        >\n        b\n      \n    \n    {\\displaystyle a>c>b}\n  \n\n  \n    \n      \n        b\n        >\n        a\n        >\n        c\n      \n    \n    {\\displaystyle b>a>c}\n  \n\n  \n    \n      \n        b\n        >\n        c\n        >\n        a\n      \n    \n    {\\displaystyle b>c>a}\n  \n\n  \n    \n      \n        c\n        >\n        a\n        >\n        b\n      \n    \n    {\\displaystyle c>a>b}\n  \n\n  \n    \n      \n        c\n        >\n        b\n        >\n        a\n      \n    \n    {\\displaystyle c>b>a}\n  \n\n  \n    \n      \n        a\n        >\n        b\n        =\n        c\n      \n    \n    {\\displaystyle a>b=c}\n  \n\n  \n    \n      \n        b\n        =\n        c\n        >\n        a\n      \n    \n    {\\displaystyle b=c>a}\n  \n\n  \n    \n      \n        b\n        >\n        a\n        =\n        c\n      \n    \n    {\\displaystyle b>a=c}\n  \n\n  \n    \n      \n        a\n        =\n        c\n        >\n        b\n      \n    \n    {\\displaystyle a=c>b}\n  \n\n  \n    \n      \n        c\n        >\n        a\n        =\n        b\n      \n    \n    {\\displaystyle c>a=b}\n  \n\n  \n    \n      \n        a\n        =\n        b\n        >\n        c\n      \n    \n    {\\displaystyle a=b>c}\n  \n\n  \n    \n      \n        a\n        =\n        b\n        =\n        c\n      \n    \n    {\\displaystyle a=b=c}\n  If the number of alternatives is n, and indifference is not allowed, then the number of possible preference orders for any given n-value is n!.  If indifference is allowed, then the number of possible preference orders is the number of total preorders. It can be expressed as a function of n:\n\n  \n    \n      \n        \n          \u2211\n          \n            k\n            =\n            1\n          \n          \n            n\n          \n        \n        k\n        !\n        \n          S\n          \n            2\n          \n        \n        (\n        n\n        ,\n        k\n        )\n        ,\n      \n    \n    {\\displaystyle \\sum _{k=1}^{n}k!S_{2}(n,k),}\n  where S2(n, k) is the Stirling number of the second kind.\n\n\n== Applications ==\nOne important application of pairwise comparisons is the widely used Analytic Hierarchy Process, a structured technique for helping people deal with complex decisions. It uses pairwise comparisons of tangible and intangible factors to construct ratio scales that are useful in making important decisions.\n\n\n== See also ==\nAnalytic Hierarchy Process\nLaw of comparative judgment\nPotentially all pairwise rankings of all possible alternatives (PAPRIKA) method\nPROMETHEE pairwise comparison method\nPreference (economics)\nStochastic Transitivity\nCondorcet method\n\n\n== References ==\n\nSloane, N. J. A. (ed.). \"Sequence A000142 (Factorial numbers)\". The On-Line Encyclopedia of Integer Sequences. OEIS Foundation.\nSloane, N. J. A. (ed.). \"Sequence A000670 (Number of preferential arrangements of n labeled elements)\". The On-Line Encyclopedia of Integer Sequences. OEIS Foundation.\nY. Chevaleyre, P.E. Dunne, U. Endriss, J. Lang, M. Lema\u00eetre, N. Maudet, J. Padget, S. Phelps, J.A. Rodr\u00edguez-Aguilar, and P. Sousa. Issues in Multiagent Resource Allocation. Informatica, 30:3\u201331, 2006.\n\n\n== Further reading ==\nBradley, R.A. and Terry, M.E. (1952). Rank analysis of incomplete block designs, I. the method of paired comparisons. Biometrika, 39, 324\u2013345.\nDavid, H.A. (1988). The Method of Paired Comparisons. New York: Oxford University Press.\nLuce, R.D. (1959). Individual Choice Behaviours: A Theoretical Analysis. New York: J. Wiley.\nThurstone, L.L. (1927).  A law of comparative judgement. Psychological Review, 34, 278\u2013286.\nThurstone, L.L. (1929).  The Measurement of Psychological Value.  In T.V. Smith and W.K. Wright (Eds.), Essays in Philosophy by Seventeen Doctors of Philosophy of the \tUniversity of Chicago.  Chicago: Open Court.\nThurstone, L.L. (1959).  The Measurement of Values.  Chicago: The University of Chicago Press.\nZermelo, E. (1928). Die Berechnung der Turnier-Ergebnisse als ein Maximumproblem der Wahrscheinlichkeitsrechnung, Mathematische Zeitschrift 29, 1929, S. 436\u2013460", {"entities": [[0, 19, "TRAINED_CATEGORY"], [33, 44, "TRAINED_CATEGORY"], [58, 66, "TRAINED_CATEGORY"], [70, 75, "TRAINED_CATEGORY"], [94, 105, "TRAINED_CATEGORY"], [127, 143, "TRAINED_CATEGORY"], [147, 173, "TRAINED_CATEGORY"], [193, 209, "TRAINED_CATEGORY"], [225, 235, "TRAINED_CATEGORY"], [239, 258, "TRAINED_CATEGORY"], [270, 290, "TRAINED_CATEGORY"], [294, 305, "TRAINED_CATEGORY"], [307, 316, "TRAINED_CATEGORY"], [318, 332, "TRAINED_CATEGORY"], [334, 347, "TRAINED_CATEGORY"], [349, 362, "TRAINED_CATEGORY"], [364, 376, "TRAINED_CATEGORY"], [377, 414, "TRAINED_CATEGORY"], [420, 441, "TRAINED_CATEGORY"], [443, 445, "TRAINED_CATEGORY"], [470, 487, "TRAINED_CATEGORY"], [489, 530, "TRAINED_CATEGORY"], [548, 569, "TRAINED_CATEGORY"], [579, 599, "TRAINED_CATEGORY"], [604, 615, "TRAINED_CATEGORY"], [631, 633, "TRAINED_CATEGORY"], [649, 656, "TRAINED_CATEGORY"], [660, 680, "TRAINED_CATEGORY"], [682, 691, "TRAINED_CATEGORY"], [699, 712, "TRAINED_CATEGORY"], [716, 737, "TRAINED_CATEGORY"], [751, 771, "TRAINED_CATEGORY"], [776, 790, "TRAINED_CATEGORY"], [793, 802, "TRAINED_CATEGORY"], [821, 831, "TRAINED_CATEGORY"], [853, 858, "TRAINED_CATEGORY"], [865, 876, "TRAINED_CATEGORY"], [885, 895, "TRAINED_CATEGORY"], [899, 909, "TRAINED_CATEGORY"], [916, 938, "TRAINED_CATEGORY"], [960, 973, "TRAINED_CATEGORY"], [977, 989, "TRAINED_CATEGORY"], [1000, 1012, "TRAINED_CATEGORY"], [1021, 1055, "TRAINED_CATEGORY"], [1057, 1072, "TRAINED_CATEGORY"], [1093, 1114, "TRAINED_CATEGORY"], [1120, 1140, "TRAINED_CATEGORY"], [1172, 1205, "TRAINED_CATEGORY"], [1207, 1216, "TRAINED_CATEGORY"], [1232, 1233, "TRAINED_CATEGORY"], [1252, 1261, "TRAINED_CATEGORY"], [1270, 1271, "TRAINED_CATEGORY"], [1281, 1282, "TRAINED_CATEGORY"], [1291, 1295, "TRAINED_CATEGORY"], [1297, 1306, "TRAINED_CATEGORY"], [1330, 1347, "TRAINED_CATEGORY"], [1350, 1355, "TRAINED_CATEGORY"], [1360, 1364, "TRAINED_CATEGORY"], [1371, 1391, "TRAINED_CATEGORY"], [1398, 1403, "TRAINED_CATEGORY"], [1407, 1456, "TRAINED_CATEGORY"], [1472, 1492, "TRAINED_CATEGORY"], [1506, 1513, "TRAINED_CATEGORY"], [1517, 1537, "TRAINED_CATEGORY"], [1554, 1559, "TRAINED_CATEGORY"], [1582, 1620, "TRAINED_CATEGORY"], [1649, 1669, "TRAINED_CATEGORY"], [1672, 1683, "TRAINED_CATEGORY"], [1684, 1689, "TRAINED_CATEGORY"], [1690, 1706, "TRAINED_CATEGORY"], [1736, 1751, "TRAINED_CATEGORY"], [1761, 1772, "TRAINED_CATEGORY"], [1774, 1787, "TRAINED_CATEGORY"], [1804, 1821, "TRAINED_CATEGORY"], [1825, 1853, "TRAINED_CATEGORY"], [1863, 1872, "TRAINED_CATEGORY"], [1878, 1901, "TRAINED_CATEGORY"], [1905, 1917, "TRAINED_CATEGORY"], [1921, 1930, "TRAINED_CATEGORY"], [1932, 1960, "TRAINED_CATEGORY"], [1991, 2018, "TRAINED_CATEGORY"], [2026, 2035, "TRAINED_CATEGORY"], [2043, 2068, "TRAINED_CATEGORY"], [2073, 2086, "TRAINED_CATEGORY"], [2116, 2117, "TRAINED_CATEGORY"], [2144, 2156, "TRAINED_CATEGORY"], [2162, 2168, "TRAINED_CATEGORY"], [2169, 2170, "TRAINED_CATEGORY"], [2199, 2201, "TRAINED_CATEGORY"], [2231, 2232, "TRAINED_CATEGORY"], [2256, 2257, "TRAINED_CATEGORY"], [2270, 2271, "TRAINED_CATEGORY"], [2379, 2380, "TRAINED_CATEGORY"], [2452, 2453, "TRAINED_CATEGORY"], [2572, 2573, "TRAINED_CATEGORY"], [2630, 2631, "TRAINED_CATEGORY"], [2675, 2676, "TRAINED_CATEGORY"], [2919, 2920, "TRAINED_CATEGORY"], [2968, 2969, "TRAINED_CATEGORY"], [3051, 3052, "TRAINED_CATEGORY"], [3115, 3116, "TRAINED_CATEGORY"], [3164, 3165, "TRAINED_CATEGORY"], [3312, 3313, "TRAINED_CATEGORY"], [3444, 3445, "TRAINED_CATEGORY"], [3540, 3616, "TRAINED_CATEGORY"], [3617, 3636, "TRAINED_CATEGORY"], [3688, 3689, "TRAINED_CATEGORY"], [3713, 3714, "TRAINED_CATEGORY"], [3775, 3776, "TRAINED_CATEGORY"], [3785, 3803, "TRAINED_CATEGORY"], [3807, 3813, "TRAINED_CATEGORY"], [3838, 3839, "TRAINED_CATEGORY"], [3871, 3872, "TRAINED_CATEGORY"], [3902, 3903, "TRAINED_CATEGORY"], [3950, 3971, "TRAINED_CATEGORY"], [3973, 3984, "TRAINED_CATEGORY"], [3988, 3997, "TRAINED_CATEGORY"], [4004, 4011, "TRAINED_CATEGORY"], [4013, 4031, "TRAINED_CATEGORY"], [4048, 4069, "TRAINED_CATEGORY"], [4073, 4082, "TRAINED_CATEGORY"], [4087, 4107, "TRAINED_CATEGORY"], [4111, 4120, "TRAINED_CATEGORY"], [4122, 4135, "TRAINED_CATEGORY"], [4137, 4158, "TRAINED_CATEGORY"], [4170, 4185, "TRAINED_CATEGORY"], [4190, 4201, "TRAINED_CATEGORY"], [4240, 4254, "TRAINED_CATEGORY"], [4258, 4281, "TRAINED_CATEGORY"], [4283, 4292, "TRAINED_CATEGORY"], [4298, 4308, "TRAINED_CATEGORY"], [4312, 4332, "TRAINED_CATEGORY"], [4336, 4347, "TRAINED_CATEGORY"], [4361, 4380, "TRAINED_CATEGORY"], [4384, 4400, "TRAINED_CATEGORY"], [4402, 4411, "TRAINED_CATEGORY"], [4413, 4424, "TRAINED_CATEGORY"], [4426, 4433, "TRAINED_CATEGORY"], [4439, 4445, "TRAINED_CATEGORY"], [4447, 4449, "TRAINED_CATEGORY"], [4463, 4475, "TRAINED_CATEGORY"], [4479, 4489, "TRAINED_CATEGORY"], [4490, 4492, "TRAINED_CATEGORY"], [4507, 4520, "TRAINED_CATEGORY"], [4525, 4541, "TRAINED_CATEGORY"], [4542, 4552, "TRAINED_CATEGORY"], [4566, 4578, "TRAINED_CATEGORY"], [4586, 4608, "TRAINED_CATEGORY"], [4613, 4628, "TRAINED_CATEGORY"], [4630, 4639, "TRAINED_CATEGORY"], [4645, 4657, "TRAINED_CATEGORY"], [4666, 4675, "TRAINED_CATEGORY"], [4698, 4700, "TRAINED_CATEGORY"], [4727, 4747, "TRAINED_CATEGORY"], [4753, 4771, "TRAINED_CATEGORY"], [4775, 4793, "TRAINED_CATEGORY"], [4827, 4844, "TRAINED_CATEGORY"], [4865, 4871, "TRAINED_CATEGORY"], [4878, 4894, "TRAINED_CATEGORY"], [4898, 4910, "TRAINED_CATEGORY"], [4912, 4921, "TRAINED_CATEGORY"], [4925, 4937, "TRAINED_CATEGORY"], [4957, 4979, "TRAINED_CATEGORY"], [4982, 5006, "TRAINED_CATEGORY"], [5007, 5031, "TRAINED_CATEGORY"], [5032, 5056, "TRAINED_CATEGORY"], [5078, 5085, "TRAINED_CATEGORY"], [5101, 5105, "TRAINED_CATEGORY"], [5109, 5112, "TRAINED_CATEGORY"], [5120, 5136, "TRAINED_CATEGORY"], [5138, 5139, "TRAINED_CATEGORY"], [5146, 5181, "TRAINED_CATEGORY"], [5187, 5188, "TRAINED_CATEGORY"], [5195, 5233, "TRAINED_CATEGORY"], [5235, 5255, "TRAINED_CATEGORY"], [5266, 5270, "TRAINED_CATEGORY"], [5274, 5293, "TRAINED_CATEGORY"], [5297, 5309, "TRAINED_CATEGORY"], [5351, 5380, "TRAINED_CATEGORY"], [5388, 5398, "TRAINED_CATEGORY"], [5402, 5408, "TRAINED_CATEGORY"], [5412, 5421, "TRAINED_CATEGORY"], [5425, 5440, "TRAINED_CATEGORY"], [5444, 5452, "TRAINED_CATEGORY"], [5460, 5469, "TRAINED_CATEGORY"], [5514, 5519, "TRAINED_CATEGORY"], [5529, 5549, "TRAINED_CATEGORY"], [5560, 5572, "TRAINED_CATEGORY"], [5597, 5611, "TRAINED_CATEGORY"], [5615, 5626, "TRAINED_CATEGORY"], [5630, 5636, "TRAINED_CATEGORY"], [5645, 5652, "TRAINED_CATEGORY"], [5687, 5706, "TRAINED_CATEGORY"], [5707, 5710, "TRAINED_CATEGORY"], [5735, 5745, "TRAINED_CATEGORY"], [5749, 5769, "TRAINED_CATEGORY"], [5779, 5794, "TRAINED_CATEGORY"], [5798, 5810, "TRAINED_CATEGORY"], [5828, 5834, "TRAINED_CATEGORY"], [5841, 5849, "TRAINED_CATEGORY"], [5854, 5868, "TRAINED_CATEGORY"], [5872, 5884, "TRAINED_CATEGORY"], [5906, 5918, "TRAINED_CATEGORY"], [5948, 5969, "TRAINED_CATEGORY"], [5980, 5983, "TRAINED_CATEGORY"], [5989, 5995, "TRAINED_CATEGORY"], [6000, 6003, "TRAINED_CATEGORY"], [6011, 6017, "TRAINED_CATEGORY"], [6061, 6071, "TRAINED_CATEGORY"], [6073, 6083, "TRAINED_CATEGORY"], [6089, 6099, "TRAINED_CATEGORY"], [6111, 6146, "TRAINED_CATEGORY"], [6158, 6171, "TRAINED_CATEGORY"], [6173, 6180, "TRAINED_CATEGORY"], [6181, 6182, "TRAINED_CATEGORY"], [6205, 6207, "TRAINED_CATEGORY"], [6235, 6263, "TRAINED_CATEGORY"], [6282, 6283, "TRAINED_CATEGORY"], [6299, 6300, "TRAINED_CATEGORY"], [6343, 6371, "TRAINED_CATEGORY"], [6401, 6406, "TRAINED_CATEGORY"], [6415, 6421, "TRAINED_CATEGORY"], [6428, 6429, "TRAINED_CATEGORY"], [6451, 6454, "TRAINED_CATEGORY"], [6472, 6473, "TRAINED_CATEGORY"], [6499, 6516, "TRAINED_CATEGORY"], [6521, 6541, "TRAINED_CATEGORY"], [6543, 6562, "TRAINED_CATEGORY"], [6571, 6572, "TRAINED_CATEGORY"], [6577, 6578, "TRAINED_CATEGORY"], [6588, 6618, "TRAINED_CATEGORY"], [6633, 6641, "TRAINED_CATEGORY"], [6662, 6663, "TRAINED_CATEGORY"], [6668, 6669, "TRAINED_CATEGORY"], [6674, 6675, "TRAINED_CATEGORY"], [6680, 6681, "TRAINED_CATEGORY"], [6692, 6699, "TRAINED_CATEGORY"], [6701, 6704, "TRAINED_CATEGORY"], [6725, 6741, "TRAINED_CATEGORY"], [6745, 6750, "TRAINED_CATEGORY"], [6759, 6770, "TRAINED_CATEGORY"], [6774, 6791, "TRAINED_CATEGORY"], [6820, 6821, "TRAINED_CATEGORY"], [6826, 6827, "TRAINED_CATEGORY"], [6835, 6838, "TRAINED_CATEGORY"], [6863, 6870, "TRAINED_CATEGORY"], [6875, 6882, "TRAINED_CATEGORY"], [6888, 6891, "TRAINED_CATEGORY"], [6916, 6923, "TRAINED_CATEGORY"], [6928, 6935, "TRAINED_CATEGORY"], [6951, 6952, "TRAINED_CATEGORY"], [6957, 6958, "TRAINED_CATEGORY"], [6981, 6989, "TRAINED_CATEGORY"], [6990, 6991, "TRAINED_CATEGORY"], [6996, 6997, "TRAINED_CATEGORY"], [7009, 7012, "TRAINED_CATEGORY"], [7020, 7021, "TRAINED_CATEGORY"], [7027, 7029, "TRAINED_CATEGORY"], [7035, 7052, "TRAINED_CATEGORY"], [7059, 7079, "TRAINED_CATEGORY"], [7087, 7091, "TRAINED_CATEGORY"], [7106, 7113, "TRAINED_CATEGORY"], [7117, 7141, "TRAINED_CATEGORY"], [7157, 7168, "TRAINED_CATEGORY"], [7173, 7179, "TRAINED_CATEGORY"], [7183, 7195, "TRAINED_CATEGORY"], [7197, 7199, "TRAINED_CATEGORY"], [7201, 7203, "TRAINED_CATEGORY"], [7205, 7207, "TRAINED_CATEGORY"], [7214, 7218, "TRAINED_CATEGORY"], [7237, 7245, "TRAINED_CATEGORY"], [7326, 7344, "TRAINED_CATEGORY"], [7345, 7349, "TRAINED_CATEGORY"], [7355, 7356, "TRAINED_CATEGORY"], [7363, 7393, "TRAINED_CATEGORY"], [7443, 7444, "TRAINED_CATEGORY"], [7463, 7464, "TRAINED_CATEGORY"], [7570, 7571, "TRAINED_CATEGORY"], [7603, 7638, "TRAINED_CATEGORY"], [7657, 7678, "TRAINED_CATEGORY"], [7696, 7711, "TRAINED_CATEGORY"], [7764, 7765, "TRAINED_CATEGORY"], [7821, 7852, "TRAINED_CATEGORY"], [7891, 7892, "TRAINED_CATEGORY"], [7910, 7925, "TRAINED_CATEGORY"], [7926, 7959, "TRAINED_CATEGORY"], [7978, 7979, "TRAINED_CATEGORY"], [8105, 8106, "TRAINED_CATEGORY"], [8138, 8173, "TRAINED_CATEGORY"], [8192, 8193, "TRAINED_CATEGORY"], [8319, 8320, "TRAINED_CATEGORY"], [8338, 8353, "TRAINED_CATEGORY"], [8386, 8407, "TRAINED_CATEGORY"], [8426, 8427, "TRAINED_CATEGORY"], [8459, 8460, "TRAINED_CATEGORY"], [8463, 8494, "TRAINED_CATEGORY"], [8533, 8534, "TRAINED_CATEGORY"], [8566, 8567, "TRAINED_CATEGORY"], [8620, 8621, "TRAINED_CATEGORY"], [8640, 8641, "TRAINED_CATEGORY"], [8673, 8676, "TRAINED_CATEGORY"], [8727, 8728, "TRAINED_CATEGORY"], [8747, 8748, "TRAINED_CATEGORY"], [8780, 8785, "TRAINED_CATEGORY"], [8792, 8802, "TRAINED_CATEGORY"], [8806, 8818, "TRAINED_CATEGORY"], [8822, 8823, "TRAINED_CATEGORY"], [8829, 8841, "TRAINED_CATEGORY"], [8863, 8873, "TRAINED_CATEGORY"], [8877, 8903, "TRAINED_CATEGORY"], [8908, 8925, "TRAINED_CATEGORY"], [8937, 8949, "TRAINED_CATEGORY"], [8967, 8977, "TRAINED_CATEGORY"], [8981, 9007, "TRAINED_CATEGORY"], [9011, 9021, "TRAINED_CATEGORY"], [9025, 9040, "TRAINED_CATEGORY"], [9042, 9044, "TRAINED_CATEGORY"], [9065, 9075, "TRAINED_CATEGORY"], [9079, 9080, "TRAINED_CATEGORY"], [9142, 9143, "TRAINED_CATEGORY"], [9236, 9237, "TRAINED_CATEGORY"], [9267, 9268, "TRAINED_CATEGORY"], [9443, 9447, "TRAINED_CATEGORY"], [9449, 9450, "TRAINED_CATEGORY"], [9455, 9474, "TRAINED_CATEGORY"], [9478, 9493, "TRAINED_CATEGORY"], [9500, 9512, "TRAINED_CATEGORY"], [9516, 9541, "TRAINED_CATEGORY"], [9545, 9565, "TRAINED_CATEGORY"], [9569, 9611, "TRAINED_CATEGORY"], [9613, 9635, "TRAINED_CATEGORY"], [9648, 9654, "TRAINED_CATEGORY"], [9665, 9682, "TRAINED_CATEGORY"], [9684, 9686, "TRAINED_CATEGORY"], [9701, 9712, "TRAINED_CATEGORY"], [9716, 9747, "TRAINED_CATEGORY"], [9761, 9773, "TRAINED_CATEGORY"], [9800, 9819, "TRAINED_CATEGORY"], [9838, 9864, "TRAINED_CATEGORY"], [9865, 9868, "TRAINED_CATEGORY"], [9872, 9892, "TRAINED_CATEGORY"], [9893, 9917, "TRAINED_CATEGORY"], [9918, 9926, "TRAINED_CATEGORY"], [9930, 9955, "TRAINED_CATEGORY"], [9956, 9972, "TRAINED_CATEGORY"], [9973, 9982, "TRAINED_CATEGORY"], [9992, 10009, "TRAINED_CATEGORY"], [10010, 10020, "TRAINED_CATEGORY"], [10022, 10031, "TRAINED_CATEGORY"], [10033, 10056, "TRAINED_CATEGORY"], [10057, 10073, "TRAINED_CATEGORY"], [10079, 10089, "TRAINED_CATEGORY"], [10094, 10100, "TRAINED_CATEGORY"], [10102, 10110, "TRAINED_CATEGORY"], [10112, 10114, "TRAINED_CATEGORY"], [10119, 10135, "TRAINED_CATEGORY"], [10136, 10154, "TRAINED_CATEGORY"], [10164, 10169, "TRAINED_CATEGORY"], [10186, 10203, "TRAINED_CATEGORY"], [10205, 10220, "TRAINED_CATEGORY"], [10222, 10228, "TRAINED_CATEGORY"], [10230, 10238, "TRAINED_CATEGORY"], [10240, 10242, "TRAINED_CATEGORY"], [10247, 10263, "TRAINED_CATEGORY"], [10265, 10271, "TRAINED_CATEGORY"], [10275, 10300, "TRAINED_CATEGORY"], [10306, 10322, "TRAINED_CATEGORY"], [10332, 10337, "TRAINED_CATEGORY"], [10354, 10371, "TRAINED_CATEGORY"], [10373, 10388, "TRAINED_CATEGORY"], [10390, 10403, "TRAINED_CATEGORY"], [10405, 10415, "TRAINED_CATEGORY"], [10417, 10427, "TRAINED_CATEGORY"], [10429, 10436, "TRAINED_CATEGORY"], [10438, 10449, "TRAINED_CATEGORY"], [10451, 10460, "TRAINED_CATEGORY"], [10462, 10471, "TRAINED_CATEGORY"], [10473, 10482, "TRAINED_CATEGORY"], [10484, 10506, "TRAINED_CATEGORY"], [10512, 10520, "TRAINED_CATEGORY"], [10522, 10528, "TRAINED_CATEGORY"], [10532, 10562, "TRAINED_CATEGORY"], [10564, 10575, "TRAINED_CATEGORY"], [10597, 10612, "TRAINED_CATEGORY"], [10616, 10623, "TRAINED_CATEGORY"], [10625, 10629, "TRAINED_CATEGORY"], [10634, 10639, "TRAINED_CATEGORY"], [10641, 10645, "TRAINED_CATEGORY"], [10654, 10667, "TRAINED_CATEGORY"], [10671, 10695, "TRAINED_CATEGORY"], [10697, 10699, "TRAINED_CATEGORY"], [10700, 10710, "TRAINED_CATEGORY"], [10714, 10732, "TRAINED_CATEGORY"], [10734, 10744, "TRAINED_CATEGORY"], [10759, 10764, "TRAINED_CATEGORY"], [10766, 10770, "TRAINED_CATEGORY"], [10779, 10789, "TRAINED_CATEGORY"], [10793, 10811, "TRAINED_CATEGORY"], [10813, 10821, "TRAINED_CATEGORY"], [10823, 10846, "TRAINED_CATEGORY"], [10848, 10852, "TRAINED_CATEGORY"], [10854, 10858, "TRAINED_CATEGORY"], [10867, 10895, "TRAINED_CATEGORY"], [10897, 10919, "TRAINED_CATEGORY"], [10921, 10929, "TRAINED_CATEGORY"], [10931, 10939, "TRAINED_CATEGORY"], [10941, 10950, "TRAINED_CATEGORY"], [10952, 10956, "TRAINED_CATEGORY"], [10966, 10971, "TRAINED_CATEGORY"], [10975, 10996, "TRAINED_CATEGORY"], [10998, 11018, "TRAINED_CATEGORY"], [11033, 11042, "TRAINED_CATEGORY"], [11044, 11048, "TRAINED_CATEGORY"], [11058, 11073, "TRAINED_CATEGORY"], [11077, 11096, "TRAINED_CATEGORY"], [11102, 11112, "TRAINED_CATEGORY"], [11117, 11128, "TRAINED_CATEGORY"], [11129, 11133, "TRAINED_CATEGORY"], [11135, 11143, "TRAINED_CATEGORY"], [11147, 11157, "TRAINED_CATEGORY"], [11161, 11178, "TRAINED_CATEGORY"], [11182, 11192, "TRAINED_CATEGORY"], [11196, 11211, "TRAINED_CATEGORY"], [11215, 11222, "TRAINED_CATEGORY"], [11225, 11232, "TRAINED_CATEGORY"], [11234, 11244, "TRAINED_CATEGORY"], [11246, 11255, "TRAINED_CATEGORY"], [11257, 11261, "TRAINED_CATEGORY"], [11271, 11286, "TRAINED_CATEGORY"], [11290, 11296, "TRAINED_CATEGORY"], [11299, 11306, "TRAINED_CATEGORY"], [11308, 11322, "TRAINED_CATEGORY"], [11326, 11339, "TRAINED_CATEGORY"], [11341, 11348, "TRAINED_CATEGORY"], [11350, 11352, "TRAINED_CATEGORY"], [11361, 11398, "TRAINED_CATEGORY"], [11403, 11453, "TRAINED_CATEGORY"], [11455, 11480, "TRAINED_CATEGORY"], [11491, 11493, "TRAINED_CATEGORY"], [197, 200, "CARDINAL"], [515, 530, "PERSON"], [619, 623, "DATE"], [682, 691, "PERSON"], [751, 771, "PERSON"], [776, 790, "ORG"], [793, 802, "PERSON"], [945, 953, "GPE"], [1021, 1024, "CARDINAL"], [1124, 1127, "CARDINAL"], [1361, 1364, "WORK_OF_ART"], [1371, 1384, "ORG"], [1472, 1481, "ORG"], [1546, 1553, "PERSON"], [1554, 1559, "PERSON"], [1566, 1569, "ORG"], [1676, 1683, "PERSON"], [1684, 1689, "PERSON"], [1696, 1699, "ORG"], [1778, 1781, "ORG"], [1804, 1813, "PERSON"], [1863, 1872, "PERSON"], [1971, 1985, "CARDINAL"], [2077, 2080, "ORG"], [3503, 3539, "WORK_OF_ART"], [3618, 3624, "PRODUCT"], [3625, 3626, "PRODUCT"], [3766, 3772, "PRODUCT"], [3921, 3947, "WORK_OF_ART"], [4126, 4129, "ORG"], [4141, 4152, "NORP"], [4174, 4179, "PERSON"], [4283, 4292, "PERSON"], [5035, 5038, "GPE"], [5043, 5046, "PERSON"], [5053, 5056, "WORK_OF_ART"], [5060, 5063, "PERSON"], [5068, 5071, "WORK_OF_ART"], [5109, 5112, "WORK_OF_ART"], [5649, 5652, "ORG"], [6729, 6734, "CARDINAL"], [7035, 7045, "NORP"], [7121, 7125, "CARDINAL"], [7205, 7207, "PERSON"], [7326, 7331, "CARDINAL"], [9170, 9171, "CARDINAL"], [9443, 9447, "PRODUCT"], [9482, 9488, "ORDINAL"], [9516, 9519, "CARDINAL"], [9957, 9964, "ORG"], [10033, 10056, "LOC"], [10094, 10100, "ORG"], [10102, 10110, "PERSON"], [10112, 10115, "GPE"], [10119, 10135, "WORK_OF_ART"], [10158, 10182, "ORG"], [10186, 10203, "LOC"], [10205, 10220, "ORG"], [10222, 10228, "ORG"], [10230, 10238, "PERSON"], [10240, 10243, "GPE"], [10247, 10263, "WORK_OF_ART"], [10326, 10350, "ORG"], [10354, 10371, "LOC"], [10373, 10388, "ORG"], [10390, 10403, "PERSON"], [10405, 10415, "PERSON"], [10417, 10427, "PERSON"], [10429, 10436, "PERSON"], [10438, 10449, "PERSON"], [10451, 10460, "PERSON"], [10462, 10471, "PERSON"], [10473, 10482, "GPE"], [10484, 10506, "GPE"], [10512, 10520, "PERSON"], [10564, 10575, "GPE"], [10577, 10590, "DATE"], [10616, 10623, "GPE"], [10625, 10629, "GPE"], [10634, 10639, "GPE"], [10641, 10645, "GPE"], [10647, 10651, "DATE"], [10697, 10699, "NORP"], [10734, 10744, "PERSON"], [10746, 10748, "DATE"], [10750, 10757, "CARDINAL"], [10759, 10764, "GPE"], [10766, 10770, "GPE"], [10772, 10776, "DATE"], [10779, 10811, "WORK_OF_ART"], [10813, 10821, "GPE"], [10823, 10846, "ORG"], [10854, 10858, "GPE"], [10860, 10864, "DATE"], [10921, 10929, "GPE"], [10931, 10939, "PERSON"], [10941, 10950, "PERSON"], [10952, 10956, "GPE"], [10958, 10962, "DATE"], [10998, 11018, "ORG"], [11020, 11022, "DATE"], [11024, 11031, "CARDINAL"], [11044, 11048, "GPE"], [11050, 11054, "DATE"], [11058, 11096, "WORK_OF_ART"], [11102, 11112, "PERSON"], [11117, 11128, "PERSON"], [11257, 11261, "PERSON"], [11263, 11267, "DATE"], [11271, 11296, "WORK_OF_ART"], [11299, 11306, "GPE"], [11308, 11339, "ORG"], [11341, 11348, "PERSON"], [11354, 11358, "DATE"], [11361, 11398, "PERSON"], [11403, 11421, "PERSON"], [11426, 11453, "GPE"], [11455, 11468, "GPE"], [11481, 11489, "DATE"]]}], ["In psychology, economics and philosophy, a preference is a technical term usually used in relation to choosing between alternatives. For example, someone prefers A over B if they would rather choose A than B.\nPreference can also be used in insolvency terms.\n\n\n== Psychology ==\nIn psychology, preferences refer to an individual's attitude towards a set of objects, typically reflected in an explicit decision-making process (Lichtenstein & Slovic, 2006). The term is also used to mean evaluative judgment in the sense of liking or disliking an object (e.g., Scherer, 2005) which is the most typical definition employed in psychology. However, it does not mean that a preference is necessarily stable over time. Preference can be notably modified by decision-making processes, such as choices (Brehm, 1956; Sharot, De Martino, & Dolan, 2009), even unconsciously (see Coppin, Delplanque, Cayeux, Porcherot, & Sander, 2010). Consequently, preference can be affected by a person's surroundings and upbringing in terms of geographical location, cultural background, religious beliefs, and education. These factors are found to affect preference as repeated exposure to a certain idea or concept correlates with a positive preference.\n\n\n== Economics ==\n\nIn economics and other social sciences, preference refers to the set of assumptions related to ordering some alternatives, based on the degree of happiness, satisfaction, gratification, enjoyment, or utility they provide, a process which results in an optimal \"choice\" (whether real or imagined). Although economists are usually not interested in choices or preferences in themselves, they are interested in the theory of choice because it serves as a background for empirical demand analysis.\nThe so-called Expected Utility Theory (EUT), which was introduced by John von Neumann and Oskar Morgenstern in 1944, explains that so long as an agent's preferences over risky options follow a set of axioms, then he is maximizing the expected value of a utility function. This theory specifically identified four axioms that determine an individual's preference when selecting an alternative out of a series of choices that maximizes expected utility for him. These include Completeness, Transitivity, Independence, and, Continuity.\n\n\n== Other ==\n\"Preference\" may also refer to non-choices, such as genetic and biological explanations for one's preference. Sexual orientation, for example, is no longer considered a sexual preference by most individuals, but is debatable based on philosophical and/or scientific ideas.\n\n\n== Insolvency ==\nIn Insolvency, the term can be used to describe when a company pays a specific creditor or group of creditors. From doing this, that creditor(s) is made better off, than other creditors. After paying the 'preferred creditor', the company seeks to go into a formal insolvency like an administration or liquidation.  There must be a desire to make the creditor better off, for them to be a preference. If the preference is proven, legal action can occur. It is a wrongful act of trading. Disqualification is a risk. Preference arises within the context of the principle maintaining that one of the main objectives in the winding up of an insolvent company is to ensure the equal treatment of creditors. The rules on preferences allow paying up their creditors as insolvency looms, but that it must prove that the transaction is a result of ordinary commercial considerations. Also, under the English Insolvency Act 1986, if a creditor was proven to have forced the company to pay, the resulting payment would not be considered a preference since it would not constitute unfairness.\n\n\n== See also ==\nMotivation\nPreference-based planning (in artificial intelligence)\nPreference revelation\nChoice\nPairwise comparison\n\n\n== References ==\n\n\n=== General ===\n\n\n== External links ==\nStanford Encyclopedia of Philosophy article on 'Preferences'\nCustomer preference formation DOC (white paper from International Communications Research)", {"entities": [[3, 13, "TRAINED_CATEGORY"], [15, 24, "TRAINED_CATEGORY"], [29, 39, "TRAINED_CATEGORY"], [41, 53, "TRAINED_CATEGORY"], [57, 73, "TRAINED_CATEGORY"], [90, 98, "TRAINED_CATEGORY"], [119, 131, "TRAINED_CATEGORY"], [137, 144, "TRAINED_CATEGORY"], [146, 153, "TRAINED_CATEGORY"], [169, 170, "TRAINED_CATEGORY"], [174, 178, "TRAINED_CATEGORY"], [206, 219, "TRAINED_CATEGORY"], [240, 256, "TRAINED_CATEGORY"], [263, 273, "TRAINED_CATEGORY"], [280, 290, "TRAINED_CATEGORY"], [292, 303, "TRAINED_CATEGORY"], [313, 337, "TRAINED_CATEGORY"], [346, 351, "TRAINED_CATEGORY"], [355, 362, "TRAINED_CATEGORY"], [387, 422, "TRAINED_CATEGORY"], [424, 436, "TRAINED_CATEGORY"], [439, 445, "TRAINED_CATEGORY"], [454, 462, "TRAINED_CATEGORY"], [484, 503, "TRAINED_CATEGORY"], [507, 516, "TRAINED_CATEGORY"], [540, 549, "TRAINED_CATEGORY"], [550, 564, "TRAINED_CATEGORY"], [581, 608, "TRAINED_CATEGORY"], [621, 631, "TRAINED_CATEGORY"], [642, 644, "TRAINED_CATEGORY"], [664, 676, "TRAINED_CATEGORY"], [704, 708, "TRAINED_CATEGORY"], [710, 720, "TRAINED_CATEGORY"], [748, 773, "TRAINED_CATEGORY"], [783, 790, "TRAINED_CATEGORY"], [792, 797, "TRAINED_CATEGORY"], [805, 811, "TRAINED_CATEGORY"], [813, 823, "TRAINED_CATEGORY"], [827, 832, "TRAINED_CATEGORY"], [865, 871, "TRAINED_CATEGORY"], [873, 883, "TRAINED_CATEGORY"], [885, 891, "TRAINED_CATEGORY"], [893, 902, "TRAINED_CATEGORY"], [906, 912, "TRAINED_CATEGORY"], [935, 945, "TRAINED_CATEGORY"], [965, 988, "TRAINED_CATEGORY"], [1007, 1012, "TRAINED_CATEGORY"], [1016, 1037, "TRAINED_CATEGORY"], [1039, 1058, "TRAINED_CATEGORY"], [1060, 1077, "TRAINED_CATEGORY"], [1083, 1092, "TRAINED_CATEGORY"], [1094, 1107, "TRAINED_CATEGORY"], [1128, 1138, "TRAINED_CATEGORY"], [1142, 1159, "TRAINED_CATEGORY"], [1163, 1177, "TRAINED_CATEGORY"], [1181, 1188, "TRAINED_CATEGORY"], [1205, 1226, "TRAINED_CATEGORY"], [1233, 1242, "TRAINED_CATEGORY"], [1250, 1259, "TRAINED_CATEGORY"], [1264, 1285, "TRAINED_CATEGORY"], [1287, 1297, "TRAINED_CATEGORY"], [1308, 1315, "TRAINED_CATEGORY"], [1319, 1330, "TRAINED_CATEGORY"], [1351, 1368, "TRAINED_CATEGORY"], [1379, 1389, "TRAINED_CATEGORY"], [1393, 1402, "TRAINED_CATEGORY"], [1404, 1416, "TRAINED_CATEGORY"], [1418, 1431, "TRAINED_CATEGORY"], [1433, 1442, "TRAINED_CATEGORY"], [1447, 1454, "TRAINED_CATEGORY"], [1455, 1459, "TRAINED_CATEGORY"], [1469, 1478, "TRAINED_CATEGORY"], [1496, 1514, "TRAINED_CATEGORY"], [1553, 1563, "TRAINED_CATEGORY"], [1594, 1601, "TRAINED_CATEGORY"], [1605, 1616, "TRAINED_CATEGORY"], [1620, 1630, "TRAINED_CATEGORY"], [1632, 1636, "TRAINED_CATEGORY"], [1655, 1665, "TRAINED_CATEGORY"], [1669, 1675, "TRAINED_CATEGORY"], [1684, 1686, "TRAINED_CATEGORY"], [1697, 1709, "TRAINED_CATEGORY"], [1714, 1739, "TRAINED_CATEGORY"], [1741, 1778, "TRAINED_CATEGORY"], [1779, 1783, "TRAINED_CATEGORY"], [1810, 1826, "TRAINED_CATEGORY"], [1831, 1848, "TRAINED_CATEGORY"], [1883, 1905, "TRAINED_CATEGORY"], [1911, 1924, "TRAINED_CATEGORY"], [1932, 1937, "TRAINED_CATEGORY"], [1941, 1947, "TRAINED_CATEGORY"], [1954, 1956, "TRAINED_CATEGORY"], [1971, 1989, "TRAINED_CATEGORY"], [1993, 2011, "TRAINED_CATEGORY"], [2013, 2024, "TRAINED_CATEGORY"], [2049, 2060, "TRAINED_CATEGORY"], [2076, 2102, "TRAINED_CATEGORY"], [2118, 2132, "TRAINED_CATEGORY"], [2140, 2148, "TRAINED_CATEGORY"], [2152, 2159, "TRAINED_CATEGORY"], [2160, 2174, "TRAINED_CATEGORY"], [2184, 2191, "TRAINED_CATEGORY"], [2196, 2199, "TRAINED_CATEGORY"], [2215, 2227, "TRAINED_CATEGORY"], [2229, 2241, "TRAINED_CATEGORY"], [2243, 2255, "TRAINED_CATEGORY"], [2262, 2272, "TRAINED_CATEGORY"], [2288, 2299, "TRAINED_CATEGORY"], [2319, 2330, "TRAINED_CATEGORY"], [2340, 2375, "TRAINED_CATEGORY"], [2380, 2396, "TRAINED_CATEGORY"], [2398, 2416, "TRAINED_CATEGORY"], [2422, 2429, "TRAINED_CATEGORY"], [2478, 2494, "TRAINED_CATEGORY"], [2522, 2559, "TRAINED_CATEGORY"], [2566, 2576, "TRAINED_CATEGORY"], [2583, 2593, "TRAINED_CATEGORY"], [2595, 2603, "TRAINED_CATEGORY"], [2633, 2642, "TRAINED_CATEGORY"], [2648, 2667, "TRAINED_CATEGORY"], [2671, 2676, "TRAINED_CATEGORY"], [2680, 2689, "TRAINED_CATEGORY"], [2750, 2765, "TRAINED_CATEGORY"], [2780, 2803, "TRAINED_CATEGORY"], [2806, 2817, "TRAINED_CATEGORY"], [2835, 2854, "TRAINED_CATEGORY"], [2860, 2877, "TRAINED_CATEGORY"], [2881, 2892, "TRAINED_CATEGORY"], [2909, 2917, "TRAINED_CATEGORY"], [2926, 2938, "TRAINED_CATEGORY"], [2955, 2959, "TRAINED_CATEGORY"], [2966, 2978, "TRAINED_CATEGORY"], [2983, 2997, "TRAINED_CATEGORY"], [3009, 3021, "TRAINED_CATEGORY"], [3033, 3035, "TRAINED_CATEGORY"], [3039, 3053, "TRAINED_CATEGORY"], [3057, 3064, "TRAINED_CATEGORY"], [3066, 3082, "TRAINED_CATEGORY"], [3086, 3092, "TRAINED_CATEGORY"], [3094, 3104, "TRAINED_CATEGORY"], [3119, 3130, "TRAINED_CATEGORY"], [3134, 3147, "TRAINED_CATEGORY"], [3172, 3191, "TRAINED_CATEGORY"], [3195, 3206, "TRAINED_CATEGORY"], [3213, 3233, "TRAINED_CATEGORY"], [3247, 3266, "TRAINED_CATEGORY"], [3270, 3279, "TRAINED_CATEGORY"], [3281, 3290, "TRAINED_CATEGORY"], [3294, 3305, "TRAINED_CATEGORY"], [3322, 3337, "TRAINED_CATEGORY"], [3341, 3351, "TRAINED_CATEGORY"], [3368, 3370, "TRAINED_CATEGORY"], [3387, 3402, "TRAINED_CATEGORY"], [3406, 3414, "TRAINED_CATEGORY"], [3418, 3452, "TRAINED_CATEGORY"], [3466, 3492, "TRAINED_CATEGORY"], [3502, 3512, "TRAINED_CATEGORY"], [3539, 3550, "TRAINED_CATEGORY"], [3559, 3580, "TRAINED_CATEGORY"], [3624, 3626, "TRAINED_CATEGORY"], [3648, 3658, "TRAINED_CATEGORY"], [3677, 3713, "TRAINED_CATEGORY"], [3718, 3741, "TRAINED_CATEGORY"], [3743, 3764, "TRAINED_CATEGORY"], [3765, 3771, "TRAINED_CATEGORY"], [3772, 3791, "TRAINED_CATEGORY"], [3797, 3807, "TRAINED_CATEGORY"], [3817, 3824, "TRAINED_CATEGORY"], [3834, 3848, "TRAINED_CATEGORY"], [3877, 3887, "TRAINED_CATEGORY"], [3900, 3911, "TRAINED_CATEGORY"], [3913, 3946, "TRAINED_CATEGORY"], [3947, 3959, "TRAINED_CATEGORY"], [3965, 4002, "TRAINED_CATEGORY"], [424, 445, "ORG"], [447, 451, "DATE"], [557, 564, "GPE"], [566, 570, "DATE"], [792, 797, "ORG"], [805, 811, "NORP"], [813, 823, "NORP"], [834, 838, "DATE"], [865, 871, "ORG"], [893, 902, "ORG"], [914, 918, "DATE"], [1233, 1242, "ORG"], [1810, 1826, "PERSON"], [1831, 1848, "PERSON"], [1852, 1856, "DATE"], [2049, 2053, "CARDINAL"], [2215, 2227, "ORG"], [2262, 2272, "ORG"], [2289, 2299, "WORK_OF_ART"], [3466, 3497, "LAW"], [3677, 3687, "PERSON"], [3834, 3842, "ORG"], [3852, 3860, "ORG"], [3943, 3946, "ORG"], [3965, 4002, "ORG"]]}], ["Given a collection of points in two, three, or higher dimensional space, a \"best fitting\" line can be defined as one that minimizes the average squared distance from a point to the line. The next best-fitting line can be similarly chosen from directions perpendicular to the first. Repeating this process yields an orthogonal basis in which different individual dimensions of the data are uncorrelated. These basis vectors are called principal components, and several related procedures principal component analysis (PCA). \nPCA is mostly used as a tool in exploratory data analysis and for making predictive models. It is often used to visualize genetic distance and relatedness between populations. PCA is either done by singular value decomposition of a design matrix or by doing the following 2 steps:\n\ncalculating the data covariance (or correlation) matrix of the original data\nperforming eigenvalue decomposition on the covariance matrixUsually the original data is normalized before performing the PCA. The normalization of each attribute consists of mean centering \u2013 subtracting its variable's measured mean from each data value so that its empirical mean (average) is zero. Some fields, in addition to normalizing the mean, do so for each variable's variance (to make it equal to 1); see z-scores. The results of a PCA are usually discussed in terms of component scores, sometimes called factor scores (the transformed variable values corresponding to a particular data point), and loadings (the weight by which each standardized original variable should be multiplied to get the component score). If component scores are standardized to unit variance, loadings must contain the data variance in them (and that is the magnitude of eigenvalues). If component scores are not standardized (therefore they contain the data variance) then loadings must be unit-scaled, (\"normalized\") and these weights are called eigenvectors; they are the cosines of orthogonal rotation of variables into principal components or back.\nPCA is the simplest of the true eigenvector-based multivariate analyses. Often, its operation can be thought of as revealing the internal structure of the data in a way that best explains the variance in the data. If a multivariate dataset is visualised as a set of coordinates in a high-dimensional data space (1 axis per variable), PCA can supply the user with a lower-dimensional picture, a projection of this object when viewed from its most informative viewpoint. This is done by using only the first few principal components so that the dimensionality of the transformed data is reduced.\nPCA is closely related to factor analysis. Factor analysis typically incorporates more domain specific assumptions about the underlying structure and solves eigenvectors of a slightly different matrix.\nPCA is also related to canonical correlation analysis (CCA). CCA defines coordinate systems that optimally describe the cross-covariance between two datasets while PCA defines a new orthogonal coordinate system that optimally describes variance in a single dataset.Robust and L1-norm-based variants of standard PCA have also been proposed.\n\n\n== History ==\nPCA was invented in 1901 by Karl Pearson, as an analogue of the principal axis theorem in mechanics; it was later independently developed and named by Harold Hotelling in the 1930s. Depending on the field of application, it is also named the discrete Karhunen\u2013Lo\u00e8ve transform (KLT) in signal processing, the Hotelling transform in multivariate quality control, proper orthogonal decomposition (POD) in mechanical engineering, singular value decomposition (SVD) of X (Golub and Van Loan, 1983), eigenvalue decomposition (EVD) of XTX in linear algebra, factor analysis (for a discussion of the differences between PCA and factor analysis see Ch. 7 of Jolliffe's Principal Component Analysis), Eckart\u2013Young theorem (Harman, 1960), or empirical orthogonal functions (EOF) in meteorological science, empirical eigenfunction decomposition (Sirovich, 1987), empirical component analysis (Lorenz, 1956), quasiharmonic modes (Brooks et al., 1988), spectral decomposition in noise and vibration, and empirical modal analysis in structural dynamics.\n\n\n== Intuition ==\nPCA can be thought of as fitting a p-dimensional ellipsoid to the data, where each axis of the ellipsoid represents a principal component. If some axis of the ellipsoid is small, then the variance along that axis is also small, and by omitting that axis and its corresponding principal component from our representation of the dataset, we lose only an equally small amount of information.\nTo find the axes of the ellipsoid, we must first subtract the mean of each variable from the dataset to center the data around the origin. Then, we compute the covariance matrix of the data and calculate the eigenvalues and corresponding eigenvectors of this covariance matrix. Then we must normalize each of the orthogonal eigenvectors to become unit vectors. Once this is done, each of the mutually orthogonal, unit eigenvectors can be interpreted as an axis of the ellipsoid fitted to the data. This choice of basis will transform our covariance matrix into a diagonalised form with the diagonal elements representing the variance of each axis. The proportion of the variance that each eigenvector represents can be calculated by dividing the eigenvalue corresponding to that eigenvector by the sum of all eigenvalues.\nThis procedure is sensitive to the scaling of the data, and there is no consensus as to how to best scale the data to obtain optimal results.\n\n\n== Details ==\nPCA is defined as an orthogonal linear transformation that transforms the data to a new coordinate system such that the greatest variance by some scalar projection of the data comes to lie on the first coordinate (called the first principal component), the second greatest variance on the second coordinate, and so on.Consider an \n  \n    \n      \n        n\n        \u00d7\n        p\n      \n    \n    {\\displaystyle n\\times p}\n   data matrix, X, with column-wise zero empirical mean (the sample mean of each column has been shifted to zero), where each of the n rows represents a different repetition of the experiment, and each of the p columns gives a particular kind of feature (say, the results from a particular sensor).\nMathematically, the transformation is defined by a set of size \n  \n    \n      \n        l\n      \n    \n    {\\displaystyle l}\n   of p-dimensional vectors of weights or coefficients \n  \n    \n      \n        \n          \n            w\n          \n          \n            (\n            k\n            )\n          \n        \n        =\n        (\n        \n          w\n          \n            1\n          \n        \n        ,\n        \u2026\n        ,\n        \n          w\n          \n            l\n          \n        \n        \n          )\n          \n            (\n            k\n            )\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {w} _{(k)}=(w_{1},\\dots ,w_{l})_{(k)}}\n   that map each row vector \n  \n    \n      \n        \n          \n            x\n          \n          \n            (\n            i\n            )\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {x} _{(i)}}\n   of X to a new vector of principal component scores \n  \n    \n      \n        \n          \n            t\n          \n          \n            (\n            i\n            )\n          \n        \n        =\n        (\n        \n          t\n          \n            1\n          \n        \n        ,\n        \u2026\n        ,\n        \n          t\n          \n            l\n          \n        \n        \n          )\n          \n            (\n            i\n            )\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {t} _{(i)}=(t_{1},\\dots ,t_{l})_{(i)}}\n  , given by\n\n  \n    \n      \n        \n          \n            \n              t\n              \n                k\n              \n            \n          \n          \n            (\n            i\n            )\n          \n        \n        =\n        \n          \n            x\n          \n          \n            (\n            i\n            )\n          \n        \n        \u22c5\n        \n          \n            w\n          \n          \n            (\n            k\n            )\n          \n        \n        \n        \n          f\n          o\n          r\n        \n        \n        i\n        =\n        1\n        ,\n        \u2026\n        ,\n        n\n        \n        k\n        =\n        1\n        ,\n        \u2026\n        ,\n        l\n      \n    \n    {\\displaystyle {t_{k}}_{(i)}=\\mathbf {x} _{(i)}\\cdot \\mathbf {w} _{(k)}\\qquad \\mathrm {for} \\qquad i=1,\\dots ,n\\qquad k=1,\\dots ,l}\n  in such a way that the individual variables \n  \n    \n      \n        \n          t\n          \n            1\n          \n        \n        ,\n        \u2026\n        ,\n        \n          t\n          \n            l\n          \n        \n      \n    \n    {\\displaystyle t_{1},\\dots ,t_{l}}\n   of t considered over the data set successively inherit the maximum possible variance from X, with each coefficient vector w constrained to be a unit vector (where \n  \n    \n      \n        l\n      \n    \n    {\\displaystyle l}\n   is usually selected to be less than \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n   to reduce dimensionality).\n\n\n=== First component ===\nIn order to maximize variance, the first weight vector w(1) thus has to satisfy\n\n  \n    \n      \n        \n          \n            w\n          \n          \n            (\n            1\n            )\n          \n        \n        =\n        \n          \n            \n              arg\n              \n              m\n              a\n              x\n            \n            \n              \u2016\n              \n                w\n              \n              \u2016\n              =\n              1\n            \n          \n        \n        \n        \n          {\n          \n            \n              \u2211\n              \n                i\n              \n            \n            \n              \n                (\n                \n                  t\n                  \n                    1\n                  \n                \n                )\n              \n              \n                (\n                i\n                )\n              \n              \n                2\n              \n            \n          \n          }\n        \n        =\n        \n          \n            \n              arg\n              \n              m\n              a\n              x\n            \n            \n              \u2016\n              \n                w\n              \n              \u2016\n              =\n              1\n            \n          \n        \n        \n        \n          {\n          \n            \n              \u2211\n              \n                i\n              \n            \n            \n              \n                (\n                \n                  \n                    \n                      x\n                    \n                    \n                      (\n                      i\n                      )\n                    \n                  \n                  \u22c5\n                  \n                    w\n                  \n                \n                )\n              \n              \n                2\n              \n            \n          \n          }\n        \n      \n    \n    {\\displaystyle \\mathbf {w} _{(1)}={\\underset {\\Vert \\mathbf {w} \\Vert =1}{\\operatorname {\\arg \\,max} }}\\,\\left\\{\\sum _{i}\\left(t_{1}\\right)_{(i)}^{2}\\right\\}={\\underset {\\Vert \\mathbf {w} \\Vert =1}{\\operatorname {\\arg \\,max} }}\\,\\left\\{\\sum _{i}\\left(\\mathbf {x} _{(i)}\\cdot \\mathbf {w} \\right)^{2}\\right\\}}\n  Equivalently, writing this in matrix form gives\n\n  \n    \n      \n        \n          \n            w\n          \n          \n            (\n            1\n            )\n          \n        \n        =\n        \n          \n            \n              arg\n              \n              m\n              a\n              x\n            \n            \n              \u2016\n              \n                w\n              \n              \u2016\n              =\n              1\n            \n          \n        \n        \n        {\n        \u2016\n        \n          X\n          w\n        \n        \n          \u2016\n          \n            2\n          \n        \n        }\n        =\n        \n          \n            \n              arg\n              \n              m\n              a\n              x\n            \n            \n              \u2016\n              \n                w\n              \n              \u2016\n              =\n              1\n            \n          \n        \n        \n        \n          {\n          \n            \n              \n                w\n              \n              \n                T\n              \n            \n            \n              \n                X\n                \n                  T\n                \n              \n            \n            \n              X\n              w\n            \n          \n          }\n        \n      \n    \n    {\\displaystyle \\mathbf {w} _{(1)}={\\underset {\\Vert \\mathbf {w} \\Vert =1}{\\operatorname {\\arg \\,max} }}\\,\\{\\Vert \\mathbf {Xw} \\Vert ^{2}\\}={\\underset {\\Vert \\mathbf {w} \\Vert =1}{\\operatorname {\\arg \\,max} }}\\,\\left\\{\\mathbf {w} ^{T}\\mathbf {X^{T}} \\mathbf {Xw} \\right\\}}\n  Since w(1) has been defined to be a unit vector, it equivalently also satisfies\n\n  \n    \n      \n        \n          \n            w\n          \n          \n            (\n            1\n            )\n          \n        \n        =\n        \n          \n            arg\n            \n            m\n            a\n            x\n          \n        \n        \n        \n          {\n          \n            \n              \n                \n                  \n                    w\n                  \n                  \n                    T\n                  \n                \n                \n                  \n                    X\n                    \n                      T\n                    \n                  \n                \n                \n                  X\n                  w\n                \n              \n              \n                \n                  \n                    w\n                  \n                  \n                    T\n                  \n                \n                \n                  w\n                \n              \n            \n          \n          }\n        \n      \n    \n    {\\displaystyle \\mathbf {w} _{(1)}={\\operatorname {\\arg \\,max} }\\,\\left\\{{\\frac {\\mathbf {w} ^{T}\\mathbf {X^{T}} \\mathbf {Xw} }{\\mathbf {w} ^{T}\\mathbf {w} }}\\right\\}}\n  The quantity to be maximised can be recognised as a Rayleigh quotient. A standard result for a positive semidefinite matrix such as XTX is that the quotient's maximum possible value is the largest eigenvalue of the matrix, which occurs when w is the corresponding eigenvector.\nWith w(1) found, the first principal component of a data vector x(i) can then be given as a score t1(i) = x(i) \u22c5 w(1) in the transformed co-ordinates, or as the corresponding vector in the original variables, {x(i) \u22c5 w(1)} w(1).\n\n\n=== Further components ===\nThe kth component can be found by subtracting the first k \u2212 1 principal components from X:\n\n  \n    \n      \n        \n          \n            \n              \n                X\n                ^\n              \n            \n          \n          \n            k\n          \n        \n        =\n        \n          X\n        \n        \u2212\n        \n          \u2211\n          \n            s\n            =\n            1\n          \n          \n            k\n            \u2212\n            1\n          \n        \n        \n          X\n        \n        \n          \n            w\n          \n          \n            (\n            s\n            )\n          \n        \n        \n          \n            w\n          \n          \n            (\n            s\n            )\n          \n          \n            \n              T\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {\\hat {X}} _{k}=\\mathbf {X} -\\sum _{s=1}^{k-1}\\mathbf {X} \\mathbf {w} _{(s)}\\mathbf {w} _{(s)}^{\\rm {T}}}\n  and then finding the weight vector which extracts the maximum variance from this new data matrix\n\n  \n    \n      \n        \n          \n            w\n          \n          \n            (\n            k\n            )\n          \n        \n        =\n        \n          \n            \n              a\n              r\n              g\n              \n              m\n              a\n              x\n            \n            \n              \u2016\n              \n                w\n              \n              \u2016\n              =\n              1\n            \n          \n        \n        \n          {\n          \n            \u2016\n            \n              \n                \n                  \n                    X\n                    ^\n                  \n                \n              \n              \n                k\n              \n            \n            \n              w\n            \n            \n              \u2016\n              \n                2\n              \n            \n          \n          }\n        \n        =\n        \n          \n            arg\n            \n            m\n            a\n            x\n          \n        \n        \n        \n          {\n          \n            \n              \n                \n                  \n                    \n                      w\n                    \n                    \n                      T\n                    \n                  \n                  \n                    \n                      \n                        \n                          X\n                          ^\n                        \n                      \n                    \n                    \n                      k\n                    \n                    \n                      T\n                    \n                  \n                  \n                    \n                      \n                        \n                          X\n                          ^\n                        \n                      \n                    \n                    \n                      k\n                    \n                  \n                  \n                    w\n                  \n                \n                \n                  \n                    \n                      w\n                    \n                    \n                      T\n                    \n                  \n                  \n                    w\n                  \n                \n              \n            \n          \n          }\n        \n      \n    \n    {\\displaystyle \\mathbf {w} _{(k)}={\\underset {\\Vert \\mathbf {w} \\Vert =1}{\\operatorname {arg\\,max} }}\\left\\{\\Vert \\mathbf {\\hat {X}} _{k}\\mathbf {w} \\Vert ^{2}\\right\\}={\\operatorname {\\arg \\,max} }\\,\\left\\{{\\tfrac {\\mathbf {w} ^{T}\\mathbf {\\hat {X}} _{k}^{T}\\mathbf {\\hat {X}} _{k}\\mathbf {w} }{\\mathbf {w} ^{T}\\mathbf {w} }}\\right\\}}\n  It turns out that this gives the remaining eigenvectors of XTX, with the maximum values for the quantity in brackets given by their corresponding eigenvalues. Thus the weight vectors are eigenvectors of XTX.\nThe kth principal component of a data vector x(i) can therefore be given as a score tk(i) = x(i) \u22c5 w(k) in the transformed co-ordinates, or as the corresponding vector in the space of the original variables, {x(i) \u22c5 w(k)} w(k), where w(k) is the kth eigenvector of XTX.\nThe full principal components decomposition of X can therefore be given as\n\n  \n    \n      \n        \n          T\n        \n        =\n        \n          X\n        \n        \n          W\n        \n      \n    \n    {\\displaystyle \\mathbf {T} =\\mathbf {X} \\mathbf {W} }\n  where W is a p-by-p matrix of weights whose columns are the eigenvectors of XTX. The transpose of W is sometimes called the whitening or sphering transformation. Columns of W multiplied by the square root of corresponding eigenvalues, that is, eigenvectors scaled up by the variances, are called loadings in PCA or in Factor analysis.\n\n\n=== Covariances ===\nXTX itself can be recognised as proportional to the empirical sample covariance matrix of the dataset XT.\nThe sample covariance Q between two of the different principal components over the dataset is given by:\n\n  \n    \n      \n        \n          \n            \n              \n                Q\n                (\n                \n                  \n                    P\n                    C\n                  \n                  \n                    (\n                    j\n                    )\n                  \n                \n                ,\n                \n                  \n                    P\n                    C\n                  \n                  \n                    (\n                    k\n                    )\n                  \n                \n                )\n              \n              \n                \n                \u221d\n                (\n                \n                  X\n                \n                \n                  \n                    w\n                  \n                  \n                    (\n                    j\n                    )\n                  \n                \n                \n                  )\n                  \n                    T\n                  \n                \n                (\n                \n                  X\n                \n                \n                  \n                    w\n                  \n                  \n                    (\n                    k\n                    )\n                  \n                \n                )\n              \n            \n            \n              \n              \n                \n                =\n                \n                  \n                    w\n                  \n                  \n                    (\n                    j\n                    )\n                  \n                  \n                    T\n                  \n                \n                \n                  \n                    X\n                  \n                  \n                    T\n                  \n                \n                \n                  X\n                \n                \n                  \n                    w\n                  \n                  \n                    (\n                    k\n                    )\n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  \n                    w\n                  \n                  \n                    (\n                    j\n                    )\n                  \n                  \n                    T\n                  \n                \n                \n                  \u03bb\n                  \n                    (\n                    k\n                    )\n                  \n                \n                \n                  \n                    w\n                  \n                  \n                    (\n                    k\n                    )\n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  \u03bb\n                  \n                    (\n                    k\n                    )\n                  \n                \n                \n                  \n                    w\n                  \n                  \n                    (\n                    j\n                    )\n                  \n                  \n                    T\n                  \n                \n                \n                  \n                    w\n                  \n                  \n                    (\n                    k\n                    )\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}Q(\\mathrm {PC} _{(j)},\\mathrm {PC} _{(k)})&\\propto (\\mathbf {X} \\mathbf {w} _{(j)})^{T}(\\mathbf {X} \\mathbf {w} _{(k)})\\\\&=\\mathbf {w} _{(j)}^{T}\\mathbf {X} ^{T}\\mathbf {X} \\mathbf {w} _{(k)}\\\\&=\\mathbf {w} _{(j)}^{T}\\lambda _{(k)}\\mathbf {w} _{(k)}\\\\&=\\lambda _{(k)}\\mathbf {w} _{(j)}^{T}\\mathbf {w} _{(k)}\\end{aligned}}}\n  where the eigenvalue property of w(k) has been used to move from line 2 to line 3. However eigenvectors w(j) and w(k) corresponding to eigenvalues of a symmetric matrix are orthogonal (if the eigenvalues are different), or can be orthogonalised (if the vectors happen to share an equal repeated value). The product in the final line is therefore zero; there is no sample covariance between different principal components over the dataset.\nAnother way to characterise the principal components transformation is therefore as the transformation to coordinates which diagonalise the empirical sample covariance matrix.\nIn matrix form, the empirical covariance matrix for the original variables can be written\n\n  \n    \n      \n        \n          Q\n        \n        \u221d\n        \n          \n            X\n          \n          \n            T\n          \n        \n        \n          X\n        \n        =\n        \n          W\n        \n        \n          \u039b\n        \n        \n          \n            W\n          \n          \n            T\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {Q} \\propto \\mathbf {X} ^{T}\\mathbf {X} =\\mathbf {W} \\mathbf {\\Lambda } \\mathbf {W} ^{T}}\n  The empirical covariance matrix between the principal components becomes\n\n  \n    \n      \n        \n          \n            W\n          \n          \n            T\n          \n        \n        \n          Q\n        \n        \n          W\n        \n        \u221d\n        \n          \n            W\n          \n          \n            T\n          \n        \n        \n          W\n        \n        \n        \n          \u039b\n        \n        \n        \n          \n            W\n          \n          \n            T\n          \n        \n        \n          W\n        \n        =\n        \n          \u039b\n        \n      \n    \n    {\\displaystyle \\mathbf {W} ^{T}\\mathbf {Q} \\mathbf {W} \\propto \\mathbf {W} ^{T}\\mathbf {W} \\,\\mathbf {\\Lambda } \\,\\mathbf {W} ^{T}\\mathbf {W} =\\mathbf {\\Lambda } }\n  where \u039b is the diagonal matrix of eigenvalues \u03bb(k) of XTX. \u03bb(k) is equal to the sum of the squares over the dataset associated with each component k, that is, \u03bb(k) = \u03a3i tk2(i) = \u03a3i (x(i) \u22c5 w(k))2.\n\n\n=== Dimensionality reduction ===\nThe transformation T = X W maps a data vector x(i) from an original space of p variables to a new space of p variables which are uncorrelated over the dataset. However, not all the principal components need to be kept. Keeping only the first L principal components, produced by using only the first L eigenvectors, gives the truncated transformation\n\n  \n    \n      \n        \n          \n            T\n          \n          \n            L\n          \n        \n        =\n        \n          X\n        \n        \n          \n            W\n          \n          \n            L\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {T} _{L}=\\mathbf {X} \\mathbf {W} _{L}}\n  where the matrix TL now has n rows but only L columns. In other words, PCA learns a linear transformation \n  \n    \n      \n        t\n        =\n        \n          W\n          \n            T\n          \n        \n        x\n        ,\n        x\n        \u2208\n        \n          R\n          \n            p\n          \n        \n        ,\n        t\n        \u2208\n        \n          R\n          \n            L\n          \n        \n        ,\n      \n    \n    {\\displaystyle t=W^{T}x,x\\in R^{p},t\\in R^{L},}\n   where the columns of p \u00d7 L matrix W form an orthogonal basis for the L features (the components of representation t) that are decorrelated. By construction, of all the transformed data matrices with only L columns, this score matrix maximises the variance in the original data that has been preserved, while minimising the total squared reconstruction error \n  \n    \n      \n        \u2016\n        \n          T\n        \n        \n          \n            W\n          \n          \n            T\n          \n        \n        \u2212\n        \n          \n            T\n          \n          \n            L\n          \n        \n        \n          \n            W\n          \n          \n            L\n          \n          \n            T\n          \n        \n        \n          \u2016\n          \n            2\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\|\\mathbf {T} \\mathbf {W} ^{T}-\\mathbf {T} _{L}\\mathbf {W} _{L}^{T}\\|_{2}^{2}}\n   or \n  \n    \n      \n        \u2016\n        \n          X\n        \n        \u2212\n        \n          \n            X\n          \n          \n            L\n          \n        \n        \n          \u2016\n          \n            2\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\|\\mathbf {X} -\\mathbf {X} _{L}\\|_{2}^{2}}\n  .\n\nSuch dimensionality reduction can be a very useful step for visualising and processing high-dimensional datasets, while still retaining as much of the variance in the dataset as possible. For example, selecting L = 2 and keeping only the first two principal components finds the two-dimensional plane through the high-dimensional dataset in which the data is most spread out, so if the data contains clusters these too may be most spread out, and therefore most visible to be plotted out in a two-dimensional diagram; whereas if two directions through the data (or two of the original variables) are chosen at random, the clusters may be much less spread apart from each other, and may in fact be much more likely to substantially overlay each other, making them indistinguishable.\nSimilarly, in regression analysis, the larger the number of explanatory variables allowed, the greater is the chance of overfitting the model, producing conclusions that fail to generalise to other datasets. One approach, especially when there are strong correlations between different possible explanatory variables, is to reduce them to a few principal components and then run the regression against them, a method called principal component regression.\nDimensionality reduction may also be appropriate when the variables in a dataset are noisy. If each column of the dataset contains independent identically distributed Gaussian noise, then the columns of T will also contain similarly identically distributed Gaussian noise (such a distribution is invariant under the effects of the matrix W, which can be thought of as a high-dimensional rotation of the co-ordinate axes). However, with more of the total variance concentrated in the first few principal components compared to the same noise variance, the proportionate effect of the noise is less\u2014the first few components achieve a higher signal-to-noise ratio. PCA thus can have the effect of concentrating much of the signal into the first few principal components, which can usefully be captured by dimensionality reduction; while the later principal components may be dominated by noise, and so disposed of without great loss.\n\n\n=== Singular value decomposition ===\nThe principal components transformation can also be associated with another matrix factorization, the singular value decomposition (SVD) of X,\n\n  \n    \n      \n        \n          X\n        \n        =\n        \n          U\n        \n        \n          \u03a3\n        \n        \n          \n            W\n          \n          \n            T\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {X} =\\mathbf {U} \\mathbf {\\Sigma } \\mathbf {W} ^{T}}\n  Here \u03a3 is an n-by-p rectangular diagonal matrix of positive numbers \u03c3(k), called the singular values of X; U is an n-by-n matrix, the columns of which are orthogonal unit vectors of length n called the left singular vectors of X; and W is a p-by-p whose columns are orthogonal unit vectors of length p and called the right singular vectors of X.\nIn terms of this factorization, the matrix XTX can be written\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    X\n                  \n                  \n                    T\n                  \n                \n                \n                  X\n                \n              \n              \n                \n                =\n                \n                  W\n                \n                \n                  \n                    \u03a3\n                  \n                  \n                    T\n                  \n                \n                \n                  \n                    U\n                  \n                  \n                    T\n                  \n                \n                \n                  U\n                \n                \n                  \u03a3\n                \n                \n                  \n                    W\n                  \n                  \n                    T\n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  W\n                \n                \n                  \n                    \u03a3\n                  \n                  \n                    T\n                  \n                \n                \n                  \u03a3\n                \n                \n                  \n                    W\n                  \n                  \n                    T\n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  W\n                \n                \n                  \n                    \n                      \n                        \u03a3\n                        ^\n                      \n                    \n                  \n                  \n                    2\n                  \n                \n                \n                  \n                    W\n                  \n                  \n                    T\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}\\mathbf {X} ^{T}\\mathbf {X} &=\\mathbf {W} \\mathbf {\\Sigma } ^{T}\\mathbf {U} ^{T}\\mathbf {U} \\mathbf {\\Sigma } \\mathbf {W} ^{T}\\\\&=\\mathbf {W} \\mathbf {\\Sigma } ^{T}\\mathbf {\\Sigma } \\mathbf {W} ^{T}\\\\&=\\mathbf {W} \\mathbf {\\hat {\\Sigma }} ^{2}\\mathbf {W} ^{T}\\end{aligned}}}\n  where  \n  \n    \n      \n        \n          \n            \n              \u03a3\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {\\hat {\\Sigma }} }\n   is the square diagonal matrix with the singular values of  X  and the excess zeros chopped off that satisfies  \n  \n    \n      \n        \n          \n            \n              \n                \n                  \u03a3\n                  ^\n                \n              \n            \n            \n              2\n            \n          \n        \n        =\n        \n          \n            \u03a3\n          \n          \n            T\n          \n        \n        \n          \u03a3\n        \n      \n    \n    {\\displaystyle \\mathbf {{\\hat {\\Sigma }}^{2}} =\\mathbf {\\Sigma } ^{T}\\mathbf {\\Sigma } }\n  . Comparison with the eigenvector factorization of XTX establishes that the right singular vectors W of X are equivalent to the eigenvectors of XTX, while the singular values \u03c3(k) of  \n  \n    \n      \n        \n          X\n        \n      \n    \n    {\\displaystyle \\mathbf {X} }\n   are equal to the square-root of the eigenvalues \u03bb(k) of XTX.\nUsing the singular value decomposition the score matrix T can be written\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  T\n                \n              \n              \n                \n                =\n                \n                  X\n                \n                \n                  W\n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  U\n                \n                \n                  \u03a3\n                \n                \n                  \n                    W\n                  \n                  \n                    T\n                  \n                \n                \n                  W\n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  U\n                \n                \n                  \u03a3\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}\\mathbf {T} &=\\mathbf {X} \\mathbf {W} \\\\&=\\mathbf {U} \\mathbf {\\Sigma } \\mathbf {W} ^{T}\\mathbf {W} \\\\&=\\mathbf {U} \\mathbf {\\Sigma } \\end{aligned}}}\n  so each column of T is given by one of the left singular vectors of X multiplied by the corresponding singular value. This form is also the polar decomposition of T.\nEfficient algorithms exist to calculate the SVD of X without having to form the matrix XTX, so computing the SVD is now the standard way to calculate a principal components analysis from a data matrix, unless only a handful of components are required.\nAs with the eigen-decomposition, a truncated n \u00d7 L score matrix TL can be obtained by considering only the first L largest singular values and their singular vectors:\n\n  \n    \n      \n        \n          \n            T\n          \n          \n            L\n          \n        \n        =\n        \n          \n            U\n          \n          \n            L\n          \n        \n        \n          \n            \u03a3\n          \n          \n            L\n          \n        \n        =\n        \n          X\n        \n        \n          \n            W\n          \n          \n            L\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {T} _{L}=\\mathbf {U} _{L}\\mathbf {\\Sigma } _{L}=\\mathbf {X} \\mathbf {W} _{L}}\n  The truncation of a matrix M or T using a truncated singular value decomposition in this way produces a truncated matrix that is the nearest possible matrix of rank L to the original matrix, in the sense of the difference between the two having the smallest possible Frobenius norm, a result known as the Eckart\u2013Young theorem [1936].\n\n\n== Further considerations ==\nGiven a set of points in Euclidean space, the first principal component corresponds to a line that passes through the multidimensional mean and minimizes the sum of squares of the distances of the points from the line. The second principal component corresponds to the same concept after all correlation with the first principal component has been subtracted from the points. The singular values (in \u03a3) are the square roots of the eigenvalues of the matrix XTX. Each eigenvalue is proportional to the portion of the \"variance\" (more correctly of the sum of the squared distances of the points from their multidimensional mean) that is associated with each eigenvector. The sum of all the eigenvalues is equal to the sum of the squared distances of the points from their multidimensional mean. PCA essentially rotates the set of points around their mean in order to align with the principal components. This moves as much of the variance as possible (using an orthogonal transformation) into the first few dimensions. The values in the remaining dimensions, therefore, tend to be small and may be dropped with minimal loss of information (see below). PCA is often used in this manner for dimensionality reduction. PCA has the distinction of being the optimal orthogonal transformation for keeping the subspace that has largest \"variance\" (as defined above). This advantage, however, comes at the price of greater computational requirements if compared, for example, and when applicable, to the discrete cosine transform, and in particular to the DCT-II which is simply known as the \"DCT\". Nonlinear dimensionality reduction techniques tend to be more computationally demanding than PCA.\nPCA is sensitive to the scaling of the variables. If we have just two variables and they have the same sample variance and are positively correlated, then the PCA will entail a rotation by 45\u00b0 and the \"weights\" (they are the cosines of rotation) for the two variables with respect to the principal component will be equal. But if we multiply all values of the first variable by 100, then the first principal component will be almost the same as that variable, with a small contribution from the other variable, whereas the second component will be almost aligned with the second original variable. This means that whenever the different variables have different units (like temperature and mass), PCA is a somewhat arbitrary method of analysis. (Different results would be obtained if one used Fahrenheit rather than Celsius for example.) Pearson's original paper was entitled \"On Lines and Planes of Closest Fit to Systems of Points in Space\" \u2013 \"in space\" implies physical Euclidean space where such concerns do not arise. One way of making the PCA less arbitrary is to use variables scaled so as to have unit variance, by standardizing the data and hence use the autocorrelation matrix instead of the autocovariance matrix as a basis for PCA. However, this compresses (or expands) the fluctuations in all dimensions of the signal space to unit variance.\nMean subtraction (a.k.a. \"mean centering\") is necessary for performing classical PCA to ensure that the first principal component describes the direction of maximum variance. If mean subtraction is not performed, the first principal component might instead correspond more or less to the mean of the data. A mean of zero is needed for finding a basis that minimizes the mean square error of the approximation of the data.Mean-centering is unnecessary if performing a principal components analysis on a correlation matrix, as the data are already centered after calculating correlations. Correlations are derived from the cross-product of two standard scores (Z-scores) or statistical moments (hence the name: Pearson Product-Moment Correlation). Also see the article by Kromrey & Foster-Johnson (1998) on \"Mean-centering in Moderated Regression: Much Ado About Nothing\".\nPCA is a popular primary technique in pattern recognition. It is not, however, optimized for class separability. However, it has been used to quantify the distance between two or more classes by calculating center of mass for each class in principal component space and reporting Euclidean distance between center of mass of two or more classes. The linear discriminant analysis is an alternative which is optimized for class separability.\n\n\n== Table of symbols and abbreviations ==\n\n\n== Properties and limitations of PCA ==\n\n\n=== Properties ===\nSome properties of PCA include:\nProperty 1: For any integer q, 1 \u2264 q \u2264 p, consider the orthogonal linear transformation\n\n  \n    \n      \n        y\n        =\n        \n          \n            B\n            \u2032\n          \n        \n        x\n      \n    \n    {\\displaystyle y=\\mathbf {B'} x}\n  \nwhere \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n   is a q-element vector and \n  \n    \n      \n        \n          \n            B\n            \u2032\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {B'} }\n   is a (q \u00d7 p) matrix, and let \n  \n    \n      \n        \n          \n            \u03a3\n          \n          \n            y\n          \n        \n        =\n        \n          \n            B\n            \u2032\n          \n        \n        \n          \u03a3\n        \n        \n          B\n        \n      \n    \n    {\\displaystyle \\mathbf {\\Sigma } _{y}=\\mathbf {B'} \\mathbf {\\Sigma } \\mathbf {B} }\n   be the variance-covariance matrix for \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  . Then the trace of \n  \n    \n      \n        \n          \n            \u03a3\n          \n          \n            y\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {\\Sigma } _{y}}\n  , denoted \n  \n    \n      \n        \n          tr\n        \n        (\n        \n          \n            \u03a3\n          \n          \n            y\n          \n        \n        )\n      \n    \n    {\\displaystyle {\\text{tr}}(\\mathbf {\\Sigma } _{y})}\n  , is maximized by taking \n  \n    \n      \n        \n          B\n        \n        =\n        \n          \n            A\n          \n          \n            q\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {B} =\\mathbf {A} _{q}}\n  , where \n  \n    \n      \n        \n          \n            A\n          \n          \n            q\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {A} _{q}}\n   consists of the first q columns of \n  \n    \n      \n        \n          A\n        \n      \n    \n    {\\displaystyle \\mathbf {A} }\n   \n  \n    \n      \n        (\n        \n          \n            B\n            \u2032\n          \n        \n      \n    \n    {\\displaystyle (\\mathbf {B'} }\n   is the transposition of \n  \n    \n      \n        \n          B\n        \n        )\n      \n    \n    {\\displaystyle \\mathbf {B} )}\n  .Property 2: Consider again the orthonormal transformation\n\n  \n    \n      \n        y\n        =\n        \n          \n            B\n            \u2032\n          \n        \n        x\n      \n    \n    {\\displaystyle y=\\mathbf {B'} x}\n  \nwith \n  \n    \n      \n        x\n        ,\n        \n          B\n        \n        ,\n        \n          A\n        \n      \n    \n    {\\displaystyle x,\\mathbf {B} ,\\mathbf {A} }\n   and \n  \n    \n      \n        \n          \n            \u03a3\n          \n          \n            y\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {\\Sigma } _{y}}\n   defined as before. Then \n  \n    \n      \n        \n          tr\n        \n        (\n        \n          \n            \u03a3\n          \n          \n            y\n          \n        \n        )\n      \n    \n    {\\displaystyle {\\text{tr}}(\\mathbf {\\Sigma } _{y})}\n   is minimized by taking \n  \n    \n      \n        \n          B\n        \n        =\n        \n          \n            A\n          \n          \n            q\n          \n          \n            \u2217\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {B} =\\mathbf {A} _{q}^{*},}\n   where \n  \n    \n      \n        \n          \n            A\n          \n          \n            q\n          \n          \n            \u2217\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {A} _{q}^{*}}\n   consists of the last q columns of \n  \n    \n      \n        \n          A\n        \n      \n    \n    {\\displaystyle \\mathbf {A} }\n  .The statistical implication of this property is that the last few PCs are not simply unstructured left-overs after removing the important PCs. Because these last PCs have variances as small as possible they are useful in their own right. They can help to detect unsuspected near-constant linear relationships between the elements of x, and they may also be useful in regression, in selecting a subset of variables from x, and in outlier detection.\n\nProperty 3: (Spectral Decomposition of \u03a3)\n\n  \n    \n      \n        \n          \u03a3\n        \n        =\n        \n          \u03bb\n          \n            1\n          \n        \n        \n          \u03b1\n          \n            1\n          \n        \n        \n          \u03b1\n          \n            1\n          \n          \u2032\n        \n        +\n        \u22ef\n        +\n        \n          \u03bb\n          \n            p\n          \n        \n        \n          \u03b1\n          \n            p\n          \n        \n        \n          \u03b1\n          \n            p\n          \n          \u2032\n        \n      \n    \n    {\\displaystyle \\mathbf {\\Sigma } =\\lambda _{1}\\alpha _{1}\\alpha _{1}'+\\cdots +\\lambda _{p}\\alpha _{p}\\alpha _{p}'}\n  Before we look at its usage, we first look at diagonal elements,\n\n  \n    \n      \n        \n          Var\n        \n        (\n        \n          x\n          \n            j\n          \n        \n        )\n        =\n        \n          \u2211\n          \n            k\n            =\n            1\n          \n          \n            P\n          \n        \n        \n          \u03bb\n          \n            k\n          \n        \n        \n          \u03b1\n          \n            k\n            j\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle {\\text{Var}}(x_{j})=\\sum _{k=1}^{P}\\lambda _{k}\\alpha _{kj}^{2}}\n  Then, perhaps the main statistical implication of the result is that not only can we decompose the combined variances of all the elements of x into decreasing contributions due to each PC, but we can also decompose the whole covariance matrix into contributions \n  \n    \n      \n        \n          \u03bb\n          \n            k\n          \n        \n        \n          \u03b1\n          \n            k\n          \n        \n        \n          \u03b1\n          \n            k\n          \n          \u2032\n        \n      \n    \n    {\\displaystyle \\lambda _{k}\\alpha _{k}\\alpha _{k}'}\n   from each PC. Although not strictly decreasing, the elements of \n  \n    \n      \n        \n          \u03bb\n          \n            k\n          \n        \n        \n          \u03b1\n          \n            k\n          \n        \n        \n          \u03b1\n          \n            k\n          \n          \u2032\n        \n      \n    \n    {\\displaystyle \\lambda _{k}\\alpha _{k}\\alpha _{k}'}\n   will tend to become smaller as \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n   increases, as \n  \n    \n      \n        \n          \u03bb\n          \n            k\n          \n        \n        \n          \u03b1\n          \n            k\n          \n        \n        \n          \u03b1\n          \n            k\n          \n          \u2032\n        \n      \n    \n    {\\displaystyle \\lambda _{k}\\alpha _{k}\\alpha _{k}'}\n   is nonincreasing for increasing \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  , whereas the elements of \n  \n    \n      \n        \n          \u03b1\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle \\alpha _{k}}\n   tend to stay about the same size because of the normalization constraints: \n  \n    \n      \n        \n          \u03b1\n          \n            k\n          \n          \u2032\n        \n        \n          \u03b1\n          \n            k\n          \n        \n        =\n        1\n        ,\n        k\n        =\n        1\n        ,\n        \u22ef\n        ,\n        p\n      \n    \n    {\\displaystyle \\alpha _{k}'\\alpha _{k}=1,k=1,\\cdots ,p}\n  .\n\n\n=== Limitations ===\nAs noted above, the results of PCA depend on the scaling of the variables. This can be cured by scaling each feature by its standard deviation, so that one ends up with dimensionless features with unital variance.The applicability of PCA as described above is limited by certain (tacit) assumptions made in its derivation. In particular, PCA can capture linear correlations between the features but fails when this assumption is violated (see Figure 6a in the reference). In some cases, coordinate transformations can restore the linearity assumption and PCA can then be applied (see kernel PCA).\nAnother limitation is the mean-removal process before constructing the covariance matrix for PCA. In fields such as astronomy, all the signals are non-negative, and the mean-removal process will force the mean of some astrophysical exposures to be zero, which consequently creates unphysical negative fluxes, and forward modeling has to be performed to recover the true magnitude of the signals. As an alternative method, non-negative matrix factorization focusing only on the non-negative elements in the matrices, which is well-suited for astrophysical observations. See more at Relation between PCA and Non-negative Matrix Factorization.\n\n\n=== PCA and information theory ===\nDimensionality reduction loses information, in general. PCA-based dimensionality reduction tends to minimize that information loss, under certain signal and noise models.\nUnder the assumption that\n\n  \n    \n      \n        \n          x\n        \n        =\n        \n          s\n        \n        +\n        \n          n\n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {x} =\\mathbf {s} +\\mathbf {n} ,}\n  that is, that the data vector \n  \n    \n      \n        \n          x\n        \n      \n    \n    {\\displaystyle \\mathbf {x} }\n   is the sum of the desired information-bearing signal \n  \n    \n      \n        \n          s\n        \n      \n    \n    {\\displaystyle \\mathbf {s} }\n   and a noise signal \n  \n    \n      \n        \n          n\n        \n      \n    \n    {\\displaystyle \\mathbf {n} }\n   one can show that PCA can be optimal for dimensionality reduction, from an information-theoretic point-of-view.\nIn particular, Linsker showed that if \n  \n    \n      \n        \n          s\n        \n      \n    \n    {\\displaystyle \\mathbf {s} }\n   is Gaussian and \n  \n    \n      \n        \n          n\n        \n      \n    \n    {\\displaystyle \\mathbf {n} }\n   is Gaussian noise with a covariance matrix proportional to the identity matrix, the PCA maximizes the mutual information \n  \n    \n      \n        I\n        (\n        \n          y\n        \n        ;\n        \n          s\n        \n        )\n      \n    \n    {\\displaystyle I(\\mathbf {y} ;\\mathbf {s} )}\n   between the desired information \n  \n    \n      \n        \n          s\n        \n      \n    \n    {\\displaystyle \\mathbf {s} }\n   and the dimensionality-reduced output \n  \n    \n      \n        \n          y\n        \n        =\n        \n          \n            W\n          \n          \n            L\n          \n          \n            T\n          \n        \n        \n          x\n        \n      \n    \n    {\\displaystyle \\mathbf {y} =\\mathbf {W} _{L}^{T}\\mathbf {x} }\n  .If the noise is still Gaussian and has a covariance matrix proportional to the identity matrix (that is, the components of the vector \n  \n    \n      \n        \n          n\n        \n      \n    \n    {\\displaystyle \\mathbf {n} }\n   are iid), but the information-bearing signal \n  \n    \n      \n        \n          s\n        \n      \n    \n    {\\displaystyle \\mathbf {s} }\n   is non-Gaussian (which is a common scenario), PCA at least minimizes an upper bound on the information loss, which is defined as\n\n  \n    \n      \n        I\n        (\n        \n          x\n        \n        ;\n        \n          s\n        \n        )\n        \u2212\n        I\n        (\n        \n          y\n        \n        ;\n        \n          s\n        \n        )\n        .\n      \n    \n    {\\displaystyle I(\\mathbf {x} ;\\mathbf {s} )-I(\\mathbf {y} ;\\mathbf {s} ).}\n  The optimality of PCA is also preserved if the noise \n  \n    \n      \n        \n          n\n        \n      \n    \n    {\\displaystyle \\mathbf {n} }\n   is iid and at least more Gaussian (in terms of the Kullback\u2013Leibler divergence) than the information-bearing signal \n  \n    \n      \n        \n          s\n        \n      \n    \n    {\\displaystyle \\mathbf {s} }\n  . In general, even if the above signal model holds, PCA loses its information-theoretic optimality as soon as the noise \n  \n    \n      \n        \n          n\n        \n      \n    \n    {\\displaystyle \\mathbf {n} }\n   becomes dependent.\n\n\n== Computing PCA using the covariance method ==\nThe following is a detailed description of PCA using the covariance method (see also here) as opposed to the correlation method.The goal is to transform a given data set X of dimension p to an alternative data set Y of smaller dimension L. Equivalently, we are seeking to find the matrix Y, where Y is the Karhunen\u2013Lo\u00e8ve transform (KLT) of matrix X:\n\n  \n    \n      \n        \n          Y\n        \n        =\n        \n          K\n          L\n          T\n        \n        {\n        \n          X\n        \n        }\n      \n    \n    {\\displaystyle \\mathbf {Y} =\\mathbb {KLT} \\{\\mathbf {X} \\}}\n  \n\n\n=== Organize the data set ===\nSuppose you have data comprising a set of observations of p variables, and you want to reduce the data so that each observation can be described with only L variables, L < p. Suppose further, that the data are arranged as a set of n data vectors \n  \n    \n      \n        \n          \n            x\n          \n          \n            1\n          \n        \n        \u2026\n        \n          \n            x\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {x} _{1}\\ldots \\mathbf {x} _{n}}\n   with each \n  \n    \n      \n        \n          \n            x\n          \n          \n            i\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {x} _{i}}\n   representing a single grouped observation of the p variables.\n\nWrite \n  \n    \n      \n        \n          \n            x\n          \n          \n            1\n          \n        \n        \u2026\n        \n          \n            x\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {x} _{1}\\ldots \\mathbf {x} _{n}}\n   as row vectors, each of which has p columns.\nPlace the row vectors into a single matrix X of dimensions n \u00d7 p.\n\n\n=== Calculate the empirical mean ===\nFind the empirical mean along each column j = 1, ..., p.\nPlace the calculated mean values into an empirical mean vector u of dimensions p \u00d7 1.\n  \n    \n      \n        \n          u\n          \n            j\n          \n        \n        =\n        \n          \n            1\n            n\n          \n        \n        \n          \u2211\n          \n            i\n            =\n            1\n          \n          \n            n\n          \n        \n        \n          X\n          \n            i\n            j\n          \n        \n      \n    \n    {\\displaystyle u_{j}={1 \\over n}\\sum _{i=1}^{n}X_{ij}}\n  \n\n\n=== Calculate the deviations from the mean ===\nMean subtraction is an integral part of the solution towards finding a principal component basis that minimizes the mean square error of approximating the data. Hence we proceed by centering the data as follows:\n\nSubtract the empirical mean vector \n  \n    \n      \n        \n          \n            u\n          \n          \n            T\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {u} ^{T}}\n   from each row of the data matrix X.\nStore mean-subtracted data in the n \u00d7 p matrix B.\n  \n    \n      \n        \n          B\n        \n        =\n        \n          X\n        \n        \u2212\n        \n          h\n        \n        \n          \n            u\n          \n          \n            T\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {B} =\\mathbf {X} -\\mathbf {h} \\mathbf {u} ^{T}}\n  \nwhere h is an n \u00d7 1 column vector of all 1s:\n  \n    \n      \n        \n          h\n          \n            i\n          \n        \n        =\n        1\n        \n        \n        \n        \n          for \n        \n        i\n        =\n        1\n        ,\n        \u2026\n        ,\n        n\n      \n    \n    {\\displaystyle h_{i}=1\\,\\qquad \\qquad {\\text{for }}i=1,\\ldots ,n}\n  \n\n\n=== Find the covariance matrix ===\nFind the p \u00d7 p empirical covariance matrix C from matrix B:\n  \n    \n      \n        \n          C\n        \n        =\n        \n          \n            1\n            \n              n\n              \u2212\n              1\n            \n          \n        \n        \n          \n            B\n          \n          \n            \u2217\n          \n        \n        \n          B\n        \n      \n    \n    {\\displaystyle \\mathbf {C} ={1 \\over {n-1}}\\mathbf {B} ^{*}\\mathbf {B} }\n  \nwhere \n  \n    \n      \n        \u2217\n      \n    \n    {\\displaystyle *}\n   is the conjugate transpose operator. If B consists entirely of real numbers, which is the case in many applications, the \"conjugate transpose\" is the same as the regular transpose.The reasoning behind using n \u2212 1 instead of n to calculate the covariance is Bessel's correction.\n\n\n=== Find the eigenvectors and eigenvalues of the covariance matrix ===\nCompute the matrix V of eigenvectors which diagonalizes the covariance matrix C:\n  \n    \n      \n        \n          \n            V\n          \n          \n            \u2212\n            1\n          \n        \n        \n          C\n        \n        \n          V\n        \n        =\n        \n          D\n        \n      \n    \n    {\\displaystyle \\mathbf {V} ^{-1}\\mathbf {C} \\mathbf {V} =\\mathbf {D} }\n  where D is the diagonal matrix of eigenvalues of C. This step will typically involve the use of a computer-based algorithm for computing eigenvectors and eigenvalues. These algorithms are readily available as sub-components of most matrix algebra systems, such as SAS, R, MATLAB, Mathematica, SciPy, IDL (Interactive Data Language), or GNU Octave as well as OpenCV.Matrix D will take the form of an p \u00d7 p diagonal matrix, where\n  \n    \n      \n        \n          D\n          \n            k\n            l\n          \n        \n        =\n        \n          \u03bb\n          \n            k\n          \n        \n        \n        \n          for \n        \n        k\n        =\n        l\n      \n    \n    {\\displaystyle D_{kl}=\\lambda _{k}\\qquad {\\text{for }}k=l}\n  \nis the jth eigenvalue of the covariance matrix C, and\n\n  \n    \n      \n        \n          D\n          \n            k\n            l\n          \n        \n        =\n        0\n        \n        \n          for \n        \n        k\n        \u2260\n        l\n        .\n      \n    \n    {\\displaystyle D_{kl}=0\\qquad {\\text{for }}k\\neq l.}\n  Matrix V, also of dimension p \u00d7 p, contains p column vectors, each of length p, which represent the p eigenvectors of the covariance matrix C.\nThe eigenvalues and eigenvectors are ordered and paired. The jth eigenvalue corresponds to the jth eigenvector.\nMatrix V denotes the matrix of right eigenvectors (as opposed to left eigenvectors). In general, the matrix of right eigenvectors need not be the (conjugate) transpose of the matrix of left eigenvectors.\n\n\n=== Rearrange the eigenvectors and eigenvalues ===\nSort the columns of the eigenvector matrix V and eigenvalue matrix D in order of decreasing eigenvalue.\nMake sure to maintain the correct pairings between the columns in each matrix.\n\n\n=== Compute the cumulative energy content for each eigenvector ===\nThe eigenvalues represent the distribution of the source data's energy among each of the eigenvectors, where the eigenvectors form a basis for the data. The cumulative energy content g for the jth eigenvector is the sum of the energy content across all of the eigenvalues from 1 through j:\n  \n    \n      \n        \n          g\n          \n            j\n          \n        \n        =\n        \n          \u2211\n          \n            k\n            =\n            1\n          \n          \n            j\n          \n        \n        \n          D\n          \n            k\n            k\n          \n        \n        \n        \n          f\n          o\n          r\n        \n        \n        j\n        =\n        1\n        ,\n        \u2026\n        ,\n        p\n      \n    \n    {\\displaystyle g_{j}=\\sum _{k=1}^{j}D_{kk}\\qquad \\mathrm {for} \\qquad j=1,\\dots ,p}\n  \n\n\n=== Select a subset of the eigenvectors as basis vectors ===\nSave the first L columns of V as the p \u00d7 L matrix W:\n  \n    \n      \n        \n          W\n          \n            k\n            l\n          \n        \n        =\n        \n          V\n          \n            k\n            l\n          \n        \n        \n        \n          f\n          o\n          r\n        \n        \n        k\n        =\n        1\n        ,\n        \u2026\n        ,\n        p\n        \n        l\n        =\n        1\n        ,\n        \u2026\n        ,\n        L\n      \n    \n    {\\displaystyle W_{kl}=V_{kl}\\qquad \\mathrm {for} \\qquad k=1,\\dots ,p\\qquad l=1,\\dots ,L}\n  where\n  \n    \n      \n        1\n        \u2264\n        L\n        \u2264\n        p\n        .\n      \n    \n    {\\displaystyle 1\\leq L\\leq p.}\n  Use the vector g as a guide in choosing an appropriate value for L. The goal is to choose a value of L as small as possible while achieving a reasonably high value of g on a percentage basis. For example, you may want to choose L so that the cumulative energy g is above a certain threshold, like 90 percent. In this case, choose the smallest value of L such that\n  \n    \n      \n        \n          \n            \n              g\n              \n                L\n              \n            \n            \n              g\n              \n                p\n              \n            \n          \n        \n        \u2265\n        0.9\n        \n      \n    \n    {\\displaystyle {\\frac {g_{L}}{g_{p}}}\\geq 0.9\\,}\n  \n\n\n=== Project the z-scores of the data onto the new basis ===\nThe projected vectors are the columns of the matrix\n  \n    \n      \n        \n          T\n        \n        =\n        \n          Z\n        \n        \u22c5\n        \n          W\n        \n        =\n        \n          K\n          L\n          T\n        \n        {\n        \n          X\n        \n        }\n        .\n      \n    \n    {\\displaystyle \\mathbf {T} =\\mathbf {Z} \\cdot \\mathbf {W} =\\mathbb {KLT} \\{\\mathbf {X} \\}.}\n  The rows of matrix T represent the Kosambi-Karhunen\u2013Lo\u00e8ve transforms (KLT) of the data vectors in the rows of matrix X.\n\n\n== Derivation of PCA using the covariance method ==\nLet X be a d-dimensional random vector expressed as column vector. Without loss of generality, assume X has zero mean.\nWe want to find \n  \n    \n      \n        (\n        \u2217\n        )\n        \n      \n    \n    {\\displaystyle (\\ast )\\,}\n   a d \u00d7 d orthonormal transformation matrix P so that PX has a diagonal covariance matrix (that is, PX is a random vector with all its distinct components pairwise uncorrelated).\nA quick computation assuming \n  \n    \n      \n        P\n      \n    \n    {\\displaystyle P}\n   were unitary yields:\n\n  \n    \n      \n        \n          \n            \n              \n                cov\n                \u2061\n                (\n                P\n                X\n                )\n              \n              \n                \n                =\n                \n                  E\n                \n                [\n                P\n                X\n                 \n                (\n                P\n                X\n                \n                  )\n                  \n                    \u2217\n                  \n                \n                ]\n              \n            \n            \n              \n              \n                \n                =\n                \n                  E\n                \n                [\n                P\n                X\n                 \n                \n                  X\n                  \n                    \u2217\n                  \n                \n                \n                  P\n                  \n                    \u2217\n                  \n                \n                ]\n              \n            \n            \n              \n              \n                \n                =\n                P\n                 \n                \n                  E\n                \n                [\n                X\n                \n                  X\n                  \n                    \u2217\n                  \n                \n                ]\n                \n                  P\n                  \n                    \u2217\n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                P\n                 \n                cov\n                \u2061\n                (\n                X\n                )\n                \n                  P\n                  \n                    \u2212\n                    1\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}\\operatorname {cov} (PX)&=\\mathbb {E} [PX~(PX)^{*}]\\\\&=\\mathbb {E} [PX~X^{*}P^{*}]\\\\&=P~\\mathbb {E} [XX^{*}]P^{*}\\\\&=P~\\operatorname {cov} (X)P^{-1}\\\\\\end{aligned}}}\n  Hence \n  \n    \n      \n        (\n        \u2217\n        )\n        \n      \n    \n    {\\displaystyle (\\ast )\\,}\n   holds if and only if \n  \n    \n      \n        cov\n        \u2061\n        (\n        X\n        )\n      \n    \n    {\\displaystyle \\operatorname {cov} (X)}\n   were diagonalisable by \n  \n    \n      \n        P\n      \n    \n    {\\displaystyle P}\n  .\nThis is very constructive, as cov(X) is guaranteed to be a non-negative definite matrix and thus is guaranteed to be diagonalisable by some unitary matrix.\n\n\n== Covariance-free computation ==\nIn practical implementations, especially with high dimensional data (large p), the naive covariance method is rarely used because it is not efficient due to high computational and memory costs of explicitly determining the covariance matrix. The covariance-free approach avoids the np2 operations of explicitly calculating and storing the covariance matrix XTX, instead utilizing one of matrix-free methods, for example, based on the function evaluating the product XT(X r) at the cost of 2np operations.\n\n\n=== Iterative computation ===\nOne way to compute the first principal component efficiently is shown in the following pseudo-code, for a data matrix X with zero mean, without ever computing its covariance matrix.\n\nr = a random vector of length p\n\n  \n    \n      \n        \n          r\n        \n        =\n        \n          \n            \n              r\n            \n            \n              \n                |\n              \n              \n                r\n              \n              \n                |\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {r} ={\\frac {\\mathbf {r} }{|\\mathbf {r} |}}}\n  \ndo c times:\n      s = 0 (a vector of length p)\n      for each row \n  \n    \n      \n        \n          x\n        \n        \u2208\n        \n          X\n        \n      \n    \n    {\\displaystyle \\mathbf {x} \\in \\mathbf {X} }\n  \n            \n  \n    \n      \n        \n          s\n        \n        =\n        \n          s\n        \n        +\n        (\n        \n          x\n        \n        \u22c5\n        \n          r\n        \n        )\n        \n          x\n        \n      \n    \n    {\\displaystyle \\mathbf {s} =\\mathbf {s} +(\\mathbf {x} \\cdot \\mathbf {r} )\\mathbf {x} }\n  \n      \n  \n    \n      \n        e\n        i\n        g\n        e\n        n\n        v\n        a\n        l\n        u\n        e\n        =\n        \n          \n            r\n          \n          \n            T\n          \n        \n        \n          s\n        \n      \n    \n    {\\displaystyle eigenvalue=\\mathbf {r} ^{T}\\mathbf {s} }\n  \n      \n  \n    \n      \n        e\n        r\n        r\n        o\n        r\n        =\n        \n          |\n        \n        e\n        i\n        g\n        e\n        n\n        v\n        a\n        l\n        u\n        e\n        \u22c5\n        \n          r\n        \n        \u2212\n        \n          s\n        \n        \n          |\n        \n      \n    \n    {\\displaystyle error=|eigenvalue\\cdot \\mathbf {r} -\\mathbf {s} |}\n  \n      \n  \n    \n      \n        \n          r\n        \n        =\n        \n          \n            \n              s\n            \n            \n              \n                |\n              \n              \n                s\n              \n              \n                |\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\mathbf {r} ={\\frac {\\mathbf {s} }{|\\mathbf {s} |}}}\n  \n      exit if \n  \n    \n      \n        e\n        r\n        r\n        o\n        r\n        <\n        t\n        o\n        l\n        e\n        r\n        a\n        n\n        c\n        e\n      \n    \n    {\\displaystyle error<tolerance}\n  \nreturn \n  \n    \n      \n        e\n        i\n        g\n        e\n        n\n        v\n        a\n        l\n        u\n        e\n        ,\n        \n          r\n        \n      \n    \n    {\\displaystyle eigenvalue,\\mathbf {r} }\n  \n\nThis power iteration algorithm simply calculates the vector XT(X r), normalizes, and places the result back in r. The eigenvalue is approximated by rT (XTX) r, which is the Rayleigh quotient on the unit vector r for the covariance matrix XTX . If the largest singular value is well separated from the next largest one, the vector r gets close to the first principal component of X within the number of iterations c, which is small relative to p, at the total cost 2cnp. The power iteration convergence can be accelerated without noticeably sacrificing the small cost per iteration using more advanced matrix-free methods, such as the Lanczos algorithm or the Locally Optimal Block Preconditioned Conjugate Gradient (LOBPCG) method.\nSubsequent principal components can be computed one-by-one via deflation or simultaneously as a block. In the former approach, imprecisions in already computed approximate principal components additively affect the accuracy of the subsequently computed principal components, thus increasing the error with every new computation. The latter approach in the block power method replaces single-vectors r and s with block-vectors, matrices R and S. Every column of R approximates one of the leading principal components, while all columns are iterated simultaneously. The main calculation is evaluation of the product XT(X R). Implemented, for example., in LOBPCG, efficient blocking eliminates the accumulation of the errors, allows using high-level BLAS matrix-matrix product functions, and typically leads to faster convergence, compared to the single-vector one-by-one technique.\n\n\n=== The NIPALS method ===\nNon-linear iterative partial least squares (NIPALS) is a variant the classical power iteration with matrix deflation by subtraction implemented for computing the first few components in a principal component or partial least squares analysis. For very-high-dimensional datasets, such as those generated in the *omics sciences (for example, genomics, metabolomics) it is usually only necessary to compute the first few PCs. The non-linear iterative partial least squares (NIPALS) algorithm updates iterative approximations to the leading scores and loadings t1 and r1T by the power iteration multiplying on every iteration by X on the left and on the right, that is, calculation of the covariance matrix is avoided, just as in the matrix-free implementation of the power iterations to XTX, based on the function evaluating the product XT(X r) = ((X r)TX)T.\nThe matrix deflation by subtraction is performed by subtracting the outer product, t1r1T from X leaving the deflated residual matrix used to calculate the subsequent leading PCs. \nFor large data matrices, or matrices that have a high degree of column collinearity, NIPALS suffers from loss of orthogonality of PCs due to machine precision round-off errors accumulated in each iteration and matrix deflation by subtraction. A Gram\u2013Schmidt re-orthogonalization algorithm is applied to both the scores and the loadings at each iteration step to eliminate this loss of orthogonality. NIPALS reliance on single-vector multiplications cannot take advantage of high-level BLAS and results in slow convergence for clustered leading singular values\u2014both these deficiencies are resolved in more sophisticated matrix-free block solvers, such as the Locally Optimal Block Preconditioned Conjugate Gradient (LOBPCG) method.\n\n\n=== Online/sequential estimation ===\nIn an \"online\" or \"streaming\" situation with data arriving piece by piece rather than being stored in a single batch, it is useful to make an estimate of the PCA projection that can be updated sequentially. This can be done efficiently, but requires different algorithms.\n\n\n== PCA and qualitative variables ==\nIn PCA, it is common that we want to introduce qualitative variables as supplementary elements. For example, many quantitative variables have been measured on plants. For these plants, some qualitative variables are available as, for example, the species to which the plant belongs. These data were subjected to PCA for quantitative variables. When analyzing the results, it is natural to connect the principal components to the qualitative variable species.\nFor this, the following results are produced.\n\nIdentification, on the factorial planes, of the different species, for example, using different colors.\nRepresentation, on the factorial planes, of the centers of gravity of plants belonging to the same species.\nFor each center of gravity and each axis, p-value to judge the significance of the difference between the center of gravity and origin.These results are what is called introducing a qualitative variable as supplementary element. This procedure is detailed in and Husson, L\u00ea & Pag\u00e8s 2009 and Pag\u00e8s 2013.\nFew software offer this option in an \"automatic\" way. This is the case of SPAD that historically, following the work of Ludovic Lebart, was the first to propose this option, and the R package FactoMineR.\n\n\n== Applications ==\n\n\n=== Quantitative finance ===\n\nIn quantitative finance, principal component analysis can be directly applied to the risk management of interest rate derivative portfolios. Trading multiple swap instruments which are usually a function of 30-500 other market quotable swap instruments is sought to be reduced to usually 3 or 4 principal components, representing the path of interest rates on a macro basis. Converting risks to be represented as those to factor loadings (or multipliers) provides assessments and understanding beyond that available to simply collectively viewing risks to individual 30-500 buckets.\nPCA has also been applied to equity portfolios in a similar fashion, both to portfolio risk and to risk return. One application is to reduce portfolio risk, where allocation strategies are applied to the \"principal portfolios\" instead of the underlying stocks. A second is to enhance portfolio return, using the principal components to select stocks with upside potential.\n\n\n=== Neuroscience ===\nA variant of principal components analysis is used in neuroscience to identify the specific properties of a stimulus that increase a neuron's probability of generating an action potential. This technique is known as spike-triggered covariance analysis. In a typical application an experimenter presents a white noise process as a stimulus (usually either as a sensory input to a test subject, or as a current injected directly into the neuron) and records a train of action potentials, or spikes, produced by the neuron as a result. Presumably, certain features of the stimulus make the neuron more likely to spike. In order to extract these features, the experimenter calculates the covariance matrix of the spike-triggered ensemble, the set of all stimuli (defined and discretized over a finite time window, typically on the order of 100 ms) that immediately preceded a spike. The eigenvectors of the difference between the spike-triggered covariance matrix and the covariance matrix of the prior stimulus ensemble (the set of all stimuli, defined over the same length time window) then indicate the directions in the space of stimuli along which the variance of the spike-triggered ensemble differed the most from that of the prior stimulus ensemble. Specifically, the eigenvectors with the largest positive eigenvalues correspond to the directions along which the variance of the spike-triggered ensemble showed the largest positive change compared to the variance of the prior. Since these were the directions in which varying the stimulus led to a spike, they are often good approximations of the sought after relevant stimulus features.\nIn neuroscience, PCA is also used to discern the identity of a neuron from the shape of its action potential. Spike sorting is an important procedure because extracellular recording techniques often pick up signals from more than one neuron. In spike sorting, one first uses PCA to reduce the dimensionality of the space of action potential waveforms, and then performs clustering analysis to associate specific action potentials with individual neurons.\nPCA as a dimension reduction technique is particularly suited to detect coordinated activities of large neuronal ensembles. It has been used in determining collective variables, that is, order parameters, during phase transitions in the brain.\n\n\n== Relation with other methods ==\n\n\n=== Correspondence analysis ===\nCorrespondence analysis (CA)\nwas developed by Jean-Paul Benz\u00e9cri\nand is conceptually similar to PCA, but scales the data (which should be non-negative) so that rows and columns are treated equivalently. It is traditionally applied to contingency tables.\nCA decomposes the chi-squared statistic associated to this table into orthogonal factors.\nBecause CA is a descriptive technique, it can be applied to tables for which the chi-squared statistic is appropriate or not.\nSeveral variants of CA are available including detrended correspondence analysis and canonical correspondence analysis. One special extension is multiple correspondence analysis, which may be seen as the counterpart of principal component analysis for categorical data.\n\n\n=== Factor analysis ===\nPrincipal component analysis creates variables that are linear combinations of the original variables. The new variables have the property that the variables are all orthogonal. The PCA transformation can be helpful as a pre-processing step before clustering. PCA is a variance-focused approach seeking to reproduce the total variable variance, in which components reflect both common and unique variance of the variable. PCA is generally preferred for purposes of data reduction (that is, translating variable space into optimal factor space) but not when the goal is to detect the latent construct or factors.\nFactor analysis is similar to principal component analysis, in that factor analysis also involves linear combinations of variables. Different from PCA, factor analysis is a correlation-focused approach seeking to reproduce the inter-correlations among variables, in which the factors \"represent the common variance of variables, excluding unique variance\". In terms of the correlation matrix, this corresponds with focusing on explaining the off-diagonal terms (that is, shared co-variance), while PCA focuses on explaining the terms that sit on the diagonal. However, as a side result, when trying to reproduce the on-diagonal terms, PCA also tends to fit relatively well the off-diagonal correlations. Results given by PCA and factor analysis are very similar in most situations, but this is not always the case, and there are some problems where the results are significantly different. Factor analysis is generally used when the research purpose is detecting data structure (that is, latent constructs or factors) or causal modeling. If the factor model is incorrectly formulated or the assumptions are not met, then factor analysis will give erroneous results.\n\n\n=== K-means clustering ===\nIt has been asserted that the relaxed solution of k-means clustering, specified by the cluster indicators, is given by the principal components, and the PCA subspace spanned by the principal directions is identical to the cluster centroid subspace. However, that PCA is a useful relaxation of k-means clustering was not a new result, and it is straightforward to uncover counterexamples to the statement that the cluster centroid subspace is spanned by the principal directions.\n\n\n=== Non-negative matrix factorization ===\n Non-negative matrix factorization (NMF) is a dimension reduction method where only non-negative elements in the matrices are used, which is therefore a promising method in astronomy, in the sense that astrophysical signals are non-negative. The PCA components are orthogonal to each other, while the NMF components are all non-negative and therefore constructs a non-orthogonal basis.\nIn PCA, the contribution of each component is ranked based on the magnitude of its corresponding eigenvalue, which is equivalent to the fractional residual variance (FRV) in analyzing empirical data. For NMF, its components are ranked based only on the empirical FRV curves. The residual fractional eigenvalue plots, that is, \n  \n    \n      \n        1\n        \u2212\n        \n          \u2211\n          \n            i\n            =\n            1\n          \n          \n            k\n          \n        \n        \n          \u03bb\n          \n            i\n          \n        \n        \n          /\n        \n        \n          \u2211\n          \n            k\n            =\n            1\n          \n          \n            n\n          \n        \n        \n          \u03bb\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle 1-\\sum _{i=1}^{k}\\lambda _{i}/\\sum _{k=1}^{n}\\lambda _{k}}\n   as a function of component number \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n   given a total of \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   components, for PCA has a flat plateau, where no data is captured to remove the quasi-static noise, then the curves dropped quickly as an indication of over-fitting and captures random noise. The FRV curves for NMF is decreasing continuously  when the NMF components are constructed sequentially, indicating the continuous capturing of quasi-static noise; then converge to higher levels than PCA, indicating the less over-fitting property of NMF.\n\n\n== Generalizations ==\n\n\n=== Sparse PCA ===\n\nA particular disadvantage of PCA is that the principal components are usually linear combinations of all input variables. Sparse PCA overcomes this disadvantage by finding linear combinations that contain just a few input variables. It extends the classic method of principal component analysis (PCA) for the reduction of dimensionality of data by adding sparsity constraint on the input variables. \nSeveral approaches have been proposed, including\n\na regression framework,\na convex relaxation/semidefinite programming framework,\na generalized power method framework\nan alternating maximization framework\nforward-backward greedy search and exact methods using branch-and-bound techniques,\nBayesian formulation framework.The methodological and theoretical developments of Sparse PCA as well as its applications in scientific studies are recently reviewed in a survey paper.\n\n\n=== Nonlinear PCA ===\n\nMost of the modern methods for nonlinear dimensionality reduction find their theoretical and algorithmic roots in PCA or K-means. Pearson's original idea was to take a straight line (or plane) which will be \"the best fit\" to a set of data points. Principal curves and manifolds give the natural geometric framework for PCA generalization and extend the geometric interpretation of PCA by explicitly constructing an embedded manifold for data approximation, and by encoding using standard geometric projection onto the manifold, as it is illustrated by Fig.\nSee also the elastic map algorithm and principal geodesic analysis. Another popular generalization is kernel PCA, which corresponds to PCA performed in a reproducing kernel Hilbert space associated with a positive definite kernel.\nIn multilinear subspace learning, PCA is generalized to multilinear PCA (MPCA) that extracts features directly from tensor representations. MPCA is solved by performing PCA in each mode of the tensor iteratively. MPCA has been applied to face recognition, gait recognition, etc. MPCA is further extended to uncorrelated MPCA, non-negative MPCA and robust MPCA.\nN-way principal component analysis may be performed with models such as Tucker decomposition, PARAFAC, multiple factor analysis, co-inertia analysis, STATIS, and DISTATIS.\n\n\n=== Robust PCA ===\nWhile PCA finds the mathematically optimal method (as in minimizing the squared error), it is still sensitive to outliers in the data that produce large errors, something that the method tries to avoid in the first place. It is therefore common practice to remove outliers before computing PCA. However, in some contexts, outliers can be difficult to identify. For example, in data mining algorithms like correlation clustering, the assignment of points to clusters and outliers is not known beforehand. \nA recently proposed generalization of PCA based on a weighted PCA increases robustness by assigning different weights to data objects based on their estimated relevancy.\nOutlier-resistant variants of PCA have also been proposed, based on L1-norm formulations (L1-PCA).Robust principal component analysis (RPCA) via decomposition in low-rank and sparse matrices is a modification of PCA that works well with respect to grossly corrupted observations.\n\n\n== Similar techniques ==\n\n\n=== Independent component analysis ===\nIndependent component analysis (ICA) is directed to similar problems as principal component analysis, but finds additively separable components rather than successive approximations.\n\n\n=== Network component analysis ===\nGiven a matrix \n  \n    \n      \n        E\n      \n    \n    {\\displaystyle E}\n  , it tries to decompose it into two matrices such that \n  \n    \n      \n        E\n        =\n        A\n        P\n      \n    \n    {\\displaystyle E=AP}\n  . A key difference from techniques such as PCA and ICA is that some of the entries of \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   are constrained to be 0. Here \n  \n    \n      \n        P\n      \n    \n    {\\displaystyle P}\n   is termed the regulatory layer. While in general such a decomposition can have multiple solutions, they prove that if the following conditions are satisfied :\n\n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   has full column rank\nEach column of \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   must have at least \n  \n    \n      \n        L\n        \u2212\n        1\n      \n    \n    {\\displaystyle L-1}\n   zeroes where \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n   is the number of columns of \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n   (or alternatively the number of rows of \n  \n    \n      \n        P\n      \n    \n    {\\displaystyle P}\n  ). The justification for this criterion is that if a node is removed from the regulatory layer along with all the output nodes connected to it, the result must still be characterized by a connectivity matrix with full column rank.\n\n  \n    \n      \n        P\n      \n    \n    {\\displaystyle P}\n   must have full row rank.then the decomposition is unique up to multiplication by a scalar.\n\n\n== Software/source code ==\nALGLIB - a C++ and C# library that implements PCA and truncated PCA\nAnalytica \u2013 The built-in EigenDecomp function computes principal components.\nELKI \u2013 includes PCA for projection, including robust variants of PCA, as well as PCA-based clustering algorithms.\nGretl \u2013 principal component analysis can be performed either via the pca command or via the princomp() function.\nJulia \u2013 Supports PCA with the pca function in the MultivariateStats package\nKNIME \u2013 A java based nodal arranging software for Analysis, in this the nodes called PCA, PCA compute, PCA Apply, PCA inverse make it easily.\nMathematica \u2013 Implements principal component analysis with the PrincipalComponents command using both covariance and correlation methods.\nMathPHP - PHP mathematics library with support for PCA.\nMATLAB Statistics Toolbox \u2013 The functions princomp and pca (R2012b) give the principal components, while the function pcares gives the residuals and reconstructed matrix for a low-rank PCA approximation.\nMatplotlib \u2013 Python library have a PCA package in the .mlab module.\nmlpack \u2013 Provides an implementation of principal component analysis in C++.\nNAG Library \u2013 Principal components analysis is implemented via the g03aa routine (available in both the Fortran versions of the Library).\nNMath \u2013 Proprietary numerical library containing PCA for the .NET Framework.\nGNU Octave \u2013 Free software computational environment mostly compatible with MATLAB, the function princomp gives the principal component.\nOpenCV\nOracle Database 12c \u2013 Implemented via DBMS_DATA_MINING.SVDS_SCORING_MODE by specifying setting value SVDS_SCORING_PCA\nOrange (software) \u2013 Integrates PCA in its visual programming environment. PCA displays a scree plot (degree of explained variance) where user can interactively select the number of principal components.\nOrigin \u2013 Contains PCA in its Pro version.\nQlucore \u2013 Commercial software for analyzing multivariate data with instant response using PCA.\nR \u2013 Free statistical package, the functions princomp and prcomp can be used for principal component analysis; prcomp uses singular value decomposition which generally gives better numerical accuracy. Some packages that implement PCA in R, include, but are not limited to: ade4, vegan, ExPosition, dimRed, and FactoMineR.\nSAS - Proprietary software; for example, see \nScikit-learn \u2013 Python library for machine learning which contains PCA, Probabilistic PCA, Kernel PCA, Sparse PCA and other techniques in the decomposition module.\nWeka \u2013 Java library for machine learning which contains modules for computing principal components.\n\n\n== See also ==\n\n\n== References ==\n\n\n== Further reading ==\nJackson, J.E. (1991). A User's Guide to Principal Components (Wiley).\nJolliffe, I. T. (1986). Principal Component Analysis. Springer Series in Statistics. Springer-Verlag. pp. 487. CiteSeerX 10.1.1.149.8828. doi:10.1007/b98835. ISBN 978-0-387-95442-4.\nJolliffe, I.T. (2002). Principal Component Analysis, second edition (Springer).\nHusson Fran\u00e7ois, L\u00ea S\u00e9bastien & Pag\u00e8s J\u00e9r\u00f4me (2009). Exploratory Multivariate Analysis by Example Using R. Chapman & Hall/CRC The R Series, London. 224p. ISBN 978-2-7535-0938-2\nPag\u00e8s J\u00e9r\u00f4me (2014). Multiple Factor Analysis by Example Using R. Chapman & Hall/CRC The R Series London 272 p\n\n\n== External links ==\nUniversity of Copenhagen video by Rasmus Bro on YouTube\nStanford University video by Andrew Ng on YouTube\nA Tutorial on Principal Component Analysis\nA layman's introduction to principal component analysis on YouTube (a video of less than 100 seconds.)\nStatQuest: Principal Component Analysis (PCA) clearly explained on YouTube\nSee also the list of Software implementations", {"entities": [[6, 18, "TRAINED_CATEGORY"], [22, 28, "TRAINED_CATEGORY"], [47, 71, "TRAINED_CATEGORY"], [73, 94, "TRAINED_CATEGORY"], [132, 160, "TRAINED_CATEGORY"], [166, 173, "TRAINED_CATEGORY"], [177, 185, "TRAINED_CATEGORY"], [187, 213, "TRAINED_CATEGORY"], [243, 253, "TRAINED_CATEGORY"], [292, 304, "TRAINED_CATEGORY"], [312, 331, "TRAINED_CATEGORY"], [341, 372, "TRAINED_CATEGORY"], [376, 384, "TRAINED_CATEGORY"], [403, 422, "TRAINED_CATEGORY"], [460, 515, "TRAINED_CATEGORY"], [517, 520, "TRAINED_CATEGORY"], [524, 527, "TRAINED_CATEGORY"], [546, 552, "TRAINED_CATEGORY"], [556, 581, "TRAINED_CATEGORY"], [597, 614, "TRAINED_CATEGORY"], [616, 618, "TRAINED_CATEGORY"], [646, 662, "TRAINED_CATEGORY"], [667, 678, "TRAINED_CATEGORY"], [687, 698, "TRAINED_CATEGORY"], [700, 703, "TRAINED_CATEGORY"], [722, 750, "TRAINED_CATEGORY"], [754, 769, "TRAINED_CATEGORY"], [782, 803, "TRAINED_CATEGORY"], [818, 837, "TRAINED_CATEGORY"], [842, 853, "TRAINED_CATEGORY"], [855, 861, "TRAINED_CATEGORY"], [865, 918, "TRAINED_CATEGORY"], [922, 936, "TRAINED_CATEGORY"], [951, 968, "TRAINED_CATEGORY"], [1001, 1008, "TRAINED_CATEGORY"], [1010, 1027, "TRAINED_CATEGORY"], [1031, 1045, "TRAINED_CATEGORY"], [1058, 1072, "TRAINED_CATEGORY"], [1087, 1115, "TRAINED_CATEGORY"], [1121, 1136, "TRAINED_CATEGORY"], [1145, 1163, "TRAINED_CATEGORY"], [1183, 1194, "TRAINED_CATEGORY"], [1199, 1207, "TRAINED_CATEGORY"], [1223, 1231, "TRAINED_CATEGORY"], [1243, 1267, "TRAINED_CATEGORY"], [1277, 1279, "TRAINED_CATEGORY"], [1297, 1305, "TRAINED_CATEGORY"], [1307, 1318, "TRAINED_CATEGORY"], [1322, 1327, "TRAINED_CATEGORY"], [1353, 1358, "TRAINED_CATEGORY"], [1362, 1378, "TRAINED_CATEGORY"], [1412, 1443, "TRAINED_CATEGORY"], [1461, 1484, "TRAINED_CATEGORY"], [1501, 1511, "TRAINED_CATEGORY"], [1521, 1556, "TRAINED_CATEGORY"], [1585, 1604, "TRAINED_CATEGORY"], [1610, 1626, "TRAINED_CATEGORY"], [1647, 1660, "TRAINED_CATEGORY"], [1662, 1670, "TRAINED_CATEGORY"], [1684, 1701, "TRAINED_CATEGORY"], [1705, 1709, "TRAINED_CATEGORY"], [1723, 1736, "TRAINED_CATEGORY"], [1740, 1751, "TRAINED_CATEGORY"], [1757, 1773, "TRAINED_CATEGORY"], [1806, 1810, "TRAINED_CATEGORY"], [1819, 1836, "TRAINED_CATEGORY"], [1843, 1851, "TRAINED_CATEGORY"], [1892, 1905, "TRAINED_CATEGORY"], [1931, 1935, "TRAINED_CATEGORY"], [1940, 1951, "TRAINED_CATEGORY"], [1955, 1974, "TRAINED_CATEGORY"], [1978, 1987, "TRAINED_CATEGORY"], [1993, 2013, "TRAINED_CATEGORY"], [2023, 2026, "TRAINED_CATEGORY"], [2046, 2094, "TRAINED_CATEGORY"], [2103, 2116, "TRAINED_CATEGORY"], [2148, 2170, "TRAINED_CATEGORY"], [2174, 2182, "TRAINED_CATEGORY"], [2186, 2191, "TRAINED_CATEGORY"], [2211, 2223, "TRAINED_CATEGORY"], [2227, 2235, "TRAINED_CATEGORY"], [2240, 2254, "TRAINED_CATEGORY"], [2280, 2285, "TRAINED_CATEGORY"], [2289, 2300, "TRAINED_CATEGORY"], [2304, 2333, "TRAINED_CATEGORY"], [2334, 2341, "TRAINED_CATEGORY"], [2346, 2354, "TRAINED_CATEGORY"], [2357, 2360, "TRAINED_CATEGORY"], [2372, 2380, "TRAINED_CATEGORY"], [2386, 2413, "TRAINED_CATEGORY"], [2415, 2427, "TRAINED_CATEGORY"], [2431, 2442, "TRAINED_CATEGORY"], [2460, 2490, "TRAINED_CATEGORY"], [2514, 2553, "TRAINED_CATEGORY"], [2562, 2580, "TRAINED_CATEGORY"], [2584, 2604, "TRAINED_CATEGORY"], [2617, 2620, "TRAINED_CATEGORY"], [2650, 2658, "TRAINED_CATEGORY"], [2660, 2675, "TRAINED_CATEGORY"], [2699, 2731, "TRAINED_CATEGORY"], [2738, 2762, "TRAINED_CATEGORY"], [2774, 2786, "TRAINED_CATEGORY"], [2790, 2817, "TRAINED_CATEGORY"], [2819, 2822, "TRAINED_CATEGORY"], [2842, 2872, "TRAINED_CATEGORY"], [2874, 2877, "TRAINED_CATEGORY"], [2903, 2910, "TRAINED_CATEGORY"], [2935, 2955, "TRAINED_CATEGORY"], [2964, 2976, "TRAINED_CATEGORY"], [2983, 2986, "TRAINED_CATEGORY"], [2995, 3029, "TRAINED_CATEGORY"], [3055, 3063, "TRAINED_CATEGORY"], [3067, 3083, "TRAINED_CATEGORY"], [3084, 3117, "TRAINED_CATEGORY"], [3121, 3133, "TRAINED_CATEGORY"], [3164, 3171, "TRAINED_CATEGORY"], [3175, 3178, "TRAINED_CATEGORY"], [3203, 3215, "TRAINED_CATEGORY"], [3220, 3231, "TRAINED_CATEGORY"], [3265, 3274, "TRAINED_CATEGORY"], [3276, 3278, "TRAINED_CATEGORY"], [3346, 3355, "TRAINED_CATEGORY"], [3370, 3379, "TRAINED_CATEGORY"], [3383, 3394, "TRAINED_CATEGORY"], [3396, 3398, "TRAINED_CATEGORY"], [3435, 3450, "TRAINED_CATEGORY"], [3452, 3455, "TRAINED_CATEGORY"], [3460, 3477, "TRAINED_CATEGORY"], [3479, 3502, "TRAINED_CATEGORY"], [3506, 3534, "TRAINED_CATEGORY"], [3536, 3567, "TRAINED_CATEGORY"], [3569, 3572, "TRAINED_CATEGORY"], [3577, 3599, "TRAINED_CATEGORY"], [3601, 3629, "TRAINED_CATEGORY"], [3631, 3634, "TRAINED_CATEGORY"], [3639, 3640, "TRAINED_CATEGORY"], [3642, 3647, "TRAINED_CATEGORY"], [3652, 3660, "TRAINED_CATEGORY"], [3669, 3693, "TRAINED_CATEGORY"], [3694, 3698, "TRAINED_CATEGORY"], [3703, 3706, "TRAINED_CATEGORY"], [3710, 3724, "TRAINED_CATEGORY"], [3726, 3741, "TRAINED_CATEGORY"], [3747, 3759, "TRAINED_CATEGORY"], [3763, 3778, "TRAINED_CATEGORY"], [3787, 3790, "TRAINED_CATEGORY"], [3795, 3810, "TRAINED_CATEGORY"], [3824, 3863, "TRAINED_CATEGORY"], [3864, 3872, "TRAINED_CATEGORY"], [3873, 3886, "TRAINED_CATEGORY"], [3887, 3894, "TRAINED_CATEGORY"], [3906, 3936, "TRAINED_CATEGORY"], [3938, 3941, "TRAINED_CATEGORY"], [3946, 3968, "TRAINED_CATEGORY"], [3970, 4007, "TRAINED_CATEGORY"], [4009, 4017, "TRAINED_CATEGORY"], [4026, 4054, "TRAINED_CATEGORY"], [4056, 4062, "TRAINED_CATEGORY"], [4071, 4090, "TRAINED_CATEGORY"], [4092, 4105, "TRAINED_CATEGORY"], [4114, 4136, "TRAINED_CATEGORY"], [4140, 4145, "TRAINED_CATEGORY"], [4150, 4159, "TRAINED_CATEGORY"], [4165, 4189, "TRAINED_CATEGORY"], [4193, 4212, "TRAINED_CATEGORY"], [4219, 4228, "TRAINED_CATEGORY"], [4232, 4235, "TRAINED_CATEGORY"], [4265, 4290, "TRAINED_CATEGORY"], [4294, 4302, "TRAINED_CATEGORY"], [4310, 4319, "TRAINED_CATEGORY"], [4323, 4336, "TRAINED_CATEGORY"], [4348, 4369, "TRAINED_CATEGORY"], [4374, 4383, "TRAINED_CATEGORY"], [4387, 4400, "TRAINED_CATEGORY"], [4416, 4428, "TRAINED_CATEGORY"], [4440, 4444, "TRAINED_CATEGORY"], [4533, 4551, "TRAINED_CATEGORY"], [4555, 4566, "TRAINED_CATEGORY"], [4568, 4570, "TRAINED_CATEGORY"], [4576, 4604, "TRAINED_CATEGORY"], [4608, 4619, "TRAINED_CATEGORY"], [4629, 4637, "TRAINED_CATEGORY"], [4641, 4654, "TRAINED_CATEGORY"], [4656, 4658, "TRAINED_CATEGORY"], [4679, 4687, "TRAINED_CATEGORY"], [4691, 4704, "TRAINED_CATEGORY"], [4710, 4721, "TRAINED_CATEGORY"], [4732, 4740, "TRAINED_CATEGORY"], [4748, 4758, "TRAINED_CATEGORY"], [4766, 4768, "TRAINED_CATEGORY"], [4777, 4798, "TRAINED_CATEGORY"], [4802, 4810, "TRAINED_CATEGORY"], [4825, 4840, "TRAINED_CATEGORY"], [4845, 4871, "TRAINED_CATEGORY"], [4875, 4897, "TRAINED_CATEGORY"], [4904, 4906, "TRAINED_CATEGORY"], [4930, 4957, "TRAINED_CATEGORY"], [4968, 4980, "TRAINED_CATEGORY"], [5034, 5051, "TRAINED_CATEGORY"], [5074, 5081, "TRAINED_CATEGORY"], [5085, 5098, "TRAINED_CATEGORY"], [5109, 5117, "TRAINED_CATEGORY"], [5119, 5130, "TRAINED_CATEGORY"], [5134, 5139, "TRAINED_CATEGORY"], [5155, 5176, "TRAINED_CATEGORY"], [5182, 5201, "TRAINED_CATEGORY"], [5207, 5228, "TRAINED_CATEGORY"], [5242, 5254, "TRAINED_CATEGORY"], [5258, 5267, "TRAINED_CATEGORY"], [5269, 5283, "TRAINED_CATEGORY"], [5287, 5299, "TRAINED_CATEGORY"], [5305, 5321, "TRAINED_CATEGORY"], [5363, 5377, "TRAINED_CATEGORY"], [5395, 5411, "TRAINED_CATEGORY"], [5415, 5422, "TRAINED_CATEGORY"], [5426, 5441, "TRAINED_CATEGORY"], [5443, 5457, "TRAINED_CATEGORY"], [5474, 5485, "TRAINED_CATEGORY"], [5489, 5497, "TRAINED_CATEGORY"], [5512, 5524, "TRAINED_CATEGORY"], [5549, 5557, "TRAINED_CATEGORY"], [5568, 5583, "TRAINED_CATEGORY"], [5590, 5597, "TRAINED_CATEGORY"], [5601, 5604, "TRAINED_CATEGORY"], [5619, 5654, "TRAINED_CATEGORY"], [5671, 5679, "TRAINED_CATEGORY"], [5683, 5706, "TRAINED_CATEGORY"], [5717, 5738, "TRAINED_CATEGORY"], [5742, 5764, "TRAINED_CATEGORY"], [5768, 5776, "TRAINED_CATEGORY"], [5793, 5813, "TRAINED_CATEGORY"], [5854, 5882, "TRAINED_CATEGORY"], [5886, 5907, "TRAINED_CATEGORY"], [5965, 5976, "TRAINED_CATEGORY"], [6008, 6033, "TRAINED_CATEGORY"], [6035, 6036, "TRAINED_CATEGORY"], [6043, 6074, "TRAINED_CATEGORY"], [6076, 6086, "TRAINED_CATEGORY"], [6095, 6106, "TRAINED_CATEGORY"], [6148, 6158, "TRAINED_CATEGORY"], [6170, 6192, "TRAINED_CATEGORY"], [6196, 6210, "TRAINED_CATEGORY"], [6224, 6237, "TRAINED_CATEGORY"], [6244, 6261, "TRAINED_CATEGORY"], [6265, 6272, "TRAINED_CATEGORY"], [6279, 6290, "TRAINED_CATEGORY"], [6296, 6315, "TRAINED_CATEGORY"], [6334, 6352, "TRAINED_CATEGORY"], [6367, 6372, "TRAINED_CATEGORY"], [6376, 6380, "TRAINED_CATEGORY"], [6405, 6406, "TRAINED_CATEGORY"], [6447, 6468, "TRAINED_CATEGORY"], [6472, 6479, "TRAINED_CATEGORY"], [6483, 6495, "TRAINED_CATEGORY"], [6922, 6950, "TRAINED_CATEGORY"], [6950, 6980, "TRAINED_CATEGORY"], [6996, 7011, "TRAINED_CATEGORY"], [7110, 7111, "TRAINED_CATEGORY"], [7162, 7190, "TRAINED_CATEGORY"], [7190, 7193, "TRAINED_CATEGORY"], [7203, 7204, "TRAINED_CATEGORY"], [7208, 7220, "TRAINED_CATEGORY"], [7349, 7350, "TRAINED_CATEGORY"], [7611, 7735, "TRAINED_CATEGORY"], [7815, 7816, "TRAINED_CATEGORY"], [7926, 7927, "TRAINED_CATEGORY"], [8040, 8099, "TRAINED_CATEGORY"], [8132, 8133, "TRAINED_CATEGORY"], [8298, 8299, "TRAINED_CATEGORY"], [8377, 8378, "TRAINED_CATEGORY"], [8437, 8438, "TRAINED_CATEGORY"], [8455, 8497, "TRAINED_CATEGORY"], [8497, 8521, "TRAINED_CATEGORY"], [8554, 8563, "TRAINED_CATEGORY"], [8573, 8582, "TRAINED_CATEGORY"], [8584, 8585, "TRAINED_CATEGORY"], [8592, 8602, "TRAINED_CATEGORY"], [8668, 8669, "TRAINED_CATEGORY"], [8789, 8790, "TRAINED_CATEGORY"], [8868, 8869, "TRAINED_CATEGORY"], [8886, 8894, "TRAINED_CATEGORY"], [8920, 8949, "TRAINED_CATEGORY"], [8955, 8956, "TRAINED_CATEGORY"], [8963, 8986, "TRAINED_CATEGORY"], [8987, 8988, "TRAINED_CATEGORY"], [9007, 9020, "TRAINED_CATEGORY"], [9052, 9053, "TRAINED_CATEGORY"], [9170, 9185, "TRAINED_CATEGORY"], [9200, 9214, "TRAINED_CATEGORY"], [9223, 9238, "TRAINED_CATEGORY"], [9246, 9251, "TRAINED_CATEGORY"], [9264, 9272, "TRAINED_CATEGORY"], [9274, 9297, "TRAINED_CATEGORY"], [9514, 9517, "TRAINED_CATEGORY"], [9547, 9548, "TRAINED_CATEGORY"], [9563, 9564, "TRAINED_CATEGORY"], [9853, 9854, "TRAINED_CATEGORY"], [10125, 10126, "TRAINED_CATEGORY"], [10359, 10360, "TRAINED_CATEGORY"], [10649, 10650, "TRAINED_CATEGORY"], [10870, 10979, "TRAINED_CATEGORY"], [11019, 11020, "TRAINED_CATEGORY"], [11424, 11463, "TRAINED_CATEGORY"], [11539, 11550, "TRAINED_CATEGORY"], [11605, 11606, "TRAINED_CATEGORY"], [11748, 11751, "TRAINED_CATEGORY"], [11781, 11782, "TRAINED_CATEGORY"], [11797, 11798, "TRAINED_CATEGORY"], [12013, 12014, "TRAINED_CATEGORY"], [12034, 12035, "TRAINED_CATEGORY"], [12046, 12047, "TRAINED_CATEGORY"], [12190, 12193, "TRAINED_CATEGORY"], [12223, 12224, "TRAINED_CATEGORY"], [12239, 12240, "TRAINED_CATEGORY"], [12561, 12562, "TRAINED_CATEGORY"], [12672, 12673, "TRAINED_CATEGORY"], [12746, 12747, "TRAINED_CATEGORY"], [12762, 12763, "TRAINED_CATEGORY"], [12825, 12853, "TRAINED_CATEGORY"], [12982, 13049, "TRAINED_CATEGORY"], [13066, 13071, "TRAINED_CATEGORY"], [13133, 13146, "TRAINED_CATEGORY"], [13148, 13150, "TRAINED_CATEGORY"], [13384, 13385, "TRAINED_CATEGORY"], [13977, 13978, "TRAINED_CATEGORY"], [14317, 14328, "TRAINED_CATEGORY"], [14340, 14355, "TRAINED_CATEGORY"], [14356, 14358, "TRAINED_CATEGORY"], [14374, 14386, "TRAINED_CATEGORY"], [14424, 14443, "TRAINED_CATEGORY"], [14445, 14462, "TRAINED_CATEGORY"], [14467, 14497, "TRAINED_CATEGORY"], [14506, 14509, "TRAINED_CATEGORY"], [14518, 14555, "TRAINED_CATEGORY"], [14559, 14581, "TRAINED_CATEGORY"], [14585, 14595, "TRAINED_CATEGORY"], [14615, 14616, "TRAINED_CATEGORY"], [14620, 14649, "TRAINED_CATEGORY"], [14668, 14697, "TRAINED_CATEGORY"], [14701, 14718, "TRAINED_CATEGORY"], [14741, 14748, "TRAINED_CATEGORY"], [14755, 14763, "TRAINED_CATEGORY"], [14772, 14800, "TRAINED_CATEGORY"], [14808, 14832, "TRAINED_CATEGORY"], [14836, 14858, "TRAINED_CATEGORY"], [14860, 14867, "TRAINED_CATEGORY"], [14886, 14904, "TRAINED_CATEGORY"], [14909, 14926, "TRAINED_CATEGORY"], [14955, 14991, "TRAINED_CATEGORY"], [14997, 14998, "TRAINED_CATEGORY"], [15162, 15163, "TRAINED_CATEGORY"], [15213, 15233, "TRAINED_CATEGORY"], [15278, 15279, "TRAINED_CATEGORY"], [15411, 15412, "TRAINED_CATEGORY"], [15454, 15455, "TRAINED_CATEGORY"], [15504, 15505, "TRAINED_CATEGORY"], [15572, 15573, "TRAINED_CATEGORY"], [15608, 15688, "TRAINED_CATEGORY"], [15772, 15773, "TRAINED_CATEGORY"], [15796, 15814, "TRAINED_CATEGORY"], [15816, 15817, "TRAINED_CATEGORY"], [15833, 15850, "TRAINED_CATEGORY"], [15861, 15863, "TRAINED_CATEGORY"], [15886, 15903, "TRAINED_CATEGORY"], [15919, 15939, "TRAINED_CATEGORY"], [15945, 15965, "TRAINED_CATEGORY"], [16064, 16065, "TRAINED_CATEGORY"], [16157, 16174, "TRAINED_CATEGORY"], [16189, 16190, "TRAINED_CATEGORY"], [16220, 16221, "TRAINED_CATEGORY"], [16236, 16237, "TRAINED_CATEGORY"], [16444, 16578, "TRAINED_CATEGORY"], [16661, 16662, "TRAINED_CATEGORY"], [16718, 16719, "TRAINED_CATEGORY"], [16926, 16927, "TRAINED_CATEGORY"], [17190, 17191, "TRAINED_CATEGORY"], [17346, 17347, "TRAINED_CATEGORY"], [17488, 17489, "TRAINED_CATEGORY"], [17554, 17555, "TRAINED_CATEGORY"], [17710, 17711, "TRAINED_CATEGORY"], [17852, 17853, "TRAINED_CATEGORY"], [18050, 18051, "TRAINED_CATEGORY"], [18116, 18117, "TRAINED_CATEGORY"], [18197, 18339, "TRAINED_CATEGORY"], [18340, 18355, "TRAINED_CATEGORY"], [18357, 18362, "TRAINED_CATEGORY"], [18363, 18398, "TRAINED_CATEGORY"], [18400, 18424, "TRAINED_CATEGORY"], [18536, 18549, "TRAINED_CATEGORY"], [18556, 18576, "TRAINED_CATEGORY"], [18583, 18602, "TRAINED_CATEGORY"], [18605, 18632, "TRAINED_CATEGORY"], [18648, 18650, "TRAINED_CATEGORY"], [18677, 18703, "TRAINED_CATEGORY"], [18707, 18710, "TRAINED_CATEGORY"], [18717, 18735, "TRAINED_CATEGORY"], [18740, 18752, "TRAINED_CATEGORY"], [18756, 18764, "TRAINED_CATEGORY"], [18774, 18805, "TRAINED_CATEGORY"], [18812, 18830, "TRAINED_CATEGORY"], [18835, 18847, "TRAINED_CATEGORY"], [18851, 18854, "TRAINED_CATEGORY"], [18856, 18883, "TRAINED_CATEGORY"], [18887, 18904, "TRAINED_CATEGORY"], [18932, 18939, "TRAINED_CATEGORY"], [18940, 18944, "TRAINED_CATEGORY"], [18948, 18951, "TRAINED_CATEGORY"], [18953, 18958, "TRAINED_CATEGORY"], [18963, 18991, "TRAINED_CATEGORY"], [18999, 19023, "TRAINED_CATEGORY"], [19027, 19036, "TRAINED_CATEGORY"], [19040, 19062, "TRAINED_CATEGORY"], [19064, 19071, "TRAINED_CATEGORY"], [19076, 19081, "TRAINED_CATEGORY"], [19090, 19093, "TRAINED_CATEGORY"], [19098, 19117, "TRAINED_CATEGORY"], [19121, 19124, "TRAINED_CATEGORY"], [19126, 19169, "TRAINED_CATEGORY"], [19173, 19174, "TRAINED_CATEGORY"], [19236, 19237, "TRAINED_CATEGORY"], [19276, 19277, "TRAINED_CATEGORY"], [19356, 19358, "TRAINED_CATEGORY"], [19361, 19383, "TRAINED_CATEGORY"], [19395, 19396, "TRAINED_CATEGORY"], [19407, 19408, "TRAINED_CATEGORY"], [19419, 19426, "TRAINED_CATEGORY"], [19427, 19440, "TRAINED_CATEGORY"], [19445, 19461, "TRAINED_CATEGORY"], [19465, 19468, "TRAINED_CATEGORY"], [19470, 19483, "TRAINED_CATEGORY"], [19487, 19488, "TRAINED_CATEGORY"], [19551, 19558, "TRAINED_CATEGORY"], [19562, 19563, "TRAINED_CATEGORY"], [19578, 19593, "TRAINED_CATEGORY"], [19597, 19622, "TRAINED_CATEGORY"], [19633, 19645, "TRAINED_CATEGORY"], [19659, 19672, "TRAINED_CATEGORY"], [19697, 19700, "TRAINED_CATEGORY"], [19707, 19722, "TRAINED_CATEGORY"], [19730, 19741, "TRAINED_CATEGORY"], [19746, 19749, "TRAINED_CATEGORY"], [19750, 19756, "TRAINED_CATEGORY"], [19794, 19832, "TRAINED_CATEGORY"], [19836, 19850, "TRAINED_CATEGORY"], [19852, 19875, "TRAINED_CATEGORY"], [19891, 19925, "TRAINED_CATEGORY"], [19931, 19942, "TRAINED_CATEGORY"], [20036, 20037, "TRAINED_CATEGORY"], [20595, 20596, "TRAINED_CATEGORY"], [21431, 21432, "TRAINED_CATEGORY"], [21897, 21898, "TRAINED_CATEGORY"], [22201, 22202, "TRAINED_CATEGORY"], [22501, 22502, "TRAINED_CATEGORY"], [22900, 22901, "TRAINED_CATEGORY"], [23760, 23800, "TRAINED_CATEGORY"], [23800, 23818, "TRAINED_CATEGORY"], [23819, 23836, "TRAINED_CATEGORY"], [23837, 23854, "TRAINED_CATEGORY"], [23854, 23876, "TRAINED_CATEGORY"], [23905, 23928, "TRAINED_CATEGORY"], [23932, 23935, "TRAINED_CATEGORY"], [23964, 23968, "TRAINED_CATEGORY"], [23990, 24002, "TRAINED_CATEGORY"], [24003, 24006, "TRAINED_CATEGORY"], [24012, 24015, "TRAINED_CATEGORY"], [24034, 24045, "TRAINED_CATEGORY"], [24049, 24067, "TRAINED_CATEGORY"], [24087, 24102, "TRAINED_CATEGORY"], [24148, 24159, "TRAINED_CATEGORY"], [24176, 24199, "TRAINED_CATEGORY"], [24202, 24213, "TRAINED_CATEGORY"], [24217, 24231, "TRAINED_CATEGORY"], [24260, 24280, "TRAINED_CATEGORY"], [24289, 24319, "TRAINED_CATEGORY"], [24325, 24336, "TRAINED_CATEGORY"], [24338, 24349, "TRAINED_CATEGORY"], [24366, 24405, "TRAINED_CATEGORY"], [24422, 24440, "TRAINED_CATEGORY"], [24444, 24455, "TRAINED_CATEGORY"], [24474, 24512, "TRAINED_CATEGORY"], [24517, 24528, "TRAINED_CATEGORY"], [24530, 24561, "TRAINED_CATEGORY"], [24566, 24588, "TRAINED_CATEGORY"], [24692, 24693, "TRAINED_CATEGORY"], [24728, 24729, "TRAINED_CATEGORY"], [24769, 24770, "TRAINED_CATEGORY"], [24809, 24810, "TRAINED_CATEGORY"], [24882, 24883, "TRAINED_CATEGORY"], [24918, 24919, "TRAINED_CATEGORY"], [24971, 25066, "TRAINED_CATEGORY"], [25071, 25102, "TRAINED_CATEGORY"], [25111, 25135, "TRAINED_CATEGORY"], [25269, 25270, "TRAINED_CATEGORY"], [25299, 25300, "TRAINED_CATEGORY"], [25352, 25353, "TRAINED_CATEGORY"], [25388, 25389, "TRAINED_CATEGORY"], [25429, 25430, "TRAINED_CATEGORY"], [25468, 25469, "TRAINED_CATEGORY"], [25556, 25557, "TRAINED_CATEGORY"], [25597, 25598, "TRAINED_CATEGORY"], [25637, 25638, "TRAINED_CATEGORY"], [25687, 25689, "TRAINED_CATEGORY"], [25703, 25705, "TRAINED_CATEGORY"], [25765, 25788, "TRAINED_CATEGORY"], [25802, 25804, "TRAINED_CATEGORY"], [25836, 25837, "TRAINED_CATEGORY"], [25841, 25860, "TRAINED_CATEGORY"], [25864, 25879, "TRAINED_CATEGORY"], [25884, 25887, "TRAINED_CATEGORY"], [25889, 25892, "TRAINED_CATEGORY"], [25906, 25913, "TRAINED_CATEGORY"], [25917, 25928, "TRAINED_CATEGORY"], [25934, 25945, "TRAINED_CATEGORY"], [25962, 25978, "TRAINED_CATEGORY"], [25996, 26004, "TRAINED_CATEGORY"], [26008, 26018, "TRAINED_CATEGORY"], [26019, 26025, "TRAINED_CATEGORY"], [26033, 26057, "TRAINED_CATEGORY"], [26062, 26080, "TRAINED_CATEGORY"], [26081, 26082, "TRAINED_CATEGORY"], [26085, 26088, "TRAINED_CATEGORY"], [26094, 26111, "TRAINED_CATEGORY"], [26118, 26135, "TRAINED_CATEGORY"], [26139, 26150, "TRAINED_CATEGORY"], [26154, 26165, "TRAINED_CATEGORY"], [26169, 26180, "TRAINED_CATEGORY"], [26209, 26220, "TRAINED_CATEGORY"], [26231, 26263, "TRAINED_CATEGORY"], [26289, 26326, "TRAINED_CATEGORY"], [26346, 26375, "TRAINED_CATEGORY"], [26383, 26411, "TRAINED_CATEGORY"], [26460, 26461, "TRAINED_CATEGORY"], [26496, 26497, "TRAINED_CATEGORY"], [26547, 26548, "TRAINED_CATEGORY"], [26590, 26591, "TRAINED_CATEGORY"], [26626, 26627, "TRAINED_CATEGORY"], [26665, 26692, "TRAINED_CATEGORY"], [26692, 26706, "TRAINED_CATEGORY"], [26716, 26723, "TRAINED_CATEGORY"], [26734, 26744, "TRAINED_CATEGORY"], [26745, 26747, "TRAINED_CATEGORY"], [26756, 26762, "TRAINED_CATEGORY"], [26767, 26781, "TRAINED_CATEGORY"], [26786, 26797, "TRAINED_CATEGORY"], [26799, 26802, "TRAINED_CATEGORY"], [26810, 26833, "TRAINED_CATEGORY"], [26858, 26859, "TRAINED_CATEGORY"], [26889, 26890, "TRAINED_CATEGORY"], [26914, 26915, "TRAINED_CATEGORY"], [26944, 26945, "TRAINED_CATEGORY"], [26995, 26996, "TRAINED_CATEGORY"], [27020, 27021, "TRAINED_CATEGORY"], [27060, 27061, "TRAINED_CATEGORY"], [27070, 27071, "TRAINED_CATEGORY"], [27091, 27092, "TRAINED_CATEGORY"], [27116, 27117, "TRAINED_CATEGORY"], [27165, 27187, "TRAINED_CATEGORY"], [27215, 27232, "TRAINED_CATEGORY"], [27256, 27275, "TRAINED_CATEGORY"], [27296, 27310, "TRAINED_CATEGORY"], [27314, 27330, "TRAINED_CATEGORY"], [27358, 27370, "TRAINED_CATEGORY"], [27375, 27408, "TRAINED_CATEGORY"], [27414, 27428, "TRAINED_CATEGORY"], [27430, 27447, "TRAINED_CATEGORY"], [27458, 27470, "TRAINED_CATEGORY"], [27474, 27491, "TRAINED_CATEGORY"], [27534, 27572, "TRAINED_CATEGORY"], [27618, 27619, "TRAINED_CATEGORY"], [27727, 27728, "TRAINED_CATEGORY"], [27797, 27798, "TRAINED_CATEGORY"], [27851, 27852, "TRAINED_CATEGORY"], [27887, 27888, "TRAINED_CATEGORY"], [27923, 27924, "TRAINED_CATEGORY"], [28064, 28090, "TRAINED_CATEGORY"], [28100, 28102, "TRAINED_CATEGORY"], [28208, 28209, "TRAINED_CATEGORY"], [28227, 28228, "TRAINED_CATEGORY"], [28297, 28298, "TRAINED_CATEGORY"], [28437, 28461, "TRAINED_CATEGORY"], [28500, 28529, "TRAINED_CATEGORY"], [28537, 28555, "TRAINED_CATEGORY"], [28587, 28612, "TRAINED_CATEGORY"], [28647, 28659, "TRAINED_CATEGORY"], [28663, 28674, "TRAINED_CATEGORY"], [28692, 28699, "TRAINED_CATEGORY"], [28711, 28712, "TRAINED_CATEGORY"], [28729, 28768, "TRAINED_CATEGORY"], [28775, 28800, "TRAINED_CATEGORY"], [28809, 28837, "TRAINED_CATEGORY"], [28847, 28855, "TRAINED_CATEGORY"], [28882, 28890, "TRAINED_CATEGORY"], [28900, 28908, "TRAINED_CATEGORY"], [28991, 29016, "TRAINED_CATEGORY"], [29029, 29043, "TRAINED_CATEGORY"], [29052, 29060, "TRAINED_CATEGORY"], [29072, 29094, "TRAINED_CATEGORY"], [29118, 29130, "TRAINED_CATEGORY"], [29189, 29193, "TRAINED_CATEGORY"], [29258, 29262, "TRAINED_CATEGORY"], [29296, 29315, "TRAINED_CATEGORY"], [29328, 29338, "TRAINED_CATEGORY"], [29342, 29363, "TRAINED_CATEGORY"], [29388, 29398, "TRAINED_CATEGORY"], [29414, 29423, "TRAINED_CATEGORY"], [29435, 29446, "TRAINED_CATEGORY"], [29474, 29488, "TRAINED_CATEGORY"], [29490, 29502, "TRAINED_CATEGORY"], [29530, 29549, "TRAINED_CATEGORY"], [29558, 29598, "TRAINED_CATEGORY"], [29613, 29617, "TRAINED_CATEGORY"], [29621, 29647, "TRAINED_CATEGORY"], [29661, 29675, "TRAINED_CATEGORY"], [29684, 29688, "TRAINED_CATEGORY"], [29738, 29762, "TRAINED_CATEGORY"], [29792, 29805, "TRAINED_CATEGORY"], [29809, 29818, "TRAINED_CATEGORY"], [29833, 29844, "TRAINED_CATEGORY"], [29848, 29859, "TRAINED_CATEGORY"], [29869, 29919, "TRAINED_CATEGORY"], [29926, 29937, "TRAINED_CATEGORY"], [29941, 29942, "TRAINED_CATEGORY"], [29961, 30009, "TRAINED_CATEGORY"], [30011, 30030, "TRAINED_CATEGORY"], [30050, 30061, "TRAINED_CATEGORY"], [30065, 30077, "TRAINED_CATEGORY"], [30106, 30133, "TRAINED_CATEGORY"], [30137, 30157, "TRAINED_CATEGORY"], [30182, 30200, "TRAINED_CATEGORY"], [30217, 30251, "TRAINED_CATEGORY"], [30264, 30287, "TRAINED_CATEGORY"], [30289, 30313, "TRAINED_CATEGORY"], [30317, 30326, "TRAINED_CATEGORY"], [30335, 30359, "TRAINED_CATEGORY"], [30387, 30392, "TRAINED_CATEGORY"], [30400, 30403, "TRAINED_CATEGORY"], [30418, 30428, "TRAINED_CATEGORY"], [30454, 30464, "TRAINED_CATEGORY"], [30470, 30504, "TRAINED_CATEGORY"], [30540, 30564, "TRAINED_CATEGORY"], [30572, 30602, "TRAINED_CATEGORY"], [30623, 30628, "TRAINED_CATEGORY"], [30657, 30667, "TRAINED_CATEGORY"], [30675, 30703, "TRAINED_CATEGORY"], [30708, 30747, "TRAINED_CATEGORY"], [30776, 30804, "TRAINED_CATEGORY"], [30806, 30838, "TRAINED_CATEGORY"], [30840, 30843, "TRAINED_CATEGORY"], [30848, 30849, "TRAINED_CATEGORY"], [30926, 30927, "TRAINED_CATEGORY"], [31096, 31098, "TRAINED_CATEGORY"], [31156, 31157, "TRAINED_CATEGORY"], [31169, 31170, "TRAINED_CATEGORY"], [31202, 31218, "TRAINED_CATEGORY"], [31232, 31251, "TRAINED_CATEGORY"], [31255, 31256, "TRAINED_CATEGORY"], [31258, 31259, "TRAINED_CATEGORY"], [31271, 31272, "TRAINED_CATEGORY"], [31281, 31292, "TRAINED_CATEGORY"], [31306, 31329, "TRAINED_CATEGORY"], [31333, 31341, "TRAINED_CATEGORY"], [31349, 31374, "TRAINED_CATEGORY"], [31378, 31379, "TRAINED_CATEGORY"], [31385, 31386, "TRAINED_CATEGORY"], [31397, 31398, "TRAINED_CATEGORY"], [31399, 31412, "TRAINED_CATEGORY"], [31417, 31440, "TRAINED_CATEGORY"], [31444, 31452, "TRAINED_CATEGORY"], [31494, 31496, "TRAINED_CATEGORY"], [31500, 31505, "TRAINED_CATEGORY"], [31509, 31527, "TRAINED_CATEGORY"], [31529, 31539, "TRAINED_CATEGORY"], [31540, 31543, "TRAINED_CATEGORY"], [31739, 31740, "TRAINED_CATEGORY"], [31812, 31813, "TRAINED_CATEGORY"], [31931, 32067, "TRAINED_CATEGORY"], [32160, 32161, "TRAINED_CATEGORY"], [32220, 32221, "TRAINED_CATEGORY"], [32293, 32294, "TRAINED_CATEGORY"], [32482, 32483, "TRAINED_CATEGORY"], [32661, 32662, "TRAINED_CATEGORY"], [32736, 32737, "TRAINED_CATEGORY"], [32796, 32797, "TRAINED_CATEGORY"], [33004, 33005, "TRAINED_CATEGORY"], [33183, 33184, "TRAINED_CATEGORY"], [33306, 33307, "TRAINED_CATEGORY"], [33530, 33591, "TRAINED_CATEGORY"], [33748, 33749, "TRAINED_CATEGORY"], [33752, 33753, "TRAINED_CATEGORY"], [33811, 33813, "TRAINED_CATEGORY"], [33861, 33863, "TRAINED_CATEGORY"], [33895, 33902, "TRAINED_CATEGORY"], [33933, 33935, "TRAINED_CATEGORY"], [33974, 33976, "TRAINED_CATEGORY"], [34086, 34087, "TRAINED_CATEGORY"], [34185, 34211, "TRAINED_CATEGORY"], [34217, 34236, "TRAINED_CATEGORY"], [34241, 34242, "TRAINED_CATEGORY"], [34248, 34264, "TRAINED_CATEGORY"], [34277, 34291, "TRAINED_CATEGORY"], [34392, 34393, "TRAINED_CATEGORY"], [34563, 34564, "TRAINED_CATEGORY"], [34599, 34600, "TRAINED_CATEGORY"], [34697, 34704, "TRAINED_CATEGORY"], [34722, 34729, "TRAINED_CATEGORY"], [34744, 34751, "TRAINED_CATEGORY"], [34760, 34770, "TRAINED_CATEGORY"], [34776, 34805, "TRAINED_CATEGORY"], [34830, 34856, "TRAINED_CATEGORY"], [34857, 34858, "TRAINED_CATEGORY"], [34862, 34863, "TRAINED_CATEGORY"], [34882, 34898, "TRAINED_CATEGORY"], [34902, 34905, "TRAINED_CATEGORY"], [34933, 34936, "TRAINED_CATEGORY"], [34977, 34978, "TRAINED_CATEGORY"], [35049, 35064, "TRAINED_CATEGORY"], [35068, 35087, "TRAINED_CATEGORY"], [35092, 35095, "TRAINED_CATEGORY"], [35103, 35135, "TRAINED_CATEGORY"], [35136, 35152, "TRAINED_CATEGORY"], [35153, 35154, "TRAINED_CATEGORY"], [35269, 35270, "TRAINED_CATEGORY"], [35388, 35389, "TRAINED_CATEGORY"], [35442, 35443, "TRAINED_CATEGORY"], [35602, 35603, "TRAINED_CATEGORY"], [35791, 35792, "TRAINED_CATEGORY"], [35864, 35865, "TRAINED_CATEGORY"], [36024, 36025, "TRAINED_CATEGORY"], [36078, 36079, "TRAINED_CATEGORY"], [36162, 36202, "TRAINED_CATEGORY"], [36205, 36206, "TRAINED_CATEGORY"], [36206, 36241, "TRAINED_CATEGORY"], [36242, 36244, "TRAINED_CATEGORY"], [36246, 36261, "TRAINED_CATEGORY"], [36304, 36306, "TRAINED_CATEGORY"], [36347, 36358, "TRAINED_CATEGORY"], [36362, 36363, "TRAINED_CATEGORY"], [36383, 36408, "TRAINED_CATEGORY"], [36412, 36413, "TRAINED_CATEGORY"], [36428, 36460, "TRAINED_CATEGORY"], [36462, 36471, "TRAINED_CATEGORY"], [36480, 36503, "TRAINED_CATEGORY"], [36507, 36530, "TRAINED_CATEGORY"], [36550, 36557, "TRAINED_CATEGORY"], [36561, 36562, "TRAINED_CATEGORY"], [36586, 36600, "TRAINED_CATEGORY"], [36615, 36622, "TRAINED_CATEGORY"], [36630, 36646, "TRAINED_CATEGORY"], [36660, 36691, "TRAINED_CATEGORY"], [36697, 36710, "TRAINED_CATEGORY"], [36719, 36733, "TRAINED_CATEGORY"], [36737, 36747, "TRAINED_CATEGORY"], [36770, 36793, "TRAINED_CATEGORY"], [36795, 36828, "TRAINED_CATEGORY"], [36860, 36900, "TRAINED_CATEGORY"], [36905, 36927, "TRAINED_CATEGORY"], [36977, 36978, "TRAINED_CATEGORY"], [37013, 37014, "TRAINED_CATEGORY"], [37077, 37078, "TRAINED_CATEGORY"], [37203, 37204, "TRAINED_CATEGORY"], [37254, 37255, "TRAINED_CATEGORY"], [37297, 37298, "TRAINED_CATEGORY"], [37333, 37334, "TRAINED_CATEGORY"], [37372, 37438, "TRAINED_CATEGORY"], [37439, 37452, "TRAINED_CATEGORY"], [37474, 37488, "TRAINED_CATEGORY"], [37492, 37502, "TRAINED_CATEGORY"], [37506, 37507, "TRAINED_CATEGORY"], [37514, 37554, "TRAINED_CATEGORY"], [37558, 37566, "TRAINED_CATEGORY"], [37576, 37594, "TRAINED_CATEGORY"], [37603, 37630, "TRAINED_CATEGORY"], [37634, 37640, "TRAINED_CATEGORY"], [37644, 37663, "TRAINED_CATEGORY"], [37668, 37677, "TRAINED_CATEGORY"], [37681, 37695, "TRAINED_CATEGORY"], [37719, 37755, "TRAINED_CATEGORY"], [37757, 37765, "TRAINED_CATEGORY"], [37775, 37785, "TRAINED_CATEGORY"], [37786, 37799, "TRAINED_CATEGORY"], [37813, 37835, "TRAINED_CATEGORY"], [37845, 37850, "TRAINED_CATEGORY"], [37854, 37860, "TRAINED_CATEGORY"], [37864, 37879, "TRAINED_CATEGORY"], [37881, 37910, "TRAINED_CATEGORY"], [37926, 37932, "TRAINED_CATEGORY"], [37953, 37978, "TRAINED_CATEGORY"], [37993, 38000, "TRAINED_CATEGORY"], [38004, 38011, "TRAINED_CATEGORY"], [38015, 38028, "TRAINED_CATEGORY"], [38032, 38042, "TRAINED_CATEGORY"], [38048, 38056, "TRAINED_CATEGORY"], [38058, 38088, "TRAINED_CATEGORY"], [38104, 38120, "TRAINED_CATEGORY"], [38127, 38142, "TRAINED_CATEGORY"], [38148, 38177, "TRAINED_CATEGORY"], [38203, 38213, "TRAINED_CATEGORY"], [38215, 38234, "TRAINED_CATEGORY"], [38239, 38240, "TRAINED_CATEGORY"], [38246, 38262, "TRAINED_CATEGORY"], [38266, 38281, "TRAINED_CATEGORY"], [38285, 38299, "TRAINED_CATEGORY"], [38301, 38316, "TRAINED_CATEGORY"], [38336, 38347, "TRAINED_CATEGORY"], [38351, 38364, "TRAINED_CATEGORY"], [38385, 38392, "TRAINED_CATEGORY"], [38396, 38417, "TRAINED_CATEGORY"], [38421, 38431, "TRAINED_CATEGORY"], [38437, 38464, "TRAINED_CATEGORY"], [38490, 38506, "TRAINED_CATEGORY"], [38508, 38515, "TRAINED_CATEGORY"], [38519, 38538, "TRAINED_CATEGORY"], [38551, 38558, "TRAINED_CATEGORY"], [38562, 38583, "TRAINED_CATEGORY"], [38587, 38597, "TRAINED_CATEGORY"], [38603, 38630, "TRAINED_CATEGORY"], [38632, 38635, "TRAINED_CATEGORY"], [38656, 38663, "TRAINED_CATEGORY"], [38667, 38673, "TRAINED_CATEGORY"], [38681, 38691, "TRAINED_CATEGORY"], [38695, 38700, "TRAINED_CATEGORY"], [38715, 38739, "TRAINED_CATEGORY"], [38763, 38775, "TRAINED_CATEGORY"], [38795, 38823, "TRAINED_CATEGORY"], [38830, 38854, "TRAINED_CATEGORY"], [38856, 38866, "TRAINED_CATEGORY"], [38870, 38894, "TRAINED_CATEGORY"], [38948, 38960, "TRAINED_CATEGORY"], [38964, 38975, "TRAINED_CATEGORY"], [38989, 38992, "TRAINED_CATEGORY"], [39010, 39021, "TRAINED_CATEGORY"], [39026, 39050, "TRAINED_CATEGORY"], [39052, 39055, "TRAINED_CATEGORY"], [39060, 39075, "TRAINED_CATEGORY"], [39085, 39122, "TRAINED_CATEGORY"], [39135, 39147, "TRAINED_CATEGORY"], [39157, 39174, "TRAINED_CATEGORY"], [39196, 39210, "TRAINED_CATEGORY"], [39230, 39239, "TRAINED_CATEGORY"], [39243, 39277, "TRAINED_CATEGORY"], [39295, 39302, "TRAINED_CATEGORY"], [39328, 39357, "TRAINED_CATEGORY"], [39380, 39390, "TRAINED_CATEGORY"], [39416, 39424, "TRAINED_CATEGORY"], [39427, 39472, "TRAINED_CATEGORY"], [39520, 39523, "TRAINED_CATEGORY"], [39525, 39528, "TRAINED_CATEGORY"], [39545, 39556, "TRAINED_CATEGORY"], [39560, 39573, "TRAINED_CATEGORY"], [39578, 39580, "TRAINED_CATEGORY"], [39586, 39604, "TRAINED_CATEGORY"], [39609, 39613, "TRAINED_CATEGORY"], [39619, 39643, "TRAINED_CATEGORY"], [39680, 39687, "TRAINED_CATEGORY"], [39700, 39710, "TRAINED_CATEGORY"], [39714, 39717, "TRAINED_CATEGORY"], [39722, 39734, "TRAINED_CATEGORY"], [39737, 39741, "TRAINED_CATEGORY"], [39746, 39757, "TRAINED_CATEGORY"], [39761, 39769, "TRAINED_CATEGORY"], [39775, 39792, "TRAINED_CATEGORY"], [39798, 39805, "TRAINED_CATEGORY"], [39809, 39832, "TRAINED_CATEGORY"], [39855, 39857, "TRAINED_CATEGORY"], [39867, 39877, "TRAINED_CATEGORY"], [39881, 39899, "TRAINED_CATEGORY"], [39913, 39942, "TRAINED_CATEGORY"], [39970, 39983, "TRAINED_CATEGORY"], [39990, 40010, "TRAINED_CATEGORY"], [40016, 40034, "TRAINED_CATEGORY"], [40044, 40064, "TRAINED_CATEGORY"], [40093, 40121, "TRAINED_CATEGORY"], [40148, 40171, "TRAINED_CATEGORY"], [40177, 40192, "TRAINED_CATEGORY"], [40199, 40210, "TRAINED_CATEGORY"], [40215, 40219, "TRAINED_CATEGORY"], [40222, 40225, "TRAINED_CATEGORY"], [40229, 40256, "TRAINED_CATEGORY"], [40260, 40268, "TRAINED_CATEGORY"], [40271, 40288, "TRAINED_CATEGORY"], [40310, 40313, "TRAINED_CATEGORY"], [40319, 40329, "TRAINED_CATEGORY"], [40342, 40349, "TRAINED_CATEGORY"], [40354, 40361, "TRAINED_CATEGORY"], [40364, 40388, "TRAINED_CATEGORY"], [40406, 40411, "TRAINED_CATEGORY"], [40416, 40422, "TRAINED_CATEGORY"], [40426, 40437, "TRAINED_CATEGORY"], [40441, 40448, "TRAINED_CATEGORY"], [40452, 40458, "TRAINED_CATEGORY"], [40462, 40467, "TRAINED_CATEGORY"], [40475, 40480, "TRAINED_CATEGORY"], [40490, 40514, "TRAINED_CATEGORY"], [40521, 40534, "TRAINED_CATEGORY"], [40549, 40556, "TRAINED_CATEGORY"], [40567, 40574, "TRAINED_CATEGORY"], [40600, 40609, "TRAINED_CATEGORY"], [40631, 40644, "TRAINED_CATEGORY"], [40663, 40671, "TRAINED_CATEGORY"], [40686, 40712, "TRAINED_CATEGORY"], [40724, 40749, "TRAINED_CATEGORY"], [40753, 40760, "TRAINED_CATEGORY"], [40765, 40768, "TRAINED_CATEGORY"], [40808, 40824, "TRAINED_CATEGORY"], [40828, 40842, "TRAINED_CATEGORY"], [40846, 40862, "TRAINED_CATEGORY"], [40866, 40879, "TRAINED_CATEGORY"], [40881, 40897, "TRAINED_CATEGORY"], [40952, 40965, "TRAINED_CATEGORY"], [40981, 41010, "TRAINED_CATEGORY"], [41021, 41034, "TRAINED_CATEGORY"], [41038, 41054, "TRAINED_CATEGORY"], [41059, 41075, "TRAINED_CATEGORY"], [41094, 41123, "TRAINED_CATEGORY"], [41165, 41173, "TRAINED_CATEGORY"], [41177, 41185, "TRAINED_CATEGORY"], [41187, 41193, "TRAINED_CATEGORY"], [41224, 41231, "TRAINED_CATEGORY"], [41247, 41268, "TRAINED_CATEGORY"], [41272, 41289, "TRAINED_CATEGORY"], [41293, 41301, "TRAINED_CATEGORY"], [41346, 41377, "TRAINED_CATEGORY"], [41381, 41401, "TRAINED_CATEGORY"], [41406, 41414, "TRAINED_CATEGORY"], [41454, 41466, "TRAINED_CATEGORY"], [41468, 41480, "TRAINED_CATEGORY"], [41498, 41515, "TRAINED_CATEGORY"], [41519, 41538, "TRAINED_CATEGORY"], [41540, 41548, "TRAINED_CATEGORY"], [41553, 41572, "TRAINED_CATEGORY"], [41574, 41588, "TRAINED_CATEGORY"], [41590, 41597, "TRAINED_CATEGORY"], [41598, 41624, "TRAINED_CATEGORY"], [41636, 41647, "TRAINED_CATEGORY"], [41651, 41658, "TRAINED_CATEGORY"], [41661, 41675, "TRAINED_CATEGORY"], [41705, 41725, "TRAINED_CATEGORY"], [41727, 41735, "TRAINED_CATEGORY"], [41742, 41749, "TRAINED_CATEGORY"], [41752, 41755, "TRAINED_CATEGORY"], [41759, 41786, "TRAINED_CATEGORY"], [41790, 41809, "TRAINED_CATEGORY"], [41811, 41813, "TRAINED_CATEGORY"], [41845, 41863, "TRAINED_CATEGORY"], [41874, 41876, "TRAINED_CATEGORY"], [41903, 41915, "TRAINED_CATEGORY"], [41924, 41943, "TRAINED_CATEGORY"], [41959, 41965, "TRAINED_CATEGORY"], [41969, 41973, "TRAINED_CATEGORY"], [41978, 41988, "TRAINED_CATEGORY"], [41992, 42017, "TRAINED_CATEGORY"], [42032, 42050, "TRAINED_CATEGORY"], [42059, 42065, "TRAINED_CATEGORY"], [42069, 42073, "TRAINED_CATEGORY"], [42077, 42096, "TRAINED_CATEGORY"], [42098, 42130, "TRAINED_CATEGORY"], [42134, 42148, "TRAINED_CATEGORY"], [42172, 42190, "TRAINED_CATEGORY"], [42197, 42202, "TRAINED_CATEGORY"], [42206, 42213, "TRAINED_CATEGORY"], [42218, 42231, "TRAINED_CATEGORY"], [42238, 42250, "TRAINED_CATEGORY"], [42255, 42266, "TRAINED_CATEGORY"], [42270, 42273, "TRAINED_CATEGORY"], [42283, 42293, "TRAINED_CATEGORY"], [42298, 42313, "TRAINED_CATEGORY"], [42317, 42320, "TRAINED_CATEGORY"], [42330, 42338, "TRAINED_CATEGORY"], [42346, 42357, "TRAINED_CATEGORY"], [42381, 42417, "TRAINED_CATEGORY"], [42442, 42443, "TRAINED_CATEGORY"], [42486, 42487, "TRAINED_CATEGORY"], [42530, 42579, "TRAINED_CATEGORY"], [42614, 42615, "TRAINED_CATEGORY"], [42656, 42674, "TRAINED_CATEGORY"], [42727, 42728, "TRAINED_CATEGORY"], [42779, 42804, "TRAINED_CATEGORY"], [42815, 42831, "TRAINED_CATEGORY"], [42925, 42926, "TRAINED_CATEGORY"], [42989, 42990, "TRAINED_CATEGORY"], [43044, 43045, "TRAINED_CATEGORY"], [43074, 43075, "TRAINED_CATEGORY"], [43102, 43135, "TRAINED_CATEGORY"], [43135, 43149, "TRAINED_CATEGORY"], [43179, 43180, "TRAINED_CATEGORY"], [43190, 43220, "TRAINED_CATEGORY"], [43249, 43250, "TRAINED_CATEGORY"], [43289, 43303, "TRAINED_CATEGORY"], [43355, 43356, "TRAINED_CATEGORY"], [43391, 43392, "TRAINED_CATEGORY"], [43444, 43465, "TRAINED_CATEGORY"], [43605, 43606, "TRAINED_CATEGORY"], [43653, 43687, "TRAINED_CATEGORY"], [43688, 43701, "TRAINED_CATEGORY"], [43767, 43768, "TRAINED_CATEGORY"], [43820, 43857, "TRAINED_CATEGORY"], [43917, 43919, "TRAINED_CATEGORY"], [43998, 44035, "TRAINED_CATEGORY"], [44120, 44139, "TRAINED_CATEGORY"], [44178, 44179, "TRAINED_CATEGORY"], [44347, 44373, "TRAINED_CATEGORY"], [44384, 44401, "TRAINED_CATEGORY"], [44440, 44441, "TRAINED_CATEGORY"], [44478, 44502, "TRAINED_CATEGORY"], [44537, 44567, "TRAINED_CATEGORY"], [44592, 44593, "TRAINED_CATEGORY"], [44636, 44637, "TRAINED_CATEGORY"], [44680, 44725, "TRAINED_CATEGORY"], [44728, 44729, "TRAINED_CATEGORY"], [44763, 44795, "TRAINED_CATEGORY"], [44886, 44888, "TRAINED_CATEGORY"], [45225, 45226, "TRAINED_CATEGORY"], [45273, 45307, "TRAINED_CATEGORY"], [45308, 45321, "TRAINED_CATEGORY"], [45386, 45387, "TRAINED_CATEGORY"], [45439, 45476, "TRAINED_CATEGORY"], [45511, 45512, "TRAINED_CATEGORY"], [45559, 45584, "TRAINED_CATEGORY"], [45703, 45740, "TRAINED_CATEGORY"], [45778, 45809, "TRAINED_CATEGORY"], [45829, 45847, "TRAINED_CATEGORY"], [45886, 45887, "TRAINED_CATEGORY"], [45944, 45972, "TRAINED_CATEGORY"], [45976, 45989, "TRAINED_CATEGORY"], [45998, 46014, "TRAINED_CATEGORY"], [46030, 46053, "TRAINED_CATEGORY"], [46069, 46086, "TRAINED_CATEGORY"], [46096, 46110, "TRAINED_CATEGORY"], [46147, 46151, "TRAINED_CATEGORY"], [46166, 46181, "TRAINED_CATEGORY"], [46183, 46187, "TRAINED_CATEGORY"], [46207, 46253, "TRAINED_CATEGORY"], [46262, 46274, "TRAINED_CATEGORY"], [46278, 46279, "TRAINED_CATEGORY"], [46285, 46289, "TRAINED_CATEGORY"], [46312, 46322, "TRAINED_CATEGORY"], [46337, 46345, "TRAINED_CATEGORY"], [46349, 46358, "TRAINED_CATEGORY"], [46364, 46365, "TRAINED_CATEGORY"], [46374, 46391, "TRAINED_CATEGORY"], [46394, 46402, "TRAINED_CATEGORY"], [46406, 46429, "TRAINED_CATEGORY"], [46433, 46434, "TRAINED_CATEGORY"], [46471, 46472, "TRAINED_CATEGORY"], [46511, 46512, "TRAINED_CATEGORY"], [46577, 46578, "TRAINED_CATEGORY"], [46643, 46644, "TRAINED_CATEGORY"], [46720, 46721, "TRAINED_CATEGORY"], [46730, 46731, "TRAINED_CATEGORY"], [46817, 46818, "TRAINED_CATEGORY"], [46842, 46843, "TRAINED_CATEGORY"], [46883, 46884, "TRAINED_CATEGORY"], [46908, 46909, "TRAINED_CATEGORY"], [46958, 46988, "TRAINED_CATEGORY"], [47001, 47012, "TRAINED_CATEGORY"], [47044, 47069, "TRAINED_CATEGORY"], [47082, 47084, "TRAINED_CATEGORY"], [47093, 47102, "TRAINED_CATEGORY"], [47104, 47106, "TRAINED_CATEGORY"], [47121, 47138, "TRAINED_CATEGORY"], [47328, 47329, "TRAINED_CATEGORY"], [47392, 47393, "TRAINED_CATEGORY"], [47433, 47434, "TRAINED_CATEGORY"], [47458, 47459, "TRAINED_CATEGORY"], [47499, 47500, "TRAINED_CATEGORY"], [47524, 47525, "TRAINED_CATEGORY"], [47538, 47539, "TRAINED_CATEGORY"], [47708, 47740, "TRAINED_CATEGORY"], [47744, 47754, "TRAINED_CATEGORY"], [47776, 47778, "TRAINED_CATEGORY"], [47789, 47811, "TRAINED_CATEGORY"], [47815, 47831, "TRAINED_CATEGORY"], [47835, 47836, "TRAINED_CATEGORY"], [47853, 47866, "TRAINED_CATEGORY"], [47874, 47881, "TRAINED_CATEGORY"], [47887, 47889, "TRAINED_CATEGORY"], [47909, 47936, "TRAINED_CATEGORY"], [47942, 47955, "TRAINED_CATEGORY"], [47991, 47992, "TRAINED_CATEGORY"], [48016, 48017, "TRAINED_CATEGORY"], [48057, 48058, "TRAINED_CATEGORY"], [48082, 48083, "TRAINED_CATEGORY"], [48123, 48124, "TRAINED_CATEGORY"], [48148, 48149, "TRAINED_CATEGORY"], [48222, 48233, "TRAINED_CATEGORY"], [48234, 48246, "TRAINED_CATEGORY"], [48258, 48265, "TRAINED_CATEGORY"], [48352, 48353, "TRAINED_CATEGORY"], [48377, 48378, "TRAINED_CATEGORY"], [48484, 48485, "TRAINED_CATEGORY"], [48509, 48510, "TRAINED_CATEGORY"], [48583, 48594, "TRAINED_CATEGORY"], [48595, 48607, "TRAINED_CATEGORY"], [48669, 48670, "TRAINED_CATEGORY"], [48687, 48717, "TRAINED_CATEGORY"], [48757, 48758, "TRAINED_CATEGORY"], [48782, 48783, "TRAINED_CATEGORY"], [48823, 48824, "TRAINED_CATEGORY"], [48848, 48849, "TRAINED_CATEGORY"], [48889, 48890, "TRAINED_CATEGORY"], [48914, 48915, "TRAINED_CATEGORY"], [48988, 48999, "TRAINED_CATEGORY"], [49000, 49012, "TRAINED_CATEGORY"], [49075, 49076, "TRAINED_CATEGORY"], [49108, 49109, "TRAINED_CATEGORY"], [49123, 49135, "TRAINED_CATEGORY"], [49174, 49175, "TRAINED_CATEGORY"], [49199, 49200, "TRAINED_CATEGORY"], [49287, 49300, "TRAINED_CATEGORY"], [49312, 49341, "TRAINED_CATEGORY"], [49541, 49542, "TRAINED_CATEGORY"], [49581, 49582, "TRAINED_CATEGORY"], [49685, 49696, "TRAINED_CATEGORY"], [49717, 49728, "TRAINED_CATEGORY"], [49732, 49735, "TRAINED_CATEGORY"], [49746, 49757, "TRAINED_CATEGORY"], [49761, 49774, "TRAINED_CATEGORY"], [49805, 49817, "TRAINED_CATEGORY"], [49821, 49843, "TRAINED_CATEGORY"], [49853, 49856, "TRAINED_CATEGORY"], [49870, 49892, "TRAINED_CATEGORY"], [49898, 49913, "TRAINED_CATEGORY"], [49914, 49931, "TRAINED_CATEGORY"], [49935, 49938, "TRAINED_CATEGORY"], [49972, 49999, "TRAINED_CATEGORY"], [50008, 50022, "TRAINED_CATEGORY"], [50039, 50042, "TRAINED_CATEGORY"], [50055, 50074, "TRAINED_CATEGORY"], [50083, 50095, "TRAINED_CATEGORY"], [50111, 50126, "TRAINED_CATEGORY"], [50144, 50153, "TRAINED_CATEGORY"], [50157, 50170, "TRAINED_CATEGORY"], [50176, 50186, "TRAINED_CATEGORY"], [50199, 50214, "TRAINED_CATEGORY"], [50227, 50251, "TRAINED_CATEGORY"], [50256, 50259, "TRAINED_CATEGORY"], [50285, 50295, "TRAINED_CATEGORY"], [50298, 50316, "TRAINED_CATEGORY"], [50320, 50344, "TRAINED_CATEGORY"], [50365, 50386, "TRAINED_CATEGORY"], [50391, 50394, "TRAINED_CATEGORY"], [50399, 50405, "TRAINED_CATEGORY"], [50414, 50423, "TRAINED_CATEGORY"], [50425, 50440, "TRAINED_CATEGORY"], [50463, 50487, "TRAINED_CATEGORY"], [50499, 50507, "TRAINED_CATEGORY"], [50511, 50539, "TRAINED_CATEGORY"], [50579, 50605, "TRAINED_CATEGORY"], [50611, 50627, "TRAINED_CATEGORY"], [50659, 50677, "TRAINED_CATEGORY"], [50681, 50692, "TRAINED_CATEGORY"], [50697, 50718, "TRAINED_CATEGORY"], [50720, 50753, "TRAINED_CATEGORY"], [50771, 50796, "TRAINED_CATEGORY"], [50800, 50812, "TRAINED_CATEGORY"], [50839, 50865, "TRAINED_CATEGORY"], [50879, 50887, "TRAINED_CATEGORY"], [50896, 50899, "TRAINED_CATEGORY"], [50904, 50937, "TRAINED_CATEGORY"], [50945, 50948, "TRAINED_CATEGORY"], [50953, 50971, "TRAINED_CATEGORY"], [50976, 51000, "TRAINED_CATEGORY"], [51007, 51018, "TRAINED_CATEGORY"], [51032, 51066, "TRAINED_CATEGORY"], [51085, 51106, "TRAINED_CATEGORY"], [51114, 51145, "TRAINED_CATEGORY"], [51153, 51167, "TRAINED_CATEGORY"], [51288, 51289, "TRAINED_CATEGORY"], [51510, 51517, "TRAINED_CATEGORY"], [51521, 51559, "TRAINED_CATEGORY"], [51595, 51596, "TRAINED_CATEGORY"], [51658, 51672, "TRAINED_CATEGORY"], [51767, 51770, "TRAINED_CATEGORY"], [51785, 51788, "TRAINED_CATEGORY"], [51808, 51832, "TRAINED_CATEGORY"], [51839, 51869, "TRAINED_CATEGORY"], [51873, 51877, "TRAINED_CATEGORY"], [51894, 51901, "TRAINED_CATEGORY"], [51952, 51953, "TRAINED_CATEGORY"], [52014, 52022, "TRAINED_CATEGORY"], [52124, 52138, "TRAINED_CATEGORY"], [52144, 52163, "TRAINED_CATEGORY"], [52180, 52199, "TRAINED_CATEGORY"], [52201, 52208, "TRAINED_CATEGORY"], [52219, 52241, "TRAINED_CATEGORY"], [52266, 52267, "TRAINED_CATEGORY"], [52375, 52401, "TRAINED_CATEGORY"], [52404, 52414, "TRAINED_CATEGORY"], [52430, 52453, "TRAINED_CATEGORY"], [52489, 52490, "TRAINED_CATEGORY"], [52552, 52585, "TRAINED_CATEGORY"], [52621, 52622, "TRAINED_CATEGORY"], [52674, 52675, "TRAINED_CATEGORY"], [52746, 52747, "TRAINED_CATEGORY"], [52882, 52891, "TRAINED_CATEGORY"], [52918, 52937, "TRAINED_CATEGORY"], [52954, 52973, "TRAINED_CATEGORY"], [52974, 52998, "TRAINED_CATEGORY"], [53002, 53012, "TRAINED_CATEGORY"], [53121, 53151, "TRAINED_CATEGORY"], [53187, 53188, "TRAINED_CATEGORY"], [53272, 53289, "TRAINED_CATEGORY"], [53292, 53295, "TRAINED_CATEGORY"], [53333, 53353, "TRAINED_CATEGORY"], [53399, 53400, "TRAINED_CATEGORY"], [53499, 53500, "TRAINED_CATEGORY"], [53509, 53510, "TRAINED_CATEGORY"], [53681, 53683, "TRAINED_CATEGORY"], [53686, 53696, "TRAINED_CATEGORY"], [53704, 53718, "TRAINED_CATEGORY"], [53722, 53725, "TRAINED_CATEGORY"], [53889, 53894, "TRAINED_CATEGORY"], [53898, 53910, "TRAINED_CATEGORY"], [53911, 53929, "TRAINED_CATEGORY"], [53936, 53966, "TRAINED_CATEGORY"], [54002, 54003, "TRAINED_CATEGORY"], [54030, 54054, "TRAINED_CATEGORY"], [54082, 54104, "TRAINED_CATEGORY"], [54112, 54115, "TRAINED_CATEGORY"], [54122, 54158, "TRAINED_CATEGORY"], [54170, 54179, "TRAINED_CATEGORY"], [54298, 54311, "TRAINED_CATEGORY"], [54318, 54339, "TRAINED_CATEGORY"], [54360, 54382, "TRAINED_CATEGORY"], [54386, 54389, "TRAINED_CATEGORY"], [54396, 54417, "TRAINED_CATEGORY"], [54448, 54470, "TRAINED_CATEGORY"], [54471, 54479, "TRAINED_CATEGORY"], [54496, 54508, "TRAINED_CATEGORY"], [54513, 54514, "TRAINED_CATEGORY"], [54518, 54529, "TRAINED_CATEGORY"], [54533, 54552, "TRAINED_CATEGORY"], [54557, 54558, "TRAINED_CATEGORY"], [54562, 54579, "TRAINED_CATEGORY"], [54580, 54582, "TRAINED_CATEGORY"], [54597, 54599, "TRAINED_CATEGORY"], [54620, 54630, "TRAINED_CATEGORY"], [54631, 54632, "TRAINED_CATEGORY"], [54640, 54641, "TRAINED_CATEGORY"], [54645, 54657, "TRAINED_CATEGORY"], [54658, 54673, "TRAINED_CATEGORY"], [54674, 54678, "TRAINED_CATEGORY"], [54683, 54691, "TRAINED_CATEGORY"], [54768, 54769, "TRAINED_CATEGORY"], [54780, 54793, "TRAINED_CATEGORY"], [54832, 54833, "TRAINED_CATEGORY"], [54892, 54926, "TRAINED_CATEGORY"], [54947, 54955, "TRAINED_CATEGORY"], [54972, 54975, "TRAINED_CATEGORY"], [54981, 54985, "TRAINED_CATEGORY"], [54997, 55002, "TRAINED_CATEGORY"], [55006, 55018, "TRAINED_CATEGORY"], [55022, 55033, "TRAINED_CATEGORY"], [55039, 55042, "TRAINED_CATEGORY"], [55058, 55066, "TRAINED_CATEGORY"], [55075, 55091, "TRAINED_CATEGORY"], [55114, 55130, "TRAINED_CATEGORY"], [55161, 55169, "TRAINED_CATEGORY"], [55186, 55191, "TRAINED_CATEGORY"], [55197, 55209, "TRAINED_CATEGORY"], [55394, 55395, "TRAINED_CATEGORY"], [55585, 55586, "TRAINED_CATEGORY"], [55638, 55651, "TRAINED_CATEGORY"], [55651, 55653, "TRAINED_CATEGORY"], [55672, 55700, "TRAINED_CATEGORY"], [55704, 55719, "TRAINED_CATEGORY"], [55912, 55913, "TRAINED_CATEGORY"], [56012, 56023, "TRAINED_CATEGORY"], [56043, 56052, "TRAINED_CATEGORY"], [56060, 56075, "TRAINED_CATEGORY"], [56081, 56096, "TRAINED_CATEGORY"], [56097, 56098, "TRAINED_CATEGORY"], [56102, 56112, "TRAINED_CATEGORY"], [56115, 56119, "TRAINED_CATEGORY"], [56136, 56154, "TRAINED_CATEGORY"], [56164, 56182, "TRAINED_CATEGORY"], [56189, 56200, "TRAINED_CATEGORY"], [56222, 56248, "TRAINED_CATEGORY"], [56254, 56280, "TRAINED_CATEGORY"], [56284, 56294, "TRAINED_CATEGORY"], [56336, 56337, "TRAINED_CATEGORY"], [56361, 56362, "TRAINED_CATEGORY"], [56505, 56506, "TRAINED_CATEGORY"], [56610, 56611, "TRAINED_CATEGORY"], [56635, 56636, "TRAINED_CATEGORY"], [56649, 56650, "TRAINED_CATEGORY"], [56761, 56775, "TRAINED_CATEGORY"], [56781, 56789, "TRAINED_CATEGORY"], [56794, 56810, "TRAINED_CATEGORY"], [56814, 56830, "TRAINED_CATEGORY"], [56834, 56846, "TRAINED_CATEGORY"], [56863, 56890, "TRAINED_CATEGORY"], [56906, 56927, "TRAINED_CATEGORY"], [56945, 56953, "TRAINED_CATEGORY"], [56961, 56963, "TRAINED_CATEGORY"], [56985, 56993, "TRAINED_CATEGORY"], [57016, 57041, "TRAINED_CATEGORY"], [57090, 57091, "TRAINED_CATEGORY"], [57205, 57213, "TRAINED_CATEGORY"], [57217, 57232, "TRAINED_CATEGORY"], [57233, 57262, "TRAINED_CATEGORY"], [57266, 57282, "TRAINED_CATEGORY"], [57283, 57321, "TRAINED_CATEGORY"], [57360, 57361, "TRAINED_CATEGORY"], [57379, 57380, "TRAINED_CATEGORY"], [57400, 57401, "TRAINED_CATEGORY"], [57443, 57444, "TRAINED_CATEGORY"], [57540, 57542, "TRAINED_CATEGORY"], [57545, 57585, "TRAINED_CATEGORY"], [57597, 57598, "TRAINED_CATEGORY"], [57602, 57624, "TRAINED_CATEGORY"], [57628, 57634, "TRAINED_CATEGORY"], [57670, 57671, "TRAINED_CATEGORY"], [57695, 57696, "TRAINED_CATEGORY"], [57805, 57806, "TRAINED_CATEGORY"], [57845, 57866, "TRAINED_CATEGORY"], [57898, 57913, "TRAINED_CATEGORY"], [57921, 57944, "TRAINED_CATEGORY"], [57963, 57984, "TRAINED_CATEGORY"], [57994, 58033, "TRAINED_CATEGORY"], [58039, 58047, "TRAINED_CATEGORY"], [58181, 58182, "TRAINED_CATEGORY"], [58341, 58342, "TRAINED_CATEGORY"], [58369, 58393, "TRAINED_CATEGORY"], [58393, 58437, "TRAINED_CATEGORY"], [58516, 58548, "TRAINED_CATEGORY"], [58553, 58554, "TRAINED_CATEGORY"], [58576, 58588, "TRAINED_CATEGORY"], [58599, 58607, "TRAINED_CATEGORY"], [58611, 58628, "TRAINED_CATEGORY"], [58630, 58654, "TRAINED_CATEGORY"], [58671, 58692, "TRAINED_CATEGORY"], [58693, 58706, "TRAINED_CATEGORY"], [58720, 58723, "TRAINED_CATEGORY"], [58752, 58766, "TRAINED_CATEGORY"], [58770, 58789, "TRAINED_CATEGORY"], [58802, 58818, "TRAINED_CATEGORY"], [58823, 58834, "TRAINED_CATEGORY"], [58838, 58859, "TRAINED_CATEGORY"], [58872, 58884, "TRAINED_CATEGORY"], [58888, 58900, "TRAINED_CATEGORY"], [58920, 58943, "TRAINED_CATEGORY"], [58992, 58993, "TRAINED_CATEGORY"], [59028, 59029, "TRAINED_CATEGORY"], [59083, 59084, "TRAINED_CATEGORY"], [59113, 59114, "TRAINED_CATEGORY"], [59153, 59154, "TRAINED_CATEGORY"], [59203, 59222, "TRAINED_CATEGORY"], [59224, 59234, "TRAINED_CATEGORY"], [59259, 59260, "TRAINED_CATEGORY"], [59264, 59283, "TRAINED_CATEGORY"], [59287, 59298, "TRAINED_CATEGORY"], [59302, 59304, "TRAINED_CATEGORY"], [59305, 59314, "TRAINED_CATEGORY"], [59338, 59345, "TRAINED_CATEGORY"], [59349, 59375, "TRAINED_CATEGORY"], [59390, 59402, "TRAINED_CATEGORY"], [59407, 59418, "TRAINED_CATEGORY"], [59420, 59436, "TRAINED_CATEGORY"], [59462, 59476, "TRAINED_CATEGORY"], [59480, 59507, "TRAINED_CATEGORY"], [59517, 59520, "TRAINED_CATEGORY"], [59522, 59523, "TRAINED_CATEGORY"], [59525, 59531, "TRAINED_CATEGORY"], [59533, 59544, "TRAINED_CATEGORY"], [59546, 59551, "TRAINED_CATEGORY"], [59553, 59556, "TRAINED_CATEGORY"], [59558, 59583, "TRAINED_CATEGORY"], [59589, 59599, "TRAINED_CATEGORY"], [59611, 59626, "TRAINED_CATEGORY"], [59637, 59645, "TRAINED_CATEGORY"], [59649, 59673, "TRAINED_CATEGORY"], [59740, 59741, "TRAINED_CATEGORY"], [59754, 59755, "TRAINED_CATEGORY"], [59805, 59806, "TRAINED_CATEGORY"], [59830, 59831, "TRAINED_CATEGORY"], [59902, 59903, "TRAINED_CATEGORY"], [59955, 59969, "TRAINED_CATEGORY"], [59970, 59997, "TRAINED_CATEGORY"], [60005, 60023, "TRAINED_CATEGORY"], [60027, 60050, "TRAINED_CATEGORY"], [60091, 60092, "TRAINED_CATEGORY"], [60116, 60117, "TRAINED_CATEGORY"], [60130, 60131, "TRAINED_CATEGORY"], [60222, 60223, "TRAINED_CATEGORY"], [60232, 60233, "TRAINED_CATEGORY"], [60242, 60243, "TRAINED_CATEGORY"], [60270, 60321, "TRAINED_CATEGORY"], [60325, 60333, "TRAINED_CATEGORY"], [60343, 60358, "TRAINED_CATEGORY"], [60369, 60385, "TRAINED_CATEGORY"], [60395, 60403, "TRAINED_CATEGORY"], [60421, 60439, "TRAINED_CATEGORY"], [60443, 60464, "TRAINED_CATEGORY"], [60465, 60467, "TRAINED_CATEGORY"], [60468, 60483, "TRAINED_CATEGORY"], [60488, 60500, "TRAINED_CATEGORY"], [60525, 60543, "TRAINED_CATEGORY"], [60559, 60578, "TRAINED_CATEGORY"], [60580, 60588, "TRAINED_CATEGORY"], [60597, 60607, "TRAINED_CATEGORY"], [60611, 60629, "TRAINED_CATEGORY"], [60650, 60662, "TRAINED_CATEGORY"], [60677, 60687, "TRAINED_CATEGORY"], [60691, 60709, "TRAINED_CATEGORY"], [60722, 60736, "TRAINED_CATEGORY"], [60751, 60761, "TRAINED_CATEGORY"], [60765, 60782, "TRAINED_CATEGORY"], [60800, 60816, "TRAINED_CATEGORY"], [60821, 60832, "TRAINED_CATEGORY"], [60842, 60853, "TRAINED_CATEGORY"], [60857, 60905, "TRAINED_CATEGORY"], [60909, 60914, "TRAINED_CATEGORY"], [60929, 60939, "TRAINED_CATEGORY"], [60963, 60983, "TRAINED_CATEGORY"], [60992, 61003, "TRAINED_CATEGORY"], [61007, 61018, "TRAINED_CATEGORY"], [61034, 61063, "TRAINED_CATEGORY"], [61068, 61084, "TRAINED_CATEGORY"], [61089, 61104, "TRAINED_CATEGORY"], [61115, 61131, "TRAINED_CATEGORY"], [61135, 61159, "TRAINED_CATEGORY"], [61174, 61190, "TRAINED_CATEGORY"], [61198, 61214, "TRAINED_CATEGORY"], [61220, 61227, "TRAINED_CATEGORY"], [61232, 61240, "TRAINED_CATEGORY"], [61242, 61273, "TRAINED_CATEGORY"], [61278, 61297, "TRAINED_CATEGORY"], [61301, 61308, "TRAINED_CATEGORY"], [61312, 61330, "TRAINED_CATEGORY"], [61345, 61360, "TRAINED_CATEGORY"], [61376, 61377, "TRAINED_CATEGORY"], [61413, 61414, "TRAINED_CATEGORY"], [61514, 61515, "TRAINED_CATEGORY"], [61578, 61579, "TRAINED_CATEGORY"], [61619, 61620, "TRAINED_CATEGORY"], [61644, 61645, "TRAINED_CATEGORY"], [61720, 61721, "TRAINED_CATEGORY"], [61760, 61761, "TRAINED_CATEGORY"], [61820, 61821, "TRAINED_CATEGORY"], [61839, 61865, "TRAINED_CATEGORY"], [61908, 61917, "TRAINED_CATEGORY"], [61938, 61946, "TRAINED_CATEGORY"], [61950, 61966, "TRAINED_CATEGORY"], [61970, 61983, "TRAINED_CATEGORY"], [61993, 62012, "TRAINED_CATEGORY"], [62016, 62017, "TRAINED_CATEGORY"], [62021, 62039, "TRAINED_CATEGORY"], [62075, 62076, "TRAINED_CATEGORY"], [62100, 62101, "TRAINED_CATEGORY"], [62114, 62115, "TRAINED_CATEGORY"], [62165, 62166, "TRAINED_CATEGORY"], [62190, 62191, "TRAINED_CATEGORY"], [62254, 62255, "TRAINED_CATEGORY"], [62266, 62267, "TRAINED_CATEGORY"], [62306, 62307, "TRAINED_CATEGORY"], [62366, 62367, "TRAINED_CATEGORY"], [62385, 62386, "TRAINED_CATEGORY"], [62445, 62446, "TRAINED_CATEGORY"], [62464, 62497, "TRAINED_CATEGORY"], [62519, 62528, "TRAINED_CATEGORY"], [62538, 62547, "TRAINED_CATEGORY"], [62623, 62624, "TRAINED_CATEGORY"], [62688, 62700, "TRAINED_CATEGORY"], [62704, 62711, "TRAINED_CATEGORY"], [62724, 62744, "TRAINED_CATEGORY"], [62749, 62751, "TRAINED_CATEGORY"], [62752, 62760, "TRAINED_CATEGORY"], [62774, 62781, "TRAINED_CATEGORY"], [62785, 62786, "TRAINED_CATEGORY"], [62824, 62847, "TRAINED_CATEGORY"], [62851, 62852, "TRAINED_CATEGORY"], [62856, 62874, "TRAINED_CATEGORY"], [62880, 62887, "TRAINED_CATEGORY"], [62889, 62892, "TRAINED_CATEGORY"], [62912, 62913, "TRAINED_CATEGORY"], [62922, 62945, "TRAINED_CATEGORY"], [62955, 62974, "TRAINED_CATEGORY"], [62981, 62991, "TRAINED_CATEGORY"], [62996, 63005, "TRAINED_CATEGORY"], [63014, 63032, "TRAINED_CATEGORY"], [63036, 63037, "TRAINED_CATEGORY"], [63396, 63408, "TRAINED_CATEGORY"], [63412, 63420, "TRAINED_CATEGORY"], [63426, 63439, "TRAINED_CATEGORY"], [63444, 63465, "TRAINED_CATEGORY"], [63470, 63481, "TRAINED_CATEGORY"], [63485, 63495, "TRAINED_CATEGORY"], [63530, 63590, "TRAINED_CATEGORY"], [63610, 63611, "TRAINED_CATEGORY"], [63650, 63651, "TRAINED_CATEGORY"], [63662, 63675, "TRAINED_CATEGORY"], [63714, 63715, "TRAINED_CATEGORY"], [63776, 63786, "TRAINED_CATEGORY"], [63789, 63806, "TRAINED_CATEGORY"], [63807, 63817, "TRAINED_CATEGORY"], [63820, 63832, "TRAINED_CATEGORY"], [63844, 63849, "TRAINED_CATEGORY"], [63855, 63863, "TRAINED_CATEGORY"], [63867, 63875, "TRAINED_CATEGORY"], [63886, 63906, "TRAINED_CATEGORY"], [63925, 63928, "TRAINED_CATEGORY"], [63933, 63949, "TRAINED_CATEGORY"], [63953, 63961, "TRAINED_CATEGORY"], [63965, 63974, "TRAINED_CATEGORY"], [63980, 63990, "TRAINED_CATEGORY"], [63994, 63997, "TRAINED_CATEGORY"], [64004, 64025, "TRAINED_CATEGORY"], [64033, 64034, "TRAINED_CATEGORY"], [64038, 64067, "TRAINED_CATEGORY"], [64081, 64094, "TRAINED_CATEGORY"], [64104, 64108, "TRAINED_CATEGORY"], [64112, 64122, "TRAINED_CATEGORY"], [64131, 64132, "TRAINED_CATEGORY"], [64148, 64150, "TRAINED_CATEGORY"], [64264, 64307, "TRAINED_CATEGORY"], [64316, 64318, "TRAINED_CATEGORY"], [64323, 64351, "TRAINED_CATEGORY"], [64362, 64364, "TRAINED_CATEGORY"], [64368, 64383, "TRAINED_CATEGORY"], [64389, 64425, "TRAINED_CATEGORY"], [64441, 64460, "TRAINED_CATEGORY"], [64494, 64495, "TRAINED_CATEGORY"], [64527, 64528, "TRAINED_CATEGORY"], [64538, 64552, "TRAINED_CATEGORY"], [64634, 64637, "TRAINED_CATEGORY"], [64672, 64829, "TRAINED_CATEGORY"], [65705, 65706, "TRAINED_CATEGORY"], [65760, 65761, "TRAINED_CATEGORY"], [66183, 66222, "TRAINED_CATEGORY"], [66495, 66544, "TRAINED_CATEGORY"], [66564, 66588, "TRAINED_CATEGORY"], [66590, 66591, "TRAINED_CATEGORY"], [66594, 66596, "TRAINED_CATEGORY"], [66622, 66624, "TRAINED_CATEGORY"], [66626, 66663, "TRAINED_CATEGORY"], [66857, 66858, "TRAINED_CATEGORY"], [66867, 66942, "TRAINED_CATEGORY"], [66995, 66996, "TRAINED_CATEGORY"], [67014, 67029, "TRAINED_CATEGORY"], [67065, 67070, "TRAINED_CATEGORY"], [67092, 67122, "TRAINED_CATEGORY"], [67170, 67189, "TRAINED_CATEGORY"], [67194, 67223, "TRAINED_CATEGORY"], [67230, 67255, "TRAINED_CATEGORY"], [67273, 67294, "TRAINED_CATEGORY"], [67296, 67303, "TRAINED_CATEGORY"], [67306, 67333, "TRAINED_CATEGORY"], [67357, 67359, "TRAINED_CATEGORY"], [67384, 67419, "TRAINED_CATEGORY"], [67446, 67467, "TRAINED_CATEGORY"], [67469, 67497, "TRAINED_CATEGORY"], [67505, 67523, "TRAINED_CATEGORY"], [67562, 67587, "TRAINED_CATEGORY"], [67614, 67633, "TRAINED_CATEGORY"], [67639, 67646, "TRAINED_CATEGORY"], [67657, 67669, "TRAINED_CATEGORY"], [67681, 67699, "TRAINED_CATEGORY"], [67704, 67712, "TRAINED_CATEGORY"], [67716, 67730, "TRAINED_CATEGORY"], [67738, 67759, "TRAINED_CATEGORY"], [67764, 67771, "TRAINED_CATEGORY"], [67783, 67812, "TRAINED_CATEGORY"], [67837, 67862, "TRAINED_CATEGORY"], [67868, 67881, "TRAINED_CATEGORY"], [67889, 67898, "TRAINED_CATEGORY"], [67923, 67944, "TRAINED_CATEGORY"], [67947, 67948, "TRAINED_CATEGORY"], [67951, 67966, "TRAINED_CATEGORY"], [67970, 67978, "TRAINED_CATEGORY"], [68014, 68015, "TRAINED_CATEGORY"], [68082, 68083, "TRAINED_CATEGORY"], [68141, 68142, "TRAINED_CATEGORY"], [68189, 68190, "TRAINED_CATEGORY"], [68237, 68238, "TRAINED_CATEGORY"], [68377, 68384, "TRAINED_CATEGORY"], [68392, 68393, "TRAINED_CATEGORY"], [68398, 68407, "TRAINED_CATEGORY"], [68411, 68419, "TRAINED_CATEGORY"], [68431, 68439, "TRAINED_CATEGORY"], [68515, 68572, "TRAINED_CATEGORY"], [68746, 68747, "TRAINED_CATEGORY"], [68767, 68768, "TRAINED_CATEGORY"], [68857, 68859, "TRAINED_CATEGORY"], [68875, 68893, "TRAINED_CATEGORY"], [68902, 68904, "TRAINED_CATEGORY"], [68954, 68955, "TRAINED_CATEGORY"], [68964, 68965, "TRAINED_CATEGORY"], [68974, 68975, "TRAINED_CATEGORY"], [69004, 69005, "TRAINED_CATEGORY"], [69034, 69035, "TRAINED_CATEGORY"], [69088, 69089, "TRAINED_CATEGORY"], [69165, 69166, "TRAINED_CATEGORY"], [69207, 69228, "TRAINED_CATEGORY"], [69352, 69353, "TRAINED_CATEGORY"], [69371, 69372, "TRAINED_CATEGORY"], [69381, 69382, "TRAINED_CATEGORY"], [69391, 69392, "TRAINED_CATEGORY"], [69421, 69422, "TRAINED_CATEGORY"], [69461, 69462, "TRAINED_CATEGORY"], [69562, 69563, "TRAINED_CATEGORY"], [69590, 69700, "TRAINED_CATEGORY"], [69826, 69827, "TRAINED_CATEGORY"], [69874, 69875, "TRAINED_CATEGORY"], [69922, 69923, "TRAINED_CATEGORY"], [69988, 70069, "TRAINED_CATEGORY"], [70107, 70108, "TRAINED_CATEGORY"], [70117, 70118, "TRAINED_CATEGORY"], [70137, 70138, "TRAINED_CATEGORY"], [70157, 70158, "TRAINED_CATEGORY"], [70167, 70168, "TRAINED_CATEGORY"], [70177, 70178, "TRAINED_CATEGORY"], [70197, 70198, "TRAINED_CATEGORY"], [70207, 70238, "TRAINED_CATEGORY"], [70255, 70285, "TRAINED_CATEGORY"], [70321, 70322, "TRAINED_CATEGORY"], [70331, 70332, "TRAINED_CATEGORY"], [70341, 70342, "TRAINED_CATEGORY"], [70371, 70372, "TRAINED_CATEGORY"], [70401, 70402, "TRAINED_CATEGORY"], [70442, 70443, "TRAINED_CATEGORY"], [70503, 70505, "TRAINED_CATEGORY"], [70513, 70543, "TRAINED_CATEGORY"], [70562, 70572, "TRAINED_CATEGORY"], [70573, 70579, "TRAINED_CATEGORY"], [70582, 70592, "TRAINED_CATEGORY"], [70605, 70615, "TRAINED_CATEGORY"], [70624, 70626, "TRAINED_CATEGORY"], [70627, 70641, "TRAINED_CATEGORY"], [70661, 70671, "TRAINED_CATEGORY"], [70682, 70703, "TRAINED_CATEGORY"], [70707, 70715, "TRAINED_CATEGORY"], [70716, 70724, "TRAINED_CATEGORY"], [70729, 70754, "TRAINED_CATEGORY"], [70760, 70786, "TRAINED_CATEGORY"], [70810, 70830, "TRAINED_CATEGORY"], [70832, 70842, "TRAINED_CATEGORY"], [70843, 70844, "TRAINED_CATEGORY"], [70859, 70888, "TRAINED_CATEGORY"], [70892, 70893, "TRAINED_CATEGORY"], [70901, 70911, "TRAINED_CATEGORY"], [70915, 70927, "TRAINED_CATEGORY"], [70956, 70957, "TRAINED_CATEGORY"], [70962, 70976, "TRAINED_CATEGORY"], [70983, 71014, "TRAINED_CATEGORY"], [71065, 71079, "TRAINED_CATEGORY"], [71084, 71093, "TRAINED_CATEGORY"], [71100, 71133, "TRAINED_CATEGORY"], [71143, 71164, "TRAINED_CATEGORY"], [71168, 71243, "TRAINED_CATEGORY"], [71245, 71276, "TRAINED_CATEGORY"], [71308, 71317, "TRAINED_CATEGORY"], [71339, 71346, "TRAINED_CATEGORY"], [71351, 71370, "TRAINED_CATEGORY"], [71372, 71384, "TRAINED_CATEGORY"], [71388, 71437, "TRAINED_CATEGORY"], [71456, 71468, "TRAINED_CATEGORY"], [71472, 71518, "TRAINED_CATEGORY"], [71536, 71545, "TRAINED_CATEGORY"], [71551, 71572, "TRAINED_CATEGORY"], [71574, 71593, "TRAINED_CATEGORY"], [71597, 71619, "TRAINED_CATEGORY"], [71629, 71645, "TRAINED_CATEGORY"], [71657, 71670, "TRAINED_CATEGORY"], [71672, 71682, "TRAINED_CATEGORY"], [71687, 71689, "TRAINED_CATEGORY"], [71690, 71702, "TRAINED_CATEGORY"], [71706, 71707, "TRAINED_CATEGORY"], [71728, 71760, "TRAINED_CATEGORY"], [71768, 71779, "TRAINED_CATEGORY"], [71809, 71829, "TRAINED_CATEGORY"], [71833, 71843, "TRAINED_CATEGORY"], [71847, 71865, "TRAINED_CATEGORY"], [71885, 71892, "TRAINED_CATEGORY"], [71898, 71904, "TRAINED_CATEGORY"], [71906, 71924, "TRAINED_CATEGORY"], [71936, 71952, "TRAINED_CATEGORY"], [71956, 71966, "TRAINED_CATEGORY"], [71981, 72028, "TRAINED_CATEGORY"], [72053, 72071, "TRAINED_CATEGORY"], [72085, 72123, "TRAINED_CATEGORY"], [72131, 72148, "TRAINED_CATEGORY"], [72153, 72195, "TRAINED_CATEGORY"], [72197, 72203, "TRAINED_CATEGORY"], [72218, 72247, "TRAINED_CATEGORY"], [72253, 72269, "TRAINED_CATEGORY"], [72273, 72284, "TRAINED_CATEGORY"], [72311, 72335, "TRAINED_CATEGORY"], [72339, 72360, "TRAINED_CATEGORY"], [72386, 72394, "TRAINED_CATEGORY"], [72400, 72430, "TRAINED_CATEGORY"], [72459, 72478, "TRAINED_CATEGORY"], [72484, 72491, "TRAINED_CATEGORY"], [72493, 72501, "TRAINED_CATEGORY"], [72503, 72515, "TRAINED_CATEGORY"], [72517, 72519, "TRAINED_CATEGORY"], [72557, 72574, "TRAINED_CATEGORY"], [72576, 72622, "TRAINED_CATEGORY"], [72623, 72641, "TRAINED_CATEGORY"], [72650, 72674, "TRAINED_CATEGORY"], [72678, 72696, "TRAINED_CATEGORY"], [72701, 72712, "TRAINED_CATEGORY"], [72717, 72720, "TRAINED_CATEGORY"], [72724, 72743, "TRAINED_CATEGORY"], [72759, 72774, "TRAINED_CATEGORY"], [72778, 72779, "TRAINED_CATEGORY"], [72783, 72791, "TRAINED_CATEGORY"], [72799, 72808, "TRAINED_CATEGORY"], [72819, 72830, "TRAINED_CATEGORY"], [72834, 72855, "TRAINED_CATEGORY"], [72879, 72909, "TRAINED_CATEGORY"], [72913, 72933, "TRAINED_CATEGORY"], [72937, 72940, "TRAINED_CATEGORY"], [72951, 72963, "TRAINED_CATEGORY"], [72975, 72993, "TRAINED_CATEGORY"], [72997, 73008, "TRAINED_CATEGORY"], [73009, 73029, "TRAINED_CATEGORY"], [73033, 73044, "TRAINED_CATEGORY"], [73073, 73090, "TRAINED_CATEGORY"], [73092, 73097, "TRAINED_CATEGORY"], [73103, 73104, "TRAINED_CATEGORY"], [73113, 73141, "TRAINED_CATEGORY"], [73160, 73186, "TRAINED_CATEGORY"], [73193, 73212, "TRAINED_CATEGORY"], [73217, 73225, "TRAINED_CATEGORY"], [73236, 73249, "TRAINED_CATEGORY"], [73253, 73272, "TRAINED_CATEGORY"], [73274, 73280, "TRAINED_CATEGORY"], [73294, 73298, "TRAINED_CATEGORY"], [73302, 73315, "TRAINED_CATEGORY"], [73319, 73322, "TRAINED_CATEGORY"], [73330, 73364, "TRAINED_CATEGORY"], [73380, 73394, "TRAINED_CATEGORY"], [73399, 73415, "TRAINED_CATEGORY"], [73419, 73430, "TRAINED_CATEGORY"], [73432, 73438, "TRAINED_CATEGORY"], [73439, 73477, "TRAINED_CATEGORY"], [73492, 73507, "TRAINED_CATEGORY"], [73512, 73524, "TRAINED_CATEGORY"], [73528, 73547, "TRAINED_CATEGORY"], [73561, 73570, "TRAINED_CATEGORY"], [73574, 73587, "TRAINED_CATEGORY"], [73589, 73604, "TRAINED_CATEGORY"], [73608, 73637, "TRAINED_CATEGORY"], [73650, 73659, "TRAINED_CATEGORY"], [73663, 73678, "TRAINED_CATEGORY"], [73683, 73690, "TRAINED_CATEGORY"], [73694, 73710, "TRAINED_CATEGORY"], [73715, 73748, "TRAINED_CATEGORY"], [73749, 73772, "TRAINED_CATEGORY"], [73789, 73833, "TRAINED_CATEGORY"], [73843, 73902, "TRAINED_CATEGORY"], [73903, 73910, "TRAINED_CATEGORY"], [73912, 73918, "TRAINED_CATEGORY"], [73926, 73954, "TRAINED_CATEGORY"], [73962, 73998, "TRAINED_CATEGORY"], [74004, 74023, "TRAINED_CATEGORY"], [74027, 74032, "TRAINED_CATEGORY"], [74061, 74075, "TRAINED_CATEGORY"], [74077, 74079, "TRAINED_CATEGORY"], [74098, 74109, "TRAINED_CATEGORY"], [74113, 74131, "TRAINED_CATEGORY"], [74209, 74229, "TRAINED_CATEGORY"], [74234, 74239, "TRAINED_CATEGORY"], [74244, 74265, "TRAINED_CATEGORY"], [74272, 74275, "TRAINED_CATEGORY"], [74277, 74279, "TRAINED_CATEGORY"], [74295, 74297, "TRAINED_CATEGORY"], [74316, 74337, "TRAINED_CATEGORY"], [74341, 74363, "TRAINED_CATEGORY"], [74369, 74376, "TRAINED_CATEGORY"], [74378, 74405, "TRAINED_CATEGORY"], [74428, 74434, "TRAINED_CATEGORY"], [74440, 74452, "TRAINED_CATEGORY"], [74454, 74480, "TRAINED_CATEGORY"], [74503, 74510, "TRAINED_CATEGORY"], [74512, 74523, "TRAINED_CATEGORY"], [74533, 74542, "TRAINED_CATEGORY"], [74552, 74562, "TRAINED_CATEGORY"], [74581, 74584, "TRAINED_CATEGORY"], [74589, 74611, "TRAINED_CATEGORY"], [74628, 74639, "TRAINED_CATEGORY"], [74641, 74643, "TRAINED_CATEGORY"], [74666, 74690, "TRAINED_CATEGORY"], [74694, 74726, "TRAINED_CATEGORY"], [74738, 74759, "TRAINED_CATEGORY"], [74775, 74789, "TRAINED_CATEGORY"], [74794, 74814, "TRAINED_CATEGORY"], [74819, 74840, "TRAINED_CATEGORY"], [74846, 74853, "TRAINED_CATEGORY"], [74861, 74877, "TRAINED_CATEGORY"], [74879, 74893, "TRAINED_CATEGORY"], [74898, 74918, "TRAINED_CATEGORY"], [74923, 74934, "TRAINED_CATEGORY"], [74938, 74945, "TRAINED_CATEGORY"], [74949, 74955, "TRAINED_CATEGORY"], [74969, 74985, "TRAINED_CATEGORY"], [74991, 75002, "TRAINED_CATEGORY"], [75006, 75013, "TRAINED_CATEGORY"], [75029, 75036, "TRAINED_CATEGORY"], [75046, 75062, "TRAINED_CATEGORY"], [75066, 75080, "TRAINED_CATEGORY"], [75089, 75099, "TRAINED_CATEGORY"], [75103, 75110, "TRAINED_CATEGORY"], [75115, 75121, "TRAINED_CATEGORY"], [75122, 75135, "TRAINED_CATEGORY"], [75140, 75144, "TRAINED_CATEGORY"], [75167, 75189, "TRAINED_CATEGORY"], [75193, 75214, "TRAINED_CATEGORY"], [75216, 75230, "TRAINED_CATEGORY"], [75250, 75256, "TRAINED_CATEGORY"], [75258, 75260, "TRAINED_CATEGORY"], [75263, 75268, "TRAINED_CATEGORY"], [75278, 75283, "TRAINED_CATEGORY"], [75290, 75302, "TRAINED_CATEGORY"], [75309, 75320, "TRAINED_CATEGORY"], [75324, 75342, "TRAINED_CATEGORY"], [75352, 75360, "TRAINED_CATEGORY"], [75364, 75368, "TRAINED_CATEGORY"], [75398, 75406, "TRAINED_CATEGORY"], [75410, 75424, "TRAINED_CATEGORY"], [75451, 75462, "TRAINED_CATEGORY"], [75499, 75511, "TRAINED_CATEGORY"], [75521, 75541, "TRAINED_CATEGORY"], [75550, 75570, "TRAINED_CATEGORY"], [75572, 75600, "TRAINED_CATEGORY"], [75628, 75647, "TRAINED_CATEGORY"], [75651, 75686, "TRAINED_CATEGORY"], [75696, 75721, "TRAINED_CATEGORY"], [75740, 75750, "TRAINED_CATEGORY"], [75754, 75799, "TRAINED_CATEGORY"], [75827, 75862, "TRAINED_CATEGORY"], [75877, 75885, "TRAINED_CATEGORY"], [75889, 75903, "TRAINED_CATEGORY"], [75907, 75920, "TRAINED_CATEGORY"], [75933, 75938, "TRAINED_CATEGORY"], [75969, 75984, "TRAINED_CATEGORY"], [75989, 76000, "TRAINED_CATEGORY"], [76011, 76022, "TRAINED_CATEGORY"], [76027, 76040, "TRAINED_CATEGORY"], [76094, 76099, "TRAINED_CATEGORY"], [76114, 76128, "TRAINED_CATEGORY"], [76130, 76133, "TRAINED_CATEGORY"], [76159, 76176, "TRAINED_CATEGORY"], [76180, 76197, "TRAINED_CATEGORY"], [76207, 76221, "TRAINED_CATEGORY"], [76234, 76240, "TRAINED_CATEGORY"], [76242, 76257, "TRAINED_CATEGORY"], [76271, 76285, "TRAINED_CATEGORY"], [76293, 76314, "TRAINED_CATEGORY"], [76330, 76355, "TRAINED_CATEGORY"], [76368, 76389, "TRAINED_CATEGORY"], [76391, 76399, "TRAINED_CATEGORY"], [76438, 76462, "TRAINED_CATEGORY"], [76473, 76479, "TRAINED_CATEGORY"], [76485, 76501, "TRAINED_CATEGORY"], [76509, 76521, "TRAINED_CATEGORY"], [76526, 76535, "TRAINED_CATEGORY"], [76539, 76568, "TRAINED_CATEGORY"], [76580, 76592, "TRAINED_CATEGORY"], [76605, 76628, "TRAINED_CATEGORY"], [76632, 76642, "TRAINED_CATEGORY"], [76657, 76679, "TRAINED_CATEGORY"], [76694, 76713, "TRAINED_CATEGORY"], [76715, 76729, "TRAINED_CATEGORY"], [76742, 76777, "TRAINED_CATEGORY"], [76782, 76803, "TRAINED_CATEGORY"], [76804, 76819, "TRAINED_CATEGORY"], [76829, 76850, "TRAINED_CATEGORY"], [76854, 76864, "TRAINED_CATEGORY"], [76884, 76899, "TRAINED_CATEGORY"], [76903, 76917, "TRAINED_CATEGORY"], [76925, 76934, "TRAINED_CATEGORY"], [76958, 76968, "TRAINED_CATEGORY"], [76982, 76989, "TRAINED_CATEGORY"], [76993, 77010, "TRAINED_CATEGORY"], [77015, 77021, "TRAINED_CATEGORY"], [77035, 77045, "TRAINED_CATEGORY"], [77049, 77057, "TRAINED_CATEGORY"], [77071, 77087, "TRAINED_CATEGORY"], [77091, 77103, "TRAINED_CATEGORY"], [77109, 77119, "TRAINED_CATEGORY"], [77145, 77150, "TRAINED_CATEGORY"], [77162, 77176, "TRAINED_CATEGORY"], [77178, 77194, "TRAINED_CATEGORY"], [77206, 77227, "TRAINED_CATEGORY"], [77231, 77259, "TRAINED_CATEGORY"], [77261, 77268, "TRAINED_CATEGORY"], [77272, 77283, "TRAINED_CATEGORY"], [77314, 77334, "TRAINED_CATEGORY"], [77349, 77358, "TRAINED_CATEGORY"], [77362, 77368, "TRAINED_CATEGORY"], [77396, 77403, "TRAINED_CATEGORY"], [77405, 77421, "TRAINED_CATEGORY"], [77425, 77439, "TRAINED_CATEGORY"], [77448, 77485, "TRAINED_CATEGORY"], [77490, 77511, "TRAINED_CATEGORY"], [77515, 77533, "TRAINED_CATEGORY"], [77543, 77551, "TRAINED_CATEGORY"], [77555, 77566, "TRAINED_CATEGORY"], [77581, 77608, "TRAINED_CATEGORY"], [77624, 77638, "TRAINED_CATEGORY"], [77642, 77651, "TRAINED_CATEGORY"], [77655, 77662, "TRAINED_CATEGORY"], [77675, 77687, "TRAINED_CATEGORY"], [77751, 77769, "TRAINED_CATEGORY"], [77794, 77810, "TRAINED_CATEGORY"], [77816, 77848, "TRAINED_CATEGORY"], [77863, 77877, "TRAINED_CATEGORY"], [77890, 77902, "TRAINED_CATEGORY"], [77906, 77934, "TRAINED_CATEGORY"], [77942, 77969, "TRAINED_CATEGORY"], [77982, 77994, "TRAINED_CATEGORY"], [78026, 78040, "TRAINED_CATEGORY"], [78058, 78070, "TRAINED_CATEGORY"], [78078, 78085, "TRAINED_CATEGORY"], [78087, 78091, "TRAINED_CATEGORY"], [78102, 78121, "TRAINED_CATEGORY"], [78142, 78168, "TRAINED_CATEGORY"], [78173, 78185, "TRAINED_CATEGORY"], [78187, 78190, "TRAINED_CATEGORY"], [78215, 78227, "TRAINED_CATEGORY"], [78231, 78239, "TRAINED_CATEGORY"], [78245, 78254, "TRAINED_CATEGORY"], [78258, 78278, "TRAINED_CATEGORY"], [78297, 78319, "TRAINED_CATEGORY"], [78328, 78362, "TRAINED_CATEGORY"], [78377, 78384, "TRAINED_CATEGORY"], [78390, 78410, "TRAINED_CATEGORY"], [78445, 78448, "TRAINED_CATEGORY"], [78459, 78477, "TRAINED_CATEGORY"], [78481, 78490, "TRAINED_CATEGORY"], [78494, 78500, "TRAINED_CATEGORY"], [78501, 78520, "TRAINED_CATEGORY"], [78551, 78559, "TRAINED_CATEGORY"], [78573, 78599, "TRAINED_CATEGORY"], [78605, 78623, "TRAINED_CATEGORY"], [78625, 78628, "TRAINED_CATEGORY"], [78632, 78663, "TRAINED_CATEGORY"], [78697, 78719, "TRAINED_CATEGORY"], [78723, 78747, "TRAINED_CATEGORY"], [78749, 78751, "TRAINED_CATEGORY"], [78781, 78801, "TRAINED_CATEGORY"], [78837, 78854, "TRAINED_CATEGORY"], [78858, 78867, "TRAINED_CATEGORY"], [78874, 78882, "TRAINED_CATEGORY"], [78888, 78901, "TRAINED_CATEGORY"], [78911, 78934, "TRAINED_CATEGORY"], [78939, 78962, "TRAINED_CATEGORY"], [78964, 78966, "TRAINED_CATEGORY"], [78985, 79003, "TRAINED_CATEGORY"], [79035, 79038, "TRAINED_CATEGORY"], [79051, 79059, "TRAINED_CATEGORY"], [79099, 79103, "TRAINED_CATEGORY"], [79108, 79115, "TRAINED_CATEGORY"], [79142, 79144, "TRAINED_CATEGORY"], [79173, 79191, "TRAINED_CATEGORY"], [79193, 79195, "TRAINED_CATEGORY"], [79207, 79232, "TRAINED_CATEGORY"], [79247, 79257, "TRAINED_CATEGORY"], [79263, 79281, "TRAINED_CATEGORY"], [79291, 79293, "TRAINED_CATEGORY"], [79297, 79320, "TRAINED_CATEGORY"], [79322, 79324, "TRAINED_CATEGORY"], [79343, 79349, "TRAINED_CATEGORY"], [79360, 79385, "TRAINED_CATEGORY"], [79409, 79425, "TRAINED_CATEGORY"], [79429, 79431, "TRAINED_CATEGORY"], [79456, 79489, "TRAINED_CATEGORY"], [79494, 79527, "TRAINED_CATEGORY"], [79529, 79550, "TRAINED_CATEGORY"], [79554, 79586, "TRAINED_CATEGORY"], [79609, 79624, "TRAINED_CATEGORY"], [79628, 79656, "TRAINED_CATEGORY"], [79661, 79677, "TRAINED_CATEGORY"], [79685, 79700, "TRAINED_CATEGORY"], [79705, 79733, "TRAINED_CATEGORY"], [79742, 79751, "TRAINED_CATEGORY"], [79761, 79780, "TRAINED_CATEGORY"], [79784, 79806, "TRAINED_CATEGORY"], [79808, 79825, "TRAINED_CATEGORY"], [79831, 79843, "TRAINED_CATEGORY"], [79849, 79862, "TRAINED_CATEGORY"], [79883, 79905, "TRAINED_CATEGORY"], [79924, 79945, "TRAINED_CATEGORY"], [79965, 79968, "TRAINED_CATEGORY"], [79972, 79999, "TRAINED_CATEGORY"], [80021, 80048, "TRAINED_CATEGORY"], [80059, 80069, "TRAINED_CATEGORY"], [80078, 80109, "TRAINED_CATEGORY"], [80113, 80125, "TRAINED_CATEGORY"], [80127, 80130, "TRAINED_CATEGORY"], [80158, 80166, "TRAINED_CATEGORY"], [80170, 80184, "TRAINED_CATEGORY"], [80207, 80221, "TRAINED_CATEGORY"], [80227, 80247, "TRAINED_CATEGORY"], [80262, 80270, "TRAINED_CATEGORY"], [80284, 80304, "TRAINED_CATEGORY"], [80308, 80315, "TRAINED_CATEGORY"], [80317, 80332, "TRAINED_CATEGORY"], [80347, 80375, "TRAINED_CATEGORY"], [80380, 80391, "TRAINED_CATEGORY"], [80392, 80400, "TRAINED_CATEGORY"], [80415, 80434, "TRAINED_CATEGORY"], [80438, 80447, "TRAINED_CATEGORY"], [80464, 80467, "TRAINED_CATEGORY"], [80469, 80484, "TRAINED_CATEGORY"], [80488, 80518, "TRAINED_CATEGORY"], [80540, 80562, "TRAINED_CATEGORY"], [80569, 80578, "TRAINED_CATEGORY"], [80589, 80600, "TRAINED_CATEGORY"], [80612, 80631, "TRAINED_CATEGORY"], [80635, 80644, "TRAINED_CATEGORY"], [80656, 80671, "TRAINED_CATEGORY"], [80677, 80682, "TRAINED_CATEGORY"], [80686, 80708, "TRAINED_CATEGORY"], [80755, 80777, "TRAINED_CATEGORY"], [80815, 80818, "TRAINED_CATEGORY"], [80841, 80850, "TRAINED_CATEGORY"], [80889, 80902, "TRAINED_CATEGORY"], [80929, 80950, "TRAINED_CATEGORY"], [80952, 80955, "TRAINED_CATEGORY"], [80990, 81019, "TRAINED_CATEGORY"], [81021, 81028, "TRAINED_CATEGORY"], [81038, 81041, "TRAINED_CATEGORY"], [81082, 81097, "TRAINED_CATEGORY"], [81122, 81130, "TRAINED_CATEGORY"], [81146, 81159, "TRAINED_CATEGORY"], [81166, 81177, "TRAINED_CATEGORY"], [81207, 81222, "TRAINED_CATEGORY"], [81246, 81266, "TRAINED_CATEGORY"], [81280, 81294, "TRAINED_CATEGORY"], [81295, 81322, "TRAINED_CATEGORY"], [81326, 81333, "TRAINED_CATEGORY"], [81338, 81353, "TRAINED_CATEGORY"], [81358, 81374, "TRAINED_CATEGORY"], [81404, 81419, "TRAINED_CATEGORY"], [81438, 81453, "TRAINED_CATEGORY"], [81464, 81481, "TRAINED_CATEGORY"], [81489, 81496, "TRAINED_CATEGORY"], [81512, 81514, "TRAINED_CATEGORY"], [81538, 81558, "TRAINED_CATEGORY"], [81562, 81580, "TRAINED_CATEGORY"], [81595, 81617, "TRAINED_CATEGORY"], [81631, 81655, "TRAINED_CATEGORY"], [81661, 81677, "TRAINED_CATEGORY"], [81689, 81713, "TRAINED_CATEGORY"], [81730, 81759, "TRAINED_CATEGORY"], [81775, 81778, "TRAINED_CATEGORY"], [81782, 81801, "TRAINED_CATEGORY"], [81805, 81823, "TRAINED_CATEGORY"], [81832, 81844, "TRAINED_CATEGORY"], [81850, 81852, "TRAINED_CATEGORY"], [81883, 81898, "TRAINED_CATEGORY"], [81902, 81915, "TRAINED_CATEGORY"], [81921, 81950, "TRAINED_CATEGORY"], [81965, 81989, "TRAINED_CATEGORY"], [81997, 82030, "TRAINED_CATEGORY"], [82036, 82069, "TRAINED_CATEGORY"], [82071, 82074, "TRAINED_CATEGORY"], [82079, 82107, "TRAINED_CATEGORY"], [82114, 82140, "TRAINED_CATEGORY"], [82144, 82156, "TRAINED_CATEGORY"], [82186, 82204, "TRAINED_CATEGORY"], [82208, 82217, "TRAINED_CATEGORY"], [82222, 82231, "TRAINED_CATEGORY"], [82237, 82258, "TRAINED_CATEGORY"], [82277, 82295, "TRAINED_CATEGORY"], [82332, 82350, "TRAINED_CATEGORY"], [82397, 82419, "TRAINED_CATEGORY"], [82424, 82427, "TRAINED_CATEGORY"], [82429, 82445, "TRAINED_CATEGORY"], [82449, 82463, "TRAINED_CATEGORY"], [82483, 82496, "TRAINED_CATEGORY"], [82500, 82528, "TRAINED_CATEGORY"], [82553, 82585, "TRAINED_CATEGORY"], [82587, 82590, "TRAINED_CATEGORY"], [82605, 82619, "TRAINED_CATEGORY"], [82625, 82628, "TRAINED_CATEGORY"], [82630, 82644, "TRAINED_CATEGORY"], [82670, 82694, "TRAINED_CATEGORY"], [82696, 82736, "TRAINED_CATEGORY"], [82738, 82782, "TRAINED_CATEGORY"], [82827, 82828, "TRAINED_CATEGORY"], [82932, 82933, "TRAINED_CATEGORY"], [82957, 82958, "TRAINED_CATEGORY"], [83053, 83054, "TRAINED_CATEGORY"], [83158, 83159, "TRAINED_CATEGORY"], [83183, 83184, "TRAINED_CATEGORY"], [83221, 83260, "TRAINED_CATEGORY"], [83261, 83262, "TRAINED_CATEGORY"], [83262, 83288, "TRAINED_CATEGORY"], [83289, 83290, "TRAINED_CATEGORY"], [83291, 83292, "TRAINED_CATEGORY"], [83301, 83311, "TRAINED_CATEGORY"], [83315, 83331, "TRAINED_CATEGORY"], [83356, 83357, "TRAINED_CATEGORY"], [83375, 83390, "TRAINED_CATEGORY"], [83401, 83408, "TRAINED_CATEGORY"], [83436, 83437, "TRAINED_CATEGORY"], [83454, 83485, "TRAINED_CATEGORY"], [83491, 83494, "TRAINED_CATEGORY"], [83499, 83513, "TRAINED_CATEGORY"], [83521, 83528, "TRAINED_CATEGORY"], [83551, 83573, "TRAINED_CATEGORY"], [83580, 83590, "TRAINED_CATEGORY"], [83610, 83623, "TRAINED_CATEGORY"], [83627, 83639, "TRAINED_CATEGORY"], [83653, 83665, "TRAINED_CATEGORY"], [83686, 83689, "TRAINED_CATEGORY"], [83723, 83741, "TRAINED_CATEGORY"], [83783, 83807, "TRAINED_CATEGORY"], [83811, 83829, "TRAINED_CATEGORY"], [83848, 83861, "TRAINED_CATEGORY"], [83867, 83870, "TRAINED_CATEGORY"], [83883, 83913, "TRAINED_CATEGORY"], [83917, 83920, "TRAINED_CATEGORY"], [83927, 83942, "TRAINED_CATEGORY"], [83952, 83962, "TRAINED_CATEGORY"], [83968, 83993, "TRAINED_CATEGORY"], [83997, 84000, "TRAINED_CATEGORY"], [84009, 84033, "TRAINED_CATEGORY"], [84053, 84065, "TRAINED_CATEGORY"], [84069, 84088, "TRAINED_CATEGORY"], [84090, 84100, "TRAINED_CATEGORY"], [84111, 84128, "TRAINED_CATEGORY"], [84140, 84159, "TRAINED_CATEGORY"], [84173, 84199, "TRAINED_CATEGORY"], [84201, 84203, "TRAINED_CATEGORY"], [84212, 84230, "TRAINED_CATEGORY"], [84234, 84262, "TRAINED_CATEGORY"], [84264, 84267, "TRAINED_CATEGORY"], [84273, 84286, "TRAINED_CATEGORY"], [84290, 84304, "TRAINED_CATEGORY"], [84308, 84312, "TRAINED_CATEGORY"], [84323, 84342, "TRAINED_CATEGORY"], [84346, 84365, "TRAINED_CATEGORY"], [84368, 84386, "TRAINED_CATEGORY"], [84418, 84440, "TRAINED_CATEGORY"], [84442, 84496, "TRAINED_CATEGORY"], [84498, 84534, "TRAINED_CATEGORY"], [84535, 84572, "TRAINED_CATEGORY"], [84573, 84603, "TRAINED_CATEGORY"], [84608, 84621, "TRAINED_CATEGORY"], [84628, 84655, "TRAINED_CATEGORY"], [84657, 84687, "TRAINED_CATEGORY"], [84688, 84735, "TRAINED_CATEGORY"], [84739, 84749, "TRAINED_CATEGORY"], [84761, 84777, "TRAINED_CATEGORY"], [84781, 84799, "TRAINED_CATEGORY"], [84825, 84839, "TRAINED_CATEGORY"], [84847, 84860, "TRAINED_CATEGORY"], [84874, 84892, "TRAINED_CATEGORY"], [84897, 84931, "TRAINED_CATEGORY"], [84937, 84976, "TRAINED_CATEGORY"], [84980, 84983, "TRAINED_CATEGORY"], [84987, 84994, "TRAINED_CATEGORY"], [84996, 85019, "TRAINED_CATEGORY"], [85032, 85047, "TRAINED_CATEGORY"], [85052, 85057, "TRAINED_CATEGORY"], [85091, 85096, "TRAINED_CATEGORY"], [85100, 85111, "TRAINED_CATEGORY"], [85113, 85129, "TRAINED_CATEGORY"], [85134, 85143, "TRAINED_CATEGORY"], [85149, 85180, "TRAINED_CATEGORY"], [85185, 85203, "TRAINED_CATEGORY"], [85215, 85243, "TRAINED_CATEGORY"], [85247, 85250, "TRAINED_CATEGORY"], [85278, 85298, "TRAINED_CATEGORY"], [85303, 85321, "TRAINED_CATEGORY"], [85345, 85374, "TRAINED_CATEGORY"], [85380, 85392, "TRAINED_CATEGORY"], [85397, 85399, "TRAINED_CATEGORY"], [85418, 85421, "TRAINED_CATEGORY"], [85432, 85457, "TRAINED_CATEGORY"], [85462, 85489, "TRAINED_CATEGORY"], [85491, 85521, "TRAINED_CATEGORY"], [85525, 85535, "TRAINED_CATEGORY"], [85558, 85561, "TRAINED_CATEGORY"], [85575, 85609, "TRAINED_CATEGORY"], [85626, 85652, "TRAINED_CATEGORY"], [85688, 85691, "TRAINED_CATEGORY"], [85722, 85725, "TRAINED_CATEGORY"], [85727, 85731, "TRAINED_CATEGORY"], [85747, 85755, "TRAINED_CATEGORY"], [85770, 85792, "TRAINED_CATEGORY"], [85794, 85798, "TRAINED_CATEGORY"], [85823, 85826, "TRAINED_CATEGORY"], [85830, 85839, "TRAINED_CATEGORY"], [85843, 85853, "TRAINED_CATEGORY"], [85867, 85871, "TRAINED_CATEGORY"], [85897, 85908, "TRAINED_CATEGORY"], [85910, 85926, "TRAINED_CATEGORY"], [85933, 85937, "TRAINED_CATEGORY"], [85961, 85978, "TRAINED_CATEGORY"], [85980, 85997, "TRAINED_CATEGORY"], [86002, 86013, "TRAINED_CATEGORY"], [86015, 86049, "TRAINED_CATEGORY"], [86072, 86078, "TRAINED_CATEGORY"], [86087, 86107, "TRAINED_CATEGORY"], [86109, 86116, "TRAINED_CATEGORY"], [86118, 86142, "TRAINED_CATEGORY"], [86144, 86163, "TRAINED_CATEGORY"], [86165, 86171, "TRAINED_CATEGORY"], [86177, 86185, "TRAINED_CATEGORY"], [86193, 86203, "TRAINED_CATEGORY"], [86214, 86217, "TRAINED_CATEGORY"], [86224, 86257, "TRAINED_CATEGORY"], [86276, 86293, "TRAINED_CATEGORY"], [86296, 86298, "TRAINED_CATEGORY"], [86321, 86329, "TRAINED_CATEGORY"], [86333, 86341, "TRAINED_CATEGORY"], [86355, 86367, "TRAINED_CATEGORY"], [86384, 86394, "TRAINED_CATEGORY"], [86413, 86428, "TRAINED_CATEGORY"], [86430, 86432, "TRAINED_CATEGORY"], [86446, 86461, "TRAINED_CATEGORY"], [86472, 86480, "TRAINED_CATEGORY"], [86498, 86501, "TRAINED_CATEGORY"], [86515, 86528, "TRAINED_CATEGORY"], [86530, 86538, "TRAINED_CATEGORY"], [86573, 86580, "TRAINED_CATEGORY"], [86585, 86607, "TRAINED_CATEGORY"], [86613, 86635, "TRAINED_CATEGORY"], [86637, 86651, "TRAINED_CATEGORY"], [86655, 86661, "TRAINED_CATEGORY"], [86665, 86673, "TRAINED_CATEGORY"], [86678, 86686, "TRAINED_CATEGORY"], [86713, 86747, "TRAINED_CATEGORY"], [86751, 86754, "TRAINED_CATEGORY"], [86764, 86778, "TRAINED_CATEGORY"], [86789, 86799, "TRAINED_CATEGORY"], [86813, 86830, "TRAINED_CATEGORY"], [86834, 86846, "TRAINED_CATEGORY"], [86856, 86881, "TRAINED_CATEGORY"], [86883, 86909, "TRAINED_CATEGORY"], [86913, 86916, "TRAINED_CATEGORY"], [86951, 86971, "TRAINED_CATEGORY"], [86988, 87016, "TRAINED_CATEGORY"], [87018, 87022, "TRAINED_CATEGORY"], [87028, 87041, "TRAINED_CATEGORY"], [87045, 87073, "TRAINED_CATEGORY"], [87077, 87091, "TRAINED_CATEGORY"], [87095, 87098, "TRAINED_CATEGORY"], [87120, 87127, "TRAINED_CATEGORY"], [87131, 87161, "TRAINED_CATEGORY"], [87168, 87186, "TRAINED_CATEGORY"], [87196, 87226, "TRAINED_CATEGORY"], [87231, 87261, "TRAINED_CATEGORY"], [87263, 87266, "TRAINED_CATEGORY"], [87283, 87299, "TRAINED_CATEGORY"], [87303, 87331, "TRAINED_CATEGORY"], [87343, 87374, "TRAINED_CATEGORY"], [87387, 87412, "TRAINED_CATEGORY"], [87420, 87446, "TRAINED_CATEGORY"], [87457, 87465, "TRAINED_CATEGORY"], [87490, 87491, "TRAINED_CATEGORY"], [87530, 87532, "TRAINED_CATEGORY"], [87552, 87554, "TRAINED_CATEGORY"], [87560, 87572, "TRAINED_CATEGORY"], [87607, 87608, "TRAINED_CATEGORY"], [87627, 87638, "TRAINED_CATEGORY"], [87656, 87674, "TRAINED_CATEGORY"], [87680, 87696, "TRAINED_CATEGORY"], [87702, 87712, "TRAINED_CATEGORY"], [87721, 87724, "TRAINED_CATEGORY"], [87729, 87732, "TRAINED_CATEGORY"], [87749, 87760, "TRAINED_CATEGORY"], [87881, 87882, "TRAINED_CATEGORY"], [87969, 87989, "TRAINED_CATEGORY"], [87999, 88017, "TRAINED_CATEGORY"], [88019, 88023, "TRAINED_CATEGORY"], [88038, 88062, "TRAINED_CATEGORY"], [88103, 88104, "TRAINED_CATEGORY"], [88146, 88162, "TRAINED_CATEGORY"], [88163, 88174, "TRAINED_CATEGORY"], [88202, 88203, "TRAINED_CATEGORY"], [88251, 88285, "TRAINED_CATEGORY"], [88294, 88295, "TRAINED_CATEGORY"], [88382, 88383, "TRAINED_CATEGORY"], [88424, 88434, "TRAINED_CATEGORY"], [88438, 88445, "TRAINED_CATEGORY"], [88473, 88474, "TRAINED_CATEGORY"], [88492, 88507, "TRAINED_CATEGORY"], [88507, 88540, "TRAINED_CATEGORY"], [88544, 88548, "TRAINED_CATEGORY"], [88576, 88577, "TRAINED_CATEGORY"], [88595, 88610, "TRAINED_CATEGORY"], [88617, 88634, "TRAINED_CATEGORY"], [88639, 88653, "TRAINED_CATEGORY"], [88665, 88671, "TRAINED_CATEGORY"], [88688, 88708, "TRAINED_CATEGORY"], [88720, 88740, "TRAINED_CATEGORY"], [88754, 88756, "TRAINED_CATEGORY"], [88758, 88768, "TRAINED_CATEGORY"], [88800, 88821, "TRAINED_CATEGORY"], [88827, 88843, "TRAINED_CATEGORY"], [88869, 88870, "TRAINED_CATEGORY"], [88918, 88926, "TRAINED_CATEGORY"], [88937, 88954, "TRAINED_CATEGORY"], [88971, 88985, "TRAINED_CATEGORY"], [88989, 88997, "TRAINED_CATEGORY"], [89002, 89024, "TRAINED_CATEGORY"], [89028, 89034, "TRAINED_CATEGORY"], [89037, 89042, "TRAINED_CATEGORY"], [89047, 89048, "TRAINED_CATEGORY"], [89048, 89057, "TRAINED_CATEGORY"], [89074, 89077, "TRAINED_CATEGORY"], [89092, 89095, "TRAINED_CATEGORY"], [89108, 89141, "TRAINED_CATEGORY"], [89151, 89171, "TRAINED_CATEGORY"], [89173, 89177, "TRAINED_CATEGORY"], [89189, 89192, "TRAINED_CATEGORY"], [89197, 89207, "TRAINED_CATEGORY"], [89219, 89234, "TRAINED_CATEGORY"], [89238, 89241, "TRAINED_CATEGORY"], [89275, 89285, "TRAINED_CATEGORY"], [89287, 89292, "TRAINED_CATEGORY"], [89295, 89323, "TRAINED_CATEGORY"], [89352, 89367, "TRAINED_CATEGORY"], [89375, 89398, "TRAINED_CATEGORY"], [89400, 89405, "TRAINED_CATEGORY"], [89408, 89420, "TRAINED_CATEGORY"], [89426, 89442, "TRAINED_CATEGORY"], [89446, 89475, "TRAINED_CATEGORY"], [89476, 89481, "TRAINED_CATEGORY"], [89497, 89521, "TRAINED_CATEGORY"], [89526, 89534, "TRAINED_CATEGORY"], [89544, 89553, "TRAINED_CATEGORY"], [89566, 89577, "TRAINED_CATEGORY"], [89590, 89601, "TRAINED_CATEGORY"], [89607, 89609, "TRAINED_CATEGORY"], [89618, 89629, "TRAINED_CATEGORY"], [89632, 89671, "TRAINED_CATEGORY"], [89677, 89708, "TRAINED_CATEGORY"], [89715, 89754, "TRAINED_CATEGORY"], [89756, 89789, "TRAINED_CATEGORY"], [89795, 89802, "TRAINED_CATEGORY"], [89807, 89810, "TRAINED_CATEGORY"], [89812, 89837, "TRAINED_CATEGORY"], [89840, 89862, "TRAINED_CATEGORY"], [89867, 89870, "TRAINED_CATEGORY"], [89871, 89878, "TRAINED_CATEGORY"], [89885, 89909, "TRAINED_CATEGORY"], [89917, 89936, "TRAINED_CATEGORY"], [89943, 89956, "TRAINED_CATEGORY"], [89975, 89981, "TRAINED_CATEGORY"], [89986, 90014, "TRAINED_CATEGORY"], [90016, 90026, "TRAINED_CATEGORY"], [90029, 90043, "TRAINED_CATEGORY"], [90049, 90062, "TRAINED_CATEGORY"], [90066, 90082, "TRAINED_CATEGORY"], [90084, 90090, "TRAINED_CATEGORY"], [90102, 90119, "TRAINED_CATEGORY"], [90123, 90151, "TRAINED_CATEGORY"], [90155, 90158, "TRAINED_CATEGORY"], [90160, 90171, "TRAINED_CATEGORY"], [90174, 90203, "TRAINED_CATEGORY"], [90255, 90280, "TRAINED_CATEGORY"], [90284, 90295, "TRAINED_CATEGORY"], [90298, 90303, "TRAINED_CATEGORY"], [90306, 90335, "TRAINED_CATEGORY"], [90347, 90350, "TRAINED_CATEGORY"], [90355, 90373, "TRAINED_CATEGORY"], [90388, 90427, "TRAINED_CATEGORY"], [90451, 90457, "TRAINED_CATEGORY"], [90459, 90480, "TRAINED_CATEGORY"], [90487, 90510, "TRAINED_CATEGORY"], [90512, 90538, "TRAINED_CATEGORY"], [90606, 90619, "TRAINED_CATEGORY"], [90620, 90643, "TRAINED_CATEGORY"], [90644, 90653, "TRAINED_CATEGORY"], [90668, 90671, "TRAINED_CATEGORY"], [90675, 90709, "TRAINED_CATEGORY"], [90711, 90714, "TRAINED_CATEGORY"], [90724, 90736, "TRAINED_CATEGORY"], [90738, 90744, "TRAINED_CATEGORY"], [90748, 90766, "TRAINED_CATEGORY"], [90774, 90778, "TRAINED_CATEGORY"], [90804, 90814, "TRAINED_CATEGORY"], [90818, 90838, "TRAINED_CATEGORY"], [90840, 90846, "TRAINED_CATEGORY"], [90849, 90861, "TRAINED_CATEGORY"], [90865, 90880, "TRAINED_CATEGORY"], [90882, 90889, "TRAINED_CATEGORY"], [90892, 90911, "TRAINED_CATEGORY"], [90926, 90943, "TRAINED_CATEGORY"], [90949, 90965, "TRAINED_CATEGORY"], [90972, 90975, "TRAINED_CATEGORY"], [90977, 90978, "TRAINED_CATEGORY"], [90981, 91005, "TRAINED_CATEGORY"], [91007, 91020, "TRAINED_CATEGORY"], [91034, 91040, "TRAINED_CATEGORY"], [91057, 91085, "TRAINED_CATEGORY"], [91087, 91093, "TRAINED_CATEGORY"], [91099, 91127, "TRAINED_CATEGORY"], [91150, 91175, "TRAINED_CATEGORY"], [91177, 91190, "TRAINED_CATEGORY"], [91206, 91209, "TRAINED_CATEGORY"], [91213, 91214, "TRAINED_CATEGORY"], [91249, 91253, "TRAINED_CATEGORY"], [91255, 91260, "TRAINED_CATEGORY"], [91262, 91272, "TRAINED_CATEGORY"], [91274, 91280, "TRAINED_CATEGORY"], [91298, 91324, "TRAINED_CATEGORY"], [91330, 91337, "TRAINED_CATEGORY"], [91359, 91373, "TRAINED_CATEGORY"], [91378, 91394, "TRAINED_CATEGORY"], [91410, 91413, "TRAINED_CATEGORY"], [91415, 91432, "TRAINED_CATEGORY"], [91434, 91444, "TRAINED_CATEGORY"], [91446, 91456, "TRAINED_CATEGORY"], [91461, 91477, "TRAINED_CATEGORY"], [91481, 91505, "TRAINED_CATEGORY"], [91507, 91511, "TRAINED_CATEGORY"], [91514, 91526, "TRAINED_CATEGORY"], [91531, 91547, "TRAINED_CATEGORY"], [91563, 91570, "TRAINED_CATEGORY"], [91585, 91605, "TRAINED_CATEGORY"], [91629, 91639, "TRAINED_CATEGORY"], [91648, 91663, "TRAINED_CATEGORY"], [91667, 91674, "TRAINED_CATEGORY"], [91676, 91680, "TRAINED_CATEGORY"], [91689, 91703, "TRAINED_CATEGORY"], [91707, 91727, "TRAINED_CATEGORY"], [91729, 91734, "TRAINED_CATEGORY"], [91737, 91745, "TRAINED_CATEGORY"], [91747, 91752, "TRAINED_CATEGORY"], [91761, 91789, "TRAINED_CATEGORY"], [91791, 91806, "TRAINED_CATEGORY"], [91810, 91820, "TRAINED_CATEGORY"], [91822, 91837, "TRAINED_CATEGORY"], [91839, 91841, "TRAINED_CATEGORY"], [91875, 91886, "TRAINED_CATEGORY"], [91886, 91893, "TRAINED_CATEGORY"], [91895, 91899, "TRAINED_CATEGORY"], [91919, 91927, "TRAINED_CATEGORY"], [91929, 91933, "TRAINED_CATEGORY"], [91942, 91970, "TRAINED_CATEGORY"], [91972, 91986, "TRAINED_CATEGORY"], [91988, 91996, "TRAINED_CATEGORY"], [91999, 92014, "TRAINED_CATEGORY"], [92016, 92028, "TRAINED_CATEGORY"], [92031, 92043, "TRAINED_CATEGORY"], [92052, 92085, "TRAINED_CATEGORY"], [92089, 92096, "TRAINED_CATEGORY"], [92097, 92113, "TRAINED_CATEGORY"], [92116, 92120, "TRAINED_CATEGORY"], [92125, 92137, "TRAINED_CATEGORY"], [92153, 92188, "TRAINED_CATEGORY"], [92197, 92221, "TRAINED_CATEGORY"], [92225, 92232, "TRAINED_CATEGORY"], [92233, 92249, "TRAINED_CATEGORY"], [92252, 92256, "TRAINED_CATEGORY"], [92256, 92260, "TRAINED_CATEGORY"], [92261, 92280, "TRAINED_CATEGORY"], [92281, 92286, "TRAINED_CATEGORY"], [92292, 92306, "TRAINED_CATEGORY"], [92324, 92334, "TRAINED_CATEGORY"], [92344, 92354, "TRAINED_CATEGORY"], [92358, 92365, "TRAINED_CATEGORY"], [92366, 92391, "TRAINED_CATEGORY"], [92395, 92404, "TRAINED_CATEGORY"], [92408, 92415, "TRAINED_CATEGORY"], [92416, 92426, "TRAINED_CATEGORY"], [92430, 92458, "TRAINED_CATEGORY"], [92459, 92482, "TRAINED_CATEGORY"], [92486, 92514, "TRAINED_CATEGORY"], [92518, 92525, "TRAINED_CATEGORY"], [92527, 92534, "TRAINED_CATEGORY"], [92538, 92559, "TRAINED_CATEGORY"], [92573, 92601, "TRAINED_CATEGORY"], [92603, 92606, "TRAINED_CATEGORY"], [92629, 92636, "TRAINED_CATEGORY"], [92646, 92654, "TRAINED_CATEGORY"], [92658, 92682, "TRAINED_CATEGORY"], [32, 35, "CARDINAL"], [37, 42, "CARDINAL"], [275, 280, "ORDINAL"], [524, 527, "ORG"], [700, 703, "ORG"], [796, 797, "CARDINAL"], [1005, 1008, "ORG"], [1177, 1181, "CARDINAL"], [1289, 1290, "CARDINAL"], [1324, 1327, "ORG"], [2023, 2026, "ORG"], [2335, 2336, "CARDINAL"], [2357, 2360, "ORG"], [2523, 2528, "ORDINAL"], [2617, 2620, "ORG"], [2819, 2822, "ORG"], [2874, 2877, "ORG"], [2880, 2883, "ORG"], [2964, 2967, "CARDINAL"], [2983, 2986, "ORG"], [3130, 3133, "ORG"], [3175, 3178, "ORG"], [3195, 3199, "DATE"], [3203, 3215, "PERSON"], [3326, 3342, "PERSON"], [3346, 3355, "DATE"], [3426, 3434, "PERSON"], [3435, 3440, "GPE"], [3452, 3455, "PERSON"], [3483, 3492, "NORP"], [3569, 3572, "ORG"], [3631, 3634, "ORG"], [3642, 3647, "PERSON"], [3652, 3660, "GPE"], [3662, 3666, "DATE"], [3695, 3698, "ORG"], [3703, 3706, "ORG"], [3787, 3790, "ORG"], [3824, 3832, "PERSON"], [3835, 3863, "ORG"], [3866, 3872, "PERSON"], [3888, 3894, "ORG"], [3896, 3900, "DATE"], [3938, 3941, "ORG"], [4019, 4023, "DATE"], [4056, 4062, "GPE"], [4064, 4068, "DATE"], [4092, 4105, "PERSON"], [4107, 4111, "DATE"], [4664, 4669, "ORDINAL"], [5568, 5575, "PERSON"], [5601, 5604, "ORG"], [5797, 5802, "ORDINAL"], [5826, 5831, "ORDINAL"], [5858, 5864, "ORDINAL"], [5890, 5896, "ORDINAL"], [5994, 6007, "WORK_OF_ART"], [6055, 6059, "CARDINAL"], [6127, 6131, "CARDINAL"], [7189, 7190, "CARDINAL"], [7678, 7699, "WORK_OF_ART"], [7704, 7705, "CARDINAL"], [8496, 8497, "CARDINAL"], [8499, 8519, "ORG"], [8523, 8540, "PERSON"], [8573, 8582, "GPE"], [8828, 8853, "WORK_OF_ART"], [9071, 9091, "WORK_OF_ART"], [9170, 9190, "WORK_OF_ART"], [9223, 9228, "ORDINAL"], [9278, 9283, "ORDINAL"], [9298, 9301, "PERSON"], [9421, 9422, "CARDINAL"], [10005, 10006, "CARDINAL"], [10191, 10192, "CARDINAL"], [10513, 10514, "CARDINAL"], [10978, 10979, "CARDINAL"], [11121, 11122, "CARDINAL"], [11200, 11225, "PRODUCT"], [11251, 11268, "GPE"], [11270, 11299, "QUANTITY"], [11316, 11317, "CARDINAL"], [11375, 11392, "GPE"], [11394, 11423, "QUANTITY"], [11440, 11441, "CARDINAL"], [11442, 11459, "GPE"], [11462, 11463, "CARDINAL"], [11465, 11506, "ORG"], [12826, 12853, "WORK_OF_ART"], [12877, 12894, "GPE"], [12896, 12927, "QUANTITY"], [12928, 12950, "PERSON"], [12982, 12999, "GPE"], [13001, 13032, "QUANTITY"], [13105, 13108, "PERSON"], [13277, 13278, "CARDINAL"], [14260, 14265, "ORG"], [14426, 14434, "ORG"], [14506, 14509, "ORG"], [14656, 14659, "PERSON"], [14672, 14677, "ORDINAL"], [14757, 14760, "PERSON"], [14764, 14767, "PERSON"], [14868, 14871, "PERSON"], [14874, 14877, "PERSON"], [14959, 14964, "ORDINAL"], [14969, 14970, "CARDINAL"], [15232, 15253, "PERSON"], [15306, 15307, "CARDINAL"], [15356, 15357, "ORG"], [15370, 15371, "CARDINAL"], [15572, 15608, "PERSON"], [15772, 15773, "CARDINAL"], [15831, 15832, "CARDINAL"], [16390, 16391, "CARDINAL"], [18341, 18355, "LOC"], [18363, 18380, "FAC"], [18500, 18505, "ORG"], [18561, 18576, "MONEY"], [18588, 18589, "CARDINAL"], [18606, 18616, "GPE"], [18707, 18710, "ORG"], [18851, 18854, "ORG"], [18860, 18863, "PERSON"], [18901, 18904, "PERSON"], [18948, 18951, "PERSON"], [18955, 18958, "PERSON"], [19072, 19075, "PERSON"], [19078, 19081, "PERSON"], [19090, 19093, "PERSON"], [19102, 19105, "NORP"], [19121, 19124, "ORG"], [19465, 19468, "ORG"], [19697, 19700, "ORG"], [19746, 19749, "ORG"], [19848, 19850, "ORG"], [19876, 19887, "CARDINAL"], [23589, 23590, "CARDINAL"], [23609, 23610, "CARDINAL"], [23689, 23704, "NORP"], [23802, 23812, "ORG"], [23838, 23848, "ORG"], [23932, 23935, "PERSON"], [23969, 23970, "CARDINAL"], [23979, 23980, "CARDINAL"], [24012, 24015, "PERSON"], [24245, 24249, "CARDINAL"], [25884, 25887, "ORG"], [25996, 26004, "PERSON"], [26008, 26010, "PERSON"], [26108, 26111, "PERSON"], [26298, 26303, "ORDINAL"], [26355, 26360, "ORDINAL"], [26665, 26689, "WORK_OF_ART"], [26691, 26692, "CARDINAL"], [26720, 26721, "CARDINAL"], [26799, 26802, "ORG"], [26889, 26914, "PERSON"], [27188, 27203, "GPE"], [27851, 27887, "ORG"], [27964, 27965, "CARDINAL"], [28025, 28026, "CARDINAL"], [28064, 28102, "WORK_OF_ART"], [28137, 28138, "CARDINAL"], [28438, 28461, "WORK_OF_ART"], [28479, 28480, "CARDINAL"], [28715, 28716, "CARDINAL"], [28738, 28743, "ORDINAL"], [28744, 28747, "CARDINAL"], [28779, 28782, "CARDINAL"], [28993, 28996, "CARDINAL"], [29029, 29032, "CARDINAL"], [29065, 29068, "CARDINAL"], [29490, 29493, "CARDINAL"], [29905, 29913, "NORP"], [29995, 30003, "NORP"], [30221, 30226, "ORDINAL"], [30339, 30344, "ORDINAL"], [30474, 30479, "ORDINAL"], [30675, 30683, "NORP"], [30840, 30843, "ORG"], [31074, 31098, "WORK_OF_ART"], [31258, 31259, "ORG"], [31385, 31386, "PRODUCT"], [31540, 31543, "ORG"], [32160, 32220, "ORG"], [33436, 33437, "CARDINAL"], [33530, 33708, "PERSON"], [33753, 33764, "WORK_OF_ART"], [33774, 33780, "PRODUCT"], [33824, 33830, "PRODUCT"], [33874, 33880, "PRODUCT"], [33896, 33902, "PRODUCT"], [33952, 33958, "PRODUCT"], [34167, 34173, "PRODUCT"], [34259, 34264, "CARDINAL"], [34486, 34487, "CARDINAL"], [34698, 34704, "PRODUCT"], [34714, 34729, "PRODUCT"], [34745, 34751, "PRODUCT"], [34809, 34812, "ORG"], [34857, 34863, "PRODUCT"], [34902, 34905, "ORG"], [35092, 35095, "ORG"], [36376, 36379, "CARDINAL"], [36507, 36509, "CARDINAL"], [36597, 36600, "ORG"], [36619, 36622, "ORG"], [36807, 36812, "ORG"], [36869, 36874, "ORDINAL"], [37372, 37396, "WORK_OF_ART"], [37398, 37399, "CARDINAL"], [37428, 37434, "PRODUCT"], [37466, 37467, "CARDINAL"], [37708, 37711, "CARDINAL"], [37741, 37750, "ORG"], [37779, 37785, "PERSON"], [37801, 37805, "CARDINAL"], [37864, 37873, "NORP"], [37885, 37890, "ORDINAL"], [38062, 38068, "ORDINAL"], [38152, 38157, "ORDINAL"], [38296, 38299, "ORG"], [38632, 38635, "ORG"], [38834, 38839, "ORDINAL"], [39052, 39055, "ORG"], [39380, 39390, "FAC"], [39416, 39425, "PRODUCT"], [39520, 39523, "ORG"], [39525, 39528, "ORG"], [39591, 39594, "CARDINAL"], [39684, 39687, "ORG"], [39714, 39716, "CARDINAL"], [39779, 39782, "CARDINAL"], [39885, 39890, "ORDINAL"], [39903, 39906, "CARDINAL"], [39917, 39922, "ORDINAL"], [40048, 40054, "ORDINAL"], [40097, 40103, "ORDINAL"], [40222, 40225, "ORG"], [40319, 40329, "ORG"], [40342, 40349, "ORG"], [40364, 40371, "PERSON"], [40403, 40467, "WORK_OF_ART"], [40499, 40508, "NORP"], [40549, 40552, "CARDINAL"], [40765, 40768, "ORG"], [40985, 40990, "ORDINAL"], [41098, 41103, "ORDINAL"], [41197, 41201, "CARDINAL"], [41519, 41522, "CARDINAL"], [41590, 41624, "ORG"], [41651, 41675, "ORG"], [41677, 41681, "DATE"], [41752, 41755, "ORG"], [41916, 41935, "CARDINAL"], [42032, 42041, "NORP"], [42077, 42088, "CARDINAL"], [42240, 42250, "EVENT"], [42270, 42273, "ORG"], [42317, 42320, "ORG"], [42339, 42340, "CARDINAL"], [42549, 42562, "ORG"], [42633, 42653, "WORK_OF_ART"], [42780, 42804, "WORK_OF_ART"], [43102, 43131, "WORK_OF_ART"], [43268, 43287, "WORK_OF_ART"], [43430, 43459, "WORK_OF_ART"], [43462, 43465, "MONEY"], [43689, 43695, "PRODUCT"], [43698, 43701, "MONEY"], [43895, 43919, "WORK_OF_ART"], [43922, 43938, "WORK_OF_ART"], [44073, 44108, "WORK_OF_ART"], [44124, 44129, "ORDINAL"], [44478, 44505, "WORK_OF_ART"], [44519, 44520, "CARDINAL"], [44699, 44712, "ORG"], [45035, 45064, "WORK_OF_ART"], [45318, 45321, "MONEY"], [45560, 45584, "WORK_OF_ART"], [45599, 45600, "CARDINAL"], [45778, 45810, "WORK_OF_ART"], [45886, 45914, "PRODUCT"], [46403, 46404, "CARDINAL"], [47011, 47012, "CARDINAL"], [47107, 47112, "ORDINAL"], [47175, 47196, "ORG"], [47356, 47357, "CARDINAL"], [47654, 47669, "ORG"], [47670, 47671, "PRODUCT"], [47681, 47691, "MONEY"], [48232, 48233, "CARDINAL"], [48593, 48603, "MONEY"], [48998, 49008, "MONEY"], [49655, 49670, "PRODUCT"], [49732, 49735, "ORG"], [49935, 49938, "ORG"], [50039, 50042, "ORG"], [50151, 50153, "CARDINAL"], [50256, 50259, "ORG"], [50391, 50394, "ORG"], [50546, 50550, "CARDINAL"], [50917, 50937, "ORG"], [50945, 50948, "ORG"], [51032, 51035, "ORG"], [51326, 51347, "WORK_OF_ART"], [51353, 51377, "GPE"], [51595, 51622, "PRODUCT"], [51623, 51654, "WORK_OF_ART"], [51736, 51767, "WORK_OF_ART"], [51785, 51788, "ORG"], [51894, 51901, "PERSON"], [52014, 52022, "NORP"], [52090, 52121, "WORK_OF_ART"], [52124, 52132, "NORP"], [52205, 52208, "ORG"], [52375, 52422, "WORK_OF_ART"], [52517, 52548, "WORK_OF_ART"], [52674, 52746, "ORG"], [52854, 52855, "CARDINAL"], [52901, 52909, "NORP"], [53076, 53107, "WORK_OF_ART"], [53187, 53214, "PRODUCT"], [53249, 53261, "NORP"], [53499, 53500, "ORG"], [53628, 53655, "WORK_OF_ART"], [53657, 53668, "GPE"], [53686, 53697, "PRODUCT"], [53722, 53725, "ORG"], [53820, 53851, "WORK_OF_ART"], [53876, 53884, "NORP"], [53902, 53910, "PERSON"], [54112, 54115, "ORG"], [54243, 54274, "WORK_OF_ART"], [54298, 54311, "WORK_OF_ART"], [54386, 54389, "ORG"], [54580, 54582, "PERSON"], [54649, 54657, "PERSON"], [54658, 54663, "GPE"], [54675, 54678, "PERSON"], [54905, 54909, "PERSON"], [55433, 55454, "WORK_OF_ART"], [55459, 55460, "CARDINAL"], [55482, 55483, "CARDINAL"], [55624, 55645, "WORK_OF_ART"], [55650, 55651, "CARDINAL"], [55951, 55972, "WORK_OF_ART"], [55977, 55978, "CARDINAL"], [56000, 56001, "CARDINAL"], [56126, 56135, "FAC"], [56205, 56206, "CARDINAL"], [56425, 56426, "CARDINAL"], [56533, 56534, "CARDINAL"], [56751, 56760, "ORG"], [57165, 57186, "WORK_OF_ART"], [57379, 57400, "PERSON"], [57518, 57542, "WORK_OF_ART"], [57545, 57555, "WORK_OF_ART"], [57570, 57577, "WORK_OF_ART"], [57632, 57634, "CARDINAL"], [57735, 57736, "CARDINAL"], [57825, 57826, "CARDINAL"], [57865, 57883, "ORG"], [58136, 58137, "CARDINAL"], [58181, 58182, "PRODUCT"], [58197, 58198, "CARDINAL"], [58397, 58398, "CARDINAL"], [58770, 58776, "ORG"], [59042, 59043, "CARDINAL"], [59366, 59375, "ORG"], [59485, 59507, "ORG"], [59517, 59520, "ORG"], [59525, 59531, "GPE"], [59533, 59544, "GPE"], [59546, 59551, "GPE"], [60170, 60200, "PERCENT"], [60232, 60233, "ORG"], [60271, 60284, "WORK_OF_ART"], [60325, 60333, "PERSON"], [60580, 60588, "PERSON"], [60790, 60799, "ORG"], [61026, 61033, "ORG"], [61366, 61367, "CARDINAL"], [61542, 61543, "CARDINAL"], [61780, 61781, "CARDINAL"], [61901, 61907, "ORG"], [61997, 62002, "ORDINAL"], [62445, 62463, "ORG"], [62464, 62505, "WORK_OF_ART"], [62583, 62584, "CARDINAL"], [62652, 62671, "LAW"], [62981, 62991, "PERCENT"], [63886, 63906, "FAC"], [63907, 63912, "GPE"], [63925, 63928, "PERSON"], [63980, 63997, "ORG"], [64137, 64141, "CARDINAL"], [64316, 64318, "ORG"], [64362, 64364, "ORG"], [64513, 64533, "WORK_OF_ART"], [66371, 66372, "ORG"], [66565, 66588, "WORK_OF_ART"], [66906, 66933, "WORK_OF_ART"], [67196, 67206, "GPE"], [67584, 67587, "ORG"], [67607, 67610, "CARDINAL"], [67716, 67719, "ORDINAL"], [67764, 67767, "CARDINAL"], [67787, 67792, "ORDINAL"], [67889, 67893, "CARDINAL"], [68353, 68361, "GPE"], [68396, 68397, "CARDINAL"], [68573, 68584, "PRODUCT"], [68835, 68859, "WORK_OF_ART"], [68862, 68873, "GPE"], [68888, 68905, "PRODUCT"], [69193, 69206, "WORK_OF_ART"], [69989, 70010, "WORK_OF_ART"], [70017, 70037, "FAC"], [70038, 70053, "GPE"], [70665, 70668, "ORG"], [70686, 70694, "ORG"], [70751, 70754, "ORG"], [70863, 70868, "ORDINAL"], [70977, 70981, "CARDINAL"], [71147, 71154, "GPE"], [71168, 71227, "ORG"], [71293, 71296, "CARDINAL"], [71300, 71303, "CARDINAL"], [71721, 71724, "CARDINAL"], [71898, 71904, "GPE"], [71992, 72010, "PERSON"], [72103, 72106, "CARDINAL"], [72135, 72141, "ORG"], [72197, 72203, "ORG"], [72315, 72320, "ORDINAL"], [72561, 72566, "ORDINAL"], [72624, 72630, "ORG"], [72632, 72641, "ORG"], [72937, 72940, "ORG"], [73274, 73280, "ORG"], [73434, 73438, "PERSON"], [73439, 73446, "PERSON"], [73468, 73477, "ORG"], [73589, 73595, "ORG"], [73674, 73678, "ORG"], [73843, 73902, "ORG"], [73926, 73932, "PERSON"], [74117, 74120, "ORG"], [74236, 74239, "ORG"], [74272, 74275, "ORG"], [75250, 75273, "ORG"], [75364, 75368, "ORG"], [75410, 75424, "PERSON"], [75434, 75439, "ORDINAL"], [75521, 75533, "ORG"], [75754, 75756, "CARDINAL"], [75835, 75836, "CARDINAL"], [75840, 75841, "CARDINAL"], [76114, 76116, "CARDINAL"], [76130, 76133, "ORG"], [76242, 76245, "CARDINAL"], [76393, 76399, "ORDINAL"], [76509, 76521, "ORG"], [77362, 77365, "CARDINAL"], [78187, 78190, "ORG"], [78390, 78403, "CARDINAL"], [78430, 78433, "CARDINAL"], [78445, 78448, "ORG"], [78911, 78925, "GPE"], [78985, 79003, "PERSON"], [79035, 79038, "ORG"], [79193, 79195, "ORG"], [79291, 79293, "ORG"], [79429, 79431, "ORG"], [79529, 79532, "CARDINAL"], [79887, 79890, "ORG"], [79965, 79968, "ORG"], [80127, 80130, "ORG"], [80227, 80234, "GPE"], [80464, 80467, "ORG"], [80815, 80818, "ORG"], [80952, 80955, "ORG"], [81038, 81041, "ORG"], [81489, 81496, "ORG"], [81665, 81668, "ORG"], [81775, 81778, "ORG"], [82071, 82074, "ORG"], [82281, 82284, "ORG"], [82336, 82339, "ORG"], [82424, 82427, "ORG"], [82587, 82590, "ORG"], [82625, 82628, "ORG"], [82684, 82687, "PRODUCT"], [82771, 82772, "CARDINAL"], [82781, 82802, "PERSON"], [82855, 82856, "CARDINAL"], [83081, 83082, "CARDINAL"], [83289, 83294, "PERSON"], [83375, 83395, "WORK_OF_ART"], [83455, 83475, "WORK_OF_ART"], [83491, 83494, "ORG"], [83671, 83674, "ORG"], [83686, 83689, "ORG"], [83727, 83730, "ORG"], [83867, 83870, "ORG"], [83917, 83920, "ORG"], [83952, 83958, "NORP"], [83959, 83962, "ORG"], [83997, 84000, "ORG"], [84097, 84100, "ORG"], [84264, 84267, "ORG"], [84657, 84665, "NORP"], [84739, 84749, "ORG"], [84980, 84983, "ORG"], [84996, 85003, "ORG"], [85247, 85250, "ORG"], [85448, 85457, "ORG"], [85532, 85535, "ORG"], [85558, 85561, "ORG"], [85596, 85609, "FAC"], [85688, 85691, "ORG"], [85722, 85725, "ORG"], [85727, 85731, "ORG"], [85794, 85798, "ORG"], [85823, 85826, "ORG"], [85867, 85871, "ORG"], [85933, 85937, "ORG"], [85974, 85978, "ORG"], [85993, 85997, "ORG"], [86009, 86013, "ORG"], [86087, 86093, "PERSON"], [86109, 86116, "ORG"], [86193, 86203, "ORG"], [86214, 86217, "ORG"], [86417, 86422, "ORDINAL"], [86498, 86501, "ORG"], [86751, 86754, "ORG"], [86775, 86778, "ORG"], [86913, 86916, "ORG"], [87018, 87022, "ORG"], [87095, 87098, "ORG"], [87196, 87207, "ORG"], [87263, 87266, "ORG"], [87420, 87427, "ORG"], [87509, 87528, "WORK_OF_ART"], [87560, 87563, "CARDINAL"], [87672, 87674, "ORG"], [87721, 87724, "ORG"], [87729, 87732, "ORG"], [87807, 87827, "WORK_OF_ART"], [87849, 87850, "CARDINAL"], [88294, 88295, "ORG"], [88304, 88305, "CARDINAL"], [88323, 88345, "WORK_OF_ART"], [88401, 88421, "ORG"], [88492, 88507, "WORK_OF_ART"], [88595, 88614, "WORK_OF_ART"], [88888, 88908, "WORK_OF_ART"], [89028, 89034, "PERSON"], [89074, 89077, "ORG"], [89092, 89096, "ORG"], [89096, 89105, "GPE"], [89121, 89132, "ORG"], [89173, 89177, "ORG"], [89189, 89192, "ORG"], [89238, 89241, "ORG"], [89254, 89257, "ORG"], [89287, 89292, "ORG"], [89400, 89405, "PERSON"], [89450, 89467, "ORG"], [89476, 89481, "ORG"], [89526, 89534, "ORG"], [89561, 89564, "ORG"], [89579, 89588, "ORG"], [89590, 89593, "ORG"], [89618, 89629, "PERSON"], [89681, 89700, "ORG"], [89766, 89769, "ORG"], [89807, 89810, "ORG"], [89819, 89837, "ORG"], [90016, 90026, "PERSON"], [90029, 90035, "ORG"], [90051, 90054, "ORG"], [90155, 90158, "WORK_OF_ART"], [90160, 90163, "ORG"], [90223, 90240, "LOC"], [90264, 90271, "NORP"], [90298, 90303, "ORG"], [90306, 90317, "ORG"], [90355, 90373, "PRODUCT"], [90375, 90385, "LOC"], [90451, 90457, "ORG"], [90535, 90538, "DATE"], [90637, 90643, "PERSON"], [90657, 90671, "ORG"], [90849, 90861, "WORK_OF_ART"], [90869, 90872, "NORP"], [90882, 90889, "GPE"], [90972, 90975, "ORG"], [91262, 91272, "PERSON"], [91298, 91315, "ORG"], [91359, 91365, "ORG"], [91410, 91413, "ORG"], [91415, 91432, "PERSON"], [91434, 91444, "PERSON"], [91446, 91456, "ORG"], [91507, 91511, "PRODUCT"], [91514, 91518, "ORG"], [91667, 91674, "GPE"], [91676, 91680, "GPE"], [91682, 91686, "DATE"], [91729, 91734, "PERSON"], [91737, 91745, "PERSON"], [91747, 91752, "PERSON"], [91754, 91758, "DATE"], [91761, 91789, "ORG"], [91822, 91837, "ORG"], [91843, 91846, "CARDINAL"], [91858, 91873, "PERSON"], [91900, 91903, "CARDINAL"], [91919, 91927, "GPE"], [91929, 91933, "GPE"], [91935, 91939, "DATE"], [91942, 91970, "ORG"], [91972, 91978, "ORDINAL"], [91999, 92014, "PERSON"], [92045, 92049, "DATE"], [92052, 92096, "PERSON"], [92139, 92145, "GPE"], [92147, 92151, "CARDINAL"], [92158, 92161, "CARDINAL"], [92190, 92194, "DATE"], [92292, 92300, "ORG"], [92310, 92334, "ORG"], [92344, 92354, "PERSON"], [92358, 92365, "WORK_OF_ART"], [92366, 92385, "ORG"], [92395, 92407, "PERSON"], [92408, 92416, "WORK_OF_ART"], [92518, 92525, "WORK_OF_ART"], [92538, 92559, "TIME"], [92629, 92636, "FAC"]]}], ["For rank reversals in voting, see Voting paradox.In decision-making, a rank reversal is a change in the rank ordering of the preferability of alternative possible decisions when, for example, the method of choosing changes or the set of other available alternatives changes.  The issue of rank reversals lies at the heart of many debates in decision-making and multi-criteria decision-making, in particular.\nUnlike most other computational procedures, it is hard to tell if a particular decision-making method has derived the correct answer or not.  Such methods analyze a set of alternatives described in terms of some criteria.  They determine which alternative is the best one, or they provide relative weights of how the alternatives perform, or just how the alternatives should be ranked when all the criteria are considered simultaneously.  This is exactly where the challenge with decision making exists.  Often it is hard, if not practically impossible, to determine whether a correct answer has been reached or not.  With other computational methods, for instance with a job scheduling method, one can examine a set of different answers and then categorize the answers according to some metric of performance (for instance, a project's completion time).  But this may not be possible to do with the answers derived by most decision making methods.  After all, determining the best decision making method leads to a decision making paradox.\nThus the following question emerges:  How can one evaluate decision-making methods?  This is a very difficult issue and may not be answered in a globally accepted manner.\nA critical part in answering this fundamental question is played by what is known as rank reversals.\n\n\n== Rank reversal ==\nOne way to test the validity of decision-making methods is to construct special test problems and then study the solutions they derive.  If the solutions exhibit some logic contradictions (in the form of undesirable rank reversals of the alternatives), then one may argue that something is wrong with the method that derived them.\nTo see the above point more clearly, suppose that three candidates are evaluated for some job opening.  Let us designate these candidates as A, B, and C.  Suppose that some decision making method has determined that the best candidate for that job is person A, followed by B, who is followed by C.  This is the first ranking and it is indicated as follows:  A > B > C (where > means better than).  Next, suppose that candidate B (who is not the best one) is replaced by an even worse candidate, say person D.  That is, now we have B > D, and candidate B is replaced by D while candidates A and C remain in the pool of candidates with exactly the same characteristics as before.  When the new set of alternatives (i.e., candidates A, D and C) are ranked together and by assuming that the criteria have exactly the same weights as before, then should not candidate A still be the best one?  It turns out that under some decision making methods the best alternative may be different now.  This is known as a rank reversal and it is one of the types of rank reversals.\nThe first type of rank reversal in the above context was observed by Belton and Gear in 1983 as part of a study  of the analytic hierarchy process (AHP).  They first considered a simple decision problem comprised by 3 alternatives and 2 criteria.  Next a copy of a non-optimal alternative was introduced.  When the 4 alternatives (i.e., the previous 3 plus the copy) were evaluated, and under the assumption that the criteria weights are exactly the same as before, it was observed that now the indication of the best alternative can change.  That is, a rank reversal may occur with the AHP.  A few years later it was observed that the AHP, as well as a new variant to it that was introduced by Professor Thomas Saaty (the inventor of the AHP) in response to the previous observation by Belton and Gear, may exhibit rank reversals when a non-optimal alternative is replaced by a worse one (and not a copy of an alternative as in Belton and Gear's experiment).The issue of rank reversals has captured the interest of many researchers and practitioners in the field of decision-making.  It is something that continues to be considered controversial by many and is frequently debated.\n\n\n== Different types of rank reversals ==\nThere are many different types of rank reversals, depending on how the alternatives in a problem are defined and evaluated.  These types are described next as Type 1, Type 2, Type 3, Type 4, and Type 5.\n\n\n=== Rank reversals of Type 1 ===\nAs stated earlier, one may introduce identical or near-identical copies of non-optimal alternatives and then check to see if the indication of the best alternative changes or not.\n\n\n=== Rank reversals of Type 2 ===\nAnother way is to replace a non-optimal alternative with a worse one and then see if the indication of the best alternative changes or not.\n\n\n=== Rank reversals of Type 3 ===\nFirst consider a problem with all the alternatives together and get a ranking.  Next, decompose the original problem into a set of smaller problems defined on two alternatives at a time and the same criteria (and their weights) as before.  Get the rankings of these smaller problems and check to see if they are in conflict with the ranking of the alternatives of the original (larger) problem.\n\n\n=== Rank reversals of Type 4 ===\nType 4 is like Type 3, but ignores the ranking of the original (larger) problem.  Instead, check to see if the rankings of the smaller problems are in conflict with each other.  For instance, suppose that the following 3 alternatives A, B, and C are considered.  Next, suppose that some 2-alternative problems are solved and the rankings A > B, B > C, and C > A, are derived from these 2-alternative problems.  Obviously, the above situation indicates a case of non-transitivity (or contradiction) as we get A > B > C > A.\n\n\n=== Rank reversals of Type 5 ===\nAll previous types of rank reversals are known to occur with the analytic hierarchy process (AHP) and its additive variants, the TOPSIS and ELECTRE methods and their variants.The weighted product model (WPM) does not exhibit the previous types of rank reversals, due to the multiplication formula it uses.  However, the WPM does cause rank reversals when it is compared with the weighted sum model (WSM) and under the condition that all the criteria of a given decision problem can be measured in exactly the same unit.  The same is true with all the previous methods as well.  This is the Type 5 ranking reversal.\nIt is quite possible to define more types of rank reversals.  One only needs to determine ways to alter a test problem and see how the ranking of the alternatives of the new problem differs from the original ranking of the alternatives of the original problem.  Furthermore, the difference in rankings, somehow, should indicate the presence of undesirable effects.\n\n\n== Are rank reversals always undesirable? ==\nDecision-making methods are used to make decisions in many aspects of human activity.  This is especially true with decisions that involve large amounts of money or decisions that may have huge impact on large numbers of people.  Given the well-established fact that different methods may yield different answers when they are fed with exactly the same problem, the question is how to evaluate them.  Rank reversals are at the very heart of assessing the merits of such methods.  At the same time, they are at the center of many heated debates in this area.  Many authors use them as means to criticize decision making methods or to better explain rational behavior. \nConsider a simple example of buying a car.  Suppose that there are two cars available to the decision maker: Car A and Car B.  Car A is much cheaper than Car B but its overall quality is much less when compared to that for Car B.  On the other hand, Car B is more expensive than Car A but it is also of better quality.  A decision maker who is concerned of the high price issue, may choose Car A over the better quality and more expensive Car B.  Next suppose that the car dealer presents to the decision maker a third car, say Car C, which is way more expensive than Car B but now the overall quality of Car C is marginally higher than that of Car B.  Under such a scenario, it is quite possible for a decision maker to alter his/her opinion and purchase Car B instead of Car A, even if he/she has not actually seen Car C.\nSuch events may take place with many rational decision makers.  In other words, rank reversals may actually be possible in rational decision making.  The issue of having rank reversals by rational decision makers has been studied extensively by Amos Tversky.  In other words, having rank reversals in certain occasions and of certain types may not be indicative to faulty decision making.  However, the key question is how to be able to distinguish when rank reversals indicate that something is wrong or when they do not conflict rational decision making.  This is a highly debated issue in the decision making community.\n\n\n== Methods that have been verified to exhibit rank reversals ==\nThe following is just a partial list of multi-criteria decision making methods which have been confirmed to exhibit various types of rank reversals:\nThe analytic hierarchy process (AHP) and some of its variants.\nThe ELECTRE (outranking) method and its variants.\nThe TOPSIS method.\nThe PROMETHEE (outranking) method.\nMulti-attribute utility theory (MAUT).\n\n\n== References ==", {"entities": [[4, 18, "TRAINED_CATEGORY"], [22, 28, "TRAINED_CATEGORY"], [34, 48, "TRAINED_CATEGORY"], [52, 67, "TRAINED_CATEGORY"], [69, 84, "TRAINED_CATEGORY"], [88, 96, "TRAINED_CATEGORY"], [100, 117, "TRAINED_CATEGORY"], [121, 138, "TRAINED_CATEGORY"], [142, 172, "TRAINED_CATEGORY"], [183, 190, "TRAINED_CATEGORY"], [215, 222, "TRAINED_CATEGORY"], [226, 233, "TRAINED_CATEGORY"], [237, 273, "TRAINED_CATEGORY"], [276, 285, "TRAINED_CATEGORY"], [289, 303, "TRAINED_CATEGORY"], [312, 321, "TRAINED_CATEGORY"], [325, 337, "TRAINED_CATEGORY"], [341, 356, "TRAINED_CATEGORY"], [361, 375, "TRAINED_CATEGORY"], [376, 391, "TRAINED_CATEGORY"], [415, 450, "TRAINED_CATEGORY"], [452, 454, "TRAINED_CATEGORY"], [474, 509, "TRAINED_CATEGORY"], [522, 540, "TRAINED_CATEGORY"], [550, 562, "TRAINED_CATEGORY"], [571, 576, "TRAINED_CATEGORY"], [580, 592, "TRAINED_CATEGORY"], [606, 611, "TRAINED_CATEGORY"], [615, 628, "TRAINED_CATEGORY"], [631, 635, "TRAINED_CATEGORY"], [646, 663, "TRAINED_CATEGORY"], [684, 688, "TRAINED_CATEGORY"], [697, 713, "TRAINED_CATEGORY"], [721, 737, "TRAINED_CATEGORY"], [759, 775, "TRAINED_CATEGORY"], [798, 814, "TRAINED_CATEGORY"], [869, 882, "TRAINED_CATEGORY"], [888, 903, "TRAINED_CATEGORY"], [919, 921, "TRAINED_CATEGORY"], [983, 999, "TRAINED_CATEGORY"], [1031, 1058, "TRAINED_CATEGORY"], [1064, 1072, "TRAINED_CATEGORY"], [1078, 1101, "TRAINED_CATEGORY"], [1103, 1106, "TRAINED_CATEGORY"], [1119, 1124, "TRAINED_CATEGORY"], [1128, 1145, "TRAINED_CATEGORY"], [1166, 1177, "TRAINED_CATEGORY"], [1191, 1202, "TRAINED_CATEGORY"], [1206, 1217, "TRAINED_CATEGORY"], [1223, 1231, "TRAINED_CATEGORY"], [1304, 1315, "TRAINED_CATEGORY"], [1327, 1355, "TRAINED_CATEGORY"], [1381, 1412, "TRAINED_CATEGORY"], [1422, 1432, "TRAINED_CATEGORY"], [1440, 1447, "TRAINED_CATEGORY"], [1454, 1476, "TRAINED_CATEGORY"], [1487, 1531, "TRAINED_CATEGORY"], [1542, 1564, "TRAINED_CATEGORY"], [1592, 1618, "TRAINED_CATEGORY"], [1620, 1635, "TRAINED_CATEGORY"], [1649, 1674, "TRAINED_CATEGORY"], [1688, 1692, "TRAINED_CATEGORY"], [1705, 1719, "TRAINED_CATEGORY"], [1726, 1739, "TRAINED_CATEGORY"], [1743, 1750, "TRAINED_CATEGORY"], [1759, 1771, "TRAINED_CATEGORY"], [1775, 1798, "TRAINED_CATEGORY"], [1815, 1836, "TRAINED_CATEGORY"], [1852, 1865, "TRAINED_CATEGORY"], [1866, 1870, "TRAINED_CATEGORY"], [1883, 1896, "TRAINED_CATEGORY"], [1905, 1930, "TRAINED_CATEGORY"], [1935, 1943, "TRAINED_CATEGORY"], [1947, 1973, "TRAINED_CATEGORY"], [1977, 1993, "TRAINED_CATEGORY"], [2001, 2004, "TRAINED_CATEGORY"], [2020, 2029, "TRAINED_CATEGORY"], [2044, 2054, "TRAINED_CATEGORY"], [2068, 2072, "TRAINED_CATEGORY"], [2081, 2096, "TRAINED_CATEGORY"], [2124, 2140, "TRAINED_CATEGORY"], [2159, 2175, "TRAINED_CATEGORY"], [2182, 2184, "TRAINED_CATEGORY"], [2195, 2211, "TRAINED_CATEGORY"], [2215, 2216, "TRAINED_CATEGORY"], [2218, 2219, "TRAINED_CATEGORY"], [2225, 2227, "TRAINED_CATEGORY"], [2263, 2269, "TRAINED_CATEGORY"], [2290, 2308, "TRAINED_CATEGORY"], [2313, 2321, "TRAINED_CATEGORY"], [2325, 2333, "TRAINED_CATEGORY"], [2347, 2348, "TRAINED_CATEGORY"], [2350, 2353, "TRAINED_CATEGORY"], [2381, 2398, "TRAINED_CATEGORY"], [2403, 2405, "TRAINED_CATEGORY"], [2432, 2441, "TRAINED_CATEGORY"], [2449, 2450, "TRAINED_CATEGORY"], [2491, 2502, "TRAINED_CATEGORY"], [2504, 2507, "TRAINED_CATEGORY"], [2544, 2567, "TRAINED_CATEGORY"], [2573, 2579, "TRAINED_CATEGORY"], [2597, 2599, "TRAINED_CATEGORY"], [2605, 2606, "TRAINED_CATEGORY"], [2607, 2610, "TRAINED_CATEGORY"], [2616, 2627, "TRAINED_CATEGORY"], [2643, 2644, "TRAINED_CATEGORY"], [2651, 2663, "TRAINED_CATEGORY"], [2668, 2669, "TRAINED_CATEGORY"], [2680, 2688, "TRAINED_CATEGORY"], [2692, 2702, "TRAINED_CATEGORY"], [2708, 2740, "TRAINED_CATEGORY"], [2758, 2769, "TRAINED_CATEGORY"], [2773, 2785, "TRAINED_CATEGORY"], [2786, 2805, "TRAINED_CATEGORY"], [2807, 2808, "TRAINED_CATEGORY"], [2813, 2814, "TRAINED_CATEGORY"], [2857, 2869, "TRAINED_CATEGORY"], [2875, 2899, "TRAINED_CATEGORY"], [2963, 2965, "TRAINED_CATEGORY"], [2987, 3000, "TRAINED_CATEGORY"], [3008, 3015, "TRAINED_CATEGORY"], [3016, 3036, "TRAINED_CATEGORY"], [3077, 3092, "TRAINED_CATEGORY"], [3097, 3099, "TRAINED_CATEGORY"], [3110, 3119, "TRAINED_CATEGORY"], [3123, 3137, "TRAINED_CATEGORY"], [3139, 3153, "TRAINED_CATEGORY"], [3157, 3170, "TRAINED_CATEGORY"], [3174, 3191, "TRAINED_CATEGORY"], [3208, 3214, "TRAINED_CATEGORY"], [3219, 3223, "TRAINED_CATEGORY"], [3235, 3239, "TRAINED_CATEGORY"], [3243, 3250, "TRAINED_CATEGORY"], [3255, 3285, "TRAINED_CATEGORY"], [3287, 3290, "TRAINED_CATEGORY"], [3294, 3298, "TRAINED_CATEGORY"], [3355, 3369, "TRAINED_CATEGORY"], [3374, 3384, "TRAINED_CATEGORY"], [3392, 3398, "TRAINED_CATEGORY"], [3402, 3427, "TRAINED_CATEGORY"], [3450, 3468, "TRAINED_CATEGORY"], [3496, 3504, "TRAINED_CATEGORY"], [3532, 3546, "TRAINED_CATEGORY"], [3552, 3572, "TRAINED_CATEGORY"], [3605, 3607, "TRAINED_CATEGORY"], [3630, 3644, "TRAINED_CATEGORY"], [3648, 3668, "TRAINED_CATEGORY"], [3691, 3706, "TRAINED_CATEGORY"], [3722, 3729, "TRAINED_CATEGORY"], [3750, 3752, "TRAINED_CATEGORY"], [3771, 3778, "TRAINED_CATEGORY"], [3808, 3810, "TRAINED_CATEGORY"], [3834, 3856, "TRAINED_CATEGORY"], [3858, 3870, "TRAINED_CATEGORY"], [3874, 3881, "TRAINED_CATEGORY"], [3886, 3894, "TRAINED_CATEGORY"], [3898, 3922, "TRAINED_CATEGORY"], [3926, 3932, "TRAINED_CATEGORY"], [3937, 3941, "TRAINED_CATEGORY"], [3955, 3969, "TRAINED_CATEGORY"], [3975, 4000, "TRAINED_CATEGORY"], [4016, 4027, "TRAINED_CATEGORY"], [4033, 4043, "TRAINED_CATEGORY"], [4047, 4061, "TRAINED_CATEGORY"], [4068, 4074, "TRAINED_CATEGORY"], [4079, 4107, "TRAINED_CATEGORY"], [4111, 4125, "TRAINED_CATEGORY"], [4139, 4151, "TRAINED_CATEGORY"], [4155, 4171, "TRAINED_CATEGORY"], [4176, 4189, "TRAINED_CATEGORY"], [4193, 4202, "TRAINED_CATEGORY"], [4206, 4221, "TRAINED_CATEGORY"], [4224, 4226, "TRAINED_CATEGORY"], [4230, 4239, "TRAINED_CATEGORY"], [4326, 4341, "TRAINED_CATEGORY"], [4345, 4359, "TRAINED_CATEGORY"], [4373, 4393, "TRAINED_CATEGORY"], [4397, 4411, "TRAINED_CATEGORY"], [4430, 4446, "TRAINED_CATEGORY"], [4450, 4459, "TRAINED_CATEGORY"], [4488, 4499, "TRAINED_CATEGORY"], [4522, 4526, "TRAINED_CATEGORY"], [4572, 4586, "TRAINED_CATEGORY"], [4590, 4594, "TRAINED_CATEGORY"], [4620, 4623, "TRAINED_CATEGORY"], [4638, 4672, "TRAINED_CATEGORY"], [4676, 4700, "TRAINED_CATEGORY"], [4723, 4740, "TRAINED_CATEGORY"], [4744, 4772, "TRAINED_CATEGORY"], [4787, 4801, "TRAINED_CATEGORY"], [4805, 4809, "TRAINED_CATEGORY"], [4816, 4827, "TRAINED_CATEGORY"], [4842, 4867, "TRAINED_CATEGORY"], [4873, 4884, "TRAINED_CATEGORY"], [4919, 4947, "TRAINED_CATEGORY"], [4962, 4976, "TRAINED_CATEGORY"], [4980, 4984, "TRAINED_CATEGORY"], [5006, 5015, "TRAINED_CATEGORY"], [5021, 5041, "TRAINED_CATEGORY"], [5059, 5068, "TRAINED_CATEGORY"], [5087, 5107, "TRAINED_CATEGORY"], [5113, 5118, "TRAINED_CATEGORY"], [5122, 5138, "TRAINED_CATEGORY"], [5150, 5166, "TRAINED_CATEGORY"], [5170, 5176, "TRAINED_CATEGORY"], [5235, 5247, "TRAINED_CATEGORY"], [5251, 5273, "TRAINED_CATEGORY"], [5294, 5298, "TRAINED_CATEGORY"], [5306, 5314, "TRAINED_CATEGORY"], [5320, 5331, "TRAINED_CATEGORY"], [5335, 5351, "TRAINED_CATEGORY"], [5355, 5384, "TRAINED_CATEGORY"], [5392, 5406, "TRAINED_CATEGORY"], [5410, 5414, "TRAINED_CATEGORY"], [5421, 5425, "TRAINED_CATEGORY"], [5436, 5440, "TRAINED_CATEGORY"], [5456, 5467, "TRAINED_CATEGORY"], [5471, 5500, "TRAINED_CATEGORY"], [5528, 5540, "TRAINED_CATEGORY"], [5544, 5564, "TRAINED_CATEGORY"], [5572, 5580, "TRAINED_CATEGORY"], [5603, 5611, "TRAINED_CATEGORY"], [5640, 5656, "TRAINED_CATEGORY"], [5658, 5659, "TRAINED_CATEGORY"], [5703, 5730, "TRAINED_CATEGORY"], [5763, 5764, "TRAINED_CATEGORY"], [5766, 5767, "TRAINED_CATEGORY"], [5768, 5771, "TRAINED_CATEGORY"], [5777, 5778, "TRAINED_CATEGORY"], [5779, 5782, "TRAINED_CATEGORY"], [5801, 5829, "TRAINED_CATEGORY"], [5843, 5862, "TRAINED_CATEGORY"], [5873, 5879, "TRAINED_CATEGORY"], [5904, 5917, "TRAINED_CATEGORY"], [5922, 5924, "TRAINED_CATEGORY"], [5933, 5938, "TRAINED_CATEGORY"], [5941, 5943, "TRAINED_CATEGORY"], [5950, 5964, "TRAINED_CATEGORY"], [5968, 5972, "TRAINED_CATEGORY"], [5979, 5997, "TRAINED_CATEGORY"], [6001, 6015, "TRAINED_CATEGORY"], [6040, 6070, "TRAINED_CATEGORY"], [6072, 6075, "TRAINED_CATEGORY"], [6081, 6102, "TRAINED_CATEGORY"], [6104, 6134, "TRAINED_CATEGORY"], [6139, 6153, "TRAINED_CATEGORY"], [6154, 6180, "TRAINED_CATEGORY"], [6182, 6185, "TRAINED_CATEGORY"], [6204, 6222, "TRAINED_CATEGORY"], [6226, 6240, "TRAINED_CATEGORY"], [6249, 6275, "TRAINED_CATEGORY"], [6276, 6278, "TRAINED_CATEGORY"], [6295, 6302, "TRAINED_CATEGORY"], [6314, 6328, "TRAINED_CATEGORY"], [6334, 6336, "TRAINED_CATEGORY"], [6354, 6376, "TRAINED_CATEGORY"], [6378, 6381, "TRAINED_CATEGORY"], [6393, 6406, "TRAINED_CATEGORY"], [6412, 6428, "TRAINED_CATEGORY"], [6432, 6456, "TRAINED_CATEGORY"], [6476, 6497, "TRAINED_CATEGORY"], [6522, 6546, "TRAINED_CATEGORY"], [6565, 6592, "TRAINED_CATEGORY"], [6594, 6596, "TRAINED_CATEGORY"], [6625, 6635, "TRAINED_CATEGORY"], [6639, 6653, "TRAINED_CATEGORY"], [6684, 6688, "TRAINED_CATEGORY"], [6698, 6712, "TRAINED_CATEGORY"], [6725, 6736, "TRAINED_CATEGORY"], [6740, 6756, "TRAINED_CATEGORY"], [6760, 6775, "TRAINED_CATEGORY"], [6789, 6809, "TRAINED_CATEGORY"], [6813, 6829, "TRAINED_CATEGORY"], [6833, 6853, "TRAINED_CATEGORY"], [6869, 6883, "TRAINED_CATEGORY"], [6887, 6895, "TRAINED_CATEGORY"], [6922, 6934, "TRAINED_CATEGORY"], [6938, 6957, "TRAINED_CATEGORY"], [6968, 6982, "TRAINED_CATEGORY"], [7006, 7029, "TRAINED_CATEGORY"], [7047, 7056, "TRAINED_CATEGORY"], [7060, 7072, "TRAINED_CATEGORY"], [7076, 7090, "TRAINED_CATEGORY"], [7122, 7131, "TRAINED_CATEGORY"], [7145, 7158, "TRAINED_CATEGORY"], [7162, 7167, "TRAINED_CATEGORY"], [7171, 7180, "TRAINED_CATEGORY"], [7195, 7206, "TRAINED_CATEGORY"], [7210, 7223, "TRAINED_CATEGORY"], [7227, 7233, "TRAINED_CATEGORY"], [7242, 7267, "TRAINED_CATEGORY"], [7273, 7290, "TRAINED_CATEGORY"], [7301, 7318, "TRAINED_CATEGORY"], [7324, 7328, "TRAINED_CATEGORY"], [7342, 7366, "TRAINED_CATEGORY"], [7368, 7380, "TRAINED_CATEGORY"], [7400, 7404, "TRAINED_CATEGORY"], [7407, 7421, "TRAINED_CATEGORY"], [7429, 7443, "TRAINED_CATEGORY"], [7457, 7467, "TRAINED_CATEGORY"], [7471, 7483, "TRAINED_CATEGORY"], [7489, 7502, "TRAINED_CATEGORY"], [7504, 7508, "TRAINED_CATEGORY"], [7516, 7526, "TRAINED_CATEGORY"], [7530, 7549, "TRAINED_CATEGORY"], [7553, 7562, "TRAINED_CATEGORY"], [7565, 7577, "TRAINED_CATEGORY"], [7582, 7586, "TRAINED_CATEGORY"], [7590, 7595, "TRAINED_CATEGORY"], [7625, 7632, "TRAINED_CATEGORY"], [7654, 7671, "TRAINED_CATEGORY"], [7683, 7699, "TRAINED_CATEGORY"], [7710, 7715, "TRAINED_CATEGORY"], [7741, 7749, "TRAINED_CATEGORY"], [7763, 7781, "TRAINED_CATEGORY"], [7783, 7788, "TRAINED_CATEGORY"], [7793, 7806, "TRAINED_CATEGORY"], [7828, 7833, "TRAINED_CATEGORY"], [7838, 7857, "TRAINED_CATEGORY"], [7897, 7903, "TRAINED_CATEGORY"], [7908, 7922, "TRAINED_CATEGORY"], [7924, 7929, "TRAINED_CATEGORY"], [7953, 7958, "TRAINED_CATEGORY"], [7963, 7965, "TRAINED_CATEGORY"], [7977, 7991, "TRAINED_CATEGORY"], [7994, 8010, "TRAINED_CATEGORY"], [8011, 8014, "TRAINED_CATEGORY"], [8031, 8051, "TRAINED_CATEGORY"], [8064, 8069, "TRAINED_CATEGORY"], [8075, 8093, "TRAINED_CATEGORY"], [8139, 8153, "TRAINED_CATEGORY"], [8166, 8184, "TRAINED_CATEGORY"], [8185, 8196, "TRAINED_CATEGORY"], [8202, 8207, "TRAINED_CATEGORY"], [8242, 8247, "TRAINED_CATEGORY"], [8256, 8275, "TRAINED_CATEGORY"], [8279, 8284, "TRAINED_CATEGORY"], [8319, 8325, "TRAINED_CATEGORY"], [8333, 8348, "TRAINED_CATEGORY"], [8350, 8352, "TRAINED_CATEGORY"], [8375, 8391, "TRAINED_CATEGORY"], [8401, 8429, "TRAINED_CATEGORY"], [8430, 8435, "TRAINED_CATEGORY"], [8447, 8452, "TRAINED_CATEGORY"], [8465, 8468, "TRAINED_CATEGORY"], [8491, 8497, "TRAINED_CATEGORY"], [8498, 8509, "TRAINED_CATEGORY"], [8519, 8524, "TRAINED_CATEGORY"], [8530, 8559, "TRAINED_CATEGORY"], [8565, 8576, "TRAINED_CATEGORY"], [8578, 8592, "TRAINED_CATEGORY"], [8621, 8645, "TRAINED_CATEGORY"], [8648, 8657, "TRAINED_CATEGORY"], [8668, 8682, "TRAINED_CATEGORY"], [8686, 8710, "TRAINED_CATEGORY"], [8743, 8755, "TRAINED_CATEGORY"], [8761, 8772, "TRAINED_CATEGORY"], [8781, 8795, "TRAINED_CATEGORY"], [8799, 8816, "TRAINED_CATEGORY"], [8824, 8837, "TRAINED_CATEGORY"], [8863, 8885, "TRAINED_CATEGORY"], [8897, 8913, "TRAINED_CATEGORY"], [8952, 8966, "TRAINED_CATEGORY"], [8981, 8990, "TRAINED_CATEGORY"], [9008, 9012, "TRAINED_CATEGORY"], [9029, 9053, "TRAINED_CATEGORY"], [9064, 9086, "TRAINED_CATEGORY"], [9090, 9102, "TRAINED_CATEGORY"], [9110, 9119, "TRAINED_CATEGORY"], [9126, 9133, "TRAINED_CATEGORY"], [9169, 9183, "TRAINED_CATEGORY"], [9204, 9223, "TRAINED_CATEGORY"], [9227, 9265, "TRAINED_CATEGORY"], [9303, 9316, "TRAINED_CATEGORY"], [9320, 9334, "TRAINED_CATEGORY"], [9336, 9366, "TRAINED_CATEGORY"], [9368, 9371, "TRAINED_CATEGORY"], [9385, 9397, "TRAINED_CATEGORY"], [9399, 9410, "TRAINED_CATEGORY"], [9411, 9422, "TRAINED_CATEGORY"], [9424, 9430, "TRAINED_CATEGORY"], [9435, 9447, "TRAINED_CATEGORY"], [9449, 9466, "TRAINED_CATEGORY"], [9482, 9493, "TRAINED_CATEGORY"], [9503, 9533, "TRAINED_CATEGORY"], [9535, 9539, "TRAINED_CATEGORY"], [9547, 9557, "TRAINED_CATEGORY"], [1495, 1498, "CARDINAL"], [1726, 1730, "ORG"], [1743, 1746, "CARDINAL"], [2124, 2129, "CARDINAL"], [2225, 2236, "PERSON"], [2369, 2377, "PERSON"], [2385, 2390, "ORDINAL"], [2472, 2476, "ORG"], [3143, 3148, "ORDINAL"], [3208, 3214, "GPE"], [3219, 3223, "ORG"], [3227, 3231, "DATE"], [3287, 3290, "ORG"], [3299, 3304, "ORDINAL"], [3355, 3356, "CARDINAL"], [3374, 3375, "CARDINAL"], [3387, 3391, "ORG"], [3454, 3455, "CARDINAL"], [3476, 3490, "DATE"], [3726, 3729, "ORG"], [3732, 3749, "DATE"], [3775, 3778, "ORG"], [3844, 3856, "PERSON"], [3878, 3881, "ORG"], [3926, 3932, "GPE"], [3937, 3941, "ORG"], [4024, 4027, "CARDINAL"], [4068, 4074, "GPE"], [4079, 4083, "ORG"], [4522, 4528, "PERSON"], [4535, 4536, "CARDINAL"], [4543, 4544, "CARDINAL"], [4551, 4552, "CARDINAL"], [4563, 4564, "CARDINAL"], [4572, 4576, "NORP"], [4595, 4596, "CARDINAL"], [4620, 4623, "CARDINAL"], [4787, 4791, "ORG"], [4810, 4811, "CARDINAL"], [4881, 4884, "CARDINAL"], [4962, 4966, "ORG"], [4985, 4986, "CARDINAL"], [4991, 4996, "ORDINAL"], [5071, 5075, "ORG"], [5150, 5153, "CARDINAL"], [5392, 5396, "PRODUCT"], [5415, 5416, "CARDINAL"], [5426, 5427, "CARDINAL"], [5441, 5442, "CARDINAL"], [5640, 5641, "CARDINAL"], [5950, 5954, "NORP"], [5973, 5974, "CARDINAL"], [6072, 6075, "ORG"], [6108, 6114, "ORG"], [6119, 6126, "ORG"], [6182, 6185, "ORG"], [6299, 6302, "ORG"], [6574, 6575, "CARDINAL"], [6656, 6659, "CARDINAL"], [7407, 7411, "PRODUCT"], [7741, 7744, "CARDINAL"], [8121, 8125, "ORG"], [8187, 8192, "ORDINAL"], [8202, 8207, "ORG"], [8279, 8284, "ORG"], [8447, 8452, "PRODUCT"], [8743, 8755, "PERSON"], [9368, 9371, "ORG"], [9403, 9410, "WORK_OF_ART"], [9453, 9459, "ORG"], [9535, 9539, "ORG"]]}], ["This is a worked-through example showing the use of the analytic hierarchy process (AHP) in a practical decision situation.\nSee Analytic hierarchy process#Practical examples for context for this example.\n\n\n== Overview ==\nTeachers and users of the AHP know that the best way to understand it is to work through an example. The example below shows how a broad range of considerations can be managed through use of the analytic hierarchy process.\nThe decision at hand requires a reasonably complex hierarchy to describe. It involves factors from the tangible and precisely measurable (purchase price, passenger capacity, cargo capacity), through the tangible but difficult to measure (maintenance costs, fuel costs, resale value) to the intangible and totally subjective (style).\nIn the end, there is a clear decision whose development can be seen, traced, and understood by all concerned.\n\n\n== A practical example: choosing an automobile ==\nIn an AHP hierarchy for a family buying a vehicle, the goal might be to choose the best car for the Jones family. The family might decide to consider cost, safety, style, and capacity as the criteria for making their decision. They might subdivide the cost criterion into purchase price, fuel costs, maintenance costs, and resale value. They might separate Capacity into cargo capacity and passenger capacity. The family, which for personal reasons always buys Hondas, might decide to consider as alternatives the Accord Sedan, Accord Hybrid Sedan, Pilot SUV, CR-V SUV, Element SUV, and Odyssey Minivan.\n\n\n== Constructing the hierarchy ==\nThe Jones' hierarchy could be diagrammed as shown below:\n\nAs they build their hierarchy, the Joneses should investigate the values or measurements of the different elements that make it up. If there are published safety ratings, for example, or manufacturer's specs for cargo capacity, they should be gathered as part of the process. This information will be needed later, when the criteria and alternatives are evaluated.\nNote that the measurements for some criteria, such as purchase price, can be stated with absolute certainty. Others, such as resale value, must be estimated, so must be stated with somewhat less confidence. Still others, such as style, are really in the eye of the beholder and are hard to state quantitatively at all. The AHP can accommodate all these types of criteria, even when they are present in a single problem.\nAlso note that the structure of the vehicle-buying hierarchy might be different for other families (ones who don't limit themselves to Hondas, or who care nothing about style, or who drive less than 5,000 miles (8,000 km) a year, etc.). It would definitely be different for a 25-year-old playboy who doesn't care how much his cars cost, knows he will never wreck one, and is intensely interested in speed, handling, and the numerous aspects of style.\n\n\n== Pairwise comparing the criteria with respect to the goal ==\nTo incorporate their judgments about the various elements in the hierarchy, decision makers compare the elements two by two. How they are compared will be shown later on. Right now, let's see which items are compared. Our example will begin with the four criteria in the second row of the hierarchy, though we could begin elsewhere if we wanted to. The criteria will be compared as to how important they are to the decision makers, with respect to the goal.\nEach pair of items in this row will be compared; there are a total of six pairs (cost/safety, cost/style, cost/capacity, safety/style, safety/capacity, and style/capacity). You can use the diagram below to see these pairs more clearly.\n\nIn the next row, there is a group of four subcriteria under the cost criterion, and a group of two subcriteria under the capacity criterion.\nIn the Cost subgroup, each pair of subcriteria will be compared regarding their importance with respect to the Cost criterion. (As always, their importance is judged by the decision makers.) Once again, there are six pairs to compare (Purchase Price/Fuel Costs, Purchase Price/Maintenance Costs, Purchase Price/Resale Value, Fuel Costs/Maintenance Costs, Fuel Costs/Resale Value, and Maintenance Costs/Resale Value).\nIn the Capacity subgroup, there is only one pair of subcriteria. They are compared as to how important they are with respect to the Capacity criterion.\nThings change a bit when we get to the alternatives row. Here, the cars in each group of alternatives are compared pair-by-pair with respect to the covering criterion of the group, which is the node directly above them in the hierarchy. What we are doing here is evaluating the models under consideration with respect to Purchase Price, then with respect to fuel costs, then maintenance costs, resale value, safety, style, cargo capacity, and passenger capacity. Because there are six cars in the group of alternatives, there will be fifteen comparisons for each of the eight covering criteria.\nWhen the pairwise comparisons are as numerous as those in our example, specialized AHP software can help in making them quickly and efficiently. We will assume that the Jones family has access to such software, and that it allows the opinions of various family members to be combined into an overall opinion for the group.\nThe family's first pairwise comparison is cost vs. safety. They need to decide which of these is more important in choosing the best car for them all. This can be a difficult decision. On the one hand, \"You can't put a price on safety. Nothing is more important than the life of a family member.\" But on the other hand, the family has a limited amount of money to spend, no member has ever had a major accident, and Hondas are known as very safe cars. In spite of the difficulty in comparing money to potential injury or death, the Jones family needs to determine its judgment about cost vs. safety in the car they are about to buy. They have to say which criterion is more important to them in reaching their goal, and how much more important it is (to them) than the other one. In making this judgment, they should remember that since the AHP is a flexible process, they can change their judgment later on.\nYou can imagine that there might be heated family discussion about cost vs. safety. It is the nature of the AHP to promote focused discussions about difficult aspects of the decisions to which it is applied. Such discussions encourage the communication of differences, which in turn encourages cooperation, compromise, and agreement among the members of the group.\nLet's say that the family decides that in this case, cost is moderately more important to them than safety. The software requires them to express this judgment by entering a number. They can use this table to determine it; in this case they would enter a 3 in favor of cost:\n\nContinuing our example, let's say they make the following judgments about all the comparisons of criteria, entering them into the software as numbers gotten from the table: as stated, cost is moderately important (3) over safety; also, cost is very strongly important (7) over style, and is moderately important (3) over capacity. Safety is extremely more important (9) than style, and of equal importance (1) to capacity. Capacity is very strongly important (7) over style.\nWe could show those judgments in a table like this:\n\nThe AHP software uses mathematical calculations to convert these judgments to priorities for each of the four criteria. The details of the calculations are beyond the scope of this article, but are readily available elsewhere. The software also calculates a consistency ratio that expresses the internal consistency of the judgments that have been entered.\nIn this case the judgments showed acceptable consistency, and the software used the family's inputs to assign these new priorities to the criteria:\n\nYou can duplicate this analysis at this online demonstration site; use the Line by Line Method by clicking its button, and don't forget to enter a negative number if the Criterion on the left is less important than the one on the right. If you are having trouble, click here for help. IMPORTANT: The demo site is designed for convenience, not accuracy. The priorities it returns may differ somewhat from those returned by rigorous AHP calculations. Nevertheless, it is useful in showing the mechanics of the pairwise comparison process. Once you are comfortable with the demo, you can experiment by entering your own judgments for the criteria in question. If your judgments are different from those of the Jones family, your priorities will possibly be quite different from theirs.Look again at the above diagram and note that the Subcriteria still show their default priorities. This is because the decision makers haven't entered any judgments about them. So next on the family's agenda is to pairwise compare the four Subcriteria under Cost, then the two Subcriteria under Capacity. They will compare them following the same pattern as they did for the Criteria.\nWe could imagine the result of their comparisons yielding the priorities shown here:\n\nAt this point, all the comparisons for Criteria and Subcriteria have been made, and the AHP software has derived the local priorities for each group at each level. One more step can be made here. We know how much the priority of each Criterion contributes to the priority of the Goal. Since we also know how much the priority of each Subcriterion contributes to the priority of its parent, we (and the AHP software) can calculate the global priority of each Subcriterion. That will show us the priority of each Subcriterion with respect to the Goal. The global priorities throughout the hierarchy will add up to 1.000, like this:\n\nBased on the judgments entered by the family, the AHP has derived the priorities for the factors against which each of the six cars will be compared. They are shown, from highest to lowest, in the table below. Notice that Cost and Capacity will not be evaluated directly, but that each of their Subcriteria will be evaluated on its own:\n\nThe next step is to evaluate each of the cars with respect to these factors. In the technical language of AHP, we will pairwise compare the alternatives with respect to their covering criteria.\n\n\n== Pairwise comparing the Alternatives with respect to the Criteria ==\nThe family can evaluate alternatives against their covering criteria in any order they choose. In this case, they choose the order of decreasing priority of the covering criteria. That means Purchase Price first.\n\n\n=== Purchase price ===\nThe family has established a budget of $25,000 for buying the new car, but they are willing to consider alternatives whose price exceeds their budget. To refresh your mind, here are the six cars they are considering\u2014in AHP terminology, the six alternatives\u2014along with their purchase prices:  \n\nKnowing that they will have a lot of pairwise comparisons to make, the family prepared this worksheet to help them. It shows comparative information about the price and budget status of each pair of cars:\n\nNow, what do they do?\nFirst they might compare the purchase price of the Accord Sedan to that of the Accord Hybrid. If they stick purely to arithmetic, they could say that the Sedan is favored by 1.5, since the Hybrid's price is about 1.5 times that of the Sedan, and a lower price is better. They could follow that pattern through all 15 of the comparisons, and it would give a mathematically consistent set of comparisons.\nBut merely entering the numbers wouldn't take into account things like the $25,000 budget, or the value to the family of saving, say, $5,000 vs. $1,000 on a purchase. Things like that can be highly important in making decisions, and their importance can vary greatly with the situation and the people involved. Some families might never want to exceed their budget. Others might be willing to exceed it by a few dollars or a few percent, but very unwilling to go further. Still others might not care much if they spend double their budget on the car. Because the AHP allows decision makers to enter their judgments about the data, rather than just the data themselves, it can deal with all these situations and more.\nLet's say that the Jones family is willing to exceed their budget by up to $1,000, but anything more is unacceptable. They \"never say never,\" however\u2014budget-busting cars will score as low as possible on purchase price, but won't be removed from the list of alternatives. And for cars priced under budget, a $1,000 difference in price doesn't matter much to the Joneses, but a $5,000 difference is strongly important, and a $10,000 difference is extreme. They might enter the following intensities into the AHP software (throughout this example, the judgments of decision makers are shaded in green):\n\nYou can follow the family's thinking by looking at the rationale for each judgment. Whenever a car that is under budget is compared with one that is over budget by more than $1,000, the former is extremely preferred. For cars under budget, a $1,000 less expensive car is slightly preferred, a $5,000 one is strongly preferred, and a $6,000 one is even more strongly preferred. When both cars are well over budget (comparison #6), they are equally preferred, which is to say they are equally undesirable. Because budget status and absolute price difference are enough to make each comparison, the ratio of prices never enters into the judgments.\nWhen the judgments shown above are entered, the AHP software returns the following priorities for the six alternatives with respect to Purchase Price:\n\nThe local priorities show how much the purchase price of each model contributes to the subcriterion of Purchase Price. The global priorities show how much the purchase price of each model contributes to the overall goal of choosing the best car for the Jones family.\n\n\n=== Safety ===\nComparing the alternatives on the basis of Safety is much less objective than comparing them on Purchase Price. Purchase prices are measured in dollars and can be determined to the penny. People can easily agree on the meaning of a $20,360 purchase price, and can rationally compare it to all the other prices, using methods and calculations that are understood and accepted by all.\nBut \"safety\" eludes our efforts even to define it in an objective way. Not only that, but the objective measurements of safety are limited and not readily comparable from car to car.\nThe government conducts objective crash tests, but they are incomplete measures of the \"safety\" of a given car. Also, the crash tests only compare the members of a single class of cars, such as Midsize Cars or Minivans. Is a midsize car with 100% 5-star safety ratings equally as safe as a minivan with the same ratings? It's not exactly clear. And when evaluating minivans that have 5-star ratings in all categories but one, who can say if the one with four stars for \"Frontal Impact, Driver's Side\" is safer than the one whose four stars are in \"Side Impact, Rear Occupant?\" There's really no way to tell.\nIn spite of these difficulties, the AHP provides a rational way to evaluate the relative safety of different cars.\nLet's assume that the Jones family has researched the Safety of the six Hondas they are considering. They will have found that all of them are among the safest cars on the road. All six are \"Top Safety Picks\" of the IIHS safety standards organization. All of them do very well in the crash testing programs of the National Highway Traffic Safety Administration. But there are differences between them, and the family wants to factor the differences into their decision. \"Your car can never be too safe.\"\nThe worksheet below includes the data that the family has decided to evaluate. They believe that a heavier car is a safer car, so they've documented the curb weights of their alternatives. They have investigated the results of government crash tests, and they've summarized the results on the worksheet:\n\nThe family will consider everything in the worksheet as they compare their alternatives. They are not safety experts, but they can apply their life experience to making decisions about the safety ratings. They all feel safer when driving a car that is significantly heavier than another one. One family member has seen two gruesome rollover accidents, and is terrified of a vehicle rolling over with her inside. She insists that the family car has the highest possible Rollover Rating.\nHere are the weights that the Jones family enters for the alternatives regarding Safety (throughout this example, orange shading is used for judgments where A is favored; yellow shading is used for B):\n\nWhen the judgments shown above are entered, the AHP software returns the following priorities for the six alternatives with respect to Safety:\n\nThe local priorities show how much the safety of each model contributes to the Criterion of Safety. The global priorities show how much the Safety of each model contributes to the overall goal of choosing the best car for the Jones family.\n\n\n=== Passenger capacity ===\nThis characteristic is easy to evaluate. The alternatives can carry either four or five or eight passengers. Here are the figures:\n\nThe family has decided that four is barely enough, five is perfect for their needs, and eight is just a little bit better than five. Here are their judgments:\n\nWhen the judgments shown above are entered, the AHP software returns the following priorities for the six alternatives with respect to Passenger Capacity:\n\nThe local priorities show how much the passenger capacity of each model contributes to the Subcriterion of Passenger Capacity. The global priorities show how much the passenger capacity of each model contributes to the overall goal of choosing the best car for the Jones family.\n\n\n=== Fuel costs ===\nAfter careful consideration, the Jones family believes that no matter which car they buy, they will drive it the same number of miles per year. In other words, there is nothing about any of the alternatives, including the price of fuel or the car's fuel consumption per mile, that would cause it to be driven more or fewer miles than any other alternative. They also believe that the government MPG rating is an accurate basis on which to compare the fuel consumption of the cars. Here is a worksheet showing the government MPG ratings of the Jones family alternatives:\n\nThey believe, therefore, that the fuel cost of any alternative vs. any other depends exclusively on the MPG ratings of the two cars. So the pairwise judgments they enter for any two cars will be inversely proportional to their MPG ratings. In other words, if car A has exactly twice the MPG rating of car B, the Fuel Cost for car B will be exactly twice that of car A. This table shows the judgments they will enter for all the comparisons:\n\nWhen the judgments shown above are entered, the AHP software returns the following priorities for the six alternatives with respect to Fuel Cost:\n\nThe local priorities show how much the fuel cost of each model contributes to the subcriterion of Fuel Costs. The global priorities show how much the fuel cost of each model contributes to the overall goal of choosing the best car for the Jones family.\n\n\n=== Resale value ===\nWhen the family researched Resale Value, they learned that lending institutions keep statistics on the market value of different models after various time periods. These estimated \"residual values\" are used for leasing, and are typically based on a limit of 12,000 miles (19,000 km) driven per year. Actual residual values depend on the condition of the car, and can vary with market conditions.\nThe Joneses are going to buy their car, not lease it, and they expect to drive it more than 12,000 miles per year, but they agree among themselves that the leasing figures are a good basis on which to compare the alternatives under consideration. Their bank gave them this table showing the residual value of each alternative after four years and 48,000 miles (77,000 km):\n\nAs they look at the table of residual values, they see that the residual value of a CR-V is 25% higher than that of a Pilot (0.55 is 125% of 0.44). They reason that such a greatly higher residual value is an indication of a better or more desirable car, so they want to place a premium on cars with relatively high residual value. After some thought and discussion, they decide that, when comparing residual values, they want to look at the higher one as a percentage of the lower, and assign their intensities on that basis. Where one model has a residual value that is less than 105% of another, they consider the residual values as equal for all practical purposes. Where one model has a residual value that is 125% of the residual value of another, they consider the former model as quite strongly more important, desirable, valuable, etc., as indicated by its much higher resale value. With a bit more thought and discussion, they decide to make their judgments on this basis:\n\nThey realize that not every family would do it this way, but this way seems best for them. This table shows the judgments they will enter for their Resale Value comparisons:\n\nWhen the judgments shown above are entered, the AHP software returns the following priorities for the six alternatives with respect to Resale Value:\n\nThe local priorities show how much the resale value of each model contributes to the Subcriterion of Resale Value. The global priorities show how much the resale value of each model contributes to the overall goal of choosing the best car for the Jones family.\n\n\n=== Maintenance costs ===\nThe Jones family researched maintenance costs for the cars under consideration, but they didn't find any hard figures. The closest they got was Consumer Reports magazine, which publishes 17 separate maintenance ratings for every car on the market. Their Hondas ranked very well, with all ratings \"Much Better Than Average,\" except for a few on the Pilot and Odyssey. The Pilot got \"Better Than Average\" for its audio system and the user rating, and \"Average\" for body integrity. The Odyssey got \"Better Than Average\" for body hardware and power equipment, and \"Average\" for brakes, body integrity, and user rating.\nThe Joneses also asked their favorite mechanic to evaluate the maintenance costs for their six cars. Using tire prices and mileage estimates, he came up with figures for tire costs over 60,000 miles (97,000 km) of driving. He didn't have figures for brake costs, but he said they'd be about twice as much for the SUVs and minivans as they would for the sedans. He also cautioned them that the battery in the Accord Hybrid was an expensive repair item, and that the engine placement on the Odyssey made it a more expensive car to work on.\nThe family created this worksheet to keep track of all their information about maintenance costs:\n\nEven though every column on the worksheet contains a different type of information, the Joneses can use it to make reasonable, rational judgments about Maintenance Costs. Here are the judgments they will enter:\n\nWhen the judgments shown above are entered, the AHP software returns the following priorities for the six alternatives with respect to Maintenance Costs:\n\nThe local priorities show how much the projected maintenance cost of each model contributes to the subcriterion of Maintenance Costs. The global priorities show how much the maintenance cost of each model contributes to the overall goal of choosing the best car for the Jones family.\n\n\n=== Style ===\nThe family decided that Style is important to them, but how can they determine the \"style\" of each of the six alternatives? \"Style\" is a pretty subjective concept\u2014it can truly be said that \"style is in the eye of the beholder.\" Yet through the method of pairwise comparison, the AHP gives the Jones family a way to evaluate the \"style\" of the cars they are considering.\nHonda's web site provides photos of each of the alternatives. It also has videos, commercials, rotatable 360\u00b0 views, color chips, and more, all available to help family members evaluate the Style of each car. The family can compare their alternatives two-by-two on Style, using the tools on the web site to help them make their judgments. They did just that, and here is the record of their judgments:\n\nWhen the judgments shown above are entered, the AHP software returns the following local priorities for the six alternatives with respect to Style:\n\nThe local priorities show how much the style of each model contributes to the Style Criterion. The global priorities show how much the Style of each model contributes to the overall goal of choosing the best car for the Jones family.\n\n\n=== Cargo capacity ===\nThe Cargo Capacity of each alternative, measured in cubic feet, is listed in the manufacturer's specifications for each vehicle. The Joneses don't really know how it is calculated, but they trust that it's a good indication of how much cargo can be packed into a vehicle. This worksheet shows the cargo capacities of the Jones' alternatives:\n\nCargo capacities for the alternatives vary from 14 to 148 cubic feet (4.2 m3). If they wanted to, the Jones family could enter these capacities directly into the AHP software. But that would mean that, when considering Cargo Capacity, a car with 148 cu ft (4.2 m3). of it would be over ten times as desirable as one with only 14. Given the car's use as a family vehicle, that doesn't seem quite right. So the family looks at the available capacities and determines that a 14 cu ft (0.40 m3). trunk is perfectly fine for their needs, that something about five times larger is slightly better, and that something about ten times larger is moderately so. These judgments correspond to values of 1, 2, and 3 on the AHP's Fundamental Scale.\nHere are the judgments they would enter into the AHP software:\n\nWhen the judgments shown above are entered, the AHP software returns the following local priorities for the six alternatives with respect to Cargo Capacity:\n\nThe local priorities show how much the cargo capacity of each model contributes to the subcriterion of Cargo Capacity. The global priorities show how much the cargo capacity of each model contributes to the overall goal of choosing the best car for the Jones family.\n\n\n== Making the decision ==\nIn the end, the AHP software arranges and totals the global priorities for each of the alternatives. Their grand total is 1.000, which is identical to the priority of the goal. Each alternative has a global priority corresponding to its \"fit\" to all the family's judgments about all those aspects of Cost, Safety, Style and Capacity. Here is a summary of the global priorities of the alternatives:\n\nThe Odyssey Minivan, with a global priority of 0.220, is the alternative that contributes the most to the goal of choosing the best car for the Jones family. The Accord Sedan is a close second, with a priority of 0.213. The other models have considerably less priority than those two. In descending order, they are CR-V SUV, Accord Hybrid, Element SUV, and Pilot SUV.\nThe Analytic Hierarchy Process has shown the Joneses that the Odyssey Minivan best satisfies all their criteria and judgments, followed closely by the Accord Sedan. The other alternatives fall significantly short of meeting their criteria. The family's next step is up to them. They might just go out and buy an Odyssey, or they might use the AHP or other means to refine their decision between the Odyssey and the Accord Sedan.\n\n\n== References ==\n\n\n== External links ==\nR ahp package \u2013 The R open source ahp package provides an implementation of this example.", {"entities": [[8, 32, "TRAINED_CATEGORY"], [41, 48, "TRAINED_CATEGORY"], [52, 82, "TRAINED_CATEGORY"], [83, 87, "TRAINED_CATEGORY"], [92, 122, "TRAINED_CATEGORY"], [128, 173, "TRAINED_CATEGORY"], [178, 185, "TRAINED_CATEGORY"], [190, 202, "TRAINED_CATEGORY"], [221, 229, "TRAINED_CATEGORY"], [234, 239, "TRAINED_CATEGORY"], [243, 250, "TRAINED_CATEGORY"], [261, 273, "TRAINED_CATEGORY"], [288, 290, "TRAINED_CATEGORY"], [310, 320, "TRAINED_CATEGORY"], [322, 333, "TRAINED_CATEGORY"], [350, 363, "TRAINED_CATEGORY"], [367, 381, "TRAINED_CATEGORY"], [405, 408, "TRAINED_CATEGORY"], [412, 442, "TRAINED_CATEGORY"], [444, 456, "TRAINED_CATEGORY"], [460, 464, "TRAINED_CATEGORY"], [474, 504, "TRAINED_CATEGORY"], [518, 520, "TRAINED_CATEGORY"], [530, 537, "TRAINED_CATEGORY"], [543, 596, "TRAINED_CATEGORY"], [598, 616, "TRAINED_CATEGORY"], [618, 632, "TRAINED_CATEGORY"], [681, 699, "TRAINED_CATEGORY"], [701, 711, "TRAINED_CATEGORY"], [713, 725, "TRAINED_CATEGORY"], [730, 774, "TRAINED_CATEGORY"], [780, 787, "TRAINED_CATEGORY"], [798, 814, "TRAINED_CATEGORY"], [815, 832, "TRAINED_CATEGORY"], [892, 911, "TRAINED_CATEGORY"], [922, 935, "TRAINED_CATEGORY"], [942, 958, "TRAINED_CATEGORY"], [963, 971, "TRAINED_CATEGORY"], [979, 988, "TRAINED_CATEGORY"], [990, 998, "TRAINED_CATEGORY"], [1018, 1030, "TRAINED_CATEGORY"], [1035, 1051, "TRAINED_CATEGORY"], [1053, 1063, "TRAINED_CATEGORY"], [1089, 1093, "TRAINED_CATEGORY"], [1095, 1101, "TRAINED_CATEGORY"], [1103, 1108, "TRAINED_CATEGORY"], [1114, 1122, "TRAINED_CATEGORY"], [1126, 1138, "TRAINED_CATEGORY"], [1150, 1164, "TRAINED_CATEGORY"], [1166, 1170, "TRAINED_CATEGORY"], [1187, 1205, "TRAINED_CATEGORY"], [1211, 1225, "TRAINED_CATEGORY"], [1227, 1237, "TRAINED_CATEGORY"], [1239, 1256, "TRAINED_CATEGORY"], [1262, 1274, "TRAINED_CATEGORY"], [1276, 1280, "TRAINED_CATEGORY"], [1296, 1304, "TRAINED_CATEGORY"], [1310, 1324, "TRAINED_CATEGORY"], [1329, 1347, "TRAINED_CATEGORY"], [1349, 1359, "TRAINED_CATEGORY"], [1371, 1387, "TRAINED_CATEGORY"], [1400, 1406, "TRAINED_CATEGORY"], [1436, 1448, "TRAINED_CATEGORY"], [1449, 1465, "TRAINED_CATEGORY"], [1467, 1486, "TRAINED_CATEGORY"], [1488, 1497, "TRAINED_CATEGORY"], [1499, 1507, "TRAINED_CATEGORY"], [1509, 1520, "TRAINED_CATEGORY"], [1526, 1541, "TRAINED_CATEGORY"], [1561, 1574, "TRAINED_CATEGORY"], [1578, 1598, "TRAINED_CATEGORY"], [1639, 1643, "TRAINED_CATEGORY"], [1650, 1665, "TRAINED_CATEGORY"], [1667, 1678, "TRAINED_CATEGORY"], [1698, 1708, "TRAINED_CATEGORY"], [1712, 1724, "TRAINED_CATEGORY"], [1728, 1750, "TRAINED_CATEGORY"], [1761, 1763, "TRAINED_CATEGORY"], [1791, 1805, "TRAINED_CATEGORY"], [1811, 1818, "TRAINED_CATEGORY"], [1823, 1843, "TRAINED_CATEGORY"], [1848, 1862, "TRAINED_CATEGORY"], [1864, 1868, "TRAINED_CATEGORY"], [1891, 1895, "TRAINED_CATEGORY"], [1899, 1910, "TRAINED_CATEGORY"], [1912, 1928, "TRAINED_CATEGORY"], [1956, 1968, "TRAINED_CATEGORY"], [1973, 1985, "TRAINED_CATEGORY"], [2011, 2027, "TRAINED_CATEGORY"], [2032, 2045, "TRAINED_CATEGORY"], [2055, 2069, "TRAINED_CATEGORY"], [2090, 2108, "TRAINED_CATEGORY"], [2110, 2116, "TRAINED_CATEGORY"], [2126, 2138, "TRAINED_CATEGORY"], [2182, 2206, "TRAINED_CATEGORY"], [2214, 2220, "TRAINED_CATEGORY"], [2230, 2235, "TRAINED_CATEGORY"], [2251, 2258, "TRAINED_CATEGORY"], [2262, 2274, "TRAINED_CATEGORY"], [2320, 2327, "TRAINED_CATEGORY"], [2344, 2359, "TRAINED_CATEGORY"], [2363, 2371, "TRAINED_CATEGORY"], [2383, 2387, "TRAINED_CATEGORY"], [2403, 2419, "TRAINED_CATEGORY"], [2436, 2449, "TRAINED_CATEGORY"], [2453, 2481, "TRAINED_CATEGORY"], [2505, 2519, "TRAINED_CATEGORY"], [2521, 2525, "TRAINED_CATEGORY"], [2526, 2529, "TRAINED_CATEGORY"], [2542, 2552, "TRAINED_CATEGORY"], [2556, 2562, "TRAINED_CATEGORY"], [2567, 2570, "TRAINED_CATEGORY"], [2576, 2583, "TRAINED_CATEGORY"], [2590, 2595, "TRAINED_CATEGORY"], [2600, 2603, "TRAINED_CATEGORY"], [2610, 2631, "TRAINED_CATEGORY"], [2633, 2641, "TRAINED_CATEGORY"], [2658, 2660, "TRAINED_CATEGORY"], [2695, 2716, "TRAINED_CATEGORY"], [2717, 2720, "TRAINED_CATEGORY"], [2743, 2751, "TRAINED_CATEGORY"], [2764, 2766, "TRAINED_CATEGORY"], [2820, 2825, "TRAINED_CATEGORY"], [2827, 2835, "TRAINED_CATEGORY"], [2841, 2861, "TRAINED_CATEGORY"], [2865, 2870, "TRAINED_CATEGORY"], [2896, 2908, "TRAINED_CATEGORY"], [2914, 2921, "TRAINED_CATEGORY"], [2925, 2933, "TRAINED_CATEGORY"], [2952, 2967, "TRAINED_CATEGORY"], [2974, 2994, "TRAINED_CATEGORY"], [2998, 3011, "TRAINED_CATEGORY"], [3013, 3028, "TRAINED_CATEGORY"], [3037, 3049, "TRAINED_CATEGORY"], [3066, 3070, "TRAINED_CATEGORY"], [3122, 3124, "TRAINED_CATEGORY"], [3129, 3140, "TRAINED_CATEGORY"], [3155, 3166, "TRAINED_CATEGORY"], [3183, 3200, "TRAINED_CATEGORY"], [3204, 3218, "TRAINED_CATEGORY"], [3222, 3235, "TRAINED_CATEGORY"], [3244, 3246, "TRAINED_CATEGORY"], [3272, 3274, "TRAINED_CATEGORY"], [3286, 3298, "TRAINED_CATEGORY"], [3336, 3340, "TRAINED_CATEGORY"], [3348, 3367, "TRAINED_CATEGORY"], [3374, 3381, "TRAINED_CATEGORY"], [3385, 3393, "TRAINED_CATEGORY"], [3395, 3404, "TRAINED_CATEGORY"], [3408, 3413, "TRAINED_CATEGORY"], [3417, 3425, "TRAINED_CATEGORY"], [3454, 3461, "TRAINED_CATEGORY"], [3465, 3474, "TRAINED_CATEGORY"], [3475, 3545, "TRAINED_CATEGORY"], [3551, 3565, "TRAINED_CATEGORY"], [3568, 3571, "TRAINED_CATEGORY"], [3580, 3591, "TRAINED_CATEGORY"], [3605, 3616, "TRAINED_CATEGORY"], [3635, 3647, "TRAINED_CATEGORY"], [3658, 3665, "TRAINED_CATEGORY"], [3669, 3685, "TRAINED_CATEGORY"], [3692, 3710, "TRAINED_CATEGORY"], [3716, 3723, "TRAINED_CATEGORY"], [3727, 3742, "TRAINED_CATEGORY"], [3749, 3771, "TRAINED_CATEGORY"], [3776, 3793, "TRAINED_CATEGORY"], [3795, 3804, "TRAINED_CATEGORY"], [3808, 3819, "TRAINED_CATEGORY"], [3847, 3863, "TRAINED_CATEGORY"], [3869, 3876, "TRAINED_CATEGORY"], [3880, 3898, "TRAINED_CATEGORY"], [3912, 3928, "TRAINED_CATEGORY"], [3942, 3961, "TRAINED_CATEGORY"], [3986, 3995, "TRAINED_CATEGORY"], [4007, 4033, "TRAINED_CATEGORY"], [4035, 4067, "TRAINED_CATEGORY"], [4069, 4096, "TRAINED_CATEGORY"], [4098, 4126, "TRAINED_CATEGORY"], [4128, 4151, "TRAINED_CATEGORY"], [4157, 4187, "TRAINED_CATEGORY"], [4193, 4214, "TRAINED_CATEGORY"], [4225, 4238, "TRAINED_CATEGORY"], [4242, 4253, "TRAINED_CATEGORY"], [4255, 4259, "TRAINED_CATEGORY"], [4293, 4297, "TRAINED_CATEGORY"], [4307, 4314, "TRAINED_CATEGORY"], [4318, 4340, "TRAINED_CATEGORY"], [4342, 4348, "TRAINED_CATEGORY"], [4367, 4369, "TRAINED_CATEGORY"], [4377, 4397, "TRAINED_CATEGORY"], [4405, 4413, "TRAINED_CATEGORY"], [4417, 4427, "TRAINED_CATEGORY"], [4431, 4443, "TRAINED_CATEGORY"], [4465, 4469, "TRAINED_CATEGORY"], [4475, 4482, "TRAINED_CATEGORY"], [4486, 4508, "TRAINED_CATEGORY"], [4512, 4521, "TRAINED_CATEGORY"], [4532, 4540, "TRAINED_CATEGORY"], [4556, 4560, "TRAINED_CATEGORY"], [4564, 4577, "TRAINED_CATEGORY"], [4579, 4583, "TRAINED_CATEGORY"], [4584, 4586, "TRAINED_CATEGORY"], [4616, 4626, "TRAINED_CATEGORY"], [4633, 4646, "TRAINED_CATEGORY"], [4652, 4659, "TRAINED_CATEGORY"], [4663, 4677, "TRAINED_CATEGORY"], [4689, 4696, "TRAINED_CATEGORY"], [4700, 4710, "TRAINED_CATEGORY"], [4823, 4831, "TRAINED_CATEGORY"], [4835, 4844, "TRAINED_CATEGORY"], [4848, 4860, "TRAINED_CATEGORY"], [4876, 4895, "TRAINED_CATEGORY"], [4908, 4935, "TRAINED_CATEGORY"], [4942, 4966, "TRAINED_CATEGORY"], [4995, 5006, "TRAINED_CATEGORY"], [5008, 5032, "TRAINED_CATEGORY"], [5052, 5056, "TRAINED_CATEGORY"], [5082, 5084, "TRAINED_CATEGORY"], [5102, 5118, "TRAINED_CATEGORY"], [5123, 5129, "TRAINED_CATEGORY"], [5133, 5146, "TRAINED_CATEGORY"], [5157, 5159, "TRAINED_CATEGORY"], [5167, 5179, "TRAINED_CATEGORY"], [5183, 5205, "TRAINED_CATEGORY"], [5226, 5244, "TRAINED_CATEGORY"], [5249, 5258, "TRAINED_CATEGORY"], [5260, 5298, "TRAINED_CATEGORY"], [5311, 5317, "TRAINED_CATEGORY"], [5319, 5323, "TRAINED_CATEGORY"], [5384, 5396, "TRAINED_CATEGORY"], [5401, 5405, "TRAINED_CATEGORY"], [5423, 5443, "TRAINED_CATEGORY"], [5448, 5460, "TRAINED_CATEGORY"], [5463, 5466, "TRAINED_CATEGORY"], [5477, 5484, "TRAINED_CATEGORY"], [5488, 5494, "TRAINED_CATEGORY"], [5496, 5503, "TRAINED_CATEGORY"], [5527, 5535, "TRAINED_CATEGORY"], [5539, 5554, "TRAINED_CATEGORY"], [5564, 5578, "TRAINED_CATEGORY"], [5580, 5590, "TRAINED_CATEGORY"], [5595, 5611, "TRAINED_CATEGORY"], [5615, 5620, "TRAINED_CATEGORY"], [5631, 5640, "TRAINED_CATEGORY"], [5654, 5670, "TRAINED_CATEGORY"], [5676, 5682, "TRAINED_CATEGORY"], [5696, 5710, "TRAINED_CATEGORY"], [5715, 5720, "TRAINED_CATEGORY"], [5724, 5738, "TRAINED_CATEGORY"], [5752, 5757, "TRAINED_CATEGORY"], [5761, 5777, "TRAINED_CATEGORY"], [5781, 5786, "TRAINED_CATEGORY"], [5788, 5804, "TRAINED_CATEGORY"], [5824, 5836, "TRAINED_CATEGORY"], [5843, 5847, "TRAINED_CATEGORY"], [5852, 5858, "TRAINED_CATEGORY"], [5862, 5869, "TRAINED_CATEGORY"], [5870, 5874, "TRAINED_CATEGORY"], [5893, 5897, "TRAINED_CATEGORY"], [5910, 5925, "TRAINED_CATEGORY"], [5947, 5951, "TRAINED_CATEGORY"], [5964, 5974, "TRAINED_CATEGORY"], [6004, 6006, "TRAINED_CATEGORY"], [6014, 6018, "TRAINED_CATEGORY"], [6050, 6063, "TRAINED_CATEGORY"], [6065, 6069, "TRAINED_CATEGORY"], [6097, 6104, "TRAINED_CATEGORY"], [6108, 6126, "TRAINED_CATEGORY"], [6128, 6132, "TRAINED_CATEGORY"], [6144, 6158, "TRAINED_CATEGORY"], [6169, 6172, "TRAINED_CATEGORY"], [6212, 6229, "TRAINED_CATEGORY"], [6236, 6240, "TRAINED_CATEGORY"], [6245, 6251, "TRAINED_CATEGORY"], [6253, 6255, "TRAINED_CATEGORY"], [6259, 6269, "TRAINED_CATEGORY"], [6273, 6280, "TRAINED_CATEGORY"], [6292, 6311, "TRAINED_CATEGORY"], [6318, 6335, "TRAINED_CATEGORY"], [6339, 6352, "TRAINED_CATEGORY"], [6362, 6364, "TRAINED_CATEGORY"], [6377, 6393, "TRAINED_CATEGORY"], [6404, 6421, "TRAINED_CATEGORY"], [6425, 6436, "TRAINED_CATEGORY"], [6447, 6451, "TRAINED_CATEGORY"], [6463, 6474, "TRAINED_CATEGORY"], [6476, 6486, "TRAINED_CATEGORY"], [6492, 6501, "TRAINED_CATEGORY"], [6508, 6519, "TRAINED_CATEGORY"], [6523, 6532, "TRAINED_CATEGORY"], [6537, 6539, "TRAINED_CATEGORY"], [6549, 6559, "TRAINED_CATEGORY"], [6576, 6585, "TRAINED_CATEGORY"], [6587, 6591, "TRAINED_CATEGORY"], [6624, 6628, "TRAINED_CATEGORY"], [6634, 6640, "TRAINED_CATEGORY"], [6642, 6654, "TRAINED_CATEGORY"], [6664, 6668, "TRAINED_CATEGORY"], [6680, 6693, "TRAINED_CATEGORY"], [6706, 6714, "TRAINED_CATEGORY"], [6716, 6720, "TRAINED_CATEGORY"], [6729, 6739, "TRAINED_CATEGORY"], [6753, 6755, "TRAINED_CATEGORY"], [6760, 6769, "TRAINED_CATEGORY"], [6770, 6774, "TRAINED_CATEGORY"], [6794, 6799, "TRAINED_CATEGORY"], [6803, 6807, "TRAINED_CATEGORY"], [6821, 6832, "TRAINED_CATEGORY"], [6837, 6839, "TRAINED_CATEGORY"], [6844, 6848, "TRAINED_CATEGORY"], [6854, 6877, "TRAINED_CATEGORY"], [6884, 6903, "TRAINED_CATEGORY"], [6907, 6915, "TRAINED_CATEGORY"], [6926, 6930, "TRAINED_CATEGORY"], [6936, 6948, "TRAINED_CATEGORY"], [6952, 6959, "TRAINED_CATEGORY"], [6972, 6981, "TRAINED_CATEGORY"], [6994, 6998, "TRAINED_CATEGORY"], [7032, 7038, "TRAINED_CATEGORY"], [7046, 7050, "TRAINED_CATEGORY"], [7087, 7092, "TRAINED_CATEGORY"], [7131, 7139, "TRAINED_CATEGORY"], [7141, 7147, "TRAINED_CATEGORY"], [7185, 7190, "TRAINED_CATEGORY"], [7199, 7215, "TRAINED_CATEGORY"], [7223, 7231, "TRAINED_CATEGORY"], [7233, 7241, "TRAINED_CATEGORY"], [7278, 7283, "TRAINED_CATEGORY"], [7285, 7287, "TRAINED_CATEGORY"], [7299, 7314, "TRAINED_CATEGORY"], [7318, 7325, "TRAINED_CATEGORY"], [7338, 7354, "TRAINED_CATEGORY"], [7360, 7385, "TRAINED_CATEGORY"], [7397, 7412, "TRAINED_CATEGORY"], [7416, 7426, "TRAINED_CATEGORY"], [7439, 7456, "TRAINED_CATEGORY"], [7458, 7469, "TRAINED_CATEGORY"], [7473, 7489, "TRAINED_CATEGORY"], [7501, 7510, "TRAINED_CATEGORY"], [7514, 7526, "TRAINED_CATEGORY"], [7565, 7577, "TRAINED_CATEGORY"], [7594, 7613, "TRAINED_CATEGORY"], [7629, 7653, "TRAINED_CATEGORY"], [7657, 7670, "TRAINED_CATEGORY"], [7698, 7707, "TRAINED_CATEGORY"], [7708, 7721, "TRAINED_CATEGORY"], [7729, 7751, "TRAINED_CATEGORY"], [7757, 7769, "TRAINED_CATEGORY"], [7775, 7794, "TRAINED_CATEGORY"], [7805, 7825, "TRAINED_CATEGORY"], [7829, 7841, "TRAINED_CATEGORY"], [7844, 7847, "TRAINED_CATEGORY"], [7862, 7875, "TRAINED_CATEGORY"], [7879, 7909, "TRAINED_CATEGORY"], [7915, 7923, "TRAINED_CATEGORY"], [7927, 7938, "TRAINED_CATEGORY"], [7951, 7961, "TRAINED_CATEGORY"], [7989, 8006, "TRAINED_CATEGORY"], [8010, 8023, "TRAINED_CATEGORY"], [8027, 8035, "TRAINED_CATEGORY"], [8070, 8079, "TRAINED_CATEGORY"], [8084, 8087, "TRAINED_CATEGORY"], [8099, 8106, "TRAINED_CATEGORY"], [8123, 8127, "TRAINED_CATEGORY"], [8129, 8138, "TRAINED_CATEGORY"], [8140, 8153, "TRAINED_CATEGORY"], [8170, 8181, "TRAINED_CATEGORY"], [8187, 8195, "TRAINED_CATEGORY"], [8197, 8211, "TRAINED_CATEGORY"], [8212, 8214, "TRAINED_CATEGORY"], [8266, 8291, "TRAINED_CATEGORY"], [8307, 8309, "TRAINED_CATEGORY"], [8331, 8344, "TRAINED_CATEGORY"], [8348, 8379, "TRAINED_CATEGORY"], [8386, 8389, "TRAINED_CATEGORY"], [8411, 8419, "TRAINED_CATEGORY"], [8421, 8424, "TRAINED_CATEGORY"], [8452, 8470, "TRAINED_CATEGORY"], [8475, 8487, "TRAINED_CATEGORY"], [8491, 8499, "TRAINED_CATEGORY"], [8504, 8518, "TRAINED_CATEGORY"], [8547, 8563, "TRAINED_CATEGORY"], [8565, 8580, "TRAINED_CATEGORY"], [8619, 8625, "TRAINED_CATEGORY"], [8640, 8657, "TRAINED_CATEGORY"], [8672, 8687, "TRAINED_CATEGORY"], [8699, 8723, "TRAINED_CATEGORY"], [8741, 8760, "TRAINED_CATEGORY"], [8777, 8790, "TRAINED_CATEGORY"], [8797, 8801, "TRAINED_CATEGORY"], [8814, 8833, "TRAINED_CATEGORY"], [8857, 8877, "TRAINED_CATEGORY"], [8884, 8888, "TRAINED_CATEGORY"], [8888, 8914, "TRAINED_CATEGORY"], [8921, 8929, "TRAINED_CATEGORY"], [8931, 8935, "TRAINED_CATEGORY"], [8949, 8953, "TRAINED_CATEGORY"], [8964, 8980, "TRAINED_CATEGORY"], [8984, 8988, "TRAINED_CATEGORY"], [8997, 9009, "TRAINED_CATEGORY"], [9011, 9013, "TRAINED_CATEGORY"], [9028, 9038, "TRAINED_CATEGORY"], [9042, 9059, "TRAINED_CATEGORY"], [9069, 9083, "TRAINED_CATEGORY"], [9100, 9110, "TRAINED_CATEGORY"], [9112, 9131, "TRAINED_CATEGORY"], [9136, 9144, "TRAINED_CATEGORY"], [9149, 9160, "TRAINED_CATEGORY"], [9181, 9197, "TRAINED_CATEGORY"], [9210, 9230, "TRAINED_CATEGORY"], [9235, 9245, "TRAINED_CATEGORY"], [9249, 9259, "TRAINED_CATEGORY"], [9261, 9274, "TRAINED_CATEGORY"], [9293, 9295, "TRAINED_CATEGORY"], [9310, 9322, "TRAINED_CATEGORY"], [9326, 9340, "TRAINED_CATEGORY"], [9356, 9368, "TRAINED_CATEGORY"], [9372, 9380, "TRAINED_CATEGORY"], [9388, 9390, "TRAINED_CATEGORY"], [9410, 9422, "TRAINED_CATEGORY"], [9426, 9443, "TRAINED_CATEGORY"], [9459, 9471, "TRAINED_CATEGORY"], [9475, 9485, "TRAINED_CATEGORY"], [9487, 9489, "TRAINED_CATEGORY"], [9495, 9511, "TRAINED_CATEGORY"], [9527, 9546, "TRAINED_CATEGORY"], [9550, 9567, "TRAINED_CATEGORY"], [9584, 9586, "TRAINED_CATEGORY"], [9587, 9599, "TRAINED_CATEGORY"], [9603, 9620, "TRAINED_CATEGORY"], [9626, 9633, "TRAINED_CATEGORY"], [9637, 9645, "TRAINED_CATEGORY"], [9647, 9668, "TRAINED_CATEGORY"], [9680, 9693, "TRAINED_CATEGORY"], [9737, 9750, "TRAINED_CATEGORY"], [9762, 9772, "TRAINED_CATEGORY"], [9774, 9781, "TRAINED_CATEGORY"], [9794, 9808, "TRAINED_CATEGORY"], [9813, 9824, "TRAINED_CATEGORY"], [9847, 9859, "TRAINED_CATEGORY"], [9878, 9882, "TRAINED_CATEGORY"], [9921, 9930, "TRAINED_CATEGORY"], [9950, 9954, "TRAINED_CATEGORY"], [9959, 9967, "TRAINED_CATEGORY"], [10017, 10034, "TRAINED_CATEGORY"], [10066, 10079, "TRAINED_CATEGORY"], [10103, 10111, "TRAINED_CATEGORY"], [10117, 10124, "TRAINED_CATEGORY"], [10128, 10141, "TRAINED_CATEGORY"], [10146, 10168, "TRAINED_CATEGORY"], [10172, 10175, "TRAINED_CATEGORY"], [10177, 10179, "TRAINED_CATEGORY"], [10202, 10218, "TRAINED_CATEGORY"], [10224, 10231, "TRAINED_CATEGORY"], [10235, 10258, "TRAINED_CATEGORY"], [10265, 10273, "TRAINED_CATEGORY"], [10284, 10300, "TRAINED_CATEGORY"], [10306, 10313, "TRAINED_CATEGORY"], [10317, 10329, "TRAINED_CATEGORY"], [10333, 10343, "TRAINED_CATEGORY"], [10357, 10369, "TRAINED_CATEGORY"], [10378, 10401, "TRAINED_CATEGORY"], [10405, 10414, "TRAINED_CATEGORY"], [10415, 10419, "TRAINED_CATEGORY"], [10431, 10440, "TRAINED_CATEGORY"], [10442, 10446, "TRAINED_CATEGORY"], [10454, 10463, "TRAINED_CATEGORY"], [10478, 10486, "TRAINED_CATEGORY"], [10490, 10511, "TRAINED_CATEGORY"], [10524, 10538, "TRAINED_CATEGORY"], [10552, 10566, "TRAINED_CATEGORY"], [10571, 10581, "TRAINED_CATEGORY"], [10598, 10606, "TRAINED_CATEGORY"], [10629, 10640, "TRAINED_CATEGORY"], [10646, 10650, "TRAINED_CATEGORY"], [10675, 10687, "TRAINED_CATEGORY"], [10688, 10699, "TRAINED_CATEGORY"], [10708, 10720, "TRAINED_CATEGORY"], [10733, 10742, "TRAINED_CATEGORY"], [10753, 10765, "TRAINED_CATEGORY"], [10766, 10770, "TRAINED_CATEGORY"], [10790, 10805, "TRAINED_CATEGORY"], [10807, 10827, "TRAINED_CATEGORY"], [10839, 10860, "TRAINED_CATEGORY"], [10878, 10882, "TRAINED_CATEGORY"], [10893, 10898, "TRAINED_CATEGORY"], [10902, 10922, "TRAINED_CATEGORY"], [10932, 10942, "TRAINED_CATEGORY"], [10952, 10966, "TRAINED_CATEGORY"], [10975, 10979, "TRAINED_CATEGORY"], [10981, 10983, "TRAINED_CATEGORY"], [10990, 11013, "TRAINED_CATEGORY"], [11020, 11029, "TRAINED_CATEGORY"], [11034, 11047, "TRAINED_CATEGORY"], [11051, 11060, "TRAINED_CATEGORY"], [11064, 11068, "TRAINED_CATEGORY"], [11076, 11080, "TRAINED_CATEGORY"], [11084, 11088, "TRAINED_CATEGORY"], [11099, 11103, "TRAINED_CATEGORY"], [11118, 11136, "TRAINED_CATEGORY"], [11140, 11156, "TRAINED_CATEGORY"], [11168, 11185, "TRAINED_CATEGORY"], [11190, 11194, "TRAINED_CATEGORY"], [11223, 11227, "TRAINED_CATEGORY"], [11243, 11252, "TRAINED_CATEGORY"], [11278, 11296, "TRAINED_CATEGORY"], [11324, 11333, "TRAINED_CATEGORY"], [11339, 11352, "TRAINED_CATEGORY"], [11364, 11368, "TRAINED_CATEGORY"], [11382, 11394, "TRAINED_CATEGORY"], [11413, 11428, "TRAINED_CATEGORY"], [11434, 11436, "TRAINED_CATEGORY"], [11448, 11479, "TRAINED_CATEGORY"], [11483, 11494, "TRAINED_CATEGORY"], [11516, 11527, "TRAINED_CATEGORY"], [11547, 11561, "TRAINED_CATEGORY"], [11567, 11585, "TRAINED_CATEGORY"], [11590, 11599, "TRAINED_CATEGORY"], [11603, 11613, "TRAINED_CATEGORY"], [11617, 11623, "TRAINED_CATEGORY"], [11651, 11661, "TRAINED_CATEGORY"], [11663, 11669, "TRAINED_CATEGORY"], [11714, 11723, "TRAINED_CATEGORY"], [11729, 11745, "TRAINED_CATEGORY"], [11768, 11781, "TRAINED_CATEGORY"], [11786, 11796, "TRAINED_CATEGORY"], [11807, 11820, "TRAINED_CATEGORY"], [11848, 11860, "TRAINED_CATEGORY"], [11862, 11868, "TRAINED_CATEGORY"], [11896, 11898, "TRAINED_CATEGORY"], [11902, 11915, "TRAINED_CATEGORY"], [11919, 11932, "TRAINED_CATEGORY"], [11974, 11980, "TRAINED_CATEGORY"], [12004, 12008, "TRAINED_CATEGORY"], [12015, 12034, "TRAINED_CATEGORY"], [12038, 12045, "TRAINED_CATEGORY"], [12055, 12062, "TRAINED_CATEGORY"], [12070, 12085, "TRAINED_CATEGORY"], [12095, 12110, "TRAINED_CATEGORY"], [12117, 12125, "TRAINED_CATEGORY"], [12139, 12152, "TRAINED_CATEGORY"], [12153, 12163, "TRAINED_CATEGORY"], [12165, 12167, "TRAINED_CATEGORY"], [12182, 12202, "TRAINED_CATEGORY"], [12216, 12218, "TRAINED_CATEGORY"], [12228, 12244, "TRAINED_CATEGORY"], [12266, 12278, "TRAINED_CATEGORY"], [12300, 12308, "TRAINED_CATEGORY"], [12331, 12335, "TRAINED_CATEGORY"], [12363, 12382, "TRAINED_CATEGORY"], [12416, 12430, "TRAINED_CATEGORY"], [12458, 12466, "TRAINED_CATEGORY"], [12470, 12482, "TRAINED_CATEGORY"], [12492, 12496, "TRAINED_CATEGORY"], [12510, 12516, "TRAINED_CATEGORY"], [12518, 12537, "TRAINED_CATEGORY"], [12541, 12546, "TRAINED_CATEGORY"], [12570, 12581, "TRAINED_CATEGORY"], [12587, 12606, "TRAINED_CATEGORY"], [12634, 12654, "TRAINED_CATEGORY"], [12667, 12671, "TRAINED_CATEGORY"], [12684, 12709, "TRAINED_CATEGORY"], [12715, 12731, "TRAINED_CATEGORY"], [12744, 12756, "TRAINED_CATEGORY"], [12758, 12771, "TRAINED_CATEGORY"], [12775, 12790, "TRAINED_CATEGORY"], [12814, 12817, "TRAINED_CATEGORY"], [12829, 12850, "TRAINED_CATEGORY"], [12865, 12878, "TRAINED_CATEGORY"], [12883, 12896, "TRAINED_CATEGORY"], [12907, 12912, "TRAINED_CATEGORY"], [12927, 12933, "TRAINED_CATEGORY"], [12968, 12974, "TRAINED_CATEGORY"], [13035, 13039, "TRAINED_CATEGORY"], [13046, 13052, "TRAINED_CATEGORY"], [13054, 13081, "TRAINED_CATEGORY"], [13196, 13205, "TRAINED_CATEGORY"], [13220, 13226, "TRAINED_CATEGORY"], [13244, 13248, "TRAINED_CATEGORY"], [13288, 13292, "TRAINED_CATEGORY"], [13326, 13339, "TRAINED_CATEGORY"], [13344, 13369, "TRAINED_CATEGORY"], [13389, 13404, "TRAINED_CATEGORY"], [13406, 13415, "TRAINED_CATEGORY"], [13419, 13425, "TRAINED_CATEGORY"], [13444, 13457, "TRAINED_CATEGORY"], [13464, 13477, "TRAINED_CATEGORY"], [13503, 13519, "TRAINED_CATEGORY"], [13528, 13552, "TRAINED_CATEGORY"], [13557, 13577, "TRAINED_CATEGORY"], [13583, 13590, "TRAINED_CATEGORY"], [13594, 13608, "TRAINED_CATEGORY"], [13611, 13631, "TRAINED_CATEGORY"], [13646, 13664, "TRAINED_CATEGORY"], [13668, 13678, "TRAINED_CATEGORY"], [13694, 13710, "TRAINED_CATEGORY"], [13714, 13728, "TRAINED_CATEGORY"], [13730, 13751, "TRAINED_CATEGORY"], [13766, 13784, "TRAINED_CATEGORY"], [13788, 13798, "TRAINED_CATEGORY"], [13814, 13830, "TRAINED_CATEGORY"], [13843, 13855, "TRAINED_CATEGORY"], [13860, 13876, "TRAINED_CATEGORY"], [13884, 13890, "TRAINED_CATEGORY"], [13905, 13921, "TRAINED_CATEGORY"], [13925, 13934, "TRAINED_CATEGORY"], [13938, 13944, "TRAINED_CATEGORY"], [13983, 13987, "TRAINED_CATEGORY"], [13991, 14005, "TRAINED_CATEGORY"], [14007, 14022, "TRAINED_CATEGORY"], [14039, 14046, "TRAINED_CATEGORY"], [14072, 14081, "TRAINED_CATEGORY"], [14083, 14089, "TRAINED_CATEGORY"], [14110, 14121, "TRAINED_CATEGORY"], [14125, 14149, "TRAINED_CATEGORY"], [14178, 14180, "TRAINED_CATEGORY"], [14184, 14204, "TRAINED_CATEGORY"], [14212, 14219, "TRAINED_CATEGORY"], [14224, 14236, "TRAINED_CATEGORY"], [14298, 14309, "TRAINED_CATEGORY"], [14325, 14327, "TRAINED_CATEGORY"], [14331, 14347, "TRAINED_CATEGORY"], [14368, 14394, "TRAINED_CATEGORY"], [14398, 14404, "TRAINED_CATEGORY"], [14449, 14452, "TRAINED_CATEGORY"], [14456, 14459, "TRAINED_CATEGORY"], [14461, 14475, "TRAINED_CATEGORY"], [14485, 14506, "TRAINED_CATEGORY"], [14512, 14516, "TRAINED_CATEGORY"], [14521, 14540, "TRAINED_CATEGORY"], [14544, 14555, "TRAINED_CATEGORY"], [14560, 14571, "TRAINED_CATEGORY"], [14579, 14594, "TRAINED_CATEGORY"], [14608, 14619, "TRAINED_CATEGORY"], [14623, 14637, "TRAINED_CATEGORY"], [14641, 14645, "TRAINED_CATEGORY"], [14655, 14667, "TRAINED_CATEGORY"], [14671, 14679, "TRAINED_CATEGORY"], [14684, 14697, "TRAINED_CATEGORY"], [14703, 14729, "TRAINED_CATEGORY"], [14749, 14758, "TRAINED_CATEGORY"], [14764, 14780, "TRAINED_CATEGORY"], [14782, 14784, "TRAINED_CATEGORY"], [14826, 14834, "TRAINED_CATEGORY"], [14845, 14859, "TRAINED_CATEGORY"], [14863, 14877, "TRAINED_CATEGORY"], [14887, 14890, "TRAINED_CATEGORY"], [14915, 14925, "TRAINED_CATEGORY"], [14931, 14945, "TRAINED_CATEGORY"], [14947, 14960, "TRAINED_CATEGORY"], [14984, 15000, "TRAINED_CATEGORY"], [15009, 15020, "TRAINED_CATEGORY"], [15022, 15035, "TRAINED_CATEGORY"], [15053, 15059, "TRAINED_CATEGORY"], [15072, 15077, "TRAINED_CATEGORY"], [15081, 15099, "TRAINED_CATEGORY"], [15101, 15108, "TRAINED_CATEGORY"], [15118, 15132, "TRAINED_CATEGORY"], [15145, 15164, "TRAINED_CATEGORY"], [15168, 15182, "TRAINED_CATEGORY"], [15187, 15189, "TRAINED_CATEGORY"], [15202, 15218, "TRAINED_CATEGORY"], [15234, 15244, "TRAINED_CATEGORY"], [15248, 15262, "TRAINED_CATEGORY"], [15263, 15267, "TRAINED_CATEGORY"], [15285, 15289, "TRAINED_CATEGORY"], [15318, 15322, "TRAINED_CATEGORY"], [15333, 15348, "TRAINED_CATEGORY"], [15352, 15360, "TRAINED_CATEGORY"], [15374, 15391, "TRAINED_CATEGORY"], [15396, 15434, "TRAINED_CATEGORY"], [15443, 15447, "TRAINED_CATEGORY"], [15464, 15490, "TRAINED_CATEGORY"], [15494, 15544, "TRAINED_CATEGORY"], [15560, 15571, "TRAINED_CATEGORY"], [15580, 15584, "TRAINED_CATEGORY"], [15590, 15600, "TRAINED_CATEGORY"], [15617, 15632, "TRAINED_CATEGORY"], [15638, 15652, "TRAINED_CATEGORY"], [15655, 15663, "TRAINED_CATEGORY"], [15688, 15701, "TRAINED_CATEGORY"], [15717, 15725, "TRAINED_CATEGORY"], [15731, 15741, "TRAINED_CATEGORY"], [15767, 15771, "TRAINED_CATEGORY"], [15785, 15798, "TRAINED_CATEGORY"], [15802, 15813, "TRAINED_CATEGORY"], [15818, 15822, "TRAINED_CATEGORY"], [15837, 15853, "TRAINED_CATEGORY"], [15857, 15875, "TRAINED_CATEGORY"], [15877, 15881, "TRAINED_CATEGORY"], [15900, 15911, "TRAINED_CATEGORY"], [15915, 15937, "TRAINED_CATEGORY"], [15943, 15947, "TRAINED_CATEGORY"], [15962, 15973, "TRAINED_CATEGORY"], [15977, 15990, "TRAINED_CATEGORY"], [15993, 16003, "TRAINED_CATEGORY"], [16018, 16028, "TRAINED_CATEGORY"], [16032, 16045, "TRAINED_CATEGORY"], [16049, 16053, "TRAINED_CATEGORY"], [16062, 16080, "TRAINED_CATEGORY"], [16082, 16086, "TRAINED_CATEGORY"], [16095, 16109, "TRAINED_CATEGORY"], [16115, 16119, "TRAINED_CATEGORY"], [16130, 16151, "TRAINED_CATEGORY"], [16162, 16171, "TRAINED_CATEGORY"], [16178, 16196, "TRAINED_CATEGORY"], [16198, 16202, "TRAINED_CATEGORY"], [16231, 16236, "TRAINED_CATEGORY"], [16272, 16283, "TRAINED_CATEGORY"], [16285, 16302, "TRAINED_CATEGORY"], [16312, 16343, "TRAINED_CATEGORY"], [16365, 16374, "TRAINED_CATEGORY"], [16405, 16408, "TRAINED_CATEGORY"], [16422, 16436, "TRAINED_CATEGORY"], [16441, 16477, "TRAINED_CATEGORY"], [16488, 16499, "TRAINED_CATEGORY"], [16505, 16521, "TRAINED_CATEGORY"], [16533, 16549, "TRAINED_CATEGORY"], [16560, 16566, "TRAINED_CATEGORY"], [16579, 16591, "TRAINED_CATEGORY"], [16620, 16629, "TRAINED_CATEGORY"], [16636, 16637, "TRAINED_CATEGORY"], [16650, 16664, "TRAINED_CATEGORY"], [16677, 16678, "TRAINED_CATEGORY"], [16687, 16700, "TRAINED_CATEGORY"], [16726, 16742, "TRAINED_CATEGORY"], [16751, 16775, "TRAINED_CATEGORY"], [16780, 16800, "TRAINED_CATEGORY"], [16806, 16813, "TRAINED_CATEGORY"], [16817, 16823, "TRAINED_CATEGORY"], [16826, 16846, "TRAINED_CATEGORY"], [16861, 16871, "TRAINED_CATEGORY"], [16875, 16885, "TRAINED_CATEGORY"], [16901, 16914, "TRAINED_CATEGORY"], [16918, 16924, "TRAINED_CATEGORY"], [16926, 16947, "TRAINED_CATEGORY"], [16962, 16972, "TRAINED_CATEGORY"], [16976, 16986, "TRAINED_CATEGORY"], [17002, 17018, "TRAINED_CATEGORY"], [17031, 17043, "TRAINED_CATEGORY"], [17048, 17064, "TRAINED_CATEGORY"], [17072, 17090, "TRAINED_CATEGORY"], [17095, 17114, "TRAINED_CATEGORY"], [17136, 17152, "TRAINED_CATEGORY"], [17163, 17202, "TRAINED_CATEGORY"], [17213, 17224, "TRAINED_CATEGORY"], [17227, 17237, "TRAINED_CATEGORY"], [17298, 17309, "TRAINED_CATEGORY"], [17369, 17384, "TRAINED_CATEGORY"], [17392, 17405, "TRAINED_CATEGORY"], [17431, 17447, "TRAINED_CATEGORY"], [17456, 17480, "TRAINED_CATEGORY"], [17485, 17505, "TRAINED_CATEGORY"], [17511, 17518, "TRAINED_CATEGORY"], [17522, 17540, "TRAINED_CATEGORY"], [17543, 17563, "TRAINED_CATEGORY"], [17578, 17600, "TRAINED_CATEGORY"], [17604, 17614, "TRAINED_CATEGORY"], [17630, 17646, "TRAINED_CATEGORY"], [17650, 17668, "TRAINED_CATEGORY"], [17670, 17691, "TRAINED_CATEGORY"], [17706, 17728, "TRAINED_CATEGORY"], [17732, 17742, "TRAINED_CATEGORY"], [17758, 17774, "TRAINED_CATEGORY"], [17787, 17799, "TRAINED_CATEGORY"], [17804, 17820, "TRAINED_CATEGORY"], [17828, 17838, "TRAINED_CATEGORY"], [17849, 17870, "TRAINED_CATEGORY"], [17872, 17888, "TRAINED_CATEGORY"], [17913, 17922, "TRAINED_CATEGORY"], [17923, 17927, "TRAINED_CATEGORY"], [17933, 17937, "TRAINED_CATEGORY"], [17949, 17951, "TRAINED_CATEGORY"], [17971, 17976, "TRAINED_CATEGORY"], [17981, 17985, "TRAINED_CATEGORY"], [17990, 18001, "TRAINED_CATEGORY"], [18012, 18019, "TRAINED_CATEGORY"], [18033, 18049, "TRAINED_CATEGORY"], [18061, 18070, "TRAINED_CATEGORY"], [18074, 18078, "TRAINED_CATEGORY"], [18082, 18108, "TRAINED_CATEGORY"], [18113, 18117, "TRAINED_CATEGORY"], [18136, 18138, "TRAINED_CATEGORY"], [18177, 18198, "TRAINED_CATEGORY"], [18200, 18204, "TRAINED_CATEGORY"], [18223, 18237, "TRAINED_CATEGORY"], [18238, 18248, "TRAINED_CATEGORY"], [18252, 18269, "TRAINED_CATEGORY"], [18290, 18310, "TRAINED_CATEGORY"], [18314, 18322, "TRAINED_CATEGORY"], [18332, 18343, "TRAINED_CATEGORY"], [18352, 18366, "TRAINED_CATEGORY"], [18367, 18378, "TRAINED_CATEGORY"], [18382, 18411, "TRAINED_CATEGORY"], [18414, 18418, "TRAINED_CATEGORY"], [18444, 18457, "TRAINED_CATEGORY"], [18461, 18476, "TRAINED_CATEGORY"], [18514, 18529, "TRAINED_CATEGORY"], [18533, 18545, "TRAINED_CATEGORY"], [18550, 18572, "TRAINED_CATEGORY"], [18573, 18577, "TRAINED_CATEGORY"], [18588, 18600, "TRAINED_CATEGORY"], [18635, 18652, "TRAINED_CATEGORY"], [18657, 18668, "TRAINED_CATEGORY"], [18673, 18678, "TRAINED_CATEGORY"], [18683, 18711, "TRAINED_CATEGORY"], [18715, 18720, "TRAINED_CATEGORY"], [18722, 18735, "TRAINED_CATEGORY"], [18740, 18745, "TRAINED_CATEGORY"], [18776, 18782, "TRAINED_CATEGORY"], [18783, 18793, "TRAINED_CATEGORY"], [18800, 18813, "TRAINED_CATEGORY"], [18814, 18818, "TRAINED_CATEGORY"], [18834, 18853, "TRAINED_CATEGORY"], [18861, 18874, "TRAINED_CATEGORY"], [18900, 18916, "TRAINED_CATEGORY"], [18925, 18949, "TRAINED_CATEGORY"], [18954, 18974, "TRAINED_CATEGORY"], [18980, 18987, "TRAINED_CATEGORY"], [18991, 19000, "TRAINED_CATEGORY"], [19003, 19023, "TRAINED_CATEGORY"], [19038, 19051, "TRAINED_CATEGORY"], [19055, 19065, "TRAINED_CATEGORY"], [19081, 19097, "TRAINED_CATEGORY"], [19101, 19111, "TRAINED_CATEGORY"], [19113, 19134, "TRAINED_CATEGORY"], [19149, 19162, "TRAINED_CATEGORY"], [19166, 19176, "TRAINED_CATEGORY"], [19192, 19208, "TRAINED_CATEGORY"], [19221, 19233, "TRAINED_CATEGORY"], [19238, 19254, "TRAINED_CATEGORY"], [19262, 19274, "TRAINED_CATEGORY"], [19284, 19294, "TRAINED_CATEGORY"], [19306, 19318, "TRAINED_CATEGORY"], [19320, 19324, "TRAINED_CATEGORY"], [19338, 19358, "TRAINED_CATEGORY"], [19364, 19374, "TRAINED_CATEGORY"], [19378, 19394, "TRAINED_CATEGORY"], [19398, 19414, "TRAINED_CATEGORY"], [19421, 19441, "TRAINED_CATEGORY"], [19443, 19475, "TRAINED_CATEGORY"], [19490, 19497, "TRAINED_CATEGORY"], [19526, 19533, "TRAINED_CATEGORY"], [19537, 19549, "TRAINED_CATEGORY"], [19551, 19560, "TRAINED_CATEGORY"], [19573, 19577, "TRAINED_CATEGORY"], [19579, 19601, "TRAINED_CATEGORY"], [19612, 19625, "TRAINED_CATEGORY"], [19629, 19636, "TRAINED_CATEGORY"], [19656, 19673, "TRAINED_CATEGORY"], [19675, 19686, "TRAINED_CATEGORY"], [19704, 19713, "TRAINED_CATEGORY"], [19725, 19727, "TRAINED_CATEGORY"], [19733, 19737, "TRAINED_CATEGORY"], [19754, 19756, "TRAINED_CATEGORY"], [19784, 19788, "TRAINED_CATEGORY"], [19794, 19798, "TRAINED_CATEGORY"], [19811, 19821, "TRAINED_CATEGORY"], [19827, 19846, "TRAINED_CATEGORY"], [19851, 19863, "TRAINED_CATEGORY"], [19884, 19900, "TRAINED_CATEGORY"], [19907, 19920, "TRAINED_CATEGORY"], [19922, 19932, "TRAINED_CATEGORY"], [19938, 19942, "TRAINED_CATEGORY"], [19943, 19953, "TRAINED_CATEGORY"], [19962, 19980, "TRAINED_CATEGORY"], [19984, 20000, "TRAINED_CATEGORY"], [20007, 20017, "TRAINED_CATEGORY"], [20022, 20034, "TRAINED_CATEGORY"], [20036, 20045, "TRAINED_CATEGORY"], [20052, 20056, "TRAINED_CATEGORY"], [20065, 20074, "TRAINED_CATEGORY"], [20078, 20093, "TRAINED_CATEGORY"], [20095, 20099, "TRAINED_CATEGORY"], [20109, 20127, "TRAINED_CATEGORY"], [20131, 20137, "TRAINED_CATEGORY"], [20165, 20172, "TRAINED_CATEGORY"], [20182, 20186, "TRAINED_CATEGORY"], [20197, 20201, "TRAINED_CATEGORY"], [20214, 20250, "TRAINED_CATEGORY"], [20254, 20267, "TRAINED_CATEGORY"], [20271, 20301, "TRAINED_CATEGORY"], [20306, 20310, "TRAINED_CATEGORY"], [20325, 20334, "TRAINED_CATEGORY"], [20338, 20342, "TRAINED_CATEGORY"], [20348, 20378, "TRAINED_CATEGORY"], [20386, 20398, "TRAINED_CATEGORY"], [20403, 20413, "TRAINED_CATEGORY"], [20415, 20419, "TRAINED_CATEGORY"], [20448, 20463, "TRAINED_CATEGORY"], [20465, 20469, "TRAINED_CATEGORY"], [20486, 20500, "TRAINED_CATEGORY"], [20504, 20516, "TRAINED_CATEGORY"], [20542, 20559, "TRAINED_CATEGORY"], [20563, 20573, "TRAINED_CATEGORY"], [20581, 20590, "TRAINED_CATEGORY"], [20595, 20611, "TRAINED_CATEGORY"], [20620, 20634, "TRAINED_CATEGORY"], [20647, 20651, "TRAINED_CATEGORY"], [20661, 20680, "TRAINED_CATEGORY"], [20694, 20716, "TRAINED_CATEGORY"], [20724, 20733, "TRAINED_CATEGORY"], [20738, 20754, "TRAINED_CATEGORY"], [20763, 20767, "TRAINED_CATEGORY"], [20771, 20789, "TRAINED_CATEGORY"], [20802, 20806, "TRAINED_CATEGORY"], [20816, 20832, "TRAINED_CATEGORY"], [20910, 20938, "TRAINED_CATEGORY"], [20945, 20963, "TRAINED_CATEGORY"], [20968, 20978, "TRAINED_CATEGORY"], [20980, 20984, "TRAINED_CATEGORY"], [21000, 21015, "TRAINED_CATEGORY"], [21019, 21029, "TRAINED_CATEGORY"], [21032, 21036, "TRAINED_CATEGORY"], [21050, 21066, "TRAINED_CATEGORY"], [21076, 21078, "TRAINED_CATEGORY"], [21093, 21101, "TRAINED_CATEGORY"], [21117, 21121, "TRAINED_CATEGORY"], [21123, 21133, "TRAINED_CATEGORY"], [21140, 21153, "TRAINED_CATEGORY"], [21154, 21158, "TRAINED_CATEGORY"], [21174, 21204, "TRAINED_CATEGORY"], [21212, 21225, "TRAINED_CATEGORY"], [21251, 21267, "TRAINED_CATEGORY"], [21276, 21300, "TRAINED_CATEGORY"], [21305, 21325, "TRAINED_CATEGORY"], [21331, 21338, "TRAINED_CATEGORY"], [21342, 21354, "TRAINED_CATEGORY"], [21357, 21377, "TRAINED_CATEGORY"], [21392, 21408, "TRAINED_CATEGORY"], [21412, 21422, "TRAINED_CATEGORY"], [21438, 21454, "TRAINED_CATEGORY"], [21458, 21470, "TRAINED_CATEGORY"], [21472, 21493, "TRAINED_CATEGORY"], [21508, 21524, "TRAINED_CATEGORY"], [21528, 21538, "TRAINED_CATEGORY"], [21554, 21570, "TRAINED_CATEGORY"], [21583, 21595, "TRAINED_CATEGORY"], [21600, 21616, "TRAINED_CATEGORY"], [21624, 21635, "TRAINED_CATEGORY"], [21646, 21662, "TRAINED_CATEGORY"], [21674, 21691, "TRAINED_CATEGORY"], [21696, 21704, "TRAINED_CATEGORY"], [21711, 21724, "TRAINED_CATEGORY"], [21730, 21734, "TRAINED_CATEGORY"], [21747, 21763, "TRAINED_CATEGORY"], [21777, 21781, "TRAINED_CATEGORY"], [21790, 21815, "TRAINED_CATEGORY"], [21833, 21864, "TRAINED_CATEGORY"], [21869, 21878, "TRAINED_CATEGORY"], [21882, 21892, "TRAINED_CATEGORY"], [21894, 21906, "TRAINED_CATEGORY"], [21930, 21941, "TRAINED_CATEGORY"], [21960, 21967, "TRAINED_CATEGORY"], [21990, 21999, "TRAINED_CATEGORY"], [22004, 22011, "TRAINED_CATEGORY"], [22013, 22022, "TRAINED_CATEGORY"], [22053, 22069, "TRAINED_CATEGORY"], [22074, 22089, "TRAINED_CATEGORY"], [22109, 22123, "TRAINED_CATEGORY"], [22125, 22136, "TRAINED_CATEGORY"], [22167, 22180, "TRAINED_CATEGORY"], [22185, 22200, "TRAINED_CATEGORY"], [22220, 22226, "TRAINED_CATEGORY"], [22228, 22242, "TRAINED_CATEGORY"], [22248, 22259, "TRAINED_CATEGORY"], [22261, 22272, "TRAINED_CATEGORY"], [22284, 22307, "TRAINED_CATEGORY"], [22320, 22341, "TRAINED_CATEGORY"], [22346, 22360, "TRAINED_CATEGORY"], [22368, 22379, "TRAINED_CATEGORY"], [22384, 22401, "TRAINED_CATEGORY"], [22403, 22405, "TRAINED_CATEGORY"], [22419, 22426, "TRAINED_CATEGORY"], [22431, 22441, "TRAINED_CATEGORY"], [22461, 22470, "TRAINED_CATEGORY"], [22484, 22486, "TRAINED_CATEGORY"], [22499, 22506, "TRAINED_CATEGORY"], [22511, 22522, "TRAINED_CATEGORY"], [22528, 22530, "TRAINED_CATEGORY"], [22536, 22540, "TRAINED_CATEGORY"], [22570, 22578, "TRAINED_CATEGORY"], [22583, 22591, "TRAINED_CATEGORY"], [22595, 22599, "TRAINED_CATEGORY"], [22610, 22620, "TRAINED_CATEGORY"], [22622, 22624, "TRAINED_CATEGORY"], [22640, 22644, "TRAINED_CATEGORY"], [22650, 22661, "TRAINED_CATEGORY"], [22665, 22682, "TRAINED_CATEGORY"], [22687, 22711, "TRAINED_CATEGORY"], [22722, 22742, "TRAINED_CATEGORY"], [22746, 22757, "TRAINED_CATEGORY"], [22763, 22765, "TRAINED_CATEGORY"], [22799, 22809, "TRAINED_CATEGORY"], [22818, 22832, "TRAINED_CATEGORY"], [22841, 22846, "TRAINED_CATEGORY"], [22850, 22871, "TRAINED_CATEGORY"], [22878, 22895, "TRAINED_CATEGORY"], [22910, 22922, "TRAINED_CATEGORY"], [22926, 22939, "TRAINED_CATEGORY"], [22949, 22965, "TRAINED_CATEGORY"], [22969, 22980, "TRAINED_CATEGORY"], [22982, 22993, "TRAINED_CATEGORY"], [23002, 23004, "TRAINED_CATEGORY"], [23013, 23043, "TRAINED_CATEGORY"], [23050, 23067, "TRAINED_CATEGORY"], [23078, 23091, "TRAINED_CATEGORY"], [23092, 23096, "TRAINED_CATEGORY"], [23115, 23128, "TRAINED_CATEGORY"], [23154, 23170, "TRAINED_CATEGORY"], [23179, 23203, "TRAINED_CATEGORY"], [23208, 23228, "TRAINED_CATEGORY"], [23234, 23241, "TRAINED_CATEGORY"], [23245, 23262, "TRAINED_CATEGORY"], [23265, 23285, "TRAINED_CATEGORY"], [23300, 23330, "TRAINED_CATEGORY"], [23334, 23344, "TRAINED_CATEGORY"], [23360, 23376, "TRAINED_CATEGORY"], [23380, 23397, "TRAINED_CATEGORY"], [23399, 23420, "TRAINED_CATEGORY"], [23435, 23455, "TRAINED_CATEGORY"], [23459, 23469, "TRAINED_CATEGORY"], [23485, 23501, "TRAINED_CATEGORY"], [23514, 23526, "TRAINED_CATEGORY"], [23531, 23547, "TRAINED_CATEGORY"], [23553, 23560, "TRAINED_CATEGORY"], [23565, 23575, "TRAINED_CATEGORY"], [23589, 23594, "TRAINED_CATEGORY"], [23611, 23615, "TRAINED_CATEGORY"], [23629, 23633, "TRAINED_CATEGORY"], [23644, 23654, "TRAINED_CATEGORY"], [23667, 23687, "TRAINED_CATEGORY"], [23690, 23695, "TRAINED_CATEGORY"], [23700, 23727, "TRAINED_CATEGORY"], [23728, 23730, "TRAINED_CATEGORY"], [23755, 23760, "TRAINED_CATEGORY"], [23767, 23774, "TRAINED_CATEGORY"], [23778, 23790, "TRAINED_CATEGORY"], [23805, 23815, "TRAINED_CATEGORY"], [23819, 23838, "TRAINED_CATEGORY"], [23840, 23847, "TRAINED_CATEGORY"], [23854, 23870, "TRAINED_CATEGORY"], [23871, 23876, "TRAINED_CATEGORY"], [23889, 23899, "TRAINED_CATEGORY"], [23904, 23912, "TRAINED_CATEGORY"], [23913, 23917, "TRAINED_CATEGORY"], [23935, 23951, "TRAINED_CATEGORY"], [23961, 23967, "TRAINED_CATEGORY"], [23979, 23995, "TRAINED_CATEGORY"], [23997, 23999, "TRAINED_CATEGORY"], [24009, 24015, "TRAINED_CATEGORY"], [24017, 24028, "TRAINED_CATEGORY"], [24030, 24050, "TRAINED_CATEGORY"], [24052, 24063, "TRAINED_CATEGORY"], [24097, 24111, "TRAINED_CATEGORY"], [24121, 24130, "TRAINED_CATEGORY"], [24134, 24142, "TRAINED_CATEGORY"], [24144, 24154, "TRAINED_CATEGORY"], [24167, 24185, "TRAINED_CATEGORY"], [24200, 24205, "TRAINED_CATEGORY"], [24213, 24222, "TRAINED_CATEGORY"], [24226, 24238, "TRAINED_CATEGORY"], [24247, 24251, "TRAINED_CATEGORY"], [24257, 24272, "TRAINED_CATEGORY"], [24274, 24278, "TRAINED_CATEGORY"], [24306, 24316, "TRAINED_CATEGORY"], [24320, 24335, "TRAINED_CATEGORY"], [24343, 24356, "TRAINED_CATEGORY"], [24382, 24398, "TRAINED_CATEGORY"], [24407, 24437, "TRAINED_CATEGORY"], [24442, 24462, "TRAINED_CATEGORY"], [24468, 24475, "TRAINED_CATEGORY"], [24479, 24484, "TRAINED_CATEGORY"], [24487, 24507, "TRAINED_CATEGORY"], [24522, 24531, "TRAINED_CATEGORY"], [24535, 24545, "TRAINED_CATEGORY"], [24561, 24580, "TRAINED_CATEGORY"], [24582, 24603, "TRAINED_CATEGORY"], [24618, 24627, "TRAINED_CATEGORY"], [24631, 24641, "TRAINED_CATEGORY"], [24657, 24673, "TRAINED_CATEGORY"], [24686, 24698, "TRAINED_CATEGORY"], [24703, 24719, "TRAINED_CATEGORY"], [24727, 24741, "TRAINED_CATEGORY"], [24746, 24764, "TRAINED_CATEGORY"], [24768, 24784, "TRAINED_CATEGORY"], [24798, 24808, "TRAINED_CATEGORY"], [24823, 24856, "TRAINED_CATEGORY"], [24861, 24873, "TRAINED_CATEGORY"], [24875, 24886, "TRAINED_CATEGORY"], [24909, 24911, "TRAINED_CATEGORY"], [24931, 24935, "TRAINED_CATEGORY"], [24947, 24949, "TRAINED_CATEGORY"], [24952, 24969, "TRAINED_CATEGORY"], [24973, 24987, "TRAINED_CATEGORY"], [25007, 25016, "TRAINED_CATEGORY"], [25018, 25032, "TRAINED_CATEGORY"], [25039, 25059, "TRAINED_CATEGORY"], [25063, 25086, "TRAINED_CATEGORY"], [25089, 25105, "TRAINED_CATEGORY"], [25110, 25126, "TRAINED_CATEGORY"], [25137, 25157, "TRAINED_CATEGORY"], [25159, 25165, "TRAINED_CATEGORY"], [25171, 25175, "TRAINED_CATEGORY"], [25187, 25203, "TRAINED_CATEGORY"], [25216, 25232, "TRAINED_CATEGORY"], [25247, 25263, "TRAINED_CATEGORY"], [25308, 25322, "TRAINED_CATEGORY"], [25324, 25329, "TRAINED_CATEGORY"], [25335, 25344, "TRAINED_CATEGORY"], [25346, 25352, "TRAINED_CATEGORY"], [25358, 25360, "TRAINED_CATEGORY"], [25425, 25438, "TRAINED_CATEGORY"], [25442, 25458, "TRAINED_CATEGORY"], [25494, 25504, "TRAINED_CATEGORY"], [25514, 25538, "TRAINED_CATEGORY"], [25543, 25553, "TRAINED_CATEGORY"], [25571, 25578, "TRAINED_CATEGORY"], [25581, 25586, "TRAINED_CATEGORY"], [25609, 25620, "TRAINED_CATEGORY"], [25627, 25636, "TRAINED_CATEGORY"], [25690, 25699, "TRAINED_CATEGORY"], [25741, 25756, "TRAINED_CATEGORY"], [25771, 25777, "TRAINED_CATEGORY"], [25796, 25823, "TRAINED_CATEGORY"], [25834, 25847, "TRAINED_CATEGORY"], [25848, 25852, "TRAINED_CATEGORY"], [25870, 25886, "TRAINED_CATEGORY"], [25894, 25907, "TRAINED_CATEGORY"], [25933, 25949, "TRAINED_CATEGORY"], [25958, 25988, "TRAINED_CATEGORY"], [25993, 26013, "TRAINED_CATEGORY"], [26019, 26026, "TRAINED_CATEGORY"], [26030, 26044, "TRAINED_CATEGORY"], [26047, 26067, "TRAINED_CATEGORY"], [26082, 26100, "TRAINED_CATEGORY"], [26104, 26114, "TRAINED_CATEGORY"], [26130, 26146, "TRAINED_CATEGORY"], [26150, 26164, "TRAINED_CATEGORY"], [26166, 26187, "TRAINED_CATEGORY"], [26202, 26220, "TRAINED_CATEGORY"], [26224, 26234, "TRAINED_CATEGORY"], [26250, 26266, "TRAINED_CATEGORY"], [26279, 26291, "TRAINED_CATEGORY"], [26296, 26312, "TRAINED_CATEGORY"], [26326, 26338, "TRAINED_CATEGORY"], [26345, 26352, "TRAINED_CATEGORY"], [26354, 26370, "TRAINED_CATEGORY"], [26384, 26390, "TRAINED_CATEGORY"], [26391, 26412, "TRAINED_CATEGORY"], [26425, 26441, "TRAINED_CATEGORY"], [26443, 26460, "TRAINED_CATEGORY"], [26493, 26505, "TRAINED_CATEGORY"], [26509, 26517, "TRAINED_CATEGORY"], [26519, 26535, "TRAINED_CATEGORY"], [26540, 26557, "TRAINED_CATEGORY"], [26588, 26614, "TRAINED_CATEGORY"], [26621, 26638, "TRAINED_CATEGORY"], [26642, 26646, "TRAINED_CATEGORY"], [26648, 26654, "TRAINED_CATEGORY"], [26656, 26661, "TRAINED_CATEGORY"], [26666, 26674, "TRAINED_CATEGORY"], [26684, 26693, "TRAINED_CATEGORY"], [26697, 26718, "TRAINED_CATEGORY"], [26722, 26738, "TRAINED_CATEGORY"], [26741, 26760, "TRAINED_CATEGORY"], [26767, 26784, "TRAINED_CATEGORY"], [26798, 26813, "TRAINED_CATEGORY"], [26843, 26851, "TRAINED_CATEGORY"], [26864, 26876, "TRAINED_CATEGORY"], [26881, 26897, "TRAINED_CATEGORY"], [26899, 26915, "TRAINED_CATEGORY"], [26940, 26950, "TRAINED_CATEGORY"], [26961, 26977, "TRAINED_CATEGORY"], [26983, 27009, "TRAINED_CATEGORY"], [27029, 27045, "TRAINED_CATEGORY"], [27047, 27051, "TRAINED_CATEGORY"], [27056, 27064, "TRAINED_CATEGORY"], [27066, 27079, "TRAINED_CATEGORY"], [27081, 27092, "TRAINED_CATEGORY"], [27098, 27107, "TRAINED_CATEGORY"], [27109, 27139, "TRAINED_CATEGORY"], [27150, 27161, "TRAINED_CATEGORY"], [27167, 27186, "TRAINED_CATEGORY"], [27202, 27220, "TRAINED_CATEGORY"], [27225, 27234, "TRAINED_CATEGORY"], [27256, 27272, "TRAINED_CATEGORY"], [27274, 27296, "TRAINED_CATEGORY"], [27333, 27347, "TRAINED_CATEGORY"], [27349, 27371, "TRAINED_CATEGORY"], [27381, 27385, "TRAINED_CATEGORY"], [27387, 27391, "TRAINED_CATEGORY"], [27418, 27428, "TRAINED_CATEGORY"], [27433, 27437, "TRAINED_CATEGORY"], [27448, 27455, "TRAINED_CATEGORY"], [27465, 27470, "TRAINED_CATEGORY"], [27481, 27495, "TRAINED_CATEGORY"], [27504, 27515, "TRAINED_CATEGORY"], [27520, 27536, "TRAINED_CATEGORY"], [27543, 27553, "TRAINED_CATEGORY"], [27562, 27576, "TRAINED_CATEGORY"], [27580, 27593, "TRAINED_CATEGORY"], [27596, 27625, "TRAINED_CATEGORY"], [27635, 27652, "TRAINED_CATEGORY"], [27656, 27668, "TRAINED_CATEGORY"], [84, 87, "ORG"], [128, 136, "ORG"], [209, 217, "GPE"], [247, 250, "ORG"], [945, 948, "ORG"], [1039, 1044, "PERSON"], [1400, 1406, "ORG"], [1453, 1459, "PRODUCT"], [1467, 1486, "PERSON"], [1488, 1497, "ORG"], [1499, 1507, "ORG"], [1509, 1520, "ORG"], [1526, 1541, "PERSON"], [1671, 1678, "ORG"], [2324, 2327, "ORG"], [2556, 2562, "ORG"], [2610, 2631, "QUANTITY"], [2633, 2641, "QUANTITY"], [2784, 2787, "CARDINAL"], [3050, 3053, "CARDINAL"], [3057, 3060, "CARDINAL"], [3187, 3191, "CARDINAL"], [3204, 3218, "DATE"], [3417, 3425, "DATE"], [3465, 3468, "CARDINAL"], [3635, 3647, "DATE"], [3669, 3673, "CARDINAL"], [3727, 3730, "CARDINAL"], [3808, 3819, "GPE"], [3986, 3989, "CARDINAL"], [4230, 4233, "CARDINAL"], [4663, 4677, "PERSON"], [4823, 4826, "CARDINAL"], [4876, 4883, "CARDINAL"], [4912, 4917, "CARDINAL"], [5020, 5023, "ORG"], [5106, 5111, "PERSON"], [5273, 5278, "ORDINAL"], [5676, 5682, "ORG"], [5792, 5797, "PERSON"], [6101, 6104, "ORG"], [6277, 6280, "ORG"], [6789, 6790, "CARDINAL"], [7024, 7025, "CARDINAL"], [7079, 7080, "CARDINAL"], [7123, 7124, "CARDINAL"], [7177, 7178, "CARDINAL"], [7217, 7218, "CARDINAL"], [7270, 7271, "CARDINAL"], [7342, 7345, "ORG"], [7443, 7447, "CARDINAL"], [7927, 7938, "PERSON"], [8275, 8278, "ORG"], [8551, 8556, "PERSON"], [8676, 8687, "GPE"], [8861, 8865, "CARDINAL"], [8866, 8877, "NORP"], [8899, 8902, "CARDINAL"], [8903, 8914, "NORP"], [9001, 9009, "ORG"], [9136, 9144, "ORG"], [9149, 9160, "GPE"], [9185, 9188, "ORG"], [9261, 9264, "CARDINAL"], [9331, 9340, "ORG"], [9376, 9380, "LOC"], [9499, 9502, "ORG"], [9641, 9645, "LOC"], [9709, 9714, "CARDINAL"], [9778, 9781, "ORG"], [9851, 9854, "CARDINAL"], [10023, 10034, "GPE"], [10172, 10175, "ORG"], [10288, 10300, "PRODUCT"], [10321, 10329, "GPE"], [10524, 10538, "PERSON"], [10539, 10544, "ORDINAL"], [10611, 10617, "MONEY"], [10757, 10760, "CARDINAL"], [10790, 10793, "ORG"], [10811, 10814, "CARDINAL"], [11093, 11098, "ORDINAL"], [11172, 11178, "PRODUCT"], [11247, 11252, "ORG"], [11267, 11270, "CARDINAL"], [11300, 11309, "CARDINAL"], [11328, 11333, "ORG"], [11407, 11409, "CARDINAL"], [11572, 11578, "MONEY"], [11631, 11636, "MONEY"], [11642, 11647, "MONEY"], [11902, 11915, "MONEY"], [11919, 11932, "PERCENT"], [12059, 12062, "ORG"], [12232, 12237, "PERSON"], [12282, 12294, "MONEY"], [12521, 12526, "MONEY"], [12574, 12581, "PRODUCT"], [12590, 12595, "MONEY"], [12637, 12643, "MONEY"], [12719, 12722, "ORG"], [12978, 12994, "MONEY"], [13057, 13062, "MONEY"], [13107, 13113, "MONEY"], [13147, 13157, "MONEY"], [13240, 13241, "MONEY"], [13507, 13510, "ORG"], [13561, 13564, "CARDINAL"], [13864, 13869, "PERSON"], [13895, 13904, "PERSON"], [14128, 14134, "MONEY"], [14655, 14667, "LOC"], [14671, 14679, "NORP"], [14703, 14707, "PERCENT"], [14915, 14919, "CARDINAL"], [14990, 14994, "CARDINAL"], [15009, 15035, "WORK_OF_ART"], [15105, 15108, "ORG"], [15206, 15211, "PERSON"], [15252, 15255, "CARDINAL"], [15256, 15262, "PRODUCT"], [15366, 15369, "CARDINAL"], [15375, 15391, "WORK_OF_ART"], [15400, 15404, "ORG"], [15494, 15544, "ORG"], [16285, 16288, "CARDINAL"], [16312, 16315, "CARDINAL"], [16462, 16477, "FAC"], [16509, 16514, "PERSON"], [16730, 16733, "ORG"], [16784, 16787, "CARDINAL"], [16901, 16924, "ORG"], [17052, 17057, "PERSON"], [17072, 17081, "ORG"], [17170, 17174, "CARDINAL"], [17178, 17185, "CARDINAL"], [17255, 17259, "CARDINAL"], [17278, 17282, "CARDINAL"], [17315, 17320, "CARDINAL"], [17354, 17358, "CARDINAL"], [17435, 17438, "ORG"], [17489, 17492, "CARDINAL"], [17522, 17540, "ORG"], [17630, 17668, "ORG"], [17808, 17813, "PERSON"], [17876, 17881, "PERSON"], [18160, 18171, "QUANTITY"], [18238, 18241, "ORG"], [18367, 18370, "ORG"], [18386, 18391, "PERSON"], [18518, 18521, "ORG"], [18537, 18540, "CARDINAL"], [18592, 18595, "CARDINAL"], [18641, 18644, "ORG"], [18701, 18704, "ORG"], [18904, 18907, "ORG"], [18958, 18961, "CARDINAL"], [19242, 19247, "PERSON"], [19537, 19549, "QUANTITY"], [19551, 19560, "QUANTITY"], [19679, 19686, "FAC"], [19757, 19779, "QUANTITY"], [20007, 20017, "DATE"], [20022, 20034, "QUANTITY"], [20036, 20045, "QUANTITY"], [20133, 20137, "GPE"], [20141, 20144, "PERCENT"], [20174, 20178, "CARDINAL"], [20182, 20186, "PERCENT"], [20190, 20194, "CARDINAL"], [20581, 20584, "CARDINAL"], [20620, 20634, "PERCENT"], [20724, 20727, "CARDINAL"], [20763, 20767, "PERCENT"], [21180, 21192, "ORG"], [21255, 21258, "ORG"], [21309, 21312, "CARDINAL"], [21438, 21470, "ORG"], [21604, 21609, "PERSON"], [21650, 21655, "PERSON"], [21790, 21806, "ORG"], [21833, 21835, "CARDINAL"], [21900, 21906, "ORG"], [21943, 21967, "WORK_OF_ART"], [21990, 22011, "ORG"], [22028, 22047, "WORK_OF_ART"], [22129, 22136, "PERSON"], [22142, 22161, "WORK_OF_ART"], [22265, 22272, "ORG"], [22352, 22355, "CARDINAL"], [22442, 22459, "QUANTITY"], [22461, 22470, "QUANTITY"], [22669, 22675, "PRODUCT"], [22750, 22757, "ORG"], [22986, 22993, "ORG"], [23158, 23161, "ORG"], [23212, 23215, "CARDINAL"], [23535, 23540, "PERSON"], [23589, 23594, "PERSON"], [23671, 23674, "CARDINAL"], [23844, 23847, "ORG"], [23858, 23863, "PERSON"], [23935, 23940, "ORG"], [24040, 24043, "CARDINAL"], [24186, 24189, "CARDINAL"], [24386, 24389, "ORG"], [24446, 24449, "CARDINAL"], [24561, 24580, "EVENT"], [24707, 24712, "PERSON"], [24727, 24732, "ORG"], [24746, 24764, "PRODUCT"], [25137, 25157, "QUANTITY"], [25159, 25165, "PERCENT"], [25191, 25196, "PERSON"], [25251, 25254, "ORG"], [25308, 25322, "ORG"], [25335, 25338, "CARDINAL"], [25346, 25352, "PERCENT"], [25375, 25378, "CARDINAL"], [25401, 25404, "CARDINAL"], [25410, 25417, "CARDINAL"], [25561, 25563, "CARDINAL"], [25571, 25578, "PERCENT"], [25581, 25586, "PERSON"], [25637, 25647, "CARDINAL"], [25700, 25709, "CARDINAL"], [25781, 25782, "CARDINAL"], [25784, 25785, "CARDINAL"], [25791, 25792, "CARDINAL"], [25800, 25803, "ORG"], [25806, 25823, "FAC"], [25874, 25877, "ORG"], [25937, 25940, "ORG"], [25997, 26000, "CARDINAL"], [26030, 26044, "ORG"], [26150, 26164, "ORG"], [26300, 26305, "PERSON"], [26358, 26361, "ORG"], [26464, 26469, "CARDINAL"], [26642, 26674, "ORG"], [26741, 26760, "PERSON"], [26788, 26793, "CARDINAL"], [26885, 26890, "PERSON"], [26903, 26909, "PRODUCT"], [26927, 26933, "ORDINAL"], [26954, 26959, "CARDINAL"], [27021, 27024, "CARDINAL"], [27056, 27064, "ORG"], [27066, 27079, "PERSON"], [27081, 27092, "ORG"], [27098, 27107, "ORG"], [27109, 27139, "ORG"], [27154, 27161, "GPE"], [27260, 27266, "PRODUCT"], [27421, 27428, "PRODUCT"], [27452, 27455, "ORG"], [27562, 27570, "ORG"]]}], ["This is a worked-through example showing the use of the analytic hierarchy process (AHP) in a practical decision situation.\nSee Analytic hierarchy process#Practical examples for context for this example.\n\n\n== Overview ==\nThis example describes the use of the AHP in choosing a leader for a company whose founder is about to retire. There are several competing candidates and several competing criteria for choosing the most suitable one. By using the AHP, the board of directors is able to choose the best candidate in a rational, transparent way that can be examined and understood by all concerned.\nThe diagram below shows the AHP hierarchy at the end of the decision making process. The goal is to choose the most suitable leader based on four specific criteria. Dick is the preferred alternative, with a priority of .493. He is preferred about a third more strongly than Tom, whose priority is .358, and about three times more strongly than Harry, whose priority is only .149. Experience is the most important criterion with respect to reaching the goal, followed by Charisma, Education, and Age. These factors are weighted .547, .270, .127, and .056, respectively.\nThe balance of this article describes the derivation of these priorities.\n\n\n== Example details ==\n\n\n=== Decision scenario ===\nThe company, founded in 1960, makes specialized industrial equipment. Its future success will depend on maintaining the strength of its older product lines and on generating a constant flow of new ones. The company's founder is retiring soon, and a consulting firm has developed a detailed plan for continuing its success in his absence. The plan will take five years to implement, and will replace the founder's highly subjective \"seat of the pants\" style with a more carefully thought out way of doing business. \nThe board of directors needs to choose someone to lead the company through the change and upheaval that implementing the consultant's plan will involve. In doing this work, the new leader will be required to make many unpopular decisions and take many unpopular actions. He or she will be expected to \u201cclear the air\u201d by stepping aside after the plan is fully implemented.\nSix months ago, the board said: \n\nAfter much thought and discussion, we have identified four criteria to be used in choosing the person to guide us through the upcoming period of change: experience, education, charisma and age. Experience is important because the job requires skills and knowledge that can only be developed through practical application. And though our beloved founder was a self-made man who didn\u2019t finish high school, the times demand that our new leader have an appropriate university education. Since the new leader will have to keep us all motivated during a difficult period of change, we prefer someone with an active, charismatic leadership style. Finally, the new leader's Age is important because he or she will need to have an appropriate career path after stepping down five years from now. \u2014 Board of directors, letter to employees and shareholders\nLast week, they said: \n\nAfter an extensive search, we have selected three candidates for this very challenging position. All are presently executives with the company. Choosing among them will be difficult, but we plan to announce our decision shortly. \u2014 Board of directors, followup letter to employees and shareholders\nThe three candidates are Tom, Dick, and Harry. Summaries of their backgrounds are shown below:\n\n\n=== Decision hierarchy ===\nThe AHP hierarchy for this decision is shown below.\n\nAs the decision makers continue with the AHP, they will determine priorities for the candidates with respect to each of the decision criteria, and priorities for each of the criteria with respect to their importance in reaching the goal.The priorities will then be combined throughout the hierarchy to give an overall priority for each  candidate. The candidate with the highest priority will be the most suitable Alternative, and the ratios of the candidates' priorities will indicate their relative strengths with respect to the Goal.\n\n\n=== Pairwise comparisons ===\nThe priorities will be derived from a series of measurements: pairwise comparisons involving all the nodes.\nEach colored box in the hierarchy diagram above is called a node. \nThe nodes at each level will be compared, two by two, with respect to their contribution to the nodes above them. The results of these comparisons will be entered into a matrix which is processed mathematically to derive the priorities for all the nodes on the level.The comparisons can be made in any sequence, but in this example we will begin by comparing the Alternatives with respect to their strengths in meeting each of the Criteria. Then we'll compare the Criteria with respect to their importance to reaching the Goal.Since there are three alternatives (Tom, Dick, and Harry) and we need to compare each one to each of the others, the decision makers (the Board) will make three pairwise comparisons with respect to each Criterion: Tom vs. Dick, Tom vs. Harry, and Dick vs. Harry. For each comparison, the Board will first judge which member of the pair is weaker with respect to the Criterion under consideration. Then they will assign a relative weight to the other candidate.\nThey will use the AHP fundamental scale in assigning the weights:\n\n\n==== Alternatives vs. criteria ====\nExperience\nUsing their knowledge of the work the leaders will be required to do, the board needs to evaluate the candidates' strengths with respect to experience. Though they have good information about each candidate's work history, there is no such thing as an objective scale for measuring \"experience.\" Thanks to the AHP, the Board will be able to develop a scale, applying only to this one case, that measures the candidates' relative strengths with respect to experience.\nHere is the Board's thinking about experience:\n\nThe leader will implement a wide-ranging plan that involves major changes to a successful business. This work requires skills, knowledge, wisdom, and judgment that are usually present only in seasoned executives. Furthermore, the company is so complex and specialized that only direct experience inside it can equip a prospective leader for his job. Outside experience is also important, since it provides perspective and a view of the larger picture. \u2014 Board of Directors, Internal Memorandum\nAs a reminder, here is their summary of the candidates' experience:\n\nThe next step in the AHP is to compare pairs of candidates with respect to Experience. For each comparison, the Board decides which candidate is the weaker with respect to Experience, giving his experience a weight of 1. Then, using the AHP Fundamental Scale, they assign a weight to the experience of the other candidate.\nTheir comparisons are summarized below. (A summary in this form is not an essential part of the AHP. It is presented here only to help readers understand this example. The colors in the squares will help them see where each entry belongs in the AHP matrix):\n\nThe next step is to transfer the weights to a matrix, using a method unique to the AHP. For each pairwise comparison, the number representing the greater weight is transferred to the box of the corresponding color; the reciprocal of that number is put into the box of the color corresponding to the smaller number:\n\nBy processing this matrix mathematically, the AHP derives priorities for the candidates with respect to Experience. The priorities are measurements of their relative strengths, derived from the judgments of the decision makers as entered into the matrix. Mathematically speaking, they are the values in the matrix's principal right eigenvector. These values can be calculated in many ways, including by hand, or with a spreadsheet program, or by using specialized AHP software. They are shown below to the right of the matrix, along with an Inconsistency Factor computed by the specialized AHP software that was used to process the data:\n\nEducation\nNow the Board needs to evaluate the candidates with respect to Education. Here is their thinking on the subject:\n\nThe leader needs to have a good education, preferably with a recent MBA or engineering degree. Our founder is a self-made man who didn\u2019t finish high school. He created a successful company that relies strongly on his personal insights and \u201cseat-of-the pants\u201d judgment. But when he retires and we move into a more complex future, we need to become more thoughtfully run. Having an educated leader is vitally important to this.\nEducation is also important because our employees, particularly the technical staff, are hungry to have it in their leader. Though they love and respect \u201cthe Old Man,\u201d they have often been frustrated by his lack of appreciation for today's tools of business, engineering, and manufacturing. \u2014 Board of Directors, Internal Memorandum\nThough a person's education can be measured by academic degrees, grades and honors, those measurements are not so useful in this non-academic situation. Through its system of pairwise comparisons, the AHP can develop accurate measurements that are perfectly suited to the decision at hand. Here is the Board's summary of the candidates' educational backgrounds:\n\nAs they did previously with Experience, the Board now compares pairs of candidates with respect to Education. For each comparison, the Board decides which candidate is the weaker with respect to Education, giving his education a weight of 1. Then, using the AHP Fundamental Scale, they assign a weight to the education of the other candidate. For the sake of our example, we again provide a table summarizing their deliberations:\n\nThe Board transcribes its judgments into the AHP matrix shown below. Looking at Tom's row in the matrix, we can see that his education has three times the weight of Dick's, but only a fifth the weight of Harry's. Similar relationships can be seen in the other two rows, where Dick's education is strongly dominated by Tom's and Harry's, while Harry's education strongly dominates that of both the other men.\n\nOnce again we use AHP software to derive priorities from the numbers in the AHP matrix:\n\nThe priorities tell us that, according to the judgment of the decision makers, Harry's education is by far the strongest of the three. Generally speaking, it dominates Tom's by a factor of almost 4, (0.731\u00f70.188=3.95) and Dick's by a factor of 9 (0.731\u00f70.081=9.02).\nCharisma\nThe Board's next step is to pairwise compare the Alternatives (candidates) with respect to Charisma. Here's what they have to say about it:\n\nAs implementation of the plan proceeds, the leader will need to overcome people\u2019s natural resistance to change. We think he will often need to wield influence on the basis of his personal charm and appeal, rather than on talk, logic, or authority alone. We have called this charm and appeal \u201ccharisma\u201d. It will be an important factor in the leader\u2019s ability to implement the plan. \u2014 Board of Directors, Internal Memorandum\nHere is their summary of the candidates' leadership qualities:\n\nAnd here are their judgments about those qualities as they relate to Charisma:\n\nPutting their judgments into the matrix and processing it with the AHP software, they get:\n\nNote that even though \"charisma\" is a highly subjective concept with no imaginable measurement scale, the AHP has allowed the board to measure its relative strength among these three candidates. Also note that with different candidates, or even with different board members, the measurements would likely be different as well. The AHP's measurements apply only to the specific case at hand.\nAge\nA person's age can be determined with a precision of days or even minutes. But such measurements aren't highly useful in making the decision at hand, since there is more to \"Age\" in this context than mere chronology.\nAlso, there are U.S. laws against employment discrimination by age. Anyone using age as a decision factor must be very explicit about their reasons and justifications. In this case, it wouldn't be good if an unsuccessful candidate decided to sue the company on the basis of age discrimination.\nThe Board has said this about Age:\n\nThe leader will be expected to step down five years from now. For his benefit and ours, we need to consider how old he will be at that time. If he is at or near retirement age, he can just retire, possibly remaining with us in a consulting capacity. If he is younger, he will have more years to work, but there will likely be no place for him in our company. Based on his success as our leader, he might or might not be easily employable elsewhere. He could possibly join a competitor and take key people with him, in spite of any non-compete agreements we might negotiate.\nThe leader's age also affects his ability to interact with our workforce. Many of the people involved with our important legacy products are over age 55. Most of those connected with our newer products are in their 20s and 30s. It is important that the leader is able to relate to both these age groups, and that they are able to accept his leadership. \u2014 Board of Directors, Internal Memorandum\nTom, Dick, and Harry are now 50, 60, and 30 years old respectively. Here's a summary of the Board's evaluation of them with respect to Age:\n\nTransferring their judgments to an AHP matrix and processing it with software yields this result for the Alternatives with respect to Age:\n\n\n==== Criteria vs. the Goal ====\nNow that the decision makers have evaluated the Alternatives (candidates) with respect to their strength in meeting the Criteria, they need to evaluate the Criteria with respect to their importance in reaching the goal.\nOnce again they do this by a series of pairwise comparisons. As with the Alternatives, this part of the process requires much discussion and debate among the decision makers.In this case, the Board agrees on these relative weights for the various pairs of Criteria:\n\nNote that pairwise comparison of four nodes requires six separate comparisons, while that of three nodes requires only three.These comparisons require a larger matrix, but it is processed in the same way as the smaller ones. Here is the matrix for the Criteria, along with the resulting priorities and Consistency Factor:\n\nNote that, in this decision, Experience, the highest ranked Criterion, is about twice as important in reaching the goal as the second-highest ranked Criterion, Charisma. Similarly, Charisma is about twice as important as Education, which in turn is more than twice as important as Age.\n\n\n=== Synthesizing final priorities ===\nNow that we know the priorities of the Criteria with respect to the Goal, and the priorities of the Alternatives with respect to the Criteria, we can calculate the priorities of the Alternatives with respect to the Goal. This is a straightforward matter of multiplying and adding, carried out over the whole of the hierarchy.In our example, each Alternative's priority with respect to reaching the Goal is the sum of:\n\nHis priority with respect to Experience, multiplied by Experience's priority with respect to the Goal, and\nHis priority with respect to Education, multiplied by Education's priority with respect to the Goal, and\nHis priority with respect to Charisma, multiplied by Charisma's priority with respect to the Goal, and\nHis priority with respect to Age, multiplied by Age's priority with respect to the GoalHere are the calculations for the Candidates with respect to the Criteria:\n\nLooking only at Tom, we can see that his priority with respect to the Goal is 0.358, calculated as follows:\n\nTom's priority with respect to Experience is 0.217 x 0.547 = 0.119, plus\nTom's priority with respect to Education is 0.188 x 0.127 = 0.024, plus\nTom's priority with respect to Charisma is 0.703 x 0.270 = 0.201, plus\nTom's priority with respect to Age is 0.265 * 0.056 = 0.015,\nFor a total of 0.119 + 0.024 + 0.201 + 0.015 = 0.358Here are the overall priorities for all of the Candidates:\n\n\n=== Making the decision ===\nBased on the Board's choice of decision criteria, on their judgments about the relative importance of each, and on their judgments about each candidate with respect to each of the criteria, Dick, with a priority of 0.492, is by far the most suitable candidate. Tom, with a priority of 0.358, is second, and Harry, at 0.149, is third.\nThe Board should choose Dick as the company's new leader.\nBecause they have used the AHP, it is easy for them to trace their thinking and to justify the steps along the way to their decision. If they have second thoughts about the final outcome, they can revisit the process and make changes if appropriate. And if they choose to, they can reveal the details of their process to their consultants and confidants, to the candidates, to the shareholders, or to anyone else who might be concerned with the decision.\n\n\n== References ==\n\n\n=== Notes ===\n\n\n=== Bibliography ===\nThe Tom, Dick, and Harry example draws heavily on principles described in the books below, which are the current basic texts on the AHP. They contain detailed descriptions of the theory underlying the process, plus many examples of its use in the real world. \n\nSaaty, Thomas L. (2006). Fundamentals of Decision Making and Priority Theory. Pittsburgh, Pennsylvania: RWS Publications. ISBN 0-9620317-6-3.\nSaaty, Thomas L. (2008). Decision Making for Leaders: The Analytic Hierarchy Process for Decisions in a Complex World. Pittsburgh, Pennsylvania: RWS Publications. ISBN 0-9620317-8-X.\nSaaty, Thomas L. (2010). Principia Mathematica Decernendi: Mathematical Principles of Decision Making. Pittsburgh, Pennsylvania: RWS Publications. ISBN 978-1-888603-10-1.", {"entities": [[8, 32, "TRAINED_CATEGORY"], [41, 48, "TRAINED_CATEGORY"], [52, 82, "TRAINED_CATEGORY"], [83, 87, "TRAINED_CATEGORY"], [92, 122, "TRAINED_CATEGORY"], [128, 173, "TRAINED_CATEGORY"], [178, 185, "TRAINED_CATEGORY"], [190, 202, "TRAINED_CATEGORY"], [221, 233, "TRAINED_CATEGORY"], [244, 251, "TRAINED_CATEGORY"], [255, 262, "TRAINED_CATEGORY"], [275, 283, "TRAINED_CATEGORY"], [288, 297, "TRAINED_CATEGORY"], [298, 311, "TRAINED_CATEGORY"], [342, 370, "TRAINED_CATEGORY"], [375, 401, "TRAINED_CATEGORY"], [447, 454, "TRAINED_CATEGORY"], [456, 465, "TRAINED_CATEGORY"], [469, 478, "TRAINED_CATEGORY"], [497, 515, "TRAINED_CATEGORY"], [519, 546, "TRAINED_CATEGORY"], [601, 612, "TRAINED_CATEGORY"], [625, 642, "TRAINED_CATEGORY"], [646, 653, "TRAINED_CATEGORY"], [657, 684, "TRAINED_CATEGORY"], [686, 694, "TRAINED_CATEGORY"], [708, 732, "TRAINED_CATEGORY"], [742, 764, "TRAINED_CATEGORY"], [766, 770, "TRAINED_CATEGORY"], [774, 799, "TRAINED_CATEGORY"], [806, 816, "TRAINED_CATEGORY"], [826, 828, "TRAINED_CATEGORY"], [875, 878, "TRAINED_CATEGORY"], [880, 894, "TRAINED_CATEGORY"], [945, 950, "TRAINED_CATEGORY"], [952, 966, "TRAINED_CATEGORY"], [981, 991, "TRAINED_CATEGORY"], [995, 1023, "TRAINED_CATEGORY"], [1029, 1036, "TRAINED_CATEGORY"], [1049, 1057, "TRAINED_CATEGORY"], [1071, 1079, "TRAINED_CATEGORY"], [1081, 1090, "TRAINED_CATEGORY"], [1096, 1099, "TRAINED_CATEGORY"], [1101, 1114, "TRAINED_CATEGORY"], [1170, 1181, "TRAINED_CATEGORY"], [1185, 1197, "TRAINED_CATEGORY"], [1208, 1222, "TRAINED_CATEGORY"], [1226, 1242, "TRAINED_CATEGORY"], [1249, 1264, "TRAINED_CATEGORY"], [1274, 1291, "TRAINED_CATEGORY"], [1296, 1307, "TRAINED_CATEGORY"], [1332, 1364, "TRAINED_CATEGORY"], [1366, 1384, "TRAINED_CATEGORY"], [1412, 1424, "TRAINED_CATEGORY"], [1428, 1451, "TRAINED_CATEGORY"], [1470, 1485, "TRAINED_CATEGORY"], [1489, 1497, "TRAINED_CATEGORY"], [1499, 1520, "TRAINED_CATEGORY"], [1543, 1560, "TRAINED_CATEGORY"], [1575, 1590, "TRAINED_CATEGORY"], [1606, 1617, "TRAINED_CATEGORY"], [1621, 1632, "TRAINED_CATEGORY"], [1634, 1642, "TRAINED_CATEGORY"], [1653, 1663, "TRAINED_CATEGORY"], [1695, 1732, "TRAINED_CATEGORY"], [1736, 1745, "TRAINED_CATEGORY"], [1745, 1752, "TRAINED_CATEGORY"], [1787, 1790, "TRAINED_CATEGORY"], [1800, 1808, "TRAINED_CATEGORY"], [1811, 1820, "TRAINED_CATEGORY"], [1824, 1833, "TRAINED_CATEGORY"], [1850, 1857, "TRAINED_CATEGORY"], [1866, 1877, "TRAINED_CATEGORY"], [1886, 1896, "TRAINED_CATEGORY"], [1901, 1909, "TRAINED_CATEGORY"], [1928, 1949, "TRAINED_CATEGORY"], [1973, 1982, "TRAINED_CATEGORY"], [1984, 1998, "TRAINED_CATEGORY"], [2024, 2048, "TRAINED_CATEGORY"], [2058, 2080, "TRAINED_CATEGORY"], [2082, 2084, "TRAINED_CATEGORY"], [2088, 2091, "TRAINED_CATEGORY"], [2119, 2126, "TRAINED_CATEGORY"], [2152, 2160, "TRAINED_CATEGORY"], [2199, 2208, "TRAINED_CATEGORY"], [2223, 2235, "TRAINED_CATEGORY"], [2240, 2250, "TRAINED_CATEGORY"], [2252, 2254, "TRAINED_CATEGORY"], [2271, 2284, "TRAINED_CATEGORY"], [2308, 2318, "TRAINED_CATEGORY"], [2328, 2330, "TRAINED_CATEGORY"], [2339, 2358, "TRAINED_CATEGORY"], [2362, 2368, "TRAINED_CATEGORY"], [2370, 2380, "TRAINED_CATEGORY"], [2382, 2391, "TRAINED_CATEGORY"], [2393, 2401, "TRAINED_CATEGORY"], [2406, 2409, "TRAINED_CATEGORY"], [2411, 2421, "TRAINED_CATEGORY"], [2443, 2450, "TRAINED_CATEGORY"], [2460, 2466, "TRAINED_CATEGORY"], [2471, 2480, "TRAINED_CATEGORY"], [2516, 2537, "TRAINED_CATEGORY"], [2550, 2569, "TRAINED_CATEGORY"], [2574, 2589, "TRAINED_CATEGORY"], [2590, 2593, "TRAINED_CATEGORY"], [2608, 2619, "TRAINED_CATEGORY"], [2621, 2630, "TRAINED_CATEGORY"], [2643, 2657, "TRAINED_CATEGORY"], [2663, 2698, "TRAINED_CATEGORY"], [2706, 2720, "TRAINED_CATEGORY"], [2739, 2741, "TRAINED_CATEGORY"], [2763, 2781, "TRAINED_CATEGORY"], [2785, 2791, "TRAINED_CATEGORY"], [2793, 2795, "TRAINED_CATEGORY"], [2803, 2810, "TRAINED_CATEGORY"], [2816, 2855, "TRAINED_CATEGORY"], [2866, 2886, "TRAINED_CATEGORY"], [2908, 2910, "TRAINED_CATEGORY"], [2914, 2917, "TRAINED_CATEGORY"], [2936, 2962, "TRAINED_CATEGORY"], [3004, 3011, "TRAINED_CATEGORY"], [3015, 3024, "TRAINED_CATEGORY"], [3026, 3032, "TRAINED_CATEGORY"], [3036, 3045, "TRAINED_CATEGORY"], [3050, 3062, "TRAINED_CATEGORY"], [3074, 3078, "TRAINED_CATEGORY"], [3093, 3112, "TRAINED_CATEGORY"], [3114, 3116, "TRAINED_CATEGORY"], [3131, 3147, "TRAINED_CATEGORY"], [3152, 3182, "TRAINED_CATEGORY"], [3202, 3212, "TRAINED_CATEGORY"], [3218, 3229, "TRAINED_CATEGORY"], [3246, 3250, "TRAINED_CATEGORY"], [3274, 3276, "TRAINED_CATEGORY"], [3294, 3306, "TRAINED_CATEGORY"], [3316, 3323, "TRAINED_CATEGORY"], [3327, 3336, "TRAINED_CATEGORY"], [3338, 3353, "TRAINED_CATEGORY"], [3357, 3366, "TRAINED_CATEGORY"], [3371, 3383, "TRAINED_CATEGORY"], [3384, 3404, "TRAINED_CATEGORY"], [3409, 3412, "TRAINED_CATEGORY"], [3414, 3418, "TRAINED_CATEGORY"], [3424, 3429, "TRAINED_CATEGORY"], [3431, 3440, "TRAINED_CATEGORY"], [3444, 3461, "TRAINED_CATEGORY"], [3485, 3503, "TRAINED_CATEGORY"], [3508, 3525, "TRAINED_CATEGORY"], [3530, 3543, "TRAINED_CATEGORY"], [3564, 3583, "TRAINED_CATEGORY"], [3598, 3605, "TRAINED_CATEGORY"], [3607, 3611, "TRAINED_CATEGORY"], [3627, 3637, "TRAINED_CATEGORY"], [3642, 3656, "TRAINED_CATEGORY"], [3662, 3669, "TRAINED_CATEGORY"], [3681, 3702, "TRAINED_CATEGORY"], [3708, 3718, "TRAINED_CATEGORY"], [3731, 3743, "TRAINED_CATEGORY"], [3749, 3756, "TRAINED_CATEGORY"], [3760, 3776, "TRAINED_CATEGORY"], [3789, 3797, "TRAINED_CATEGORY"], [3798, 3812, "TRAINED_CATEGORY"], [3846, 3859, "TRAINED_CATEGORY"], [3868, 3887, "TRAINED_CATEGORY"], [3892, 3907, "TRAINED_CATEGORY"], [3909, 3922, "TRAINED_CATEGORY"], [3928, 3948, "TRAINED_CATEGORY"], [3957, 3986, "TRAINED_CATEGORY"], [3992, 4002, "TRAINED_CATEGORY"], [4006, 4032, "TRAINED_CATEGORY"], [4047, 4071, "TRAINED_CATEGORY"], [4077, 4084, "TRAINED_CATEGORY"], [4088, 4096, "TRAINED_CATEGORY"], [4104, 4112, "TRAINED_CATEGORY"], [4113, 4124, "TRAINED_CATEGORY"], [4129, 4143, "TRAINED_CATEGORY"], [4165, 4173, "TRAINED_CATEGORY"], [4177, 4189, "TRAINED_CATEGORY"], [4200, 4211, "TRAINED_CATEGORY"], [4222, 4235, "TRAINED_CATEGORY"], [4237, 4253, "TRAINED_CATEGORY"], [4257, 4278, "TRAINED_CATEGORY"], [4304, 4313, "TRAINED_CATEGORY"], [4317, 4327, "TRAINED_CATEGORY"], [4363, 4370, "TRAINED_CATEGORY"], [4374, 4392, "TRAINED_CATEGORY"], [4396, 4405, "TRAINED_CATEGORY"], [4412, 4416, "TRAINED_CATEGORY"], [4418, 4429, "TRAINED_CATEGORY"], [4433, 4450, "TRAINED_CATEGORY"], [4472, 4480, "TRAINED_CATEGORY"], [4525, 4539, "TRAINED_CATEGORY"], [4544, 4557, "TRAINED_CATEGORY"], [4561, 4570, "TRAINED_CATEGORY"], [4571, 4586, "TRAINED_CATEGORY"], [4602, 4614, "TRAINED_CATEGORY"], [4623, 4635, "TRAINED_CATEGORY"], [4636, 4638, "TRAINED_CATEGORY"], [4663, 4679, "TRAINED_CATEGORY"], [4685, 4692, "TRAINED_CATEGORY"], [4696, 4711, "TRAINED_CATEGORY"], [4731, 4743, "TRAINED_CATEGORY"], [4750, 4752, "TRAINED_CATEGORY"], [4764, 4776, "TRAINED_CATEGORY"], [4782, 4789, "TRAINED_CATEGORY"], [4793, 4809, "TRAINED_CATEGORY"], [4822, 4830, "TRAINED_CATEGORY"], [4847, 4865, "TRAINED_CATEGORY"], [4867, 4870, "TRAINED_CATEGORY"], [4872, 4876, "TRAINED_CATEGORY"], [4882, 4887, "TRAINED_CATEGORY"], [4893, 4895, "TRAINED_CATEGORY"], [4912, 4920, "TRAINED_CATEGORY"], [4932, 4942, "TRAINED_CATEGORY"], [4944, 4963, "TRAINED_CATEGORY"], [4965, 4974, "TRAINED_CATEGORY"], [4986, 5012, "TRAINED_CATEGORY"], [5018, 5025, "TRAINED_CATEGORY"], [5029, 5043, "TRAINED_CATEGORY"], [5045, 5048, "TRAINED_CATEGORY"], [5053, 5057, "TRAINED_CATEGORY"], [5059, 5062, "TRAINED_CATEGORY"], [5067, 5072, "TRAINED_CATEGORY"], [5078, 5082, "TRAINED_CATEGORY"], [5087, 5092, "TRAINED_CATEGORY"], [5098, 5113, "TRAINED_CATEGORY"], [5115, 5124, "TRAINED_CATEGORY"], [5142, 5154, "TRAINED_CATEGORY"], [5158, 5166, "TRAINED_CATEGORY"], [5182, 5189, "TRAINED_CATEGORY"], [5193, 5206, "TRAINED_CATEGORY"], [5213, 5226, "TRAINED_CATEGORY"], [5233, 5237, "TRAINED_CATEGORY"], [5250, 5267, "TRAINED_CATEGORY"], [5271, 5290, "TRAINED_CATEGORY"], [5292, 5296, "TRAINED_CATEGORY"], [5306, 5331, "TRAINED_CATEGORY"], [5345, 5356, "TRAINED_CATEGORY"], [5365, 5377, "TRAINED_CATEGORY"], [5382, 5390, "TRAINED_CATEGORY"], [5396, 5406, "TRAINED_CATEGORY"], [5413, 5428, "TRAINED_CATEGORY"], [5432, 5440, "TRAINED_CATEGORY"], [5441, 5452, "TRAINED_CATEGORY"], [5477, 5486, "TRAINED_CATEGORY"], [5505, 5530, "TRAINED_CATEGORY"], [5536, 5543, "TRAINED_CATEGORY"], [5547, 5557, "TRAINED_CATEGORY"], [5566, 5570, "TRAINED_CATEGORY"], [5576, 5592, "TRAINED_CATEGORY"], [5599, 5628, "TRAINED_CATEGORY"], [5639, 5652, "TRAINED_CATEGORY"], [5656, 5674, "TRAINED_CATEGORY"], [5689, 5700, "TRAINED_CATEGORY"], [5713, 5720, "TRAINED_CATEGORY"], [5722, 5731, "TRAINED_CATEGORY"], [5756, 5763, "TRAINED_CATEGORY"], [5782, 5795, "TRAINED_CATEGORY"], [5811, 5845, "TRAINED_CATEGORY"], [5851, 5858, "TRAINED_CATEGORY"], [5862, 5872, "TRAINED_CATEGORY"], [5909, 5919, "TRAINED_CATEGORY"], [5922, 5932, "TRAINED_CATEGORY"], [5948, 5967, "TRAINED_CATEGORY"], [5982, 5995, "TRAINED_CATEGORY"], [5999, 6020, "TRAINED_CATEGORY"], [6022, 6031, "TRAINED_CATEGORY"], [6041, 6047, "TRAINED_CATEGORY"], [6049, 6058, "TRAINED_CATEGORY"], [6060, 6066, "TRAINED_CATEGORY"], [6072, 6080, "TRAINED_CATEGORY"], [6114, 6133, "TRAINED_CATEGORY"], [6148, 6159, "TRAINED_CATEGORY"], [6195, 6217, "TRAINED_CATEGORY"], [6225, 6227, "TRAINED_CATEGORY"], [6238, 6258, "TRAINED_CATEGORY"], [6263, 6270, "TRAINED_CATEGORY"], [6272, 6290, "TRAINED_CATEGORY"], [6316, 6318, "TRAINED_CATEGORY"], [6328, 6339, "TRAINED_CATEGORY"], [6354, 6372, "TRAINED_CATEGORY"], [6374, 6381, "TRAINED_CATEGORY"], [6385, 6394, "TRAINED_CATEGORY"], [6396, 6415, "TRAINED_CATEGORY"], [6419, 6429, "TRAINED_CATEGORY"], [6439, 6452, "TRAINED_CATEGORY"], [6456, 6482, "TRAINED_CATEGORY"], [6485, 6498, "TRAINED_CATEGORY"], [6502, 6509, "TRAINED_CATEGORY"], [6524, 6529, "TRAINED_CATEGORY"], [6533, 6543, "TRAINED_CATEGORY"], [6549, 6556, "TRAINED_CATEGORY"], [6560, 6570, "TRAINED_CATEGORY"], [6576, 6591, "TRAINED_CATEGORY"], [6593, 6602, "TRAINED_CATEGORY"], [6611, 6626, "TRAINED_CATEGORY"], [6646, 6653, "TRAINED_CATEGORY"], [6657, 6667, "TRAINED_CATEGORY"], [6676, 6690, "TRAINED_CATEGORY"], [6691, 6699, "TRAINED_CATEGORY"], [6718, 6743, "TRAINED_CATEGORY"], [6745, 6749, "TRAINED_CATEGORY"], [6757, 6765, "TRAINED_CATEGORY"], [6769, 6783, "TRAINED_CATEGORY"], [6787, 6806, "TRAINED_CATEGORY"], [6808, 6825, "TRAINED_CATEGORY"], [6849, 6858, "TRAINED_CATEGORY"], [6862, 6871, "TRAINED_CATEGORY"], [6879, 6896, "TRAINED_CATEGORY"], [6900, 6907, "TRAINED_CATEGORY"], [6909, 6911, "TRAINED_CATEGORY"], [6943, 6950, "TRAINED_CATEGORY"], [6962, 6974, "TRAINED_CATEGORY"], [6976, 6986, "TRAINED_CATEGORY"], [6990, 7001, "TRAINED_CATEGORY"], [7012, 7016, "TRAINED_CATEGORY"], [7027, 7037, "TRAINED_CATEGORY"], [7049, 7063, "TRAINED_CATEGORY"], [7067, 7080, "TRAINED_CATEGORY"], [7096, 7107, "TRAINED_CATEGORY"], [7111, 7119, "TRAINED_CATEGORY"], [7127, 7135, "TRAINED_CATEGORY"], [7146, 7153, "TRAINED_CATEGORY"], [7159, 7183, "TRAINED_CATEGORY"], [7185, 7195, "TRAINED_CATEGORY"], [7209, 7227, "TRAINED_CATEGORY"], [7246, 7253, "TRAINED_CATEGORY"], [7257, 7280, "TRAINED_CATEGORY"], [7282, 7296, "TRAINED_CATEGORY"], [7300, 7311, "TRAINED_CATEGORY"], [7324, 7331, "TRAINED_CATEGORY"], [7335, 7344, "TRAINED_CATEGORY"], [7362, 7380, "TRAINED_CATEGORY"], [7397, 7408, "TRAINED_CATEGORY"], [7425, 7432, "TRAINED_CATEGORY"], [7441, 7451, "TRAINED_CATEGORY"], [7456, 7470, "TRAINED_CATEGORY"], [7476, 7483, "TRAINED_CATEGORY"], [7487, 7497, "TRAINED_CATEGORY"], [7499, 7513, "TRAINED_CATEGORY"], [7518, 7530, "TRAINED_CATEGORY"], [7534, 7558, "TRAINED_CATEGORY"], [7573, 7586, "TRAINED_CATEGORY"], [7590, 7609, "TRAINED_CATEGORY"], [7626, 7636, "TRAINED_CATEGORY"], [7663, 7667, "TRAINED_CATEGORY"], [7672, 7682, "TRAINED_CATEGORY"], [7686, 7726, "TRAINED_CATEGORY"], [7728, 7740, "TRAINED_CATEGORY"], [7762, 7771, "TRAINED_CATEGORY"], [7786, 7790, "TRAINED_CATEGORY"], [7800, 7821, "TRAINED_CATEGORY"], [7835, 7859, "TRAINED_CATEGORY"], [7861, 7865, "TRAINED_CATEGORY"], [7885, 7894, "TRAINED_CATEGORY"], [7898, 7908, "TRAINED_CATEGORY"], [7921, 7944, "TRAINED_CATEGORY"], [7957, 7985, "TRAINED_CATEGORY"], [8011, 8019, "TRAINED_CATEGORY"], [8022, 8031, "TRAINED_CATEGORY"], [8036, 8045, "TRAINED_CATEGORY"], [8064, 8078, "TRAINED_CATEGORY"], [8084, 8091, "TRAINED_CATEGORY"], [8095, 8104, "TRAINED_CATEGORY"], [8114, 8128, "TRAINED_CATEGORY"], [8132, 8143, "TRAINED_CATEGORY"], [8146, 8156, "TRAINED_CATEGORY"], [8171, 8187, "TRAINED_CATEGORY"], [8205, 8239, "TRAINED_CATEGORY"], [8241, 8252, "TRAINED_CATEGORY"], [8256, 8271, "TRAINED_CATEGORY"], [8272, 8275, "TRAINED_CATEGORY"], [8290, 8301, "TRAINED_CATEGORY"], [8303, 8305, "TRAINED_CATEGORY"], [8314, 8334, "TRAINED_CATEGORY"], [8359, 8380, "TRAINED_CATEGORY"], [8394, 8403, "TRAINED_CATEGORY"], [8424, 8426, "TRAINED_CATEGORY"], [8439, 8441, "TRAINED_CATEGORY"], [8452, 8473, "TRAINED_CATEGORY"], [8475, 8477, "TRAINED_CATEGORY"], [8523, 8541, "TRAINED_CATEGORY"], [8572, 8581, "TRAINED_CATEGORY"], [8608, 8621, "TRAINED_CATEGORY"], [8623, 8655, "TRAINED_CATEGORY"], [8676, 8678, "TRAINED_CATEGORY"], [8682, 8694, "TRAINED_CATEGORY"], [8703, 8707, "TRAINED_CATEGORY"], [8726, 8737, "TRAINED_CATEGORY"], [8740, 8744, "TRAINED_CATEGORY"], [8775, 8783, "TRAINED_CATEGORY"], [8787, 8799, "TRAINED_CATEGORY"], [8804, 8817, "TRAINED_CATEGORY"], [8821, 8829, "TRAINED_CATEGORY"], [8831, 8842, "TRAINED_CATEGORY"], [8848, 8861, "TRAINED_CATEGORY"], [8863, 8870, "TRAINED_CATEGORY"], [8874, 8883, "TRAINED_CATEGORY"], [8885, 8904, "TRAINED_CATEGORY"], [8912, 8932, "TRAINED_CATEGORY"], [8952, 8968, "TRAINED_CATEGORY"], [8970, 8976, "TRAINED_CATEGORY"], [8981, 8987, "TRAINED_CATEGORY"], [8989, 9007, "TRAINED_CATEGORY"], [9029, 9056, "TRAINED_CATEGORY"], [9066, 9076, "TRAINED_CATEGORY"], [9080, 9100, "TRAINED_CATEGORY"], [9102, 9109, "TRAINED_CATEGORY"], [9122, 9143, "TRAINED_CATEGORY"], [9173, 9185, "TRAINED_CATEGORY"], [9189, 9193, "TRAINED_CATEGORY"], [9203, 9222, "TRAINED_CATEGORY"], [9226, 9265, "TRAINED_CATEGORY"], [9271, 9275, "TRAINED_CATEGORY"], [9296, 9306, "TRAINED_CATEGORY"], [9308, 9317, "TRAINED_CATEGORY"], [9331, 9336, "TRAINED_CATEGORY"], [9340, 9350, "TRAINED_CATEGORY"], [9356, 9363, "TRAINED_CATEGORY"], [9367, 9376, "TRAINED_CATEGORY"], [9382, 9397, "TRAINED_CATEGORY"], [9399, 9408, "TRAINED_CATEGORY"], [9417, 9432, "TRAINED_CATEGORY"], [9452, 9459, "TRAINED_CATEGORY"], [9463, 9472, "TRAINED_CATEGORY"], [9481, 9494, "TRAINED_CATEGORY"], [9495, 9503, "TRAINED_CATEGORY"], [9522, 9547, "TRAINED_CATEGORY"], [9549, 9553, "TRAINED_CATEGORY"], [9561, 9569, "TRAINED_CATEGORY"], [9573, 9586, "TRAINED_CATEGORY"], [9590, 9609, "TRAINED_CATEGORY"], [9615, 9623, "TRAINED_CATEGORY"], [9627, 9638, "TRAINED_CATEGORY"], [9640, 9642, "TRAINED_CATEGORY"], [9657, 9664, "TRAINED_CATEGORY"], [9677, 9696, "TRAINED_CATEGORY"], [9699, 9708, "TRAINED_CATEGORY"], [9721, 9734, "TRAINED_CATEGORY"], [9740, 9754, "TRAINED_CATEGORY"], [9779, 9788, "TRAINED_CATEGORY"], [9792, 9802, "TRAINED_CATEGORY"], [9804, 9806, "TRAINED_CATEGORY"], [9820, 9833, "TRAINED_CATEGORY"], [9838, 9860, "TRAINED_CATEGORY"], [9864, 9868, "TRAINED_CATEGORY"], [9903, 9908, "TRAINED_CATEGORY"], [9912, 9933, "TRAINED_CATEGORY"], [9949, 9967, "TRAINED_CATEGORY"], [9975, 9991, "TRAINED_CATEGORY"], [10017, 10020, "TRAINED_CATEGORY"], [10027, 10032, "TRAINED_CATEGORY"], [10042, 10059, "TRAINED_CATEGORY"], [10087, 10105, "TRAINED_CATEGORY"], [10119, 10121, "TRAINED_CATEGORY"], [10126, 10138, "TRAINED_CATEGORY"], [10149, 10159, "TRAINED_CATEGORY"], [10165, 10176, "TRAINED_CATEGORY"], [10180, 10194, "TRAINED_CATEGORY"], [10197, 10211, "TRAINED_CATEGORY"], [10217, 10219, "TRAINED_CATEGORY"], [10239, 10251, "TRAINED_CATEGORY"], [10255, 10274, "TRAINED_CATEGORY"], [10276, 10293, "TRAINED_CATEGORY"], [10352, 10354, "TRAINED_CATEGORY"], [10365, 10368, "TRAINED_CATEGORY"], [10374, 10382, "TRAINED_CATEGORY"], [10419, 10423, "TRAINED_CATEGORY"], [10429, 10437, "TRAINED_CATEGORY"], [10463, 10471, "TRAINED_CATEGORY"], [10472, 10493, "TRAINED_CATEGORY"], [10517, 10533, "TRAINED_CATEGORY"], [10534, 10545, "TRAINED_CATEGORY"], [10552, 10559, "TRAINED_CATEGORY"], [10563, 10571, "TRAINED_CATEGORY"], [10580, 10584, "TRAINED_CATEGORY"], [10585, 10589, "TRAINED_CATEGORY"], [10608, 10610, "TRAINED_CATEGORY"], [10616, 10630, "TRAINED_CATEGORY"], [10653, 10663, "TRAINED_CATEGORY"], [10686, 10692, "TRAINED_CATEGORY"], [10695, 10713, "TRAINED_CATEGORY"], [10725, 10727, "TRAINED_CATEGORY"], [10734, 10736, "TRAINED_CATEGORY"], [10762, 10771, "TRAINED_CATEGORY"], [10775, 10784, "TRAINED_CATEGORY"], [10788, 10806, "TRAINED_CATEGORY"], [10811, 10817, "TRAINED_CATEGORY"], [10834, 10838, "TRAINED_CATEGORY"], [10840, 10845, "TRAINED_CATEGORY"], [10850, 10859, "TRAINED_CATEGORY"], [10867, 10869, "TRAINED_CATEGORY"], [10882, 10892, "TRAINED_CATEGORY"], [10904, 10913, "TRAINED_CATEGORY"], [10916, 10918, "TRAINED_CATEGORY"], [10927, 10946, "TRAINED_CATEGORY"], [10950, 10960, "TRAINED_CATEGORY"], [10963, 10970, "TRAINED_CATEGORY"], [10984, 10992, "TRAINED_CATEGORY"], [11005, 11014, "TRAINED_CATEGORY"], [11044, 11057, "TRAINED_CATEGORY"], [11061, 11087, "TRAINED_CATEGORY"], [11088, 11097, "TRAINED_CATEGORY"], [11113, 11128, "TRAINED_CATEGORY"], [11135, 11150, "TRAINED_CATEGORY"], [11154, 11158, "TRAINED_CATEGORY"], [11169, 11177, "TRAINED_CATEGORY"], [11188, 11203, "TRAINED_CATEGORY"], [11209, 11219, "TRAINED_CATEGORY"], [11235, 11237, "TRAINED_CATEGORY"], [11243, 11259, "TRAINED_CATEGORY"], [11261, 11265, "TRAINED_CATEGORY"], [11294, 11303, "TRAINED_CATEGORY"], [11308, 11335, "TRAINED_CATEGORY"], [11341, 11372, "TRAINED_CATEGORY"], [11374, 11381, "TRAINED_CATEGORY"], [11394, 11403, "TRAINED_CATEGORY"], [11415, 11436, "TRAINED_CATEGORY"], [11443, 11465, "TRAINED_CATEGORY"], [11487, 11507, "TRAINED_CATEGORY"], [11522, 11545, "TRAINED_CATEGORY"], [11547, 11563, "TRAINED_CATEGORY"], [11599, 11621, "TRAINED_CATEGORY"], [11636, 11653, "TRAINED_CATEGORY"], [11657, 11661, "TRAINED_CATEGORY"], [11663, 11666, "TRAINED_CATEGORY"], [11667, 11681, "TRAINED_CATEGORY"], [11705, 11716, "TRAINED_CATEGORY"], [11720, 11724, "TRAINED_CATEGORY"], [11728, 11740, "TRAINED_CATEGORY"], [11746, 11763, "TRAINED_CATEGORY"], [11795, 11807, "TRAINED_CATEGORY"], [11811, 11815, "TRAINED_CATEGORY"], [11849, 11861, "TRAINED_CATEGORY"], [11867, 11882, "TRAINED_CATEGORY"], [11900, 11909, "TRAINED_CATEGORY"], [11918, 11943, "TRAINED_CATEGORY"], [11947, 11950, "TRAINED_CATEGORY"], [11952, 11958, "TRAINED_CATEGORY"], [11965, 11968, "TRAINED_CATEGORY"], [11972, 11989, "TRAINED_CATEGORY"], [12018, 12031, "TRAINED_CATEGORY"], [12036, 12050, "TRAINED_CATEGORY"], [12055, 12064, "TRAINED_CATEGORY"], [12066, 12068, "TRAINED_CATEGORY"], [12089, 12114, "TRAINED_CATEGORY"], [12130, 12141, "TRAINED_CATEGORY"], [12145, 12154, "TRAINED_CATEGORY"], [12158, 12176, "TRAINED_CATEGORY"], [12178, 12187, "TRAINED_CATEGORY"], [12208, 12211, "TRAINED_CATEGORY"], [12214, 12224, "TRAINED_CATEGORY"], [12280, 12291, "TRAINED_CATEGORY"], [12296, 12300, "TRAINED_CATEGORY"], [12302, 12304, "TRAINED_CATEGORY"], [12330, 12332, "TRAINED_CATEGORY"], [12344, 12353, "TRAINED_CATEGORY"], [12358, 12360, "TRAINED_CATEGORY"], [12375, 12389, "TRAINED_CATEGORY"], [12391, 12393, "TRAINED_CATEGORY"], [12435, 12437, "TRAINED_CATEGORY"], [12441, 12462, "TRAINED_CATEGORY"], [12467, 12469, "TRAINED_CATEGORY"], [12482, 12484, "TRAINED_CATEGORY"], [12495, 12505, "TRAINED_CATEGORY"], [12540, 12548, "TRAINED_CATEGORY"], [12553, 12556, "TRAINED_CATEGORY"], [12560, 12571, "TRAINED_CATEGORY"], [12582, 12593, "TRAINED_CATEGORY"], [12597, 12607, "TRAINED_CATEGORY"], [12609, 12611, "TRAINED_CATEGORY"], [12663, 12665, "TRAINED_CATEGORY"], [12686, 12698, "TRAINED_CATEGORY"], [12708, 12718, "TRAINED_CATEGORY"], [12724, 12727, "TRAINED_CATEGORY"], [12732, 12737, "TRAINED_CATEGORY"], [12741, 12767, "TRAINED_CATEGORY"], [12768, 12770, "TRAINED_CATEGORY"], [12788, 12804, "TRAINED_CATEGORY"], [12818, 12829, "TRAINED_CATEGORY"], [12847, 12860, "TRAINED_CATEGORY"], [12870, 12880, "TRAINED_CATEGORY"], [12895, 12924, "TRAINED_CATEGORY"], [12934, 12937, "TRAINED_CATEGORY"], [12971, 12989, "TRAINED_CATEGORY"], [12997, 13006, "TRAINED_CATEGORY"], [13011, 13014, "TRAINED_CATEGORY"], [13016, 13018, "TRAINED_CATEGORY"], [13037, 13047, "TRAINED_CATEGORY"], [13069, 13090, "TRAINED_CATEGORY"], [13101, 13105, "TRAINED_CATEGORY"], [13125, 13139, "TRAINED_CATEGORY"], [13141, 13148, "TRAINED_CATEGORY"], [13152, 13161, "TRAINED_CATEGORY"], [13163, 13182, "TRAINED_CATEGORY"], [13183, 13186, "TRAINED_CATEGORY"], [13188, 13192, "TRAINED_CATEGORY"], [13198, 13203, "TRAINED_CATEGORY"], [13258, 13267, "TRAINED_CATEGORY"], [13271, 13293, "TRAINED_CATEGORY"], [13297, 13301, "TRAINED_CATEGORY"], [13307, 13314, "TRAINED_CATEGORY"], [13318, 13321, "TRAINED_CATEGORY"], [13337, 13352, "TRAINED_CATEGORY"], [13356, 13369, "TRAINED_CATEGORY"], [13385, 13387, "TRAINED_CATEGORY"], [13393, 13408, "TRAINED_CATEGORY"], [13425, 13441, "TRAINED_CATEGORY"], [13447, 13454, "TRAINED_CATEGORY"], [13458, 13461, "TRAINED_CATEGORY"], [13470, 13478, "TRAINED_CATEGORY"], [13483, 13491, "TRAINED_CATEGORY"], [13506, 13525, "TRAINED_CATEGORY"], [13541, 13557, "TRAINED_CATEGORY"], [13558, 13569, "TRAINED_CATEGORY"], [13576, 13583, "TRAINED_CATEGORY"], [13587, 13601, "TRAINED_CATEGORY"], [13613, 13625, "TRAINED_CATEGORY"], [13627, 13631, "TRAINED_CATEGORY"], [13649, 13661, "TRAINED_CATEGORY"], [13667, 13674, "TRAINED_CATEGORY"], [13678, 13694, "TRAINED_CATEGORY"], [13707, 13715, "TRAINED_CATEGORY"], [13728, 13732, "TRAINED_CATEGORY"], [13744, 13752, "TRAINED_CATEGORY"], [13756, 13776, "TRAINED_CATEGORY"], [13786, 13802, "TRAINED_CATEGORY"], [13804, 13813, "TRAINED_CATEGORY"], [13817, 13828, "TRAINED_CATEGORY"], [13838, 13853, "TRAINED_CATEGORY"], [13858, 13864, "TRAINED_CATEGORY"], [13871, 13890, "TRAINED_CATEGORY"], [13894, 13903, "TRAINED_CATEGORY"], [13905, 13914, "TRAINED_CATEGORY"], [13925, 13947, "TRAINED_CATEGORY"], [13952, 13969, "TRAINED_CATEGORY"], [13973, 13981, "TRAINED_CATEGORY"], [13989, 14013, "TRAINED_CATEGORY"], [14017, 14027, "TRAINED_CATEGORY"], [14037, 14061, "TRAINED_CATEGORY"], [14077, 14088, "TRAINED_CATEGORY"], [14109, 14126, "TRAINED_CATEGORY"], [14135, 14150, "TRAINED_CATEGORY"], [14156, 14158, "TRAINED_CATEGORY"], [14175, 14187, "TRAINED_CATEGORY"], [14191, 14207, "TRAINED_CATEGORY"], [14217, 14227, "TRAINED_CATEGORY"], [14232, 14244, "TRAINED_CATEGORY"], [14257, 14281, "TRAINED_CATEGORY"], [14286, 14304, "TRAINED_CATEGORY"], [14321, 14334, "TRAINED_CATEGORY"], [14336, 14346, "TRAINED_CATEGORY"], [14348, 14376, "TRAINED_CATEGORY"], [14418, 14426, "TRAINED_CATEGORY"], [14430, 14465, "TRAINED_CATEGORY"], [14467, 14475, "TRAINED_CATEGORY"], [14488, 14496, "TRAINED_CATEGORY"], [14528, 14537, "TRAINED_CATEGORY"], [14548, 14552, "TRAINED_CATEGORY"], [14588, 14591, "TRAINED_CATEGORY"], [14612, 14628, "TRAINED_CATEGORY"], [14642, 14644, "TRAINED_CATEGORY"], [14650, 14664, "TRAINED_CATEGORY"], [14668, 14680, "TRAINED_CATEGORY"], [14686, 14693, "TRAINED_CATEGORY"], [14697, 14705, "TRAINED_CATEGORY"], [14729, 14745, "TRAINED_CATEGORY"], [14751, 14758, "TRAINED_CATEGORY"], [14762, 14774, "TRAINED_CATEGORY"], [14776, 14778, "TRAINED_CATEGORY"], [14793, 14807, "TRAINED_CATEGORY"], [14811, 14827, "TRAINED_CATEGORY"], [14833, 14840, "TRAINED_CATEGORY"], [14844, 14852, "TRAINED_CATEGORY"], [14862, 14886, "TRAINED_CATEGORY"], [14906, 14912, "TRAINED_CATEGORY"], [14931, 14940, "TRAINED_CATEGORY"], [14944, 14957, "TRAINED_CATEGORY"], [14961, 14972, "TRAINED_CATEGORY"], [14974, 15001, "TRAINED_CATEGORY"], [15007, 15014, "TRAINED_CATEGORY"], [15027, 15035, "TRAINED_CATEGORY"], [15039, 15046, "TRAINED_CATEGORY"], [15052, 15064, "TRAINED_CATEGORY"], [15070, 15077, "TRAINED_CATEGORY"], [15081, 15091, "TRAINED_CATEGORY"], [15107, 15128, "TRAINED_CATEGORY"], [15134, 15141, "TRAINED_CATEGORY"], [15145, 15153, "TRAINED_CATEGORY"], [15159, 15171, "TRAINED_CATEGORY"], [15177, 15184, "TRAINED_CATEGORY"], [15188, 15197, "TRAINED_CATEGORY"], [15213, 15233, "TRAINED_CATEGORY"], [15239, 15246, "TRAINED_CATEGORY"], [15250, 15258, "TRAINED_CATEGORY"], [15264, 15276, "TRAINED_CATEGORY"], [15282, 15289, "TRAINED_CATEGORY"], [15293, 15301, "TRAINED_CATEGORY"], [15317, 15336, "TRAINED_CATEGORY"], [15342, 15349, "TRAINED_CATEGORY"], [15353, 15361, "TRAINED_CATEGORY"], [15367, 15379, "TRAINED_CATEGORY"], [15385, 15392, "TRAINED_CATEGORY"], [15396, 15399, "TRAINED_CATEGORY"], [15415, 15429, "TRAINED_CATEGORY"], [15435, 15442, "TRAINED_CATEGORY"], [15446, 15458, "TRAINED_CATEGORY"], [15463, 15479, "TRAINED_CATEGORY"], [15484, 15498, "TRAINED_CATEGORY"], [15504, 15511, "TRAINED_CATEGORY"], [15515, 15527, "TRAINED_CATEGORY"], [15546, 15549, "TRAINED_CATEGORY"], [15551, 15553, "TRAINED_CATEGORY"], [15567, 15579, "TRAINED_CATEGORY"], [15585, 15592, "TRAINED_CATEGORY"], [15596, 15604, "TRAINED_CATEGORY"], [15639, 15653, "TRAINED_CATEGORY"], [15659, 15666, "TRAINED_CATEGORY"], [15670, 15680, "TRAINED_CATEGORY"], [15712, 15726, "TRAINED_CATEGORY"], [15732, 15739, "TRAINED_CATEGORY"], [15743, 15752, "TRAINED_CATEGORY"], [15784, 15798, "TRAINED_CATEGORY"], [15804, 15811, "TRAINED_CATEGORY"], [15815, 15823, "TRAINED_CATEGORY"], [15855, 15869, "TRAINED_CATEGORY"], [15875, 15882, "TRAINED_CATEGORY"], [15886, 15889, "TRAINED_CATEGORY"], [15920, 15927, "TRAINED_CATEGORY"], [15977, 15999, "TRAINED_CATEGORY"], [16011, 16025, "TRAINED_CATEGORY"], [16040, 16052, "TRAINED_CATEGORY"], [16066, 16084, "TRAINED_CATEGORY"], [16088, 16105, "TRAINED_CATEGORY"], [16110, 16125, "TRAINED_CATEGORY"], [16132, 16155, "TRAINED_CATEGORY"], [16172, 16187, "TRAINED_CATEGORY"], [16194, 16208, "TRAINED_CATEGORY"], [16214, 16221, "TRAINED_CATEGORY"], [16233, 16245, "TRAINED_CATEGORY"], [16247, 16251, "TRAINED_CATEGORY"], [16258, 16268, "TRAINED_CATEGORY"], [16289, 16316, "TRAINED_CATEGORY"], [16318, 16321, "TRAINED_CATEGORY"], [16328, 16338, "TRAINED_CATEGORY"], [16364, 16369, "TRAINED_CATEGORY"], [16391, 16400, "TRAINED_CATEGORY"], [16415, 16419, "TRAINED_CATEGORY"], [16423, 16447, "TRAINED_CATEGORY"], [16457, 16461, "TRAINED_CATEGORY"], [16472, 16479, "TRAINED_CATEGORY"], [16481, 16483, "TRAINED_CATEGORY"], [16496, 16500, "TRAINED_CATEGORY"], [16510, 16524, "TRAINED_CATEGORY"], [16540, 16549, "TRAINED_CATEGORY"], [16556, 16563, "TRAINED_CATEGORY"], [16567, 16581, "TRAINED_CATEGORY"], [16586, 16590, "TRAINED_CATEGORY"], [16596, 16611, "TRAINED_CATEGORY"], [16618, 16635, "TRAINED_CATEGORY"], [16637, 16641, "TRAINED_CATEGORY"], [16654, 16665, "TRAINED_CATEGORY"], [16675, 16682, "TRAINED_CATEGORY"], [16706, 16710, "TRAINED_CATEGORY"], [16722, 16726, "TRAINED_CATEGORY"], [16738, 16749, "TRAINED_CATEGORY"], [16753, 16766, "TRAINED_CATEGORY"], [16770, 16787, "TRAINED_CATEGORY"], [16792, 16802, "TRAINED_CATEGORY"], [16807, 16821, "TRAINED_CATEGORY"], [16826, 16842, "TRAINED_CATEGORY"], [16850, 16856, "TRAINED_CATEGORY"], [16862, 16865, "TRAINED_CATEGORY"], [16890, 16902, "TRAINED_CATEGORY"], [16909, 16919, "TRAINED_CATEGORY"], [16929, 16934, "TRAINED_CATEGORY"], [16945, 16957, "TRAINED_CATEGORY"], [16962, 16969, "TRAINED_CATEGORY"], [16971, 16975, "TRAINED_CATEGORY"], [16981, 16986, "TRAINED_CATEGORY"], [16987, 16994, "TRAINED_CATEGORY"], [17012, 17022, "TRAINED_CATEGORY"], [17036, 17045, "TRAINED_CATEGORY"], [17063, 17086, "TRAINED_CATEGORY"], [17090, 17097, "TRAINED_CATEGORY"], [17099, 17103, "TRAINED_CATEGORY"], [17112, 17133, "TRAINED_CATEGORY"], [17137, 17147, "TRAINED_CATEGORY"], [17159, 17170, "TRAINED_CATEGORY"], [17177, 17190, "TRAINED_CATEGORY"], [17194, 17201, "TRAINED_CATEGORY"], [17205, 17219, "TRAINED_CATEGORY"], [17223, 17228, "TRAINED_CATEGORY"], [17230, 17239, "TRAINED_CATEGORY"], [17248, 17260, "TRAINED_CATEGORY"], [17264, 17279, "TRAINED_CATEGORY"], [17284, 17299, "TRAINED_CATEGORY"], [17301, 17311, "TRAINED_CATEGORY"], [17313, 17325, "TRAINED_CATEGORY"], [17327, 17343, "TRAINED_CATEGORY"], [17345, 17349, "TRAINED_CATEGORY"], [17351, 17370, "TRAINED_CATEGORY"], [17372, 17381, "TRAINED_CATEGORY"], [17410, 17417, "TRAINED_CATEGORY"], [17419, 17449, "TRAINED_CATEGORY"], [17454, 17463, "TRAINED_CATEGORY"], [17467, 17482, "TRAINED_CATEGORY"], [17484, 17494, "TRAINED_CATEGORY"], [17496, 17508, "TRAINED_CATEGORY"], [17510, 17526, "TRAINED_CATEGORY"], [17528, 17532, "TRAINED_CATEGORY"], [17548, 17553, "TRAINED_CATEGORY"], [17555, 17564, "TRAINED_CATEGORY"], [17573, 17605, "TRAINED_CATEGORY"], [17607, 17630, "TRAINED_CATEGORY"], [17634, 17649, "TRAINED_CATEGORY"], [17651, 17661, "TRAINED_CATEGORY"], [17663, 17675, "TRAINED_CATEGORY"], [17677, 17693, "TRAINED_CATEGORY"], [17695, 17699, "TRAINED_CATEGORY"], [84, 87, "ORG"], [128, 136, "ORG"], [209, 217, "GPE"], [259, 262, "ORG"], [451, 454, "ORG"], [629, 632, "ORG"], [742, 746, "CARDINAL"], [766, 770, "PERSON"], [820, 824, "CARDINAL"], [842, 855, "CARDINAL"], [875, 878, "PERSON"], [908, 919, "CARDINAL"], [945, 950, "PERSON"], [1071, 1079, "ORG"], [1081, 1090, "ORG"], [1096, 1099, "ORG"], [1128, 1132, "CARDINAL"], [1134, 1138, "CARDINAL"], [1140, 1144, "DATE"], [1320, 1324, "DATE"], [1653, 1663, "DATE"], [2183, 2197, "DATE"], [2271, 2275, "CARDINAL"], [2983, 3002, "DATE"], [3063, 3072, "DATE"], [3131, 3136, "CARDINAL"], [3388, 3393, "CARDINAL"], [3409, 3412, "PERSON"], [3414, 3418, "PERSON"], [3424, 3429, "PERSON"], [3512, 3515, "ORG"], [3602, 3605, "ORG"], [4092, 4096, "LOC"], [4346, 4349, "CARDINAL"], [4353, 4356, "CARDINAL"], [4826, 4830, "LOC"], [4847, 4852, "CARDINAL"], [4867, 4870, "PERSON"], [4872, 4876, "PERSON"], [4882, 4887, "PERSON"], [4986, 4991, "CARDINAL"], [5045, 5048, "PERSON"], [5053, 5057, "PERSON"], [5059, 5062, "PERSON"], [5067, 5072, "PERSON"], [5078, 5082, "PERSON"], [5087, 5092, "PERSON"], [5130, 5135, "ORDINAL"], [5197, 5206, "ORG"], [5310, 5313, "ORG"], [5365, 5377, "NORP"], [5717, 5720, "ORG"], [5726, 5731, "ORG"], [5787, 5790, "CARDINAL"], [5886, 5891, "ORG"], [6376, 6394, "ORG"], [6506, 6509, "ORG"], [6597, 6602, "ORG"], [6703, 6704, "CARDINAL"], [6718, 6743, "ORG"], [6904, 6907, "ORG"], [7053, 7056, "LOC"], [7150, 7153, "ORG"], [7429, 7432, "ORG"], [7847, 7850, "ORG"], [7973, 7976, "ORG"], [8040, 8045, "ORG"], [8095, 8104, "ORG"], [8214, 8217, "WORK_OF_ART"], [8572, 8581, "ORG"], [8726, 8737, "WORK_OF_ART"], [8804, 8809, "DATE"], [8865, 8883, "ORG"], [9106, 9109, "ORG"], [9403, 9408, "ORG"], [9463, 9472, "ORG"], [9507, 9508, "CARDINAL"], [9522, 9547, "ORG"], [9699, 9708, "ORG"], [9744, 9747, "ORG"], [9779, 9782, "PERSON"], [9838, 9843, "CARDINAL"], [9864, 9868, "PERSON"], [9883, 9888, "ORDINAL"], [9903, 9908, "PERSON"], [9959, 9962, "CARDINAL"], [9975, 9979, "PERSON"], [10017, 10020, "PERSON"], [10027, 10032, "PERSON"], [10042, 10047, "PERSON"], [10126, 10129, "ORG"], [10184, 10187, "ORG"], [10276, 10281, "PERSON"], [10325, 10330, "CARDINAL"], [10365, 10368, "PERSON"], [10386, 10394, "CARDINAL"], [10419, 10423, "PERSON"], [10441, 10442, "CARDINAL"], [10563, 10571, "PERSON"], [10996, 11014, "ORG"], [11169, 11177, "PERSON"], [11247, 11250, "ORG"], [11378, 11381, "ORG"], [11449, 11454, "CARDINAL"], [11603, 11606, "ORG"], [11720, 11724, "DATE"], [11733, 11740, "TIME"], [11900, 11904, "GPE"], [12255, 12274, "DATE"], [12495, 12505, "DATE"], [12934, 12940, "DATE"], [13003, 13006, "DATE"], [13011, 13014, "DATE"], [13143, 13161, "ORG"], [13188, 13192, "PERSON"], [13198, 13203, "PERSON"], [13212, 13214, "DATE"], [13216, 13218, "DATE"], [13224, 13236, "DATE"], [13275, 13280, "ORG"], [13359, 13362, "ORG"], [13470, 13478, "ORG"], [13487, 13491, "LOC"], [13545, 13557, "PRODUCT"], [13617, 13625, "ORG"], [13909, 13914, "ORG"], [14017, 14021, "CARDINAL"], [14037, 14040, "CARDINAL"], [14077, 14082, "CARDINAL"], [14098, 14108, "CARDINAL"], [14236, 14244, "ORG"], [14367, 14376, "ORG"], [14434, 14440, "ORDINAL"], [14488, 14496, "PERSON"], [14528, 14537, "ORG"], [14599, 14611, "ORG"], [14701, 14705, "LOC"], [14766, 14774, "GPE"], [14848, 14852, "LOC"], [15031, 15035, "LOC"], [15149, 15153, "LOC"], [15188, 15197, "ORG"], [15213, 15222, "ORG"], [15293, 15301, "ORG"], [15317, 15325, "ORG"], [15415, 15418, "ORG"], [15450, 15458, "ORG"], [15488, 15498, "ORG"], [15546, 15549, "PERSON"], [15608, 15613, "CARDINAL"], [15639, 15642, "PERSON"], [15684, 15689, "CARDINAL"], [15692, 15697, "CARDINAL"], [15700, 15705, "CARDINAL"], [15712, 15715, "PERSON"], [15743, 15752, "ORG"], [15756, 15761, "CARDINAL"], [15764, 15769, "CARDINAL"], [15772, 15777, "CARDINAL"], [15784, 15787, "PERSON"], [15815, 15823, "ORG"], [15827, 15832, "CARDINAL"], [15835, 15840, "CARDINAL"], [15843, 15848, "CARDINAL"], [15855, 15858, "PERSON"], [15886, 15889, "ORG"], [15893, 15898, "CARDINAL"], [15901, 15906, "CARDINAL"], [15909, 15914, "CARDINAL"], [15931, 15936, "CARDINAL"], [15955, 15960, "CARDINAL"], [15963, 15972, "FAC"], [16070, 16075, "ORG"], [16247, 16251, "PERSON"], [16272, 16277, "CARDINAL"], [16318, 16321, "PERSON"], [16342, 16347, "CARDINAL"], [16352, 16358, "ORDINAL"], [16364, 16369, "PERSON"], [16374, 16379, "CARDINAL"], [16384, 16389, "ORDINAL"], [16415, 16419, "PERSON"], [16476, 16479, "ORG"], [16596, 16602, "ORDINAL"], [16929, 16934, "PRODUCT"], [16945, 16957, "EVENT"], [16966, 16969, "PERSON"], [16971, 16975, "PERSON"], [16981, 16986, "PERSON"], [17094, 17097, "ORG"], [17230, 17239, "PERSON"], [17241, 17245, "DATE"], [17264, 17299, "ORG"], [17301, 17311, "GPE"], [17313, 17325, "GPE"], [17327, 17343, "ORG"], [17362, 17363, "CARDINAL"], [17372, 17381, "PERSON"], [17383, 17387, "DATE"], [17469, 17482, "ORG"], [17484, 17494, "GPE"], [17496, 17508, "GPE"], [17510, 17526, "ORG"], [17555, 17564, "PERSON"], [17566, 17570, "DATE"], [17573, 17605, "PERSON"], [17651, 17661, "GPE"], [17663, 17675, "GPE"], [17677, 17693, "ORG"], [17700, 17703, "CARDINAL"]]}], ["Thomas L. Saaty (July 18, 1926 \u2013 August 14, 2017) was a Distinguished University Professor at the University of Pittsburgh, where he taught in the Joseph M. Katz Graduate School of Business. He is the inventor, architect, and primary theoretician of the Analytic Hierarchy Process (AHP), a decision-making framework used for large-scale, multiparty, multi-criteria decision analysis, and of the Analytic Network Process (ANP), its generalization to decisions with dependence and feedback. Later on, he generalized the mathematics of the ANP to the Neural Network Process (NNP) with application to neural firing and synthesis but none of them gain such popularity as AHP.\nHe died on the 14th of August 2017 after a year-long battle with cancer.Prior to coming to the University of Pittsburgh, Saaty was professor of statistics and operations research at the Wharton School of the University of Pennsylvania (1969\u201379). Before that, he spent fifteen years working for U.S. government agencies and for companies doing government-sponsored research. His employers at that time included the Operations Evaluation Group of MIT at the Pentagon, the Office of Naval Research, and the Arms Control and Disarmament Agency at the U.S. State Department.\n\n\n== Contributions ==\nSaaty was a Distinguished University Professor at the University of Pittsburgh. He has made contributions in the fields of operations research (parametric linear programming, epidemics and the spread of biological agents, queuing theory, and behavioral mathematics as it relates to operations), arms control and disarmament, and urban design. He has written more than 35 books and 350 papers on mathematics, operations research, and decision making. Their subjects include graph theory and its applications, nonlinear mathematics, analytical planning, and game theory and conflict resolution. According to the Mathematics Genealogy Project, he has had 14 doctoral students.  Saaty himself was a student of Einar Hille at Yale.\nIn line with his long-time interest in peace and conflict resolution, in 1983 Saaty proposed that an International Center for Conflict Resolution needs to be established that would have branches in many countries and would be manned by retired diplomats, negotiators and conflict analysts. This idea was first published in an article \"Center for Conflict Resolution,\" in the March 1984 issue of the Bulletin of the Atomic Scientists, and it later appeared as an appendix in his 1989 book on Conflict Resolution co-authored with J.M. Alexander. A current revised version of this proposal is posted here with his University of Pittsburgh vita.\nA 2002 article listing the most important contributions to operations research from 1954 to date listed four from Saaty: \"Parametric Programming\" (1954, with S. I. Gass), \"Mathematical Methods of Operations Research\" (1959), \"Elements of Queueing Theory\" (1961), and \"The Analytic Hierarchy Process\" (1980). The book on operations research was the first to summarize the formal mathematical methods in the field of Operations Research and was translated to Russian and Japanese. The comprehensive work on queueing theory was reviewed by D.G. Kendall of Oxford University in Mathematical Reviews who wrote that this book is \"a substantial encyclopedia of queueing theory whose scope is indicated by the 910 items in the bibliography at the end of the book.\" The book \"Mathematical Methods of Arms Control and Disarmament\" was reviewed in Management Science in April 1969, \"This fascinating book is an important contribution to the present task of discovering some valid underlying mathematical structures in politics...highly recommended both because of its numerous fascinating models and because of the deadly importance of its subject.\"  The Analytic Hierarchy Process itself anticipates the PageRank algorithm by more than 20 years, with the same basic idea of using the eigenvector corresponding to the largest eigenvalue of a suitable matrix.\nSaaty has been elected to the National Academy of Engineering (2005), and the Real Academia de Ciencias Exactas, F\u00edsicas y Naturales (Spanish Royal Academy of Sciences, 1971). In 1973, he received the Lester R. Ford Award from the Mathematical Association of America for expository excellence in his paper \"Thirteen Colorful Variations on Guthrie's Four-color Conjecture\" on the four color problem, and in 2000 he was awarded the gold medal of the International Society on Multi-criteria Decision Making. He is the 2007 recipient of the Akao Prize of the QFD Institute. In 2008, he received the INFORMS Impact Prize for his development of the Analytic Hierarchy Process. The Impact Prize is awarded every two years to recognize contributions that have had a broad impact on the fields of operations research and the management sciences. Emphasis is placed on the breadth of the impact of an idea or body of research. In 2011 he was awarded, in a ceremony with ancient roots on YouTube, the Doktor Honoris Causa degree by Jagiellonian University in Krakow, Poland. In December 2011 he received the Herbert Simon Award for Outstanding Contribution in Information Technology and Decision Making for the paper \"The Possibility Of Group Welfare Functions\" coauthored with Professor Luis G. Vargas, published in the International Journal of Information Technology & Decision Making (IJITDM), Most of the university scholars are working on the basis he provided, Anum Bakhtyar.\nMr. Saaty died at the age of 91 on August 14, 2017, 14 months after a cancer diagnosis.\n\n\n== Education ==\nPhD, Mathematics, Yale University, 1953 (thesis, under Einar Carl Hille: \"On the Bessel Tricomi Equation\"). Post-graduate study, University of Paris, 1952\u201353. MA, Mathematics, Yale University, 1951. MS, Physics, The Catholic University of America, 1949. BA, Columbia Union College, 1948.\n\n\n== Bibliography ==\n\n\n=== Analytic hierarchy process (AHP) ===\n1980 The Analytic Hierarchy Process: Planning, Priority Setting, Resource Allocation, ISBN 0-07-054371-2, McGraw-Hill\n1982 Decision Making for Leaders: The Analytical Hierarchy Process for Decisions in a Complex World, ISBN 0-534-97959-9, Wadsworth. 1988, Paperback, ISBN 0-9620317-0-4, RWS\n1982 The Logic of Priorities: Applications in Business, Energy, Health, and Transportation, with Luis G. Vargas, ISBN 0-89838-071-5 (Hardcover) ISBN 0-89838-078-2 (Paperback), Kluwer-Nijhoff\n1985 Analytical Planning: The Organization of Systems, with Kevin P. Kearns, ISBN 0-08-032599-8, Pergamon\n1989 Conflict Resolution: The Analytic Hierarchy Process, with Joyce Alexander, ISBN 0-275-93229-X, Praeger\n1991 Prediction, Projection and Forecasting: Applications of the Analytic Hierarchy Process in Economics, Finance, Politics, Games and Sports, with Luis G. Vargas, ISBN 0-7923-9104-7, Kluwer Academic\n1992 The Hierarchon: A Dictionary of Hierarchies, with Ernest H. Forman, ISBN 0-9620317-5-5, RWS\n1994 Fundamentals of Decision Making and Priority Theory with the Analytic Hierarchy Process, ISBN 0-9620317-6-3, RWS\n1994 Decision Making in Economic, Social and Technological Environments, with Luis G. Vargas, ISBN 0-9620317-7-1, RWS\n1996 Vol. III and IV of the Analytic Hierarchy Process Series, ISBN 1-888603-07-0 RWS\n2001 Models, Methods, Concepts & Applications of the Analytic Hierarchy Process, with Luis G. Vargas, ISBN 0-7923-7267-0, Kluwer Academic\n2007 Group Decision Making: Drawing Out and Reconciling Differences, with Kirti Peniwati, ISBN 1-888603-08-9, RWS\n2008 Decision making with the analytic hierarchy process, Int. J. Services Sciences, Vol. 1, No. 1, 2008 (http://www.colorado.edu/geography/leyk/geog_5113/readings/saaty_2008.pdf) - includes a statement of priority scales which measure intangibles in relative terms.\n\n\n=== Analytic network process (ANP) ===\n1996 Decision Making with Dependence and Feedback: The Analytic Network Process, ISBN 0-9620317-9-8, RWS\n2005 Theory and Applications of the Analytic Network Process: Decision Making with Benefits, Opportunities, Costs and Risks, ISBN 1-888603-06-2, RWS\n2005 The Encyclicon, A Dictionary of Decisions with Dependence and Feedback based on the Analytic Network Process, with M\u00fcjgan S. \u00d6zdemir, ISBN 1-888603-05-4, RWS\n2006 Decision Making with the Analytic Network Process: Economic, Political, Social and Technological Applications with Benefits, Opportunities, Costs and Risks, with Luis G. Vargas, ISBN 0-387-33859-4, Springer\n2008 The Encyclicon, Volume 2: A Dictionary of Complex Decisions using the Analytic Network Process, with Brady Cillo, ISBN 1-888603-09-7, RWS\n2008 The analytic hierarchy and analytic network measurement processes: Applications to decisions under Risk', European Journal of Pure and Applied Mathematics, 1 (1), 122\u2013196, (2008)\n\n\n=== Neural network process (NNP) ===\n1999 The Brain: Unraveling the Mystery of How it Works, The Neural Network Process, ISBN 1-888603-02-X, RWS\n2009 Principia Mathematica Decernendi: Mathematical Principles of Decision Making - Generalization of the Analytic Network Process to Neural Firing and Synthesis, ISBN 1-888603-10-0, RWS\n\n\n=== Operations research ===\n1959 Mathematical Methods of Operations Research, no ISBN (translated into Japanese and Russian), McGraw-Hill. 1988 Extended edition, ISBN 0-486-65703-5, Dover (paperback)\n1961 Elements of Queueing Theory with Applications, no ISBN (translated into Russian, Spanish and German), McGraw-Hill\n\n\n=== Mathematics ===\n1964 Nonlinear Mathematics, with J. Bram, no ISBN, McGraw-Hill. 1981 Reprinted as ISBN 0-486-64233-X, Dover (paperback)\n1964-1965 Lectures on Modern Mathematics, Volumes I, II, III (Thomas L. Saaty, Editor), no ISBN (translated into Japanese), John Wiley\n1965 Finite Graphs and Networks, with R. Busacker, no ISBN (translated into Japanese, Russian, German and Hungarian), McGraw-Hill\n1967 Modern Nonlinear Equations, no ISBN, McGraw-Hill. 1981, reprinted as ISBN 0-486-64232-1, Dover (paperback)\n1969 The Spirit and Uses of the Mathematical Sciences, (Thomas L. Saaty, Editor, with F.J. Weyl), no ISBN, McGraw-Hill\n1970 Optimization in Integers and Related Extremal Problems, no ISBN (translated into Russian), McGraw-Hill\n1977 The Four-Color Problem; Assaults and Conquest, ISBN 0-07-054382-8, with Paul C. Kainen, McGraw-Hill. 1986 Revised edition, ISBN 0-486-65092-8, Dover (paperback)\n\n\n=== Applied mathematics ===\n1968 Mathematical Models of Arms Control and Disarmament, ISBN 0-471-74810-2, John Wiley\n1973 Topics in Behavioral Mathematics, no ISBN, Mathematical Association of America\n1981 Thinking with Models: Mathematical Models in the Physical, Biological, and Social Sciences, with Joyce Alexander, hardback ISBN 0-08-026475-1, paperback ISBN 978-0-08-026474-5, Pergamon\n\n\n=== Other topics ===\n1973 Compact City, with George B. Dantzig, hardback ISBN 0-7167-0784-5, paperback ISBN 0-7167-0794-2 (translated into Japanese and Russian), W.H. Freeman\n1990 Embracing the Future, with Larry W. Boone, ISBN 0-275-93573-6, Praeger\n2001 Creative Thinking, Problem Solving & Decision Making, ISBN 1-888603-03-8, RWS\n2013 Compact City: The Next Urban Evolution in Response to Climate Change, ISBN 1-888603-12-7, RWS\n\n\n== References ==\n\n\n== External links ==\nUniversity of Pittsburgh faculty biography of Thomas L. Saaty\nDecision Lens Board of Advisors\nReal Academia de Ciencias, Relaci\u00f3n de Acad\u00e9micos\nBiography of Thomas L. Saaty from the Institute for Operations Research and the Management Sciences", {"entities": [[0, 15, "TRAINED_CATEGORY"], [17, 21, "TRAINED_CATEGORY"], [33, 39, "TRAINED_CATEGORY"], [54, 90, "TRAINED_CATEGORY"], [94, 108, "TRAINED_CATEGORY"], [112, 122, "TRAINED_CATEGORY"], [130, 132, "TRAINED_CATEGORY"], [143, 177, "TRAINED_CATEGORY"], [181, 189, "TRAINED_CATEGORY"], [191, 193, "TRAINED_CATEGORY"], [197, 209, "TRAINED_CATEGORY"], [211, 220, "TRAINED_CATEGORY"], [226, 246, "TRAINED_CATEGORY"], [250, 280, "TRAINED_CATEGORY"], [281, 285, "TRAINED_CATEGORY"], [288, 315, "TRAINED_CATEGORY"], [325, 382, "TRAINED_CATEGORY"], [391, 419, "TRAINED_CATEGORY"], [421, 424, "TRAINED_CATEGORY"], [427, 445, "TRAINED_CATEGORY"], [449, 458, "TRAINED_CATEGORY"], [464, 474, "TRAINED_CATEGORY"], [479, 487, "TRAINED_CATEGORY"], [499, 501, "TRAINED_CATEGORY"], [514, 529, "TRAINED_CATEGORY"], [533, 540, "TRAINED_CATEGORY"], [544, 570, "TRAINED_CATEGORY"], [571, 575, "TRAINED_CATEGORY"], [582, 593, "TRAINED_CATEGORY"], [597, 610, "TRAINED_CATEGORY"], [615, 624, "TRAINED_CATEGORY"], [629, 633, "TRAINED_CATEGORY"], [637, 641, "TRAINED_CATEGORY"], [647, 662, "TRAINED_CATEGORY"], [666, 669, "TRAINED_CATEGORY"], [671, 673, "TRAINED_CATEGORY"], [682, 690, "TRAINED_CATEGORY"], [694, 700, "TRAINED_CATEGORY"], [712, 730, "TRAINED_CATEGORY"], [736, 742, "TRAINED_CATEGORY"], [762, 776, "TRAINED_CATEGORY"], [780, 790, "TRAINED_CATEGORY"], [792, 797, "TRAINED_CATEGORY"], [802, 811, "TRAINED_CATEGORY"], [815, 849, "TRAINED_CATEGORY"], [853, 871, "TRAINED_CATEGORY"], [875, 889, "TRAINED_CATEGORY"], [893, 905, "TRAINED_CATEGORY"], [930, 932, "TRAINED_CATEGORY"], [939, 952, "TRAINED_CATEGORY"], [965, 989, "TRAINED_CATEGORY"], [998, 1007, "TRAINED_CATEGORY"], [1014, 1043, "TRAINED_CATEGORY"], [1045, 1058, "TRAINED_CATEGORY"], [1062, 1071, "TRAINED_CATEGORY"], [1081, 1112, "TRAINED_CATEGORY"], [1116, 1119, "TRAINED_CATEGORY"], [1123, 1135, "TRAINED_CATEGORY"], [1137, 1147, "TRAINED_CATEGORY"], [1151, 1165, "TRAINED_CATEGORY"], [1171, 1210, "TRAINED_CATEGORY"], [1214, 1239, "TRAINED_CATEGORY"], [1246, 1259, "TRAINED_CATEGORY"], [1263, 1268, "TRAINED_CATEGORY"], [1273, 1309, "TRAINED_CATEGORY"], [1313, 1327, "TRAINED_CATEGORY"], [1331, 1341, "TRAINED_CATEGORY"], [1343, 1345, "TRAINED_CATEGORY"], [1355, 1368, "TRAINED_CATEGORY"], [1372, 1382, "TRAINED_CATEGORY"], [1386, 1405, "TRAINED_CATEGORY"], [1407, 1436, "TRAINED_CATEGORY"], [1438, 1447, "TRAINED_CATEGORY"], [1452, 1462, "TRAINED_CATEGORY"], [1466, 1483, "TRAINED_CATEGORY"], [1485, 1499, "TRAINED_CATEGORY"], [1505, 1527, "TRAINED_CATEGORY"], [1531, 1533, "TRAINED_CATEGORY"], [1545, 1555, "TRAINED_CATEGORY"], [1558, 1570, "TRAINED_CATEGORY"], [1575, 1586, "TRAINED_CATEGORY"], [1592, 1604, "TRAINED_CATEGORY"], [1606, 1608, "TRAINED_CATEGORY"], [1621, 1639, "TRAINED_CATEGORY"], [1644, 1654, "TRAINED_CATEGORY"], [1658, 1669, "TRAINED_CATEGORY"], [1671, 1690, "TRAINED_CATEGORY"], [1696, 1711, "TRAINED_CATEGORY"], [1713, 1727, "TRAINED_CATEGORY"], [1736, 1748, "TRAINED_CATEGORY"], [1753, 1769, "TRAINED_CATEGORY"], [1771, 1792, "TRAINED_CATEGORY"], [1794, 1813, "TRAINED_CATEGORY"], [1819, 1830, "TRAINED_CATEGORY"], [1835, 1854, "TRAINED_CATEGORY"], [1869, 1902, "TRAINED_CATEGORY"], [1904, 1906, "TRAINED_CATEGORY"], [1915, 1935, "TRAINED_CATEGORY"], [1938, 1943, "TRAINED_CATEGORY"], [1944, 1951, "TRAINED_CATEGORY"], [1956, 1965, "TRAINED_CATEGORY"], [1969, 1980, "TRAINED_CATEGORY"], [1984, 1988, "TRAINED_CATEGORY"], [1993, 1997, "TRAINED_CATEGORY"], [2003, 2025, "TRAINED_CATEGORY"], [2029, 2058, "TRAINED_CATEGORY"], [2068, 2073, "TRAINED_CATEGORY"], [2088, 2111, "TRAINED_CATEGORY"], [2116, 2135, "TRAINED_CATEGORY"], [2176, 2184, "TRAINED_CATEGORY"], [2188, 2202, "TRAINED_CATEGORY"], [2226, 2243, "TRAINED_CATEGORY"], [2245, 2256, "TRAINED_CATEGORY"], [2261, 2278, "TRAINED_CATEGORY"], [2280, 2289, "TRAINED_CATEGORY"], [2313, 2323, "TRAINED_CATEGORY"], [2325, 2331, "TRAINED_CATEGORY"], [2336, 2355, "TRAINED_CATEGORY"], [2361, 2381, "TRAINED_CATEGORY"], [2385, 2397, "TRAINED_CATEGORY"], [2401, 2422, "TRAINED_CATEGORY"], [2428, 2430, "TRAINED_CATEGORY"], [2449, 2460, "TRAINED_CATEGORY"], [2464, 2477, "TRAINED_CATEGORY"], [2481, 2500, "TRAINED_CATEGORY"], [2518, 2532, "TRAINED_CATEGORY"], [2534, 2559, "TRAINED_CATEGORY"], [2563, 2576, "TRAINED_CATEGORY"], [2615, 2625, "TRAINED_CATEGORY"], [2632, 2646, "TRAINED_CATEGORY"], [2655, 2687, "TRAINED_CATEGORY"], [2691, 2710, "TRAINED_CATEGORY"], [2724, 2728, "TRAINED_CATEGORY"], [2746, 2751, "TRAINED_CATEGORY"], [2754, 2776, "TRAINED_CATEGORY"], [2790, 2800, "TRAINED_CATEGORY"], [2828, 2847, "TRAINED_CATEGORY"], [2870, 2885, "TRAINED_CATEGORY"], [2940, 2948, "TRAINED_CATEGORY"], [2952, 2971, "TRAINED_CATEGORY"], [2999, 3030, "TRAINED_CATEGORY"], [3034, 3043, "TRAINED_CATEGORY"], [3047, 3066, "TRAINED_CATEGORY"], [3101, 3109, "TRAINED_CATEGORY"], [3111, 3133, "TRAINED_CATEGORY"], [3137, 3152, "TRAINED_CATEGORY"], [3169, 3181, "TRAINED_CATEGORY"], [3185, 3202, "TRAINED_CATEGORY"], [3206, 3226, "TRAINED_CATEGORY"], [3227, 3230, "TRAINED_CATEGORY"], [3242, 3251, "TRAINED_CATEGORY"], [3256, 3282, "TRAINED_CATEGORY"], [3286, 3301, "TRAINED_CATEGORY"], [3302, 3313, "TRAINED_CATEGORY"], [3330, 3343, "TRAINED_CATEGORY"], [3347, 3363, "TRAINED_CATEGORY"], [3367, 3374, "TRAINED_CATEGORY"], [3378, 3386, "TRAINED_CATEGORY"], [3389, 3397, "TRAINED_CATEGORY"], [3399, 3419, "TRAINED_CATEGORY"], [3423, 3435, "TRAINED_CATEGORY"], [3440, 3451, "TRAINED_CATEGORY"], [3469, 3487, "TRAINED_CATEGORY"], [3491, 3496, "TRAINED_CATEGORY"], [3504, 3525, "TRAINED_CATEGORY"], [3529, 3554, "TRAINED_CATEGORY"], [3558, 3574, "TRAINED_CATEGORY"], [3590, 3635, "TRAINED_CATEGORY"], [3639, 3647, "TRAINED_CATEGORY"], [3685, 3716, "TRAINED_CATEGORY"], [3732, 3753, "TRAINED_CATEGORY"], [3757, 3768, "TRAINED_CATEGORY"], [3772, 3802, "TRAINED_CATEGORY"], [3803, 3809, "TRAINED_CATEGORY"], [3822, 3844, "TRAINED_CATEGORY"], [3848, 3866, "TRAINED_CATEGORY"], [3873, 3892, "TRAINED_CATEGORY"], [3902, 3917, "TRAINED_CATEGORY"], [3935, 3957, "TRAINED_CATEGORY"], [3961, 3978, "TRAINED_CATEGORY"], [3980, 3985, "TRAINED_CATEGORY"], [4006, 4026, "TRAINED_CATEGORY"], [4030, 4041, "TRAINED_CATEGORY"], [4054, 4091, "TRAINED_CATEGORY"], [4093, 4112, "TRAINED_CATEGORY"], [4114, 4135, "TRAINED_CATEGORY"], [4139, 4147, "TRAINED_CATEGORY"], [4165, 4167, "TRAINED_CATEGORY"], [4177, 4201, "TRAINED_CATEGORY"], [4207, 4235, "TRAINED_CATEGORY"], [4239, 4246, "TRAINED_CATEGORY"], [4251, 4272, "TRAINED_CATEGORY"], [4276, 4285, "TRAINED_CATEGORY"], [4286, 4315, "TRAINED_CATEGORY"], [4319, 4350, "TRAINED_CATEGORY"], [4355, 4377, "TRAINED_CATEGORY"], [4391, 4393, "TRAINED_CATEGORY"], [4406, 4420, "TRAINED_CATEGORY"], [4424, 4449, "TRAINED_CATEGORY"], [4453, 4483, "TRAINED_CATEGORY"], [4485, 4487, "TRAINED_CATEGORY"], [4491, 4509, "TRAINED_CATEGORY"], [4513, 4527, "TRAINED_CATEGORY"], [4531, 4548, "TRAINED_CATEGORY"], [4559, 4561, "TRAINED_CATEGORY"], [4571, 4595, "TRAINED_CATEGORY"], [4600, 4615, "TRAINED_CATEGORY"], [4619, 4649, "TRAINED_CATEGORY"], [4651, 4667, "TRAINED_CATEGORY"], [4679, 4694, "TRAINED_CATEGORY"], [4708, 4721, "TRAINED_CATEGORY"], [4736, 4750, "TRAINED_CATEGORY"], [4754, 4764, "TRAINED_CATEGORY"], [4768, 4787, "TRAINED_CATEGORY"], [4792, 4815, "TRAINED_CATEGORY"], [4817, 4825, "TRAINED_CATEGORY"], [4839, 4850, "TRAINED_CATEGORY"], [4854, 4864, "TRAINED_CATEGORY"], [4868, 4875, "TRAINED_CATEGORY"], [4879, 4883, "TRAINED_CATEGORY"], [4887, 4895, "TRAINED_CATEGORY"], [4905, 4907, "TRAINED_CATEGORY"], [4924, 4934, "TRAINED_CATEGORY"], [4940, 4953, "TRAINED_CATEGORY"], [4957, 4964, "TRAINED_CATEGORY"], [4966, 4997, "TRAINED_CATEGORY"], [5001, 5024, "TRAINED_CATEGORY"], [5028, 5034, "TRAINED_CATEGORY"], [5036, 5042, "TRAINED_CATEGORY"], [5047, 5055, "TRAINED_CATEGORY"], [5061, 5063, "TRAINED_CATEGORY"], [5073, 5096, "TRAINED_CATEGORY"], [5101, 5125, "TRAINED_CATEGORY"], [5129, 5151, "TRAINED_CATEGORY"], [5176, 5185, "TRAINED_CATEGORY"], [5187, 5202, "TRAINED_CATEGORY"], [5206, 5229, "TRAINED_CATEGORY"], [5247, 5271, "TRAINED_CATEGORY"], [5286, 5311, "TRAINED_CATEGORY"], [5315, 5337, "TRAINED_CATEGORY"], [5340, 5348, "TRAINED_CATEGORY"], [5357, 5363, "TRAINED_CATEGORY"], [5374, 5397, "TRAINED_CATEGORY"], [5413, 5422, "TRAINED_CATEGORY"], [5423, 5425, "TRAINED_CATEGORY"], [5436, 5449, "TRAINED_CATEGORY"], [5451, 5460, "TRAINED_CATEGORY"], [5469, 5476, "TRAINED_CATEGORY"], [5486, 5492, "TRAINED_CATEGORY"], [5519, 5537, "TRAINED_CATEGORY"], [5544, 5553, "TRAINED_CATEGORY"], [5597, 5604, "TRAINED_CATEGORY"], [5612, 5628, "TRAINED_CATEGORY"], [5634, 5661, "TRAINED_CATEGORY"], [5665, 5684, "TRAINED_CATEGORY"], [5686, 5696, "TRAINED_CATEGORY"], [5700, 5705, "TRAINED_CATEGORY"], [5716, 5718, "TRAINED_CATEGORY"], [5720, 5731, "TRAINED_CATEGORY"], [5733, 5748, "TRAINED_CATEGORY"], [5756, 5758, "TRAINED_CATEGORY"], [5760, 5767, "TRAINED_CATEGORY"], [5769, 5792, "TRAINED_CATEGORY"], [5796, 5803, "TRAINED_CATEGORY"], [5811, 5813, "TRAINED_CATEGORY"], [5815, 5837, "TRAINED_CATEGORY"], [5850, 5862, "TRAINED_CATEGORY"], [5872, 5898, "TRAINED_CATEGORY"], [5899, 5903, "TRAINED_CATEGORY"], [5914, 5944, "TRAINED_CATEGORY"], [5946, 5954, "TRAINED_CATEGORY"], [5956, 5972, "TRAINED_CATEGORY"], [5974, 5993, "TRAINED_CATEGORY"], [6015, 6026, "TRAINED_CATEGORY"], [6052, 6059, "TRAINED_CATEGORY"], [6061, 6093, "TRAINED_CATEGORY"], [6098, 6107, "TRAINED_CATEGORY"], [6111, 6126, "TRAINED_CATEGORY"], [6128, 6132, "TRAINED_CATEGORY"], [6165, 6174, "TRAINED_CATEGORY"], [6176, 6180, "TRAINED_CATEGORY"], [6196, 6199, "TRAINED_CATEGORY"], [6205, 6214, "TRAINED_CATEGORY"], [6218, 6228, "TRAINED_CATEGORY"], [6230, 6242, "TRAINED_CATEGORY"], [6246, 6254, "TRAINED_CATEGORY"], [6256, 6262, "TRAINED_CATEGORY"], [6264, 6270, "TRAINED_CATEGORY"], [6276, 6290, "TRAINED_CATEGORY"], [6297, 6311, "TRAINED_CATEGORY"], [6319, 6348, "TRAINED_CATEGORY"], [6350, 6373, "TRAINED_CATEGORY"], [6376, 6390, "TRAINED_CATEGORY"], [6391, 6415, "TRAINED_CATEGORY"], [6417, 6433, "TRAINED_CATEGORY"], [6437, 6444, "TRAINED_CATEGORY"], [6451, 6466, "TRAINED_CATEGORY"], [6468, 6472, "TRAINED_CATEGORY"], [6488, 6496, "TRAINED_CATEGORY"], [6497, 6521, "TRAINED_CATEGORY"], [6523, 6553, "TRAINED_CATEGORY"], [6560, 6575, "TRAINED_CATEGORY"], [6577, 6581, "TRAINED_CATEGORY"], [6597, 6604, "TRAINED_CATEGORY"], [6605, 6620, "TRAINED_CATEGORY"], [6622, 6632, "TRAINED_CATEGORY"], [6637, 6648, "TRAINED_CATEGORY"], [6650, 6662, "TRAINED_CATEGORY"], [6666, 6696, "TRAINED_CATEGORY"], [6700, 6709, "TRAINED_CATEGORY"], [6711, 6718, "TRAINED_CATEGORY"], [6720, 6728, "TRAINED_CATEGORY"], [6730, 6735, "TRAINED_CATEGORY"], [6740, 6746, "TRAINED_CATEGORY"], [6753, 6767, "TRAINED_CATEGORY"], [6769, 6773, "TRAINED_CATEGORY"], [6789, 6804, "TRAINED_CATEGORY"], [6810, 6824, "TRAINED_CATEGORY"], [6826, 6838, "TRAINED_CATEGORY"], [6842, 6853, "TRAINED_CATEGORY"], [6860, 6876, "TRAINED_CATEGORY"], [6878, 6882, "TRAINED_CATEGORY"], [6898, 6901, "TRAINED_CATEGORY"], [6902, 6919, "TRAINED_CATEGORY"], [6923, 6938, "TRAINED_CATEGORY"], [6943, 6958, "TRAINED_CATEGORY"], [6964, 6994, "TRAINED_CATEGORY"], [6996, 7000, "TRAINED_CATEGORY"], [7016, 7019, "TRAINED_CATEGORY"], [7044, 7091, "TRAINED_CATEGORY"], [7098, 7112, "TRAINED_CATEGORY"], [7114, 7118, "TRAINED_CATEGORY"], [7143, 7146, "TRAINED_CATEGORY"], [7148, 7151, "TRAINED_CATEGORY"], [7156, 7158, "TRAINED_CATEGORY"], [7162, 7199, "TRAINED_CATEGORY"], [7201, 7205, "TRAINED_CATEGORY"], [7206, 7223, "TRAINED_CATEGORY"], [7224, 7235, "TRAINED_CATEGORY"], [7237, 7244, "TRAINED_CATEGORY"], [7246, 7254, "TRAINED_CATEGORY"], [7257, 7269, "TRAINED_CATEGORY"], [7273, 7303, "TRAINED_CATEGORY"], [7310, 7324, "TRAINED_CATEGORY"], [7346, 7361, "TRAINED_CATEGORY"], [7367, 7388, "TRAINED_CATEGORY"], [7436, 7450, "TRAINED_CATEGORY"], [7452, 7456, "TRAINED_CATEGORY"], [7502, 7532, "TRAINED_CATEGORY"], [7537, 7559, "TRAINED_CATEGORY"], [7566, 7572, "TRAINED_CATEGORY"], [7667, 7678, "TRAINED_CATEGORY"], [7682, 7697, "TRAINED_CATEGORY"], [7712, 7723, "TRAINED_CATEGORY"], [7727, 7741, "TRAINED_CATEGORY"], [7749, 7773, "TRAINED_CATEGORY"], [7774, 7778, "TRAINED_CATEGORY"], [7810, 7820, "TRAINED_CATEGORY"], [7825, 7833, "TRAINED_CATEGORY"], [7835, 7863, "TRAINED_CATEGORY"], [7865, 7869, "TRAINED_CATEGORY"], [7885, 7888, "TRAINED_CATEGORY"], [7889, 7900, "TRAINED_CATEGORY"], [7905, 7917, "TRAINED_CATEGORY"], [7921, 7949, "TRAINED_CATEGORY"], [7972, 7980, "TRAINED_CATEGORY"], [7982, 7995, "TRAINED_CATEGORY"], [7997, 8002, "TRAINED_CATEGORY"], [8007, 8012, "TRAINED_CATEGORY"], [8043, 8057, "TRAINED_CATEGORY"], [8059, 8071, "TRAINED_CATEGORY"], [8075, 8084, "TRAINED_CATEGORY"], [8090, 8100, "TRAINED_CATEGORY"], [8105, 8113, "TRAINED_CATEGORY"], [8123, 8151, "TRAINED_CATEGORY"], [8158, 8175, "TRAINED_CATEGORY"], [8177, 8181, "TRAINED_CATEGORY"], [8227, 8255, "TRAINED_CATEGORY"], [8257, 8315, "TRAINED_CATEGORY"], [8321, 8329, "TRAINED_CATEGORY"], [8331, 8344, "TRAINED_CATEGORY"], [8346, 8351, "TRAINED_CATEGORY"], [8356, 8361, "TRAINED_CATEGORY"], [8368, 8382, "TRAINED_CATEGORY"], [8384, 8388, "TRAINED_CATEGORY"], [8418, 8432, "TRAINED_CATEGORY"], [8434, 8440, "TRAINED_CATEGORY"], [8444, 8456, "TRAINED_CATEGORY"], [8460, 8477, "TRAINED_CATEGORY"], [8484, 8512, "TRAINED_CATEGORY"], [8519, 8530, "TRAINED_CATEGORY"], [8532, 8536, "TRAINED_CATEGORY"], [8552, 8555, "TRAINED_CATEGORY"], [8561, 8626, "TRAINED_CATEGORY"], [8628, 8640, "TRAINED_CATEGORY"], [8644, 8653, "TRAINED_CATEGORY"], [8660, 8664, "TRAINED_CATEGORY"], [8667, 8683, "TRAINED_CATEGORY"], [8687, 8715, "TRAINED_CATEGORY"], [8746, 8768, "TRAINED_CATEGORY"], [8769, 8773, "TRAINED_CATEGORY"], [8784, 8793, "TRAINED_CATEGORY"], [8806, 8817, "TRAINED_CATEGORY"], [8825, 8827, "TRAINED_CATEGORY"], [8835, 8861, "TRAINED_CATEGORY"], [8863, 8867, "TRAINED_CATEGORY"], [8883, 8886, "TRAINED_CATEGORY"], [8892, 8924, "TRAINED_CATEGORY"], [8926, 8949, "TRAINED_CATEGORY"], [8953, 8985, "TRAINED_CATEGORY"], [8989, 9017, "TRAINED_CATEGORY"], [9021, 9034, "TRAINED_CATEGORY"], [9039, 9048, "TRAINED_CATEGORY"], [9050, 9054, "TRAINED_CATEGORY"], [9070, 9073, "TRAINED_CATEGORY"], [9080, 9099, "TRAINED_CATEGORY"], [9104, 9129, "TRAINED_CATEGORY"], [9133, 9143, "TRAINED_CATEGORY"], [9154, 9161, "TRAINED_CATEGORY"], [9202, 9213, "TRAINED_CATEGORY"], [9215, 9236, "TRAINED_CATEGORY"], [9238, 9242, "TRAINED_CATEGORY"], [9244, 9263, "TRAINED_CATEGORY"], [9264, 9274, "TRAINED_CATEGORY"], [9276, 9289, "TRAINED_CATEGORY"], [9293, 9308, "TRAINED_CATEGORY"], [9314, 9326, "TRAINED_CATEGORY"], [9328, 9335, "TRAINED_CATEGORY"], [9383, 9394, "TRAINED_CATEGORY"], [9401, 9412, "TRAINED_CATEGORY"], [9417, 9443, "TRAINED_CATEGORY"], [9450, 9457, "TRAINED_CATEGORY"], [9459, 9479, "TRAINED_CATEGORY"], [9499, 9535, "TRAINED_CATEGORY"], [9537, 9555, "TRAINED_CATEGORY"], [9559, 9577, "TRAINED_CATEGORY"], [9579, 9588, "TRAINED_CATEGORY"], [9590, 9592, "TRAINED_CATEGORY"], [9594, 9597, "TRAINED_CATEGORY"], [9599, 9614, "TRAINED_CATEGORY"], [9616, 9622, "TRAINED_CATEGORY"], [9625, 9632, "TRAINED_CATEGORY"], [9650, 9658, "TRAINED_CATEGORY"], [9661, 9671, "TRAINED_CATEGORY"], [9672, 9690, "TRAINED_CATEGORY"], [9695, 9703, "TRAINED_CATEGORY"], [9710, 9721, "TRAINED_CATEGORY"], [9723, 9730, "TRAINED_CATEGORY"], [9778, 9787, "TRAINED_CATEGORY"], [9790, 9801, "TRAINED_CATEGORY"], [9802, 9833, "TRAINED_CATEGORY"], [9835, 9855, "TRAINED_CATEGORY"], [9876, 9912, "TRAINED_CATEGORY"], [9919, 9929, "TRAINED_CATEGORY"], [9934, 9938, "TRAINED_CATEGORY"], [9942, 9967, "TRAINED_CATEGORY"], [9969, 9985, "TRAINED_CATEGORY"], [9987, 9993, "TRAINED_CATEGORY"], [10000, 10009, "TRAINED_CATEGORY"], [10033, 10050, "TRAINED_CATEGORY"], [10054, 10062, "TRAINED_CATEGORY"], [10067, 10092, "TRAINED_CATEGORY"], [10094, 10101, "TRAINED_CATEGORY"], [10119, 10126, "TRAINED_CATEGORY"], [10129, 10140, "TRAINED_CATEGORY"], [10146, 10168, "TRAINED_CATEGORY"], [10218, 10232, "TRAINED_CATEGORY"], [10234, 10245, "TRAINED_CATEGORY"], [10247, 10267, "TRAINED_CATEGORY"], [10269, 10273, "TRAINED_CATEGORY"], [10275, 10294, "TRAINED_CATEGORY"], [10295, 10305, "TRAINED_CATEGORY"], [10321, 10332, "TRAINED_CATEGORY"], [10337, 10361, "TRAINED_CATEGORY"], [10365, 10377, "TRAINED_CATEGORY"], [10382, 10393, "TRAINED_CATEGORY"], [10395, 10399, "TRAINED_CATEGORY"], [10415, 10425, "TRAINED_CATEGORY"], [10426, 10437, "TRAINED_CATEGORY"], [10441, 10463, "TRAINED_CATEGORY"], [10465, 10498, "TRAINED_CATEGORY"], [10502, 10509, "TRAINED_CATEGORY"], [10529, 10535, "TRAINED_CATEGORY"], [10537, 10556, "TRAINED_CATEGORY"], [10560, 10572, "TRAINED_CATEGORY"], [10574, 10584, "TRAINED_CATEGORY"], [10590, 10605, "TRAINED_CATEGORY"], [10612, 10627, "TRAINED_CATEGORY"], [10627, 10642, "TRAINED_CATEGORY"], [10658, 10672, "TRAINED_CATEGORY"], [10692, 10700, "TRAINED_CATEGORY"], [10707, 10719, "TRAINED_CATEGORY"], [10724, 10741, "TRAINED_CATEGORY"], [10748, 10765, "TRAINED_CATEGORY"], [10767, 10780, "TRAINED_CATEGORY"], [10782, 10810, "TRAINED_CATEGORY"], [10865, 10877, "TRAINED_CATEGORY"], [10893, 10903, "TRAINED_CATEGORY"], [10910, 10924, "TRAINED_CATEGORY"], [10926, 10930, "TRAINED_CATEGORY"], [10954, 10976, "TRAINED_CATEGORY"], [10978, 10993, "TRAINED_CATEGORY"], [10996, 11004, "TRAINED_CATEGORY"], [11005, 11011, "TRAINED_CATEGORY"], [11013, 11017, "TRAINED_CATEGORY"], [11037, 11054, "TRAINED_CATEGORY"], [11056, 11080, "TRAINED_CATEGORY"], [11084, 11092, "TRAINED_CATEGORY"], [11096, 11110, "TRAINED_CATEGORY"], [11132, 11135, "TRAINED_CATEGORY"], [11141, 11151, "TRAINED_CATEGORY"], [11160, 11174, "TRAINED_CATEGORY"], [11192, 11202, "TRAINED_CATEGORY"], [11224, 11259, "TRAINED_CATEGORY"], [11263, 11271, "TRAINED_CATEGORY"], [11272, 11297, "TRAINED_CATEGORY"], [11308, 11331, "TRAINED_CATEGORY"], [11335, 11350, "TRAINED_CATEGORY"], [11356, 11369, "TRAINED_CATEGORY"], [11374, 11384, "TRAINED_CATEGORY"], [11385, 11393, "TRAINED_CATEGORY"], [11398, 11421, "TRAINED_CATEGORY"], [0, 15, "PERSON"], [17, 30, "DATE"], [33, 48, "DATE"], [56, 80, "ORG"], [94, 122, "ORG"], [143, 189, "FAC"], [250, 285, "FAC"], [391, 419, "ORG"], [421, 424, "ORG"], [537, 540, "ORG"], [544, 570, "ORG"], [572, 575, "ORG"], [666, 669, "ORG"], [682, 705, "DATE"], [762, 790, "ORG"], [853, 905, "ORG"], [939, 952, "DATE"], [965, 969, "GPE"], [1081, 1119, "ORG"], [1127, 1135, "ORG"], [1137, 1165, "ORG"], [1171, 1210, "ORG"], [1214, 1239, "ORG"], [1275, 1299, "ORG"], [1313, 1341, "ORG"], [1621, 1633, "CARDINAL"], [1644, 1647, "CARDINAL"], [1869, 1902, "ORG"], [1915, 1917, "CARDINAL"], [1969, 1980, "PERSON"], [1984, 1988, "ORG"], [2063, 2067, "DATE"], [2088, 2135, "ORG"], [2294, 2299, "ORDINAL"], [2365, 2375, "DATE"], [2468, 2472, "DATE"], [2518, 2532, "PERSON"], [2601, 2625, "ORG"], [2634, 2638, "DATE"], [2716, 2720, "DATE"], [2736, 2740, "CARDINAL"], [2779, 2783, "DATE"], [2790, 2800, "PERSON"], [2804, 2847, "WORK_OF_ART"], [2850, 2854, "DATE"], [2858, 2885, "WORK_OF_ART"], [2888, 2892, "DATE"], [2900, 2930, "WORK_OF_ART"], [2933, 2937, "DATE"], [2980, 2985, "ORDINAL"], [3047, 3066, "ORG"], [3089, 3096, "NORP"], [3101, 3109, "NORP"], [3169, 3181, "PERSON"], [3185, 3202, "ORG"], [3334, 3337, "CARDINAL"], [3399, 3451, "WORK_OF_ART"], [3491, 3501, "DATE"], [3772, 3802, "WORK_OF_ART"], [3826, 3834, "ORG"], [3848, 3866, "DATE"], [4006, 4041, "ORG"], [4043, 4047, "DATE"], [4054, 4091, "ORG"], [4093, 4112, "ORG"], [4114, 4121, "NORP"], [4122, 4147, "ORG"], [4149, 4153, "DATE"], [4159, 4163, "DATE"], [4177, 4201, "ORG"], [4207, 4246, "ORG"], [4287, 4350, "WORK_OF_ART"], [4359, 4363, "CARDINAL"], [4386, 4390, "DATE"], [4424, 4458, "ORG"], [4468, 4483, "WORK_OF_ART"], [4495, 4499, "DATE"], [4513, 4527, "WORK_OF_ART"], [4531, 4548, "ORG"], [4553, 4557, "DATE"], [4571, 4595, "LAW"], [4651, 4667, "LAW"], [4679, 4694, "DATE"], [4900, 4904, "DATE"], [4957, 4964, "PRODUCT"], [5001, 5024, "ORG"], [5028, 5034, "GPE"], [5036, 5042, "GPE"], [5047, 5060, "DATE"], [5073, 5151, "PERSON"], [5187, 5229, "ORG"], [5257, 5271, "PERSON"], [5286, 5355, "ORG"], [5436, 5449, "PERSON"], [5455, 5460, "PERSON"], [5469, 5482, "DATE"], [5486, 5501, "DATE"], [5503, 5512, "DATE"], [5544, 5553, "ORG"], [5557, 5560, "WORK_OF_ART"], [5562, 5573, "ORG"], [5575, 5590, "ORG"], [5612, 5628, "PERSON"], [5634, 5661, "ORG"], [5686, 5705, "ORG"], [5720, 5731, "ORG"], [5733, 5748, "ORG"], [5750, 5754, "DATE"], [5760, 5767, "ORG"], [5769, 5803, "ORG"], [5805, 5809, "DATE"], [5815, 5837, "ORG"], [5839, 5843, "DATE"], [5850, 5862, "GPE"], [5872, 5880, "GPE"], [5900, 5903, "ORG"], [5909, 5913, "DATE"], [5914, 5993, "WORK_OF_ART"], [5995, 5999, "ORG"], [6015, 6026, "ORG"], [6027, 6031, "DATE"], [6032, 6126, "WORK_OF_ART"], [6128, 6132, "ORG"], [6148, 6157, "GPE"], [6159, 6163, "DATE"], [6165, 6174, "PERSON"], [6176, 6180, "ORG"], [6196, 6199, "ORG"], [6200, 6204, "DATE"], [6205, 6228, "PRODUCT"], [6297, 6311, "PERSON"], [6313, 6317, "ORG"], [6344, 6348, "ORG"], [6376, 6390, "PERSON"], [6391, 6395, "DATE"], [6451, 6466, "PERSON"], [6468, 6472, "ORG"], [6488, 6496, "GPE"], [6497, 6501, "DATE"], [6560, 6575, "PERSON"], [6577, 6581, "ORG"], [6582, 6595, "PRODUCT"], [6597, 6609, "ORG"], [6753, 6767, "PERSON"], [6769, 6773, "ORG"], [6789, 6795, "ORG"], [6805, 6809, "DATE"], [6860, 6876, "PERSON"], [6878, 6882, "ORG"], [6898, 6901, "ORG"], [6902, 6906, "DATE"], [6907, 6958, "LAW"], [7016, 7019, "ORG"], [7020, 7024, "DATE"], [7025, 7091, "WORK_OF_ART"], [7098, 7112, "PERSON"], [7114, 7118, "ORG"], [7134, 7137, "ORG"], [7138, 7142, "DATE"], [7143, 7146, "PERSON"], [7148, 7151, "ORG"], [7201, 7205, "ORG"], [7224, 7228, "DATE"], [7310, 7324, "PERSON"], [7326, 7330, "ORG"], [7346, 7361, "ORG"], [7362, 7366, "DATE"], [7436, 7450, "PERSON"], [7452, 7456, "ORG"], [7472, 7475, "ORG"], [7476, 7480, "DATE"], [7539, 7559, "ORG"], [7561, 7564, "GPE"], [7566, 7567, "CARDINAL"], [7749, 7757, "ORG"], [7775, 7778, "ORG"], [7784, 7788, "DATE"], [7789, 7820, "WORK_OF_ART"], [7825, 7834, "WORK_OF_ART"], [7865, 7869, "ORG"], [7885, 7888, "ORG"], [7889, 7893, "DATE"], [7905, 7950, "ORG"], [8007, 8012, "PERSON"], [8014, 8018, "ORG"], [8034, 8037, "ORG"], [8038, 8042, "DATE"], [8047, 8057, "ORG"], [8105, 8113, "ORG"], [8123, 8151, "ORG"], [8158, 8175, "PERSON"], [8177, 8181, "ORG"], [8197, 8200, "ORG"], [8201, 8205, "DATE"], [8206, 8221, "WORK_OF_ART"], [8356, 8361, "PERSON"], [8368, 8382, "PERSON"], [8384, 8388, "ORG"], [8404, 8412, "ORG"], [8422, 8432, "ORG"], [8441, 8442, "CARDINAL"], [8519, 8530, "PERSON"], [8532, 8536, "ORG"], [8552, 8555, "ORG"], [8556, 8560, "DATE"], [8667, 8715, "ORG"], [8717, 8718, "CARDINAL"], [8720, 8721, "CARDINAL"], [8724, 8731, "CARDINAL"], [8734, 8738, "DATE"], [8746, 8752, "ORG"], [8770, 8773, "ORG"], [8779, 8783, "DATE"], [8784, 8793, "LAW"], [8863, 8867, "ORG"], [8883, 8886, "ORG"], [8887, 8891, "DATE"], [8892, 8924, "PERSON"], [9039, 9048, "GPE"], [9050, 9054, "ORG"], [9070, 9073, "ORG"], [9080, 9090, "ORG"], [9104, 9108, "DATE"], [9109, 9152, "WORK_OF_ART"], [9157, 9161, "ORG"], [9179, 9187, "LANGUAGE"], [9192, 9199, "LANGUAGE"], [9202, 9213, "ORG"], [9215, 9219, "DATE"], [9258, 9263, "GPE"], [9276, 9280, "DATE"], [9331, 9335, "ORG"], [9353, 9360, "LANGUAGE"], [9362, 9369, "NORP"], [9374, 9380, "NORP"], [9383, 9394, "ORG"], [9401, 9412, "ORG"], [9450, 9457, "PERSON"], [9462, 9466, "ORG"], [9468, 9479, "ORG"], [9481, 9485, "DATE"], [9499, 9503, "ORG"], [9519, 9524, "GPE"], [9537, 9546, "DATE"], [9559, 9577, "ORG"], [9590, 9592, "GPE"], [9594, 9597, "ORG"], [9599, 9614, "PERSON"], [9628, 9632, "ORG"], [9650, 9658, "NORP"], [9661, 9671, "PERSON"], [9672, 9676, "DATE"], [9684, 9690, "NORP"], [9695, 9703, "ORG"], [9710, 9721, "PERSON"], [9726, 9730, "ORG"], [9748, 9756, "LANGUAGE"], [9758, 9765, "LANGUAGE"], [9767, 9773, "NORP"], [9778, 9787, "NORP"], [9790, 9801, "ORG"], [9838, 9842, "ORG"], [9844, 9855, "ORG"], [9857, 9861, "DATE"], [9876, 9880, "ORG"], [9896, 9901, "GPE"], [9914, 9918, "DATE"], [9923, 9929, "PERSON"], [9942, 9967, "ORG"], [9970, 9985, "PERSON"], [10000, 10009, "PERSON"], [10015, 10019, "ORG"], [10021, 10032, "ORG"], [10033, 10037, "DATE"], [10038, 10092, "LAW"], [10097, 10101, "ORG"], [10119, 10126, "LANGUAGE"], [10129, 10140, "ORG"], [10146, 10168, "ORG"], [10170, 10178, "ORG"], [10183, 10191, "ORG"], [10193, 10197, "ORG"], [10218, 10232, "PERSON"], [10234, 10245, "ORG"], [10247, 10251, "DATE"], [10269, 10273, "ORG"], [10289, 10294, "GPE"], [10313, 10332, "ORG"], [10337, 10341, "DATE"], [10342, 10393, "WORK_OF_ART"], [10415, 10425, "PERSON"], [10426, 10430, "DATE"], [10441, 10463, "ORG"], [10468, 10472, "ORG"], [10474, 10509, "ORG"], [10510, 10514, "DATE"], [10590, 10605, "ORG"], [10612, 10627, "PERSON"], [10668, 10672, "ORG"], [10673, 10690, "PRODUCT"], [10692, 10700, "GPE"], [10724, 10728, "DATE"], [10729, 10741, "GPE"], [10748, 10765, "PERSON"], [10776, 10780, "ORG"], [10806, 10810, "ORG"], [10842, 10850, "NORP"], [10855, 10862, "LANGUAGE"], [10865, 10877, "PERSON"], [10878, 10882, "DATE"], [10883, 10903, "WORK_OF_ART"], [10910, 10924, "PERSON"], [10926, 10930, "ORG"], [10931, 10944, "PRODUCT"], [10959, 10976, "ORG"], [11013, 11017, "ORG"], [11033, 11036, "ORG"], [11037, 11041, "DATE"], [11112, 11116, "ORG"], [11132, 11135, "ORG"], [11160, 11168, "ORG"], [11178, 11202, "ORG"], [11224, 11239, "PERSON"], [11240, 11271, "ORG"], [11335, 11350, "PERSON"], [11356, 11393, "ORG"], [11398, 11421, "ORG"]]}], ["The analytic hierarchy process (AHP) is a structured technique for organizing and analyzing complex decisions, based on mathematics and psychology. It was developed by Thomas L. Saaty in the 1970s who partnered with Ernest Forman to develop Expert Choice in 1983, and has been extensively studied and refined since then. It represents an accurate approach for quantifying the weights of decision criteria. Individual experts\u2019 experiences are utilized to estimate the relative magnitudes of factors through pair-wise comparisons. Each of the respondents has to compare the relative importance between the two items under special designed questionnaire (note that while most of the surveys adopted the five point likert scale, AHP's questionnaire is 9 to 1 to 9, see Li et al. (2019)  )\n\n\n== Uses and applications ==\nAHP has particular application in group decision making, and is used around the world in a wide variety of decision situations, in fields such as government, business, industry, healthcare, shipbuilding and education.\nRather than prescribing a \"correct\" decision, the AHP helps decision makers find one that best suits their goal and their understanding of the problem. It provides a comprehensive and rational framework for structuring a decision problem, for representing and quantifying its elements, for relating those elements to overall goals, and for evaluating alternative solutions.\nUsers of the AHP first decompose their decision problem into a hierarchy of more easily comprehended sub-problems, each of which can be analyzed independently. The elements of the hierarchy can relate to any aspect of the decision problem\u2014tangible or intangible, carefully measured or roughly estimated, well or poorly understood\u2014anything at all that applies to the decision at hand.\nOnce the hierarchy is built, the decision makers systematically evaluate its various elements by comparing them to each other two at a time, with respect to their impact on an element above them in the hierarchy. In making the comparisons, the decision makers can use concrete data about the elements, but they typically use their judgments about the elements' relative meaning and importance. It is the essence of the AHP that human judgments, and not just the underlying information, can be used in performing the evaluations.The AHP converts these evaluations to numerical values that can be processed and compared over the entire range of the problem. A numerical weight or priority is derived for each element of the hierarchy, allowing diverse and often incommensurable elements to be compared to one another in a rational and consistent way. This capability distinguishes the AHP from other decision making techniques.\nIn the final step of the process, numerical priorities are calculated for each of the decision alternatives. These numbers represent the alternatives' relative ability to achieve the decision goal, so they allow a straightforward consideration of the various courses of action.\nSeveral firms supply computer software to assist in using the process.\nWhile it can be used by individuals working on straightforward decisions, the Analytic Hierarchy Process (AHP) is most useful where teams of people are working on complex problems, especially those with high stakes, involving human perceptions and judgments, whose resolutions have long-term repercussions.\nIt has unique advantages when important elements of the decision are difficult to quantify or compare, or where communication among team members is impeded by their different specializations, terminologies, or perspectives.\nDecision situations to which the AHP can be applied include:\nChoice \u2013 The selection of one alternative from a given set of alternatives, usually where there are multiple decision criteria involved.\nRanking \u2013 Putting a set of alternatives in order from most to least desirable.\nPrioritization \u2013 Determining the relative merit of members of a set of alternatives, as opposed to selecting a single one or merely ranking them\nResource allocation \u2013 Apportioning resources among a set of alternatives\nBenchmarking \u2013 Comparing the processes in one's own organization with those of other best-of-breed organizations\nQuality management \u2013 Dealing with the multidimensional aspects of quality and quality improvement\nConflict resolution \u2013 Settling disputes between parties with apparently incompatible goals or positionsThe applications of AHP to complex decision situations have numbered in the thousands, and have produced extensive results in problems involving planning, resource allocation, priority setting, and selection among alternatives. Other areas have included forecasting, total quality management, business process reengineering, quality function deployment, and the balanced scorecard. Many AHP applications are never reported to the world at large, because they take place at high levels of large organizations where security and privacy considerations prohibit their disclosure. But some uses of AHP are discussed in the literature. Recently these have included:\n\nSelect a type of nuclear reactors (Politecnico di Milano)\nDeciding how best to reduce the impact of global climate change (Fondazione Eni Enrico Mattei)\nQuantifying the overall quality of software systems (Microsoft Corporation)\nSelecting university faculty (Bloomsburg University of Pennsylvania)\nDeciding where to locate offshore manufacturing plants (University of Cambridge)\nAssessing risk in operating cross-country petroleum pipelines (American Society of Civil Engineers)\nDeciding how best to manage U.S. watersheds (U.S. Department of Agriculture)\nMore Effectively Define and Evaluate SAP Implementation Approaches (SAP Experts)\nAccelerated Bridge Construction Decision Making Tool to assist in determining the viability of accelerated bridge construction (ABC) over traditional construction methods and in selecting appropriate construction and contracting strategies on a case-by-case basis.AHP is sometimes used in designing highly specific procedures for particular situations, such as the rating of buildings by historic significance. It was recently applied to a project that uses video footage to assess the condition of highways in Virginia. Highway engineers first used it to determine the optimum scope of the project, then to justify its budget to lawmakers.\n\n\n== Education and scholarly research ==\nThough using the analytic hierarchy process requires no specialized academic training, it is considered an important subject in many institutions of higher learning, including schools of engineering and graduate schools of business. It is a particularly important subject in the quality field, and is taught in many specialized courses including Six Sigma, Lean Six Sigma, and QFD.The value of the AHP is recognized in developed and developing countries around the world. China is an example\u2014nearly a hundred Chinese universities offer courses in AHP, and many doctoral students choose AHP as the subject of their research and dissertations. Over 900 papers have been published on the subject in China, and there is at least one Chinese scholarly journal devoted exclusively to AHP.The International Symposium on the Analytic Hierarchy Process (ISAHP) holds biennial meetings of academics and practitioners interested in the field. A wide range of topics are covered. Those in 2005 ranged from \"Establishing Payment Standards for Surgical Specialists\", to \"Strategic Technology Roadmapping\", to \"Infrastructure Reconstruction in Devastated Countries\".\nAt the 2007 meeting in Valpara\u00edso, Chile, over 90 papers were presented from 19 countries, including the US, Germany, Japan, Chile, Malaysia, and Nepal. A similar number of papers were presented at the 2009 symposium in Pittsburgh, Pennsylvania, when 28 countries were represented. Subjects of the papers included Economic Stabilization in Latvia, Portfolio Selection in the Banking Sector, Wildfire Management to Help Mitigate Global Warming, and Rural Microprojects in Nepal.\n\n\n== Use ==\nAs can be seen in the material that follows, using the AHP involves the mathematical synthesis of numerous judgments about the decision problem at hand. It is not uncommon for these judgments to number in the dozens or even the hundreds. While the math can be done by hand or with a calculator, it is far more common to use one of several computerized methods for entering and synthesizing the judgments. The simplest of these involve standard spreadsheet software, while the most complex use custom software, often augmented by special devices for acquiring the judgments of decision makers gathered in a meeting room.\nThe procedure for using the AHP can be summarized as:\n\nModel the problem as a hierarchy containing the decision goal, the alternatives for reaching it, and the criteria for evaluating the alternatives.\nEstablish priorities among the elements of the hierarchy by making a series of judgments based on pairwise comparisons of the elements. For example, when comparing potential purchases of commercial real estate, the investors might say they prefer location over price and price over timing.\nSynthesize these judgments to yield a set of overall priorities for the hierarchy. This would combine the investors' judgments about location, price and timing for properties A, B, C, and D into overall priorities for each property.\nCheck the consistency of the judgments.\nCome to a final decision based on the results of this process.These steps are more fully described below.\n\n\n=== Model the problem as a hierarchy ===\nThe first step in the analytic hierarchy process is to model the problem as a hierarchy. In doing this, participants explore the aspects of the problem at levels from general to detailed, then express it in the multileveled way that the AHP requires. As they work to build the hierarchy, they increase their understanding of the problem, of its context, and of each other's thoughts and feelings about both.\n\n\n==== Hierarchies defined ====\nA hierarchy is a stratified system of ranking and organizing people, things, ideas, etc., where each element of the system, except for the top one, is subordinate to one or more other elements. Though the concept of hierarchy is easily grasped intuitively, it can also be described mathematically. Diagrams of hierarchies are often shaped roughly like pyramids, but other than having a single element at the top, there is nothing necessarily pyramid-shaped about a hierarchy.\nHuman organizations are often structured as hierarchies, where the hierarchical system is used for assigning responsibilities, exercising leadership, and facilitating communication. Familiar hierarchies of \"things\" include a desktop computer's tower unit at the \"top\", with its subordinate monitor, keyboard, and mouse \"below.\"\nIn the world of ideas, we use hierarchies to help us acquire detailed knowledge of complex reality: we structure the reality into its constituent parts, and these in turn into their own constituent parts, proceeding down the hierarchy as many levels as we care to. At each step, we focus on understanding a single component of the whole, temporarily disregarding the other components at this and all other levels. As we go through this process, we increase our global understanding of whatever complex reality we are studying.\nThink of the hierarchy that medical students use while learning anatomy\u2014they separately consider the musculoskeletal system (including parts and subparts like the hand and its constituent muscles and bones), the circulatory system (and its many levels and branches), the nervous system (and its numerous components and subsystems), etc., until they've covered all the systems and the important subdivisions of each. Advanced students continue the subdivision all the way to the level of the cell or molecule. In the end, the students understand the \"big picture\" and a considerable number of its details. Not only that, but they understand the relation of the individual parts to the whole. By working hierarchically, they've gained a comprehensive understanding of anatomy.\nSimilarly, when we approach a complex decision problem, we can use a hierarchy to integrate large amounts of information into our understanding of the situation. As we build this information structure, we form a better and better picture of the problem as a whole.\n\n\n==== Hierarchies in the AHP ====\nAn AHP hierarchy is a structured means of modeling the decision at hand. It consists of an overall goal, a group of options or alternatives for reaching the goal, and a group of factors or criteria that relate the alternatives to the goal. The criteria can be further broken down into subcriteria, sub-subcriteria, and so on, in as many levels as the problem requires. A criterion may not apply uniformly, but may have graded differences like a little sweetness is enjoyable but too much sweetness can be harmful. In that case the criterion is divided into subcriteria indicating different intensities of the criterion, like: little, medium, high and these intensities are prioritized through comparisons under the parent criterion, sweetness.\nPublished descriptions of AHP applications often include diagrams and descriptions of their hierarchies; some simple ones are shown throughout this article. More complex AHP hierarchies have been collected and reprinted in at least one book. More complex hierarchies can be found in a special talk page for this article.\nThe design of any AHP hierarchy will depend not only on the nature of the problem at hand, but also on the knowledge, judgments, values, opinions, needs, wants, etc. of the participants in the decision-making process. Constructing a hierarchy typically involves significant discussion, research, and discovery by those involved. Even after its initial construction, it can be changed to accommodate newly-thought-of criteria or criteria not originally considered to be important; alternatives can also be added, deleted, or changed.To better understand AHP hierarchies, consider a decision problem with a goal to be reached, three alternative ways of reaching the goal, and four criteria against which the alternatives need to be measured.\nSuch a hierarchy can be visualized as a diagram like the one immediately below, with the goal at the top, the three alternatives at the bottom, and the four criteria in between. There are useful terms for describing the parts of such diagrams: Each box is called a node. A node that is connected to one or more nodes in a level below it is called a parent node. The nodes to which it is so connected are called its children.\nApplying these definitions to the diagram below, the goal is the parent of the four criteria, and the four criteria are children of the goal. Each criterion is a parent of the three Alternatives. Note that there are only three Alternatives, but in the diagram, each of them is repeated under each of its parents.\n\nTo reduce the size of the drawing required, it is common to represent AHP hierarchies as shown in the diagram below, with only one node for each alternative, and with multiple lines connecting the alternatives and the criteria that apply to them. To avoid clutter, these lines are sometimes omitted or reduced in number. Regardless of any such simplifications in the diagram, in the actual hierarchy each criterion is individually connected to the alternatives. The lines may be thought of as being directed downward from the parent in one level to its children in the level below.\n\n\n=== Evaluate the hierarchy ===\nOnce the hierarchy has been constructed, the participants analyze it through a series of pairwise comparisons that derive numerical scales of measurement for the nodes. The criteria are pairwise compared against the goal for importance. The alternatives are pairwise compared against each of the criteria for preference. The comparisons are processed mathematically, and priorities are derived for each node.\nConsider the \"Choose a Leader\" example above. An important task of the decision makers is to determine the weight to be given each criterion in making the choice of a leader. Another important task is to determine the weight to be given to each candidate with regard to each of the criteria. The AHP not only lets them do that, but it lets them put a meaningful and objective numerical value on each of the four criteria.\n\n\n=== Establish priorities ===\nThis section explains priorities, shows how they are established, and provides a simple example.\n\n\n==== Priorities defined and explained ====\nPriorities are numbers associated with the nodes of an AHP hierarchy. They represent the relative weights of the nodes in any group.\nLike probabilities, priorities are absolute numbers between zero and one, without units or dimensions. A node with priority .200 has twice the weight in reaching the goal as one with priority .100, ten times the weight of one with priority .020, and so forth. Depending on the problem at hand, \"weight\" can refer to importance, or preference, or likelihood, or whatever factor is being considered by the decision makers.\nPriorities are distributed over a hierarchy according to its architecture, and their values depend on the information entered by users of the process. Priorities of the Goal, the Criteria, and the Alternatives are intimately related, but need to be considered separately.\nBy definition, the priority of the Goal is 1.000. The priorities of the alternatives always add up to 1.000. Things can become complicated with multiple levels of Criteria, but if there is only one level, their priorities also add to 1.000. All this is illustrated by the priorities in the example below.\n\nObserve that the priorities on each level of the example\u2014the goal, the criteria, and the alternatives\u2014all add up to 1.000.\nThe priorities shown are those that exist before any information has been entered about weights of the criteria or alternatives, so the priorities within each level are all equal. They are called the hierarchy's default priorities. If a fifth Criterion were added to this hierarchy, the default priority for each Criterion would be .200. If there were only two Alternatives, each would have a default priority of .500.\nTwo additional concepts apply when a hierarchy has more than one level of criteria: local priorities and global priorities. Consider the hierarchy shown below, which has several Subcriteria under each Criterion.\n\nThe local priorities, shown in gray, represent the relative weights of the nodes within a group of siblings with respect to their parent. The local priorities of each group of Criteria and their sibling Subcriteria add up to 1.000. The global priorities, shown in black, are obtained by multiplying the local priorities of the siblings by their parent's global priority. The global priorities for all the subcriteria in the level add up to 1.000.\nThe rule is this: Within a hierarchy, the global priorities of child nodes always add up to the global priority of their parent. Within a group of children, the local priorities add up to 1.000.\nSo far, we have looked only at default priorities. As the Analytical Hierarchy Process moves forward, the priorities will change from their default values as the decision makers input information about the importance of the various nodes. They do this by making a series of pairwise comparisons.\n\n\n== Practical examples ==\nExperienced practitioners know that the best way to understand the AHP is to work through cases and examples. Two detailed case studies, specifically designed as in-depth teaching examples, are provided as appendices to this article:\n\nSimple step-by-step example with four Criteria and three Alternatives: Choosing a leader for an organization.\nMore complex step-by-step example with ten Criteria/Subcriteria and six Alternatives: Buying a family car and Machinery Selection Example.Some of the books on AHP contain practical examples of its use, though they are not typically intended to be step-by-step learning aids. One of them contains a handful of expanded examples, plus about 400 AHP hierarchies briefly described and illustrated with figures. Many examples are discussed, mostly for professional audiences, in papers published by the International Symposium on the Analytic Hierarchy Process.\n\n\n== Criticisms ==\nThe AHP is included in most operations research and management science textbooks, and is taught in numerous universities; it is used extensively in organizations that have carefully investigated its theoretical underpinnings. While the general consensus is that it is both technically valid and practically useful, the method does have its critics. \nIn the early 1990s a series of debates between critics and proponents of AHP was published in Management Science and The Journal of the Operational Research Society. These debates seem to have been settled in favor of AHP: \n\nAn in-depth paper discussing and rebutting the academic criticisms of AHP was published in Operations Research in 2001.\nA  2008 Management Science paper reviewing 15 years of progress in all areas of Multicriteria Decision Making showed that AHP publications have far outnumbered those in any other area, characterizing their growth as \"enormous.\"\nAlso in 2008, the major society for operations research, the Institute for Operations Research and the Management Sciences formally recognized AHP's broad impact on its fields.Occasional criticisms still appear. A 1997 paper examined possible flaws in the verbal (vs. numerical) scale often used in AHP pairwise comparisons. Another from the same year claimed that innocuous changes to the AHP model can introduce order where no order exists. A 2006 paper found that the addition of criteria for which all alternatives perform equally can alter the priorities of alternatives.\n\n\n== Rank reversal ==\nDecision making involves ranking alternatives in terms of criteria or attributes of those alternatives. It is an axiom of some decision theories that when new alternatives are added to a decision problem, the ranking of the old alternatives must not change \u2014 that \"rank reversal\" must not occur.\nThere are two schools of thought about rank reversal. One maintains that new alternatives that introduce no additional attributes should not cause rank reversal under any circumstances. The other maintains that there are some situations in which rank reversal can reasonably be expected. The original formulation of AHP allowed rank reversals.  In 1993, Forman introduced a second AHP synthesis mode, called the ideal synthesis mode, to address choice situations in which the addition or removal of an 'irrelevant' alternative should not and will not cause a change in the ranks of existing alternatives. The current version of the AHP can accommodate both these schools\u2014its ideal mode preserves rank, while its distributive mode allows the ranks to change. Either mode is selected according to the problem at hand.\nRank reversal and AHP are extensively discussed in a 2001 paper in Operations Research, as well as a chapter entitled Rank Preservation and Reversal, in the current basic book on AHP. The latter presents published examples of rank reversal due to adding copies and near copies of an alternative, due to intransitivity of decision rules, due to adding phantom and decoy alternatives, and due to the switching phenomenon in utility functions. It also discusses the Distributive and Ideal Modes of AHP.\nA new form of rank reversal of AHP was found in 2014 in which AHP produces rank order reversal when eliminating irrelevant data, this is data that do not differentiate alternatives.\nThere are different types of rank reversals.  Also, other methods besides the AHP may exhibit such rank reversals.  More discussion on rank reversals with the AHP and other MCDM methods is provided in the rank reversals in decision-making page.\n\n\n== Non-monotonicity of some weight extraction methods ==\nWithin a comparison matrix one may replace a judgement with a less favorable judgment and then check to see if the indication of the new priority becomes less favorable then the original priority. In the context of tournament matrices, it has been proven by Oskar Perron that the principal right eigenvector method is not monotonic. This behaviour can also be demonstrated for reciprocal n x n matrices, where n > 3. Alternative approaches are discussed elsewhere.\n\n\n== See also ==\nAnalytic network process\nArrow's impossibility theorem\nDecision making\nDecision-making paradox\nDecision-making software\nHierarchical decision process\nL. L. Thurstone\nLaw of comparative judgment\nMulti-criteria decision analysis\nPairwise comparison\nPreference\nPrincipal component analysis\nRank reversals in decision-making\n\n\n== References ==\n\n\n== Further reading ==\nSaaty, Thomas L. Decision Making for Leaders: The Analytical Hierarchy Process for Decisions in a Complex World (1982). Belmont, California: Wadsworth. ISBN 0-534-97959-9; Paperback, Pittsburgh: RWS. ISBN 0-9620317-0-4. \"Focuses on practical application of the AHP; briefly covers theory.\"\nSaaty, Thomas L. Fundamentals of Decision Making and Priority Theory with the Analytic Hierarchy Process (1994). Pittsburgh: RWS. ISBN 0-9620317-6-3. \"A thorough exposition of the theoretical aspects of AHP.\"\nSaaty, Thomas L. Mathematical Principles of Decision Making (Principia Mathematica Decernendi) (2009). Pittsburgh: RWS. ISBN 1-888603-10-0. \"Comprehensive coverage of the AHP, its successor the ANP, and further developments of their underlying concepts.\"\nSaaty, Thomas L., with Ernest H. Forman. The Hierarchon: A Dictionary of Hierarchies. (1992) Pittsburgh: RWS. ISBN 0-9620317-5-5. \"Dozens of illustrations and examples of AHP hierarchies. A beginning classification of ideas relating to planning, conflict resolution, and decision making.\"\nSaaty, Thomas L., with Luis G. Vargas The Logic of Priorities: Applications in Business, Energy, Health, and Transportation (1982). Boston: Kluwer-Nijhoff. ISBN 0-89838-071-5 (Hardcover) ISBN 0-89838-078-2 (Paperback). Republished 1991 by RWS, ISBN 1-888603-07-0.\nKardi Teknomo. Analytic Hierarchy Process Tutorial (2012). Revoledu.\nKearns, Kevin P.; Saaty, Thomas L. Analytical Planning: The Organization of Systems (1985). Oxford: Pergamon Press. ISBN 0-08-032599-8. Republished 1991 by RWS, ISBN 1-888603-07-0.\nwith Joyce Alexander. Conflict Resolution: The Analytic Hierarchy Process (1989). New York: Praeger. ISBN 0-275-93229-X\nVargas, Luis L.; Saaty, Thomas L. Prediction, Projection and Forecasting: Applications of the Analytic Hierarchy Process in Economics, Finance, Politics, Games and Sports (1991). Boston: Kluwer Academic. ISBN 0-7923-9104-7\nVargas, Luis L.; Saaty, Thomas L. Decision Making in Economic, Social and Technological Environments (1994). Pittsburgh: RWS. ISBN 0-9620317-7-1\nVargas, Luis L.; Saaty, Thomas L. Models, Methods, Concepts & Applications of the Analytic Hierarchy Process (2001). Boston: Kluwer Academic. ISBN 0-7923-7267-0\nPeniwati, Kirti; Vargas, Luis L. Group Decision Making: Drawing Out and Reconciling Differences (2007). Pittsburgh: RWS. ISBN 1-888603-08-9\n\n\n== External links ==\nInternational Journal of the Analytic Hierarchy Process An online journal about multi-criteria decision making using the AHP.\neasyAHP Online tool to make collaborative decisions using AHP easyAHP is a free online tool to make decisions in a collaborative or individual way. easy AHP uses AHP methodology: Analytic hierarchy process.\nAHP video. (9:17 YouTube clip) Very thorough exposition of AHP by Dr. Klaus G\u00f6pel\nAnalytic Hierarchy Process (AHP) Example with Simulations using Matlab \u2013 Waqqas Farooq \u2013 AHP example for college selection using matlab.\nAn illustrated guide (pdf) \u2013 Dr. Oliver Meixner University of Wien \u2013 \"Analytic Hierarchy Process\", a very easy to understand summary of the mathematical theory\nAHP example with Matlab implementation \u2013 AHP explanation with an example and matlab code.\nR ahp package \u2013 An AHP open source package.\nIntroductory Mathematics of the Analytic Hierarchy Process \u2013 An introduction to the mathematics of the Analytic Hierarchy Process.\nHow to use AHP for Project Prioritization by Dr. James Brown (webinar)\nGuide to use AHP in Excel A guide to using AHP in Excel by Dr. Richard Hodgett\nUse the AHP Methodology to More Effectively Define and Evaluate Your SAP Implementation Approach by Jeetendra Kumar", {"entities": [[0, 30, "TRAINED_CATEGORY"], [32, 35, "TRAINED_CATEGORY"], [40, 62, "TRAINED_CATEGORY"], [92, 109, "TRAINED_CATEGORY"], [120, 131, "TRAINED_CATEGORY"], [136, 146, "TRAINED_CATEGORY"], [148, 150, "TRAINED_CATEGORY"], [168, 183, "TRAINED_CATEGORY"], [187, 196, "TRAINED_CATEGORY"], [197, 200, "TRAINED_CATEGORY"], [216, 229, "TRAINED_CATEGORY"], [241, 254, "TRAINED_CATEGORY"], [321, 323, "TRAINED_CATEGORY"], [335, 355, "TRAINED_CATEGORY"], [372, 383, "TRAINED_CATEGORY"], [387, 404, "TRAINED_CATEGORY"], [406, 437, "TRAINED_CATEGORY"], [463, 486, "TRAINED_CATEGORY"], [490, 497, "TRAINED_CATEGORY"], [506, 527, "TRAINED_CATEGORY"], [537, 552, "TRAINED_CATEGORY"], [568, 591, "TRAINED_CATEGORY"], [600, 613, "TRAINED_CATEGORY"], [620, 650, "TRAINED_CATEGORY"], [676, 687, "TRAINED_CATEGORY"], [696, 723, "TRAINED_CATEGORY"], [725, 744, "TRAINED_CATEGORY"], [765, 773, "TRAINED_CATEGORY"], [790, 794, "TRAINED_CATEGORY"], [799, 811, "TRAINED_CATEGORY"], [815, 818, "TRAINED_CATEGORY"], [823, 845, "TRAINED_CATEGORY"], [849, 870, "TRAINED_CATEGORY"], [891, 900, "TRAINED_CATEGORY"], [904, 918, "TRAINED_CATEGORY"], [922, 941, "TRAINED_CATEGORY"], [946, 952, "TRAINED_CATEGORY"], [961, 971, "TRAINED_CATEGORY"], [973, 981, "TRAINED_CATEGORY"], [983, 991, "TRAINED_CATEGORY"], [993, 1003, "TRAINED_CATEGORY"], [1005, 1017, "TRAINED_CATEGORY"], [1022, 1031, "TRAINED_CATEGORY"], [1057, 1077, "TRAINED_CATEGORY"], [1079, 1086, "TRAINED_CATEGORY"], [1093, 1108, "TRAINED_CATEGORY"], [1114, 1117, "TRAINED_CATEGORY"], [1134, 1144, "TRAINED_CATEGORY"], [1149, 1168, "TRAINED_CATEGORY"], [1172, 1183, "TRAINED_CATEGORY"], [1185, 1187, "TRAINED_CATEGORY"], [1197, 1235, "TRAINED_CATEGORY"], [1252, 1270, "TRAINED_CATEGORY"], [1305, 1317, "TRAINED_CATEGORY"], [1332, 1346, "TRAINED_CATEGORY"], [1350, 1363, "TRAINED_CATEGORY"], [1384, 1405, "TRAINED_CATEGORY"], [1407, 1412, "TRAINED_CATEGORY"], [1416, 1423, "TRAINED_CATEGORY"], [1440, 1462, "TRAINED_CATEGORY"], [1468, 1479, "TRAINED_CATEGORY"], [1483, 1520, "TRAINED_CATEGORY"], [1567, 1579, "TRAINED_CATEGORY"], [1583, 1596, "TRAINED_CATEGORY"], [1611, 1621, "TRAINED_CATEGORY"], [1625, 1645, "TRAINED_CATEGORY"], [1737, 1745, "TRAINED_CATEGORY"], [1769, 1781, "TRAINED_CATEGORY"], [1785, 1789, "TRAINED_CATEGORY"], [1796, 1809, "TRAINED_CATEGORY"], [1820, 1839, "TRAINED_CATEGORY"], [1864, 1884, "TRAINED_CATEGORY"], [1898, 1902, "TRAINED_CATEGORY"], [1924, 1930, "TRAINED_CATEGORY"], [1937, 1944, "TRAINED_CATEGORY"], [1948, 1960, "TRAINED_CATEGORY"], [1964, 1974, "TRAINED_CATEGORY"], [1981, 1985, "TRAINED_CATEGORY"], [1989, 2002, "TRAINED_CATEGORY"], [2014, 2029, "TRAINED_CATEGORY"], [2031, 2050, "TRAINED_CATEGORY"], [2059, 2072, "TRAINED_CATEGORY"], [2079, 2091, "TRAINED_CATEGORY"], [2097, 2101, "TRAINED_CATEGORY"], [2116, 2131, "TRAINED_CATEGORY"], [2138, 2168, "TRAINED_CATEGORY"], [2173, 2183, "TRAINED_CATEGORY"], [2185, 2187, "TRAINED_CATEGORY"], [2191, 2202, "TRAINED_CATEGORY"], [2206, 2213, "TRAINED_CATEGORY"], [2214, 2234, "TRAINED_CATEGORY"], [2240, 2275, "TRAINED_CATEGORY"], [2303, 2318, "TRAINED_CATEGORY"], [2319, 2326, "TRAINED_CATEGORY"], [2336, 2353, "TRAINED_CATEGORY"], [2357, 2373, "TRAINED_CATEGORY"], [2414, 2430, "TRAINED_CATEGORY"], [2434, 2445, "TRAINED_CATEGORY"], [2447, 2465, "TRAINED_CATEGORY"], [2469, 2477, "TRAINED_CATEGORY"], [2493, 2505, "TRAINED_CATEGORY"], [2509, 2522, "TRAINED_CATEGORY"], [2533, 2575, "TRAINED_CATEGORY"], [2609, 2638, "TRAINED_CATEGORY"], [2640, 2655, "TRAINED_CATEGORY"], [2670, 2677, "TRAINED_CATEGORY"], [2683, 2697, "TRAINED_CATEGORY"], [2705, 2715, "TRAINED_CATEGORY"], [2720, 2734, "TRAINED_CATEGORY"], [2738, 2749, "TRAINED_CATEGORY"], [2751, 2771, "TRAINED_CATEGORY"], [2799, 2824, "TRAINED_CATEGORY"], [2826, 2839, "TRAINED_CATEGORY"], [2850, 2884, "TRAINED_CATEGORY"], [2896, 2913, "TRAINED_CATEGORY"], [2918, 2922, "TRAINED_CATEGORY"], [2929, 2960, "TRAINED_CATEGORY"], [2964, 2983, "TRAINED_CATEGORY"], [2987, 2993, "TRAINED_CATEGORY"], [2995, 3008, "TRAINED_CATEGORY"], [3016, 3033, "TRAINED_CATEGORY"], [3053, 3064, "TRAINED_CATEGORY"], [3072, 3074, "TRAINED_CATEGORY"], [3090, 3101, "TRAINED_CATEGORY"], [3113, 3138, "TRAINED_CATEGORY"], [3140, 3170, "TRAINED_CATEGORY"], [3172, 3175, "TRAINED_CATEGORY"], [3198, 3203, "TRAINED_CATEGORY"], [3207, 3213, "TRAINED_CATEGORY"], [3229, 3245, "TRAINED_CATEGORY"], [3269, 3280, "TRAINED_CATEGORY"], [3292, 3309, "TRAINED_CATEGORY"], [3314, 3323, "TRAINED_CATEGORY"], [3325, 3342, "TRAINED_CATEGORY"], [3348, 3371, "TRAINED_CATEGORY"], [3373, 3375, "TRAINED_CATEGORY"], [3380, 3397, "TRAINED_CATEGORY"], [3403, 3421, "TRAINED_CATEGORY"], [3425, 3437, "TRAINED_CATEGORY"], [3485, 3498, "TRAINED_CATEGORY"], [3505, 3517, "TRAINED_CATEGORY"], [3532, 3563, "TRAINED_CATEGORY"], [3565, 3578, "TRAINED_CATEGORY"], [3583, 3595, "TRAINED_CATEGORY"], [3597, 3616, "TRAINED_CATEGORY"], [3626, 3633, "TRAINED_CATEGORY"], [3658, 3664, "TRAINED_CATEGORY"], [3667, 3680, "TRAINED_CATEGORY"], [3684, 3699, "TRAINED_CATEGORY"], [3705, 3716, "TRAINED_CATEGORY"], [3720, 3732, "TRAINED_CATEGORY"], [3758, 3784, "TRAINED_CATEGORY"], [3795, 3802, "TRAINED_CATEGORY"], [3813, 3818, "TRAINED_CATEGORY"], [3822, 3834, "TRAINED_CATEGORY"], [3838, 3843, "TRAINED_CATEGORY"], [3874, 3888, "TRAINED_CATEGORY"], [3903, 3921, "TRAINED_CATEGORY"], [3925, 3932, "TRAINED_CATEGORY"], [3936, 3941, "TRAINED_CATEGORY"], [3945, 3957, "TRAINED_CATEGORY"], [4014, 4018, "TRAINED_CATEGORY"], [4019, 4038, "TRAINED_CATEGORY"], [4054, 4063, "TRAINED_CATEGORY"], [4070, 4075, "TRAINED_CATEGORY"], [4079, 4091, "TRAINED_CATEGORY"], [4092, 4104, "TRAINED_CATEGORY"], [4117, 4130, "TRAINED_CATEGORY"], [4134, 4156, "TRAINED_CATEGORY"], [4185, 4190, "TRAINED_CATEGORY"], [4205, 4223, "TRAINED_CATEGORY"], [4239, 4267, "TRAINED_CATEGORY"], [4271, 4302, "TRAINED_CATEGORY"], [4303, 4322, "TRAINED_CATEGORY"], [4334, 4342, "TRAINED_CATEGORY"], [4351, 4358, "TRAINED_CATEGORY"], [4364, 4393, "TRAINED_CATEGORY"], [4397, 4422, "TRAINED_CATEGORY"], [4426, 4429, "TRAINED_CATEGORY"], [4433, 4460, "TRAINED_CATEGORY"], [4478, 4491, "TRAINED_CATEGORY"], [4511, 4528, "TRAINED_CATEGORY"], [4532, 4540, "TRAINED_CATEGORY"], [4551, 4559, "TRAINED_CATEGORY"], [4561, 4580, "TRAINED_CATEGORY"], [4582, 4598, "TRAINED_CATEGORY"], [4604, 4613, "TRAINED_CATEGORY"], [4620, 4632, "TRAINED_CATEGORY"], [4634, 4645, "TRAINED_CATEGORY"], [4660, 4671, "TRAINED_CATEGORY"], [4673, 4697, "TRAINED_CATEGORY"], [4699, 4715, "TRAINED_CATEGORY"], [4731, 4758, "TRAINED_CATEGORY"], [4764, 4786, "TRAINED_CATEGORY"], [4788, 4809, "TRAINED_CATEGORY"], [4832, 4841, "TRAINED_CATEGORY"], [4860, 4864, "TRAINED_CATEGORY"], [4870, 4875, "TRAINED_CATEGORY"], [4879, 4890, "TRAINED_CATEGORY"], [4894, 4913, "TRAINED_CATEGORY"], [4920, 4928, "TRAINED_CATEGORY"], [4933, 4940, "TRAINED_CATEGORY"], [4941, 4955, "TRAINED_CATEGORY"], [4965, 4981, "TRAINED_CATEGORY"], [4987, 4996, "TRAINED_CATEGORY"], [5000, 5003, "TRAINED_CATEGORY"], [5021, 5035, "TRAINED_CATEGORY"], [5075, 5081, "TRAINED_CATEGORY"], [5085, 5101, "TRAINED_CATEGORY"], [5103, 5124, "TRAINED_CATEGORY"], [5154, 5164, "TRAINED_CATEGORY"], [5168, 5189, "TRAINED_CATEGORY"], [5233, 5252, "TRAINED_CATEGORY"], [5256, 5272, "TRAINED_CATEGORY"], [5273, 5295, "TRAINED_CATEGORY"], [5297, 5306, "TRAINED_CATEGORY"], [5307, 5325, "TRAINED_CATEGORY"], [5327, 5348, "TRAINED_CATEGORY"], [5352, 5364, "TRAINED_CATEGORY"], [5391, 5420, "TRAINED_CATEGORY"], [5422, 5432, "TRAINED_CATEGORY"], [5436, 5445, "TRAINED_CATEGORY"], [5457, 5461, "TRAINED_CATEGORY"], [5465, 5508, "TRAINED_CATEGORY"], [5510, 5526, "TRAINED_CATEGORY"], [5530, 5545, "TRAINED_CATEGORY"], [5575, 5590, "TRAINED_CATEGORY"], [5592, 5607, "TRAINED_CATEGORY"], [5611, 5622, "TRAINED_CATEGORY"], [5661, 5690, "TRAINED_CATEGORY"], [5691, 5703, "TRAINED_CATEGORY"], [5705, 5757, "TRAINED_CATEGORY"], [5783, 5796, "TRAINED_CATEGORY"], [5800, 5831, "TRAINED_CATEGORY"], [5832, 5836, "TRAINED_CATEGORY"], [5843, 5875, "TRAINED_CATEGORY"], [5893, 5917, "TRAINED_CATEGORY"], [5922, 5944, "TRAINED_CATEGORY"], [5958, 5962, "TRAINED_CATEGORY"], [5969, 5972, "TRAINED_CATEGORY"], [6004, 6030, "TRAINED_CATEGORY"], [6035, 6056, "TRAINED_CATEGORY"], [6066, 6076, "TRAINED_CATEGORY"], [6080, 6089, "TRAINED_CATEGORY"], [6093, 6114, "TRAINED_CATEGORY"], [6116, 6118, "TRAINED_CATEGORY"], [6143, 6152, "TRAINED_CATEGORY"], [6163, 6176, "TRAINED_CATEGORY"], [6187, 6200, "TRAINED_CATEGORY"], [6204, 6212, "TRAINED_CATEGORY"], [6216, 6224, "TRAINED_CATEGORY"], [6226, 6243, "TRAINED_CATEGORY"], [6255, 6257, "TRAINED_CATEGORY"], [6271, 6288, "TRAINED_CATEGORY"], [6292, 6303, "TRAINED_CATEGORY"], [6321, 6331, "TRAINED_CATEGORY"], [6335, 6344, "TRAINED_CATEGORY"], [6349, 6360, "TRAINED_CATEGORY"], [6365, 6383, "TRAINED_CATEGORY"], [6400, 6430, "TRAINED_CATEGORY"], [6440, 6472, "TRAINED_CATEGORY"], [6474, 6476, "TRAINED_CATEGORY"], [6515, 6532, "TRAINED_CATEGORY"], [6536, 6551, "TRAINED_CATEGORY"], [6563, 6570, "TRAINED_CATEGORY"], [6574, 6606, "TRAINED_CATEGORY"], [6610, 6618, "TRAINED_CATEGORY"], [6620, 6622, "TRAINED_CATEGORY"], [6626, 6658, "TRAINED_CATEGORY"], [6662, 6679, "TRAINED_CATEGORY"], [6698, 6722, "TRAINED_CATEGORY"], [6733, 6742, "TRAINED_CATEGORY"], [6744, 6758, "TRAINED_CATEGORY"], [6764, 6777, "TRAINED_CATEGORY"], [6781, 6788, "TRAINED_CATEGORY"], [6806, 6840, "TRAINED_CATEGORY"], [6848, 6857, "TRAINED_CATEGORY"], [6859, 6864, "TRAINED_CATEGORY"], [6868, 6878, "TRAINED_CATEGORY"], [6879, 6916, "TRAINED_CATEGORY"], [6923, 6930, "TRAINED_CATEGORY"], [6934, 6937, "TRAINED_CATEGORY"], [6943, 6965, "TRAINED_CATEGORY"], [6973, 6976, "TRAINED_CATEGORY"], [6980, 6991, "TRAINED_CATEGORY"], [6995, 7009, "TRAINED_CATEGORY"], [7014, 7027, "TRAINED_CATEGORY"], [7029, 7044, "TRAINED_CATEGORY"], [7068, 7079, "TRAINED_CATEGORY"], [7083, 7088, "TRAINED_CATEGORY"], [7103, 7141, "TRAINED_CATEGORY"], [7165, 7196, "TRAINED_CATEGORY"], [7200, 7230, "TRAINED_CATEGORY"], [7232, 7237, "TRAINED_CATEGORY"], [7245, 7262, "TRAINED_CATEGORY"], [7266, 7275, "TRAINED_CATEGORY"], [7280, 7293, "TRAINED_CATEGORY"], [7308, 7317, "TRAINED_CATEGORY"], [7319, 7331, "TRAINED_CATEGORY"], [7335, 7341, "TRAINED_CATEGORY"], [7382, 7394, "TRAINED_CATEGORY"], [7395, 7412, "TRAINED_CATEGORY"], [7417, 7437, "TRAINED_CATEGORY"], [7444, 7476, "TRAINED_CATEGORY"], [7483, 7512, "TRAINED_CATEGORY"], [7516, 7536, "TRAINED_CATEGORY"], [7542, 7558, "TRAINED_CATEGORY"], [7562, 7572, "TRAINED_CATEGORY"], [7574, 7579, "TRAINED_CATEGORY"], [7581, 7595, "TRAINED_CATEGORY"], [7616, 7628, "TRAINED_CATEGORY"], [7640, 7646, "TRAINED_CATEGORY"], [7648, 7655, "TRAINED_CATEGORY"], [7657, 7662, "TRAINED_CATEGORY"], [7664, 7669, "TRAINED_CATEGORY"], [7671, 7679, "TRAINED_CATEGORY"], [7685, 7690, "TRAINED_CATEGORY"], [7692, 7708, "TRAINED_CATEGORY"], [7712, 7718, "TRAINED_CATEGORY"], [7737, 7755, "TRAINED_CATEGORY"], [7759, 7769, "TRAINED_CATEGORY"], [7771, 7783, "TRAINED_CATEGORY"], [7790, 7802, "TRAINED_CATEGORY"], [7821, 7829, "TRAINED_CATEGORY"], [7833, 7843, "TRAINED_CATEGORY"], [7853, 7875, "TRAINED_CATEGORY"], [7879, 7885, "TRAINED_CATEGORY"], [7887, 7906, "TRAINED_CATEGORY"], [7910, 7928, "TRAINED_CATEGORY"], [7930, 7949, "TRAINED_CATEGORY"], [7967, 7981, "TRAINED_CATEGORY"], [7987, 8006, "TRAINED_CATEGORY"], [8010, 8015, "TRAINED_CATEGORY"], [8020, 8025, "TRAINED_CATEGORY"], [8047, 8059, "TRAINED_CATEGORY"], [8080, 8087, "TRAINED_CATEGORY"], [8097, 8123, "TRAINED_CATEGORY"], [8127, 8145, "TRAINED_CATEGORY"], [8152, 8172, "TRAINED_CATEGORY"], [8176, 8180, "TRAINED_CATEGORY"], [8182, 8184, "TRAINED_CATEGORY"], [8205, 8220, "TRAINED_CATEGORY"], [8234, 8244, "TRAINED_CATEGORY"], [8248, 8265, "TRAINED_CATEGORY"], [8273, 8281, "TRAINED_CATEGORY"], [8297, 8301, "TRAINED_CATEGORY"], [8310, 8322, "TRAINED_CATEGORY"], [8324, 8326, "TRAINED_CATEGORY"], [8360, 8388, "TRAINED_CATEGORY"], [8419, 8432, "TRAINED_CATEGORY"], [8464, 8493, "TRAINED_CATEGORY"], [8558, 8573, "TRAINED_CATEGORY"], [8588, 8601, "TRAINED_CATEGORY"], [8605, 8620, "TRAINED_CATEGORY"], [8633, 8647, "TRAINED_CATEGORY"], [8649, 8662, "TRAINED_CATEGORY"], [8673, 8680, "TRAINED_CATEGORY"], [8710, 8721, "TRAINED_CATEGORY"], [8725, 8736, "TRAINED_CATEGORY"], [8748, 8765, "TRAINED_CATEGORY"], [8767, 8783, "TRAINED_CATEGORY"], [8797, 8799, "TRAINED_CATEGORY"], [8805, 8817, "TRAINED_CATEGORY"], [8833, 8849, "TRAINED_CATEGORY"], [8861, 8871, "TRAINED_CATEGORY"], [8878, 8890, "TRAINED_CATEGORY"], [8894, 8907, "TRAINED_CATEGORY"], [8918, 8926, "TRAINED_CATEGORY"], [8930, 8939, "TRAINED_CATEGORY"], [8949, 8969, "TRAINED_CATEGORY"], [8973, 8985, "TRAINED_CATEGORY"], [8991, 8998, "TRAINED_CATEGORY"], [9015, 9034, "TRAINED_CATEGORY"], [9038, 9060, "TRAINED_CATEGORY"], [9062, 9075, "TRAINED_CATEGORY"], [9086, 9090, "TRAINED_CATEGORY"], [9098, 9106, "TRAINED_CATEGORY"], [9112, 9117, "TRAINED_CATEGORY"], [9122, 9127, "TRAINED_CATEGORY"], [9133, 9139, "TRAINED_CATEGORY"], [9152, 9167, "TRAINED_CATEGORY"], [9177, 9182, "TRAINED_CATEGORY"], [9186, 9204, "TRAINED_CATEGORY"], [9209, 9222, "TRAINED_CATEGORY"], [9243, 9267, "TRAINED_CATEGORY"], [9274, 9282, "TRAINED_CATEGORY"], [9284, 9289, "TRAINED_CATEGORY"], [9294, 9300, "TRAINED_CATEGORY"], [9305, 9317, "TRAINED_CATEGORY"], [9317, 9323, "TRAINED_CATEGORY"], [9329, 9330, "TRAINED_CATEGORY"], [9336, 9354, "TRAINED_CATEGORY"], [9359, 9372, "TRAINED_CATEGORY"], [9380, 9395, "TRAINED_CATEGORY"], [9399, 9412, "TRAINED_CATEGORY"], [9422, 9438, "TRAINED_CATEGORY"], [9448, 9459, "TRAINED_CATEGORY"], [9463, 9475, "TRAINED_CATEGORY"], [9476, 9487, "TRAINED_CATEGORY"], [9532, 9543, "TRAINED_CATEGORY"], [9547, 9558, "TRAINED_CATEGORY"], [9563, 9577, "TRAINED_CATEGORY"], [9581, 9611, "TRAINED_CATEGORY"], [9624, 9635, "TRAINED_CATEGORY"], [9639, 9650, "TRAINED_CATEGORY"], [9667, 9679, "TRAINED_CATEGORY"], [9688, 9699, "TRAINED_CATEGORY"], [9703, 9714, "TRAINED_CATEGORY"], [9718, 9724, "TRAINED_CATEGORY"], [9764, 9766, "TRAINED_CATEGORY"], [9770, 9790, "TRAINED_CATEGORY"], [9796, 9803, "TRAINED_CATEGORY"], [9817, 9821, "TRAINED_CATEGORY"], [9836, 9849, "TRAINED_CATEGORY"], [9851, 9855, "TRAINED_CATEGORY"], [9865, 9884, "TRAINED_CATEGORY"], [9888, 9899, "TRAINED_CATEGORY"], [9904, 9915, "TRAINED_CATEGORY"], [9924, 9945, "TRAINED_CATEGORY"], [9950, 9958, "TRAINED_CATEGORY"], [9978, 9989, "TRAINED_CATEGORY"], [10003, 10014, "TRAINED_CATEGORY"], [10018, 10037, "TRAINED_CATEGORY"], [10064, 10070, "TRAINED_CATEGORY"], [10072, 10078, "TRAINED_CATEGORY"], [10080, 10085, "TRAINED_CATEGORY"], [10099, 10111, "TRAINED_CATEGORY"], [10115, 10125, "TRAINED_CATEGORY"], [10138, 10149, "TRAINED_CATEGORY"], [10169, 10195, "TRAINED_CATEGORY"], [10204, 10215, "TRAINED_CATEGORY"], [10219, 10228, "TRAINED_CATEGORY"], [10260, 10262, "TRAINED_CATEGORY"], [10301, 10309, "TRAINED_CATEGORY"], [10313, 10324, "TRAINED_CATEGORY"], [10355, 10363, "TRAINED_CATEGORY"], [10387, 10403, "TRAINED_CATEGORY"], [10407, 10414, "TRAINED_CATEGORY"], [10425, 10432, "TRAINED_CATEGORY"], [10466, 10477, "TRAINED_CATEGORY"], [10479, 10498, "TRAINED_CATEGORY"], [10523, 10534, "TRAINED_CATEGORY"], [10542, 10565, "TRAINED_CATEGORY"], [10588, 10604, "TRAINED_CATEGORY"], [10617, 10627, "TRAINED_CATEGORY"], [10646, 10659, "TRAINED_CATEGORY"], [10661, 10681, "TRAINED_CATEGORY"], [10685, 10692, "TRAINED_CATEGORY"], [10702, 10733, "TRAINED_CATEGORY"], [10753, 10776, "TRAINED_CATEGORY"], [10778, 10786, "TRAINED_CATEGORY"], [10792, 10797, "TRAINED_CATEGORY"], [10810, 10819, "TRAINED_CATEGORY"], [10823, 10828, "TRAINED_CATEGORY"], [10830, 10832, "TRAINED_CATEGORY"], [10837, 10848, "TRAINED_CATEGORY"], [10857, 10859, "TRAINED_CATEGORY"], [10868, 10886, "TRAINED_CATEGORY"], [10890, 10905, "TRAINED_CATEGORY"], [10907, 10909, "TRAINED_CATEGORY"], [10920, 10931, "TRAINED_CATEGORY"], [10937, 10958, "TRAINED_CATEGORY"], [10973, 10977, "TRAINED_CATEGORY"], [10983, 11010, "TRAINED_CATEGORY"], [11028, 11041, "TRAINED_CATEGORY"], [11042, 11056, "TRAINED_CATEGORY"], [11060, 11062, "TRAINED_CATEGORY"], [11075, 11084, "TRAINED_CATEGORY"], [11086, 11088, "TRAINED_CATEGORY"], [11112, 11130, "TRAINED_CATEGORY"], [11134, 11143, "TRAINED_CATEGORY"], [11170, 11190, "TRAINED_CATEGORY"], [11203, 11219, "TRAINED_CATEGORY"], [11224, 11226, "TRAINED_CATEGORY"], [11238, 11250, "TRAINED_CATEGORY"], [11252, 11254, "TRAINED_CATEGORY"], [11264, 11288, "TRAINED_CATEGORY"], [11292, 11316, "TRAINED_CATEGORY"], [11317, 11319, "TRAINED_CATEGORY"], [11343, 11356, "TRAINED_CATEGORY"], [11362, 11378, "TRAINED_CATEGORY"], [11398, 11405, "TRAINED_CATEGORY"], [11406, 11410, "TRAINED_CATEGORY"], [11431, 11457, "TRAINED_CATEGORY"], [11469, 11474, "TRAINED_CATEGORY"], [11479, 11487, "TRAINED_CATEGORY"], [11493, 11501, "TRAINED_CATEGORY"], [11506, 11529, "TRAINED_CATEGORY"], [11534, 11539, "TRAINED_CATEGORY"], [11542, 11564, "TRAINED_CATEGORY"], [11570, 11585, "TRAINED_CATEGORY"], [11590, 11598, "TRAINED_CATEGORY"], [11601, 11619, "TRAINED_CATEGORY"], [11625, 11648, "TRAINED_CATEGORY"], [11653, 11663, "TRAINED_CATEGORY"], [11678, 11682, "TRAINED_CATEGORY"], [11694, 11709, "TRAINED_CATEGORY"], [11714, 11740, "TRAINED_CATEGORY"], [11750, 11767, "TRAINED_CATEGORY"], [11777, 11792, "TRAINED_CATEGORY"], [11808, 11817, "TRAINED_CATEGORY"], [11821, 11829, "TRAINED_CATEGORY"], [11833, 11841, "TRAINED_CATEGORY"], [11846, 11853, "TRAINED_CATEGORY"], [11855, 11867, "TRAINED_CATEGORY"], [11879, 11895, "TRAINED_CATEGORY"], [11901, 11922, "TRAINED_CATEGORY"], [11926, 11937, "TRAINED_CATEGORY"], [11958, 11962, "TRAINED_CATEGORY"], [11974, 11986, "TRAINED_CATEGORY"], [11990, 12010, "TRAINED_CATEGORY"], [12014, 12023, "TRAINED_CATEGORY"], [12052, 12056, "TRAINED_CATEGORY"], [12067, 12096, "TRAINED_CATEGORY"], [12100, 12107, "TRAINED_CATEGORY"], [12125, 12127, "TRAINED_CATEGORY"], [12137, 12163, "TRAINED_CATEGORY"], [12165, 12167, "TRAINED_CATEGORY"], [12176, 12187, "TRAINED_CATEGORY"], [12201, 12214, "TRAINED_CATEGORY"], [12218, 12229, "TRAINED_CATEGORY"], [12235, 12252, "TRAINED_CATEGORY"], [12256, 12269, "TRAINED_CATEGORY"], [12274, 12276, "TRAINED_CATEGORY"], [12283, 12309, "TRAINED_CATEGORY"], [12311, 12313, "TRAINED_CATEGORY"], [12319, 12346, "TRAINED_CATEGORY"], [12350, 12361, "TRAINED_CATEGORY"], [12365, 12372, "TRAINED_CATEGORY"], [12381, 12392, "TRAINED_CATEGORY"], [12396, 12403, "TRAINED_CATEGORY"], [12409, 12425, "TRAINED_CATEGORY"], [12429, 12447, "TRAINED_CATEGORY"], [12460, 12472, "TRAINED_CATEGORY"], [12476, 12480, "TRAINED_CATEGORY"], [12482, 12484, "TRAINED_CATEGORY"], [12497, 12512, "TRAINED_CATEGORY"], [12514, 12521, "TRAINED_CATEGORY"], [12525, 12532, "TRAINED_CATEGORY"], [12536, 12548, "TRAINED_CATEGORY"], [12562, 12570, "TRAINED_CATEGORY"], [12576, 12583, "TRAINED_CATEGORY"], [12587, 12594, "TRAINED_CATEGORY"], [12598, 12606, "TRAINED_CATEGORY"], [12619, 12635, "TRAINED_CATEGORY"], [12639, 12647, "TRAINED_CATEGORY"], [12649, 12661, "TRAINED_CATEGORY"], [12738, 12752, "TRAINED_CATEGORY"], [12756, 12767, "TRAINED_CATEGORY"], [12778, 12789, "TRAINED_CATEGORY"], [12835, 12846, "TRAINED_CATEGORY"], [12852, 12870, "TRAINED_CATEGORY"], [12888, 12906, "TRAINED_CATEGORY"], [12926, 12935, "TRAINED_CATEGORY"], [12936, 12949, "TRAINED_CATEGORY"], [12966, 12977, "TRAINED_CATEGORY"], [12989, 13010, "TRAINED_CATEGORY"], [13014, 13027, "TRAINED_CATEGORY"], [13060, 13077, "TRAINED_CATEGORY"], [13102, 13113, "TRAINED_CATEGORY"], [13120, 13140, "TRAINED_CATEGORY"], [13142, 13151, "TRAINED_CATEGORY"], [13153, 13175, "TRAINED_CATEGORY"], [13179, 13195, "TRAINED_CATEGORY"], [13210, 13218, "TRAINED_CATEGORY"], [13223, 13235, "TRAINED_CATEGORY"], [13239, 13256, "TRAINED_CATEGORY"], [13258, 13274, "TRAINED_CATEGORY"], [13296, 13308, "TRAINED_CATEGORY"], [13310, 13338, "TRAINED_CATEGORY"], [13376, 13393, "TRAINED_CATEGORY"], [13395, 13419, "TRAINED_CATEGORY"], [13436, 13455, "TRAINED_CATEGORY"], [13460, 13472, "TRAINED_CATEGORY"], [13474, 13484, "TRAINED_CATEGORY"], [13488, 13505, "TRAINED_CATEGORY"], [13530, 13540, "TRAINED_CATEGORY"], [13544, 13555, "TRAINED_CATEGORY"], [13559, 13563, "TRAINED_CATEGORY"], [13577, 13590, "TRAINED_CATEGORY"], [13592, 13601, "TRAINED_CATEGORY"], [13603, 13609, "TRAINED_CATEGORY"], [13611, 13619, "TRAINED_CATEGORY"], [13621, 13626, "TRAINED_CATEGORY"], [13643, 13659, "TRAINED_CATEGORY"], [13663, 13690, "TRAINED_CATEGORY"], [13705, 13716, "TRAINED_CATEGORY"], [13736, 13758, "TRAINED_CATEGORY"], [13760, 13768, "TRAINED_CATEGORY"], [13774, 13783, "TRAINED_CATEGORY"], [13814, 13838, "TRAINED_CATEGORY"], [13840, 13842, "TRAINED_CATEGORY"], [13873, 13898, "TRAINED_CATEGORY"], [13902, 13910, "TRAINED_CATEGORY"], [13954, 13966, "TRAINED_CATEGORY"], [14027, 14042, "TRAINED_CATEGORY"], [14053, 14071, "TRAINED_CATEGORY"], [14077, 14083, "TRAINED_CATEGORY"], [14099, 14121, "TRAINED_CATEGORY"], [14134, 14142, "TRAINED_CATEGORY"], [14148, 14161, "TRAINED_CATEGORY"], [14176, 14192, "TRAINED_CATEGORY"], [14214, 14230, "TRAINED_CATEGORY"], [14252, 14261, "TRAINED_CATEGORY"], [14267, 14274, "TRAINED_CATEGORY"], [14299, 14307, "TRAINED_CATEGORY"], [14311, 14318, "TRAINED_CATEGORY"], [14320, 14342, "TRAINED_CATEGORY"], [14346, 14356, "TRAINED_CATEGORY"], [14362, 14379, "TRAINED_CATEGORY"], [14402, 14414, "TRAINED_CATEGORY"], [14430, 14439, "TRAINED_CATEGORY"], [14443, 14456, "TRAINED_CATEGORY"], [14458, 14466, "TRAINED_CATEGORY"], [14485, 14491, "TRAINED_CATEGORY"], [14513, 14530, "TRAINED_CATEGORY"], [14534, 14541, "TRAINED_CATEGORY"], [14548, 14550, "TRAINED_CATEGORY"], [14576, 14585, "TRAINED_CATEGORY"], [14595, 14597, "TRAINED_CATEGORY"], [14648, 14665, "TRAINED_CATEGORY"], [14669, 14680, "TRAINED_CATEGORY"], [14688, 14696, "TRAINED_CATEGORY"], [14700, 14710, "TRAINED_CATEGORY"], [14714, 14731, "TRAINED_CATEGORY"], [14737, 14754, "TRAINED_CATEGORY"], [14759, 14767, "TRAINED_CATEGORY"], [14771, 14779, "TRAINED_CATEGORY"], [14781, 14795, "TRAINED_CATEGORY"], [14799, 14807, "TRAINED_CATEGORY"], [14811, 14833, "TRAINED_CATEGORY"], [14855, 14878, "TRAINED_CATEGORY"], [14887, 14898, "TRAINED_CATEGORY"], [14908, 14912, "TRAINED_CATEGORY"], [14939, 14950, "TRAINED_CATEGORY"], [14963, 14971, "TRAINED_CATEGORY"], [14975, 14986, "TRAINED_CATEGORY"], [14997, 14999, "TRAINED_CATEGORY"], [15023, 15038, "TRAINED_CATEGORY"], [15051, 15062, "TRAINED_CATEGORY"], [15075, 15088, "TRAINED_CATEGORY"], [15093, 15109, "TRAINED_CATEGORY"], [15120, 15134, "TRAINED_CATEGORY"], [15146, 15162, "TRAINED_CATEGORY"], [15167, 15179, "TRAINED_CATEGORY"], [15194, 15198, "TRAINED_CATEGORY"], [15209, 15216, "TRAINED_CATEGORY"], [15218, 15229, "TRAINED_CATEGORY"], [15266, 15272, "TRAINED_CATEGORY"], [15288, 15312, "TRAINED_CATEGORY"], [15316, 15327, "TRAINED_CATEGORY"], [15332, 15352, "TRAINED_CATEGORY"], [15353, 15367, "TRAINED_CATEGORY"], [15397, 15413, "TRAINED_CATEGORY"], [15415, 15424, "TRAINED_CATEGORY"], [15475, 15485, "TRAINED_CATEGORY"], [15489, 15498, "TRAINED_CATEGORY"], [15502, 15514, "TRAINED_CATEGORY"], [15518, 15527, "TRAINED_CATEGORY"], [15550, 15563, "TRAINED_CATEGORY"], [15573, 15586, "TRAINED_CATEGORY"], [15609, 15625, "TRAINED_CATEGORY"], [15634, 15636, "TRAINED_CATEGORY"], [15645, 15653, "TRAINED_CATEGORY"], [15657, 15677, "TRAINED_CATEGORY"], [15690, 15706, "TRAINED_CATEGORY"], [15710, 15721, "TRAINED_CATEGORY"], [15726, 15735, "TRAINED_CATEGORY"], [15737, 15749, "TRAINED_CATEGORY"], [15780, 15788, "TRAINED_CATEGORY"], [15793, 15803, "TRAINED_CATEGORY"], [15805, 15821, "TRAINED_CATEGORY"], [15860, 15872, "TRAINED_CATEGORY"], [15877, 15887, "TRAINED_CATEGORY"], [15889, 15904, "TRAINED_CATEGORY"], [15939, 15949, "TRAINED_CATEGORY"], [15966, 15975, "TRAINED_CATEGORY"], [15986, 16015, "TRAINED_CATEGORY"], [16023, 16040, "TRAINED_CATEGORY"], [16044, 16063, "TRAINED_CATEGORY"], [16080, 16090, "TRAINED_CATEGORY"], [16103, 16117, "TRAINED_CATEGORY"], [16128, 16138, "TRAINED_CATEGORY"], [16142, 16150, "TRAINED_CATEGORY"], [16152, 16174, "TRAINED_CATEGORY"], [16191, 16201, "TRAINED_CATEGORY"], [16217, 16231, "TRAINED_CATEGORY"], [16237, 16243, "TRAINED_CATEGORY"], [16255, 16267, "TRAINED_CATEGORY"], [16269, 16276, "TRAINED_CATEGORY"], [16291, 16295, "TRAINED_CATEGORY"], [16309, 16311, "TRAINED_CATEGORY"], [16317, 16321, "TRAINED_CATEGORY"], [16326, 16368, "TRAINED_CATEGORY"], [16380, 16397, "TRAINED_CATEGORY"], [16415, 16425, "TRAINED_CATEGORY"], [16430, 16442, "TRAINED_CATEGORY"], [16452, 16462, "TRAINED_CATEGORY"], [16474, 16478, "TRAINED_CATEGORY"], [16509, 16525, "TRAINED_CATEGORY"], [16534, 16544, "TRAINED_CATEGORY"], [16572, 16582, "TRAINED_CATEGORY"], [16587, 16594, "TRAINED_CATEGORY"], [16611, 16620, "TRAINED_CATEGORY"], [16624, 16640, "TRAINED_CATEGORY"], [16642, 16646, "TRAINED_CATEGORY"], [16657, 16677, "TRAINED_CATEGORY"], [16681, 16690, "TRAINED_CATEGORY"], [16694, 16703, "TRAINED_CATEGORY"], [16710, 16723, "TRAINED_CATEGORY"], [16725, 16735, "TRAINED_CATEGORY"], [16740, 16756, "TRAINED_CATEGORY"], [16787, 16792, "TRAINED_CATEGORY"], [16796, 16806, "TRAINED_CATEGORY"], [16808, 16814, "TRAINED_CATEGORY"], [16820, 16828, "TRAINED_CATEGORY"], [16838, 16854, "TRAINED_CATEGORY"], [16867, 16875, "TRAINED_CATEGORY"], [16978, 16989, "TRAINED_CATEGORY"], [16993, 16997, "TRAINED_CATEGORY"], [17000, 17006, "TRAINED_CATEGORY"], [17021, 17031, "TRAINED_CATEGORY"], [17036, 17046, "TRAINED_CATEGORY"], [17051, 17061, "TRAINED_CATEGORY"], [17066, 17081, "TRAINED_CATEGORY"], [17105, 17124, "TRAINED_CATEGORY"], [17126, 17136, "TRAINED_CATEGORY"], [17158, 17169, "TRAINED_CATEGORY"], [17183, 17199, "TRAINED_CATEGORY"], [17205, 17217, "TRAINED_CATEGORY"], [17228, 17243, "TRAINED_CATEGORY"], [17255, 17260, "TRAINED_CATEGORY"], [17264, 17275, "TRAINED_CATEGORY"], [17277, 17287, "TRAINED_CATEGORY"], [17291, 17299, "TRAINED_CATEGORY"], [17301, 17313, "TRAINED_CATEGORY"], [17319, 17335, "TRAINED_CATEGORY"], [17401, 17411, "TRAINED_CATEGORY"], [17413, 17425, "TRAINED_CATEGORY"], [17429, 17437, "TRAINED_CATEGORY"], [17448, 17462, "TRAINED_CATEGORY"], [17466, 17482, "TRAINED_CATEGORY"], [17507, 17513, "TRAINED_CATEGORY"], [17542, 17557, "TRAINED_CATEGORY"], [17561, 17569, "TRAINED_CATEGORY"], [17587, 17601, "TRAINED_CATEGORY"], [17603, 17619, "TRAINED_CATEGORY"], [17666, 17680, "TRAINED_CATEGORY"], [17684, 17695, "TRAINED_CATEGORY"], [17717, 17731, "TRAINED_CATEGORY"], [17735, 17745, "TRAINED_CATEGORY"], [17749, 17760, "TRAINED_CATEGORY"], [17761, 17769, "TRAINED_CATEGORY"], [17771, 17783, "TRAINED_CATEGORY"], [17789, 17805, "TRAINED_CATEGORY"], [17827, 17841, "TRAINED_CATEGORY"], [17876, 17891, "TRAINED_CATEGORY"], [17915, 17922, "TRAINED_CATEGORY"], [17926, 17938, "TRAINED_CATEGORY"], [17942, 17954, "TRAINED_CATEGORY"], [17959, 17973, "TRAINED_CATEGORY"], [17981, 17991, "TRAINED_CATEGORY"], [18007, 18011, "TRAINED_CATEGORY"], [18062, 18079, "TRAINED_CATEGORY"], [18094, 18108, "TRAINED_CATEGORY"], [18110, 18130, "TRAINED_CATEGORY"], [18135, 18149, "TRAINED_CATEGORY"], [18179, 18200, "TRAINED_CATEGORY"], [18218, 18236, "TRAINED_CATEGORY"], [18246, 18269, "TRAINED_CATEGORY"], [18281, 18292, "TRAINED_CATEGORY"], [18297, 18316, "TRAINED_CATEGORY"], [18320, 18328, "TRAINED_CATEGORY"], [18330, 18346, "TRAINED_CATEGORY"], [18351, 18368, "TRAINED_CATEGORY"], [18379, 18392, "TRAINED_CATEGORY"], [18416, 18435, "TRAINED_CATEGORY"], [18442, 18456, "TRAINED_CATEGORY"], [18459, 18479, "TRAINED_CATEGORY"], [18506, 18526, "TRAINED_CATEGORY"], [18530, 18539, "TRAINED_CATEGORY"], [18547, 18554, "TRAINED_CATEGORY"], [18558, 18566, "TRAINED_CATEGORY"], [18572, 18579, "TRAINED_CATEGORY"], [18583, 18595, "TRAINED_CATEGORY"], [18597, 18617, "TRAINED_CATEGORY"], [18621, 18631, "TRAINED_CATEGORY"], [18635, 18643, "TRAINED_CATEGORY"], [18648, 18673, "TRAINED_CATEGORY"], [18691, 18712, "TRAINED_CATEGORY"], [18723, 18728, "TRAINED_CATEGORY"], [18758, 18778, "TRAINED_CATEGORY"], [18782, 18794, "TRAINED_CATEGORY"], [18798, 18828, "TRAINED_CATEGORY"], [18830, 18851, "TRAINED_CATEGORY"], [18856, 18875, "TRAINED_CATEGORY"], [18879, 18888, "TRAINED_CATEGORY"], [18906, 18914, "TRAINED_CATEGORY"], [18931, 18942, "TRAINED_CATEGORY"], [18944, 18965, "TRAINED_CATEGORY"], [18969, 18980, "TRAINED_CATEGORY"], [18998, 19017, "TRAINED_CATEGORY"], [19021, 19033, "TRAINED_CATEGORY"], [19042, 19049, "TRAINED_CATEGORY"], [19053, 19061, "TRAINED_CATEGORY"], [19063, 19083, "TRAINED_CATEGORY"], [19109, 19111, "TRAINED_CATEGORY"], [19132, 19150, "TRAINED_CATEGORY"], [19155, 19187, "TRAINED_CATEGORY"], [19203, 19217, "TRAINED_CATEGORY"], [19235, 19255, "TRAINED_CATEGORY"], [19259, 19278, "TRAINED_CATEGORY"], [19285, 19296, "TRAINED_CATEGORY"], [19303, 19317, "TRAINED_CATEGORY"], [19321, 19338, "TRAINED_CATEGORY"], [19340, 19344, "TRAINED_CATEGORY"], [19363, 19371, "TRAINED_CATEGORY"], [19375, 19395, "TRAINED_CATEGORY"], [19402, 19420, "TRAINED_CATEGORY"], [19424, 19449, "TRAINED_CATEGORY"], [19460, 19472, "TRAINED_CATEGORY"], [19487, 19494, "TRAINED_CATEGORY"], [19514, 19519, "TRAINED_CATEGORY"], [19524, 19532, "TRAINED_CATEGORY"], [19534, 19559, "TRAINED_CATEGORY"], [19589, 19594, "TRAINED_CATEGORY"], [19630, 19640, "TRAINED_CATEGORY"], [19644, 19656, "TRAINED_CATEGORY"], [19674, 19678, "TRAINED_CATEGORY"], [19692, 19705, "TRAINED_CATEGORY"], [19710, 19728, "TRAINED_CATEGORY"], [19739, 19747, "TRAINED_CATEGORY"], [19752, 19767, "TRAINED_CATEGORY"], [19790, 19794, "TRAINED_CATEGORY"], [19808, 19832, "TRAINED_CATEGORY"], [19837, 19853, "TRAINED_CATEGORY"], [19862, 19874, "TRAINED_CATEGORY"], [19879, 19906, "TRAINED_CATEGORY"], [19915, 19924, "TRAINED_CATEGORY"], [19928, 19931, "TRAINED_CATEGORY"], [19940, 19958, "TRAINED_CATEGORY"], [19962, 19969, "TRAINED_CATEGORY"], [19978, 19982, "TRAINED_CATEGORY"], [20024, 20028, "TRAINED_CATEGORY"], [20051, 20055, "TRAINED_CATEGORY"], [20065, 20074, "TRAINED_CATEGORY"], [20078, 20095, "TRAINED_CATEGORY"], [20102, 20127, "TRAINED_CATEGORY"], [20167, 20174, "TRAINED_CATEGORY"], [20176, 20189, "TRAINED_CATEGORY"], [20216, 20238, "TRAINED_CATEGORY"], [20243, 20249, "TRAINED_CATEGORY"], [20263, 20290, "TRAINED_CATEGORY"], [20294, 20324, "TRAINED_CATEGORY"], [20331, 20341, "TRAINED_CATEGORY"], [20345, 20352, "TRAINED_CATEGORY"], [20368, 20425, "TRAINED_CATEGORY"], [20444, 20465, "TRAINED_CATEGORY"], [20467, 20469, "TRAINED_CATEGORY"], [20493, 20506, "TRAINED_CATEGORY"], [20540, 20569, "TRAINED_CATEGORY"], [20577, 20598, "TRAINED_CATEGORY"], [20607, 20609, "TRAINED_CATEGORY"], [20660, 20670, "TRAINED_CATEGORY"], [20681, 20692, "TRAINED_CATEGORY"], [20698, 20713, "TRAINED_CATEGORY"], [20714, 20722, "TRAINED_CATEGORY"], [20726, 20733, "TRAINED_CATEGORY"], [20742, 20749, "TRAINED_CATEGORY"], [20754, 20764, "TRAINED_CATEGORY"], [20768, 20771, "TRAINED_CATEGORY"], [20789, 20807, "TRAINED_CATEGORY"], [20812, 20823, "TRAINED_CATEGORY"], [20827, 20859, "TRAINED_CATEGORY"], [20861, 20874, "TRAINED_CATEGORY"], [20904, 20909, "TRAINED_CATEGORY"], [20913, 20916, "TRAINED_CATEGORY"], [20926, 20931, "TRAINED_CATEGORY"], [20963, 20986, "TRAINED_CATEGORY"], [20990, 20993, "TRAINED_CATEGORY"], [21011, 21030, "TRAINED_CATEGORY"], [21040, 21072, "TRAINED_CATEGORY"], [21083, 21091, "TRAINED_CATEGORY"], [21095, 21103, "TRAINED_CATEGORY"], [21107, 21116, "TRAINED_CATEGORY"], [21120, 21149, "TRAINED_CATEGORY"], [21162, 21178, "TRAINED_CATEGORY"], [21209, 21223, "TRAINED_CATEGORY"], [21240, 21252, "TRAINED_CATEGORY"], [21282, 21299, "TRAINED_CATEGORY"], [21304, 21323, "TRAINED_CATEGORY"], [21325, 21338, "TRAINED_CATEGORY"], [21343, 21362, "TRAINED_CATEGORY"], [21367, 21390, "TRAINED_CATEGORY"], [21411, 21429, "TRAINED_CATEGORY"], [21433, 21443, "TRAINED_CATEGORY"], [21444, 21465, "TRAINED_CATEGORY"], [21480, 21492, "TRAINED_CATEGORY"], [21502, 21516, "TRAINED_CATEGORY"], [21520, 21552, "TRAINED_CATEGORY"], [21567, 21570, "TRAINED_CATEGORY"], [21571, 21591, "TRAINED_CATEGORY"], [21606, 21619, "TRAINED_CATEGORY"], [21633, 21650, "TRAINED_CATEGORY"], [21654, 21667, "TRAINED_CATEGORY"], [21682, 21687, "TRAINED_CATEGORY"], [21694, 21702, "TRAINED_CATEGORY"], [21711, 21723, "TRAINED_CATEGORY"], [21735, 21747, "TRAINED_CATEGORY"], [21751, 21759, "TRAINED_CATEGORY"], [21770, 21786, "TRAINED_CATEGORY"], [21813, 21827, "TRAINED_CATEGORY"], [21831, 21843, "TRAINED_CATEGORY"], [21850, 21863, "TRAINED_CATEGORY"], [21867, 21882, "TRAINED_CATEGORY"], [21892, 21912, "TRAINED_CATEGORY"], [21916, 21921, "TRAINED_CATEGORY"], [21925, 21933, "TRAINED_CATEGORY"], [21937, 21947, "TRAINED_CATEGORY"], [21951, 21969, "TRAINED_CATEGORY"], [21971, 21973, "TRAINED_CATEGORY"], [21977, 21985, "TRAINED_CATEGORY"], [21989, 22011, "TRAINED_CATEGORY"], [22022, 22038, "TRAINED_CATEGORY"], [22052, 22070, "TRAINED_CATEGORY"], [22072, 22083, "TRAINED_CATEGORY"], [22087, 22107, "TRAINED_CATEGORY"], [22131, 22145, "TRAINED_CATEGORY"], [22173, 22184, "TRAINED_CATEGORY"], [22188, 22195, "TRAINED_CATEGORY"], [22202, 22215, "TRAINED_CATEGORY"], [22217, 22220, "TRAINED_CATEGORY"], [22231, 22252, "TRAINED_CATEGORY"], [22268, 22292, "TRAINED_CATEGORY"], [22310, 22323, "TRAINED_CATEGORY"], [22330, 22347, "TRAINED_CATEGORY"], [22384, 22399, "TRAINED_CATEGORY"], [22409, 22422, "TRAINED_CATEGORY"], [22451, 22475, "TRAINED_CATEGORY"], [22479, 22482, "TRAINED_CATEGORY"], [22491, 22505, "TRAINED_CATEGORY"], [22517, 22523, "TRAINED_CATEGORY"], [22535, 22562, "TRAINED_CATEGORY"], [22608, 22625, "TRAINED_CATEGORY"], [22635, 22647, "TRAINED_CATEGORY"], [22651, 22658, "TRAINED_CATEGORY"], [22662, 22689, "TRAINED_CATEGORY"], [22720, 22728, "TRAINED_CATEGORY"], [22732, 22741, "TRAINED_CATEGORY"], [22745, 22766, "TRAINED_CATEGORY"], [22768, 22787, "TRAINED_CATEGORY"], [22791, 22798, "TRAINED_CATEGORY"], [22815, 22833, "TRAINED_CATEGORY"], [22834, 22863, "TRAINED_CATEGORY"], [22871, 22892, "TRAINED_CATEGORY"], [22900, 22909, "TRAINED_CATEGORY"], [22921, 22932, "TRAINED_CATEGORY"], [22958, 22969, "TRAINED_CATEGORY"], [22973, 22977, "TRAINED_CATEGORY"], [22979, 22992, "TRAINED_CATEGORY"], [22997, 23000, "TRAINED_CATEGORY"], [23030, 23042, "TRAINED_CATEGORY"], [23046, 23065, "TRAINED_CATEGORY"], [23078, 23087, "TRAINED_CATEGORY"], [23097, 23114, "TRAINED_CATEGORY"], [23119, 23127, "TRAINED_CATEGORY"], [23132, 23154, "TRAINED_CATEGORY"], [23158, 23161, "TRAINED_CATEGORY"], [23163, 23182, "TRAINED_CATEGORY"], [23193, 23201, "TRAINED_CATEGORY"], [23205, 23218, "TRAINED_CATEGORY"], [23233, 23239, "TRAINED_CATEGORY"], [23249, 23255, "TRAINED_CATEGORY"], [23259, 23273, "TRAINED_CATEGORY"], [23282, 23296, "TRAINED_CATEGORY"], [23300, 23314, "TRAINED_CATEGORY"], [23330, 23360, "TRAINED_CATEGORY"], [23373, 23397, "TRAINED_CATEGORY"], [23401, 23418, "TRAINED_CATEGORY"], [23420, 23422, "TRAINED_CATEGORY"], [23438, 23470, "TRAINED_CATEGORY"], [23474, 23477, "TRAINED_CATEGORY"], [23479, 23489, "TRAINED_CATEGORY"], [23493, 23506, "TRAINED_CATEGORY"], [23510, 23513, "TRAINED_CATEGORY"], [23541, 23544, "TRAINED_CATEGORY"], [23554, 23573, "TRAINED_CATEGORY"], [23591, 23606, "TRAINED_CATEGORY"], [23616, 23620, "TRAINED_CATEGORY"], [23647, 23659, "TRAINED_CATEGORY"], [23671, 23686, "TRAINED_CATEGORY"], [23690, 23704, "TRAINED_CATEGORY"], [23713, 23726, "TRAINED_CATEGORY"], [23735, 23742, "TRAINED_CATEGORY"], [23755, 23774, "TRAINED_CATEGORY"], [23777, 23792, "TRAINED_CATEGORY"], [23796, 23810, "TRAINED_CATEGORY"], [23816, 23823, "TRAINED_CATEGORY"], [23828, 23846, "TRAINED_CATEGORY"], [23862, 23880, "TRAINED_CATEGORY"], [23884, 23904, "TRAINED_CATEGORY"], [23911, 23927, "TRAINED_CATEGORY"], [23931, 23961, "TRAINED_CATEGORY"], [23972, 23991, "TRAINED_CATEGORY"], [23992, 23995, "TRAINED_CATEGORY"], [24008, 24019, "TRAINED_CATEGORY"], [24025, 24050, "TRAINED_CATEGORY"], [24076, 24090, "TRAINED_CATEGORY"], [24094, 24110, "TRAINED_CATEGORY"], [24165, 24176, "TRAINED_CATEGORY"], [24180, 24199, "TRAINED_CATEGORY"], [24201, 24203, "TRAINED_CATEGORY"], [24223, 24235, "TRAINED_CATEGORY"], [24241, 24279, "TRAINED_CATEGORY"], [24298, 24312, "TRAINED_CATEGORY"], [24342, 24367, "TRAINED_CATEGORY"], [24382, 24404, "TRAINED_CATEGORY"], [24447, 24471, "TRAINED_CATEGORY"], [24472, 24493, "TRAINED_CATEGORY"], [24518, 24541, "TRAINED_CATEGORY"], [24542, 24566, "TRAINED_CATEGORY"], [24567, 24596, "TRAINED_CATEGORY"], [24597, 24602, "TRAINED_CATEGORY"], [24603, 24612, "TRAINED_CATEGORY"], [24613, 24616, "TRAINED_CATEGORY"], [24620, 24640, "TRAINED_CATEGORY"], [24641, 24673, "TRAINED_CATEGORY"], [24674, 24693, "TRAINED_CATEGORY"], [24694, 24733, "TRAINED_CATEGORY"], [24734, 24748, "TRAINED_CATEGORY"], [24773, 24783, "TRAINED_CATEGORY"], [24792, 24807, "TRAINED_CATEGORY"], [24811, 24816, "TRAINED_CATEGORY"], [24848, 24855, "TRAINED_CATEGORY"], [24857, 24889, "TRAINED_CATEGORY"], [24894, 24903, "TRAINED_CATEGORY"], [24907, 24922, "TRAINED_CATEGORY"], [24931, 24938, "TRAINED_CATEGORY"], [24952, 24961, "TRAINED_CATEGORY"], [24963, 24967, "TRAINED_CATEGORY"], [24983, 24992, "TRAINED_CATEGORY"], [24994, 25004, "TRAINED_CATEGORY"], [25006, 25009, "TRAINED_CATEGORY"], [25011, 25015, "TRAINED_CATEGORY"], [25043, 25064, "TRAINED_CATEGORY"], [25068, 25075, "TRAINED_CATEGORY"], [25092, 25098, "TRAINED_CATEGORY"], [25101, 25106, "TRAINED_CATEGORY"], [25108, 25130, "TRAINED_CATEGORY"], [25134, 25149, "TRAINED_CATEGORY"], [25154, 25169, "TRAINED_CATEGORY"], [25175, 25205, "TRAINED_CATEGORY"], [25214, 25224, "TRAINED_CATEGORY"], [25226, 25229, "TRAINED_CATEGORY"], [25231, 25235, "TRAINED_CATEGORY"], [25252, 25273, "TRAINED_CATEGORY"], [25277, 25300, "TRAINED_CATEGORY"], [25304, 25307, "TRAINED_CATEGORY"], [25310, 25315, "TRAINED_CATEGORY"], [25317, 25350, "TRAINED_CATEGORY"], [25354, 25369, "TRAINED_CATEGORY"], [25370, 25403, "TRAINED_CATEGORY"], [25413, 25423, "TRAINED_CATEGORY"], [25425, 25428, "TRAINED_CATEGORY"], [25430, 25434, "TRAINED_CATEGORY"], [25451, 25473, "TRAINED_CATEGORY"], [25477, 25484, "TRAINED_CATEGORY"], [25486, 25499, "TRAINED_CATEGORY"], [25500, 25507, "TRAINED_CATEGORY"], [25513, 25533, "TRAINED_CATEGORY"], [25537, 25562, "TRAINED_CATEGORY"], [25565, 25570, "TRAINED_CATEGORY"], [25572, 25581, "TRAINED_CATEGORY"], [25588, 25604, "TRAINED_CATEGORY"], [25606, 25620, "TRAINED_CATEGORY"], [25622, 25634, "TRAINED_CATEGORY"], [25638, 25649, "TRAINED_CATEGORY"], [25651, 25668, "TRAINED_CATEGORY"], [25670, 25673, "TRAINED_CATEGORY"], [25675, 25679, "TRAINED_CATEGORY"], [25695, 25702, "TRAINED_CATEGORY"], [25706, 25719, "TRAINED_CATEGORY"], [25724, 25732, "TRAINED_CATEGORY"], [25736, 25751, "TRAINED_CATEGORY"], [25753, 25779, "TRAINED_CATEGORY"], [25783, 25788, "TRAINED_CATEGORY"], [25801, 25809, "TRAINED_CATEGORY"], [25811, 25830, "TRAINED_CATEGORY"], [25836, 25851, "TRAINED_CATEGORY"], [25854, 25859, "TRAINED_CATEGORY"], [25861, 25870, "TRAINED_CATEGORY"], [25877, 25891, "TRAINED_CATEGORY"], [25892, 25901, "TRAINED_CATEGORY"], [25905, 25915, "TRAINED_CATEGORY"], [25917, 25929, "TRAINED_CATEGORY"], [25933, 25941, "TRAINED_CATEGORY"], [25943, 25949, "TRAINED_CATEGORY"], [25951, 25957, "TRAINED_CATEGORY"], [25963, 25977, "TRAINED_CATEGORY"], [25986, 25992, "TRAINED_CATEGORY"], [25994, 26008, "TRAINED_CATEGORY"], [26010, 26014, "TRAINED_CATEGORY"], [26016, 26045, "TRAINED_CATEGORY"], [26047, 26070, "TRAINED_CATEGORY"], [26093, 26096, "TRAINED_CATEGORY"], [26098, 26102, "TRAINED_CATEGORY"], [26118, 26131, "TRAINED_CATEGORY"], [26133, 26168, "TRAINED_CATEGORY"], [26177, 26185, "TRAINED_CATEGORY"], [26187, 26193, "TRAINED_CATEGORY"], [26195, 26203, "TRAINED_CATEGORY"], [26205, 26210, "TRAINED_CATEGORY"], [26212, 26241, "TRAINED_CATEGORY"], [26243, 26259, "TRAINED_CATEGORY"], [26263, 26270, "TRAINED_CATEGORY"], [26279, 26285, "TRAINED_CATEGORY"], [26303, 26307, "TRAINED_CATEGORY"], [26343, 26346, "TRAINED_CATEGORY"], [26348, 26352, "TRAINED_CATEGORY"], [26373, 26388, "TRAINED_CATEGORY"], [26390, 26409, "TRAINED_CATEGORY"], [26411, 26441, "TRAINED_CATEGORY"], [26450, 26458, "TRAINED_CATEGORY"], [26460, 26467, "TRAINED_CATEGORY"], [26469, 26473, "TRAINED_CATEGORY"], [26488, 26494, "TRAINED_CATEGORY"], [26496, 26503, "TRAINED_CATEGORY"], [26505, 26510, "TRAINED_CATEGORY"], [26512, 26532, "TRAINED_CATEGORY"], [26534, 26544, "TRAINED_CATEGORY"], [26549, 26560, "TRAINED_CATEGORY"], [26562, 26574, "TRAINED_CATEGORY"], [26578, 26608, "TRAINED_CATEGORY"], [26612, 26621, "TRAINED_CATEGORY"], [26623, 26630, "TRAINED_CATEGORY"], [26632, 26640, "TRAINED_CATEGORY"], [26642, 26647, "TRAINED_CATEGORY"], [26652, 26658, "TRAINED_CATEGORY"], [26667, 26673, "TRAINED_CATEGORY"], [26675, 26690, "TRAINED_CATEGORY"], [26692, 26696, "TRAINED_CATEGORY"], [26698, 26717, "TRAINED_CATEGORY"], [26719, 26726, "TRAINED_CATEGORY"], [26728, 26733, "TRAINED_CATEGORY"], [26735, 26760, "TRAINED_CATEGORY"], [26764, 26811, "TRAINED_CATEGORY"], [26820, 26830, "TRAINED_CATEGORY"], [26832, 26835, "TRAINED_CATEGORY"], [26837, 26841, "TRAINED_CATEGORY"], [26843, 26862, "TRAINED_CATEGORY"], [26864, 26871, "TRAINED_CATEGORY"], [26873, 26878, "TRAINED_CATEGORY"], [26880, 26896, "TRAINED_CATEGORY"], [26898, 26905, "TRAINED_CATEGORY"], [26907, 26915, "TRAINED_CATEGORY"], [26918, 26930, "TRAINED_CATEGORY"], [26934, 26964, "TRAINED_CATEGORY"], [26973, 26979, "TRAINED_CATEGORY"], [26981, 26996, "TRAINED_CATEGORY"], [26998, 27002, "TRAINED_CATEGORY"], [27004, 27025, "TRAINED_CATEGORY"], [27027, 27032, "TRAINED_CATEGORY"], [27034, 27040, "TRAINED_CATEGORY"], [27042, 27071, "TRAINED_CATEGORY"], [27089, 27112, "TRAINED_CATEGORY"], [27121, 27131, "TRAINED_CATEGORY"], [27133, 27136, "TRAINED_CATEGORY"], [27138, 27142, "TRAINED_CATEGORY"], [27162, 27176, "TRAINED_CATEGORY"], [27180, 27201, "TRAINED_CATEGORY"], [27205, 27235, "TRAINED_CATEGORY"], [27236, 27253, "TRAINED_CATEGORY"], [27297, 27304, "TRAINED_CATEGORY"], [27306, 27313, "TRAINED_CATEGORY"], [27314, 27325, "TRAINED_CATEGORY"], [27334, 27357, "TRAINED_CATEGORY"], [27364, 27375, "TRAINED_CATEGORY"], [27379, 27397, "TRAINED_CATEGORY"], [27406, 27415, "TRAINED_CATEGORY"], [27419, 27452, "TRAINED_CATEGORY"], [27454, 27462, "TRAINED_CATEGORY"], [27468, 27483, "TRAINED_CATEGORY"], [27485, 27511, "TRAINED_CATEGORY"], [27513, 27522, "TRAINED_CATEGORY"], [27524, 27542, "TRAINED_CATEGORY"], [27544, 27568, "TRAINED_CATEGORY"], [27572, 27575, "TRAINED_CATEGORY"], [27579, 27594, "TRAINED_CATEGORY"], [27595, 27621, "TRAINED_CATEGORY"], [27622, 27626, "TRAINED_CATEGORY"], [27628, 27635, "TRAINED_CATEGORY"], [27641, 27652, "TRAINED_CATEGORY"], [27659, 27665, "TRAINED_CATEGORY"], [27668, 27681, "TRAINED_CATEGORY"], [27682, 27695, "TRAINED_CATEGORY"], [27700, 27717, "TRAINED_CATEGORY"], [27724, 27730, "TRAINED_CATEGORY"], [27732, 27752, "TRAINED_CATEGORY"], [27754, 27757, "TRAINED_CATEGORY"], [27761, 27790, "TRAINED_CATEGORY"], [27794, 27798, "TRAINED_CATEGORY"], [27801, 27828, "TRAINED_CATEGORY"], [27857, 27864, "TRAINED_CATEGORY"], [27868, 27891, "TRAINED_CATEGORY"], [27892, 27903, "TRAINED_CATEGORY"], [27909, 27930, "TRAINED_CATEGORY"], [27954, 27980, "TRAINED_CATEGORY"], [27982, 27995, "TRAINED_CATEGORY"], [27998, 28024, "TRAINED_CATEGORY"], [28026, 28050, "TRAINED_CATEGORY"], [28054, 28084, "TRAINED_CATEGORY"], [28087, 28102, "TRAINED_CATEGORY"], [28106, 28121, "TRAINED_CATEGORY"], [28125, 28155, "TRAINED_CATEGORY"], [28168, 28171, "TRAINED_CATEGORY"], [28176, 28198, "TRAINED_CATEGORY"], [28202, 28217, "TRAINED_CATEGORY"], [28218, 28226, "TRAINED_CATEGORY"], [28228, 28233, "TRAINED_CATEGORY"], [28241, 28244, "TRAINED_CATEGORY"], [28248, 28261, "TRAINED_CATEGORY"], [28271, 28274, "TRAINED_CATEGORY"], [28278, 28283, "TRAINED_CATEGORY"], [28287, 28306, "TRAINED_CATEGORY"], [28311, 28330, "TRAINED_CATEGORY"], [28371, 28403, "TRAINED_CATEGORY"], [28407, 28422, "TRAINED_CATEGORY"], [32, 35, "ORG"], [168, 183, "PERSON"], [187, 196, "DATE"], [216, 229, "PERSON"], [241, 254, "ORG"], [258, 262, "DATE"], [604, 607, "CARDINAL"], [700, 704, "CARDINAL"], [725, 728, "ORG"], [748, 749, "CARDINAL"], [753, 754, "CARDINAL"], [758, 759, "CARDINAL"], [765, 773, "PERSON"], [776, 780, "DATE"], [815, 818, "ORG"], [1083, 1086, "ORG"], [1420, 1423, "ORG"], [1917, 1920, "CARDINAL"], [2210, 2213, "ORG"], [2323, 2326, "ORG"], [2674, 2677, "ORG"], [3140, 3175, "ORG"], [3630, 3633, "ORG"], [3684, 3687, "CARDINAL"], [4426, 4429, "ORG"], [4482, 4491, "CARDINAL"], [4793, 4796, "ORG"], [5000, 5003, "ORG"], [5103, 5114, "ORG"], [5118, 5124, "PERSON"], [5191, 5219, "ORG"], [5274, 5295, "ORG"], [5327, 5364, "ORG"], [5422, 5445, "ORG"], [5510, 5545, "ORG"], [5575, 5579, "GPE"], [5592, 5622, "ORG"], [5833, 5836, "ORG"], [5969, 5972, "ORG"], [6216, 6224, "GPE"], [6244, 6249, "ORDINAL"], [6351, 6360, "ORG"], [6733, 6742, "LOC"], [6744, 6758, "PERSON"], [6764, 6771, "CARDINAL"], [6785, 6788, "ORG"], [6859, 6864, "GPE"], [6879, 6895, "CARDINAL"], [6896, 6903, "NORP"], [6934, 6937, "ORG"], [6973, 6976, "ORG"], [7083, 7088, "GPE"], [7103, 7115, "CARDINAL"], [7116, 7123, "NORP"], [7165, 7232, "ORG"], [7364, 7368, "DATE"], [7382, 7437, "WORK_OF_ART"], [7483, 7536, "WORK_OF_ART"], [7546, 7550, "DATE"], [7562, 7572, "GPE"], [7574, 7579, "GPE"], [7581, 7588, "CARDINAL"], [7616, 7618, "CARDINAL"], [7644, 7646, "GPE"], [7648, 7655, "GPE"], [7657, 7662, "GPE"], [7664, 7669, "GPE"], [7671, 7679, "GPE"], [7685, 7690, "GPE"], [7741, 7745, "DATE"], [7759, 7769, "GPE"], [7771, 7783, "GPE"], [7790, 7792, "CARDINAL"], [7879, 7885, "GPE"], [7987, 8006, "ORG"], [8010, 8015, "GPE"], [8084, 8087, "ORG"], [8238, 8244, "CARDINAL"], [8257, 8265, "CARDINAL"], [8353, 8356, "CARDINAL"], [8677, 8680, "ORG"], [9526, 9531, "PRODUCT"], [9567, 9572, "ORDINAL"], [9800, 9803, "ORG"], [12400, 12403, "ORG"], [12412, 12415, "ORG"], [13179, 13182, "ORG"], [13323, 13326, "ORG"], [13376, 13388, "CARDINAL"], [13492, 13495, "ORG"], [14027, 14030, "ORG"], [14099, 14104, "CARDINAL"], [14148, 14152, "CARDINAL"], [14271, 14274, "CARDINAL"], [14324, 14329, "CARDINAL"], [14366, 14370, "CARDINAL"], [14513, 14516, "CARDINAL"], [14718, 14722, "CARDINAL"], [14741, 14745, "CARDINAL"], [14815, 14820, "CARDINAL"], [14855, 14865, "CARDINAL"], [15023, 15026, "ORG"], [15075, 15083, "CARDINAL"], [15489, 15492, "CARDINAL"], [16273, 16276, "ORG"], [16384, 16388, "CARDINAL"], [16405, 16414, "NORP"], [16534, 16544, "ORG"], [16627, 16630, "ORG"], [16757, 16777, "CARDINAL"], [16879, 16882, "CARDINAL"], [16903, 16906, "CARDINAL"], [16927, 16930, "CARDINAL"], [16945, 16949, "CARDINAL"], [17305, 17313, "ORG"], [17323, 17335, "NORP"], [17433, 17437, "LOC"], [17441, 17446, "CARDINAL"], [17500, 17505, "CARDINAL"], [17561, 17569, "ORG"], [17632, 17637, "CARDINAL"], [17820, 17825, "CARDINAL"], [18064, 18069, "ORDINAL"], [18179, 18187, "CARDINAL"], [18188, 18200, "NORP"], [18240, 18244, "CARDINAL"], [18246, 18249, "CARDINAL"], [18297, 18310, "CARDINAL"], [18424, 18435, "NORP"], [18635, 18643, "ORG"], [18662, 18673, "NORP"], [18684, 18689, "CARDINAL"], [18899, 18904, "CARDINAL"], [19094, 19099, "CARDINAL"], [19402, 19411, "ORG"], [19491, 19494, "ORG"], [19534, 19537, "CARDINAL"], [19692, 19696, "CARDINAL"], [19710, 19715, "CARDINAL"], [19808, 19811, "CARDINAL"], [19812, 19832, "ORG"], [19837, 19840, "CARDINAL"], [19928, 19931, "ORG"], [20044, 20047, "CARDINAL"], [20102, 20111, "CARDINAL"], [20112, 20115, "ORG"], [20263, 20324, "EVENT"], [20331, 20341, "ORG"], [20349, 20352, "ORG"], [20698, 20713, "DATE"], [20768, 20771, "ORG"], [20789, 20859, "ORG"], [20913, 20916, "ORG"], [20990, 20993, "ORG"], [21011, 21030, "ORG"], [21034, 21038, "DATE"], [21043, 21047, "DATE"], [21048, 21066, "ORG"], [21083, 21091, "DATE"], [21120, 21149, "ORG"], [21162, 21165, "ORG"], [21276, 21280, "DATE"], [21325, 21362, "ORG"], [21367, 21390, "ORG"], [21411, 21414, "ORG"], [21482, 21486, "DATE"], [21567, 21570, "ORG"], [21606, 21619, "DATE"], [21658, 21661, "ORG"], [21713, 21717, "DATE"], [21850, 21854, "ORG"], [22173, 22176, "CARDINAL"], [22217, 22220, "CARDINAL"], [22479, 22482, "ORG"], [22511, 22515, "DATE"], [22517, 22523, "ORG"], [22537, 22543, "ORDINAL"], [22544, 22547, "ORG"], [22795, 22798, "ORG"], [22997, 23000, "ORG"], [23032, 23036, "DATE"], [23046, 23065, "ORG"], [23097, 23114, "ORG"], [23119, 23127, "PERSON"], [23158, 23161, "ORG"], [23438, 23477, "ORG"], [23510, 23513, "ORG"], [23527, 23531, "DATE"], [23541, 23544, "ORG"], [23739, 23742, "ORG"], [23820, 23823, "ORG"], [24223, 24235, "PERSON"], [24377, 24380, "DATE"], [24447, 24455, "ORG"], [24472, 24477, "ORG"], [24567, 24579, "ORG"], [24597, 24602, "PERSON"], [24641, 24646, "ORG"], [24734, 24738, "PRODUCT"], [24818, 24836, "PERSON"], [24924, 24928, "DATE"], [24931, 24938, "GPE"], [24940, 24950, "GPE"], [24952, 24961, "PERSON"], [24983, 24992, "GPE"], [24994, 25004, "GPE"], [25006, 25009, "ORG"], [25072, 25075, "ORG"], [25108, 25130, "PERSON"], [25134, 25169, "ORG"], [25207, 25211, "DATE"], [25214, 25224, "GPE"], [25226, 25229, "ORG"], [25304, 25307, "ORG"], [25317, 25339, "PERSON"], [25371, 25403, "PERSON"], [25406, 25410, "DATE"], [25413, 25423, "GPE"], [25425, 25428, "ORG"], [25435, 25436, "CARDINAL"], [25481, 25484, "ORG"], [25504, 25507, "ORG"], [25572, 25581, "PERSON"], [25588, 25604, "PERSON"], [25610, 25620, "PERSON"], [25652, 25656, "DATE"], [25658, 25668, "GPE"], [25696, 25702, "CARDINAL"], [25736, 25739, "ORG"], [25861, 25870, "PERSON"], [25877, 25891, "PERSON"], [25892, 25915, "PERSON"], [25979, 25983, "DATE"], [25986, 25992, "GPE"], [25994, 26008, "ORG"], [26085, 26089, "DATE"], [26093, 26096, "ORG"], [26098, 26102, "ORG"], [26118, 26131, "PERSON"], [26170, 26174, "DATE"], [26187, 26193, "PERSON"], [26195, 26203, "PERSON"], [26212, 26242, "PERSON"], [26243, 26270, "ORG"], [26272, 26276, "DATE"], [26287, 26301, "ORG"], [26335, 26339, "DATE"], [26343, 26346, "ORG"], [26348, 26352, "ORG"], [26373, 26388, "PERSON"], [26443, 26447, "DATE"], [26450, 26458, "GPE"], [26460, 26467, "ORG"], [26488, 26494, "GPE"], [26496, 26503, "PERSON"], [26512, 26532, "PERSON"], [26660, 26664, "DATE"], [26667, 26673, "GPE"], [26711, 26717, "GPE"], [26719, 26726, "PERSON"], [26735, 26760, "PERSON"], [26813, 26817, "DATE"], [26820, 26830, "GPE"], [26832, 26835, "ORG"], [26856, 26862, "GPE"], [26864, 26871, "PERSON"], [26880, 26896, "PERSON"], [26898, 26964, "ORG"], [26966, 26970, "DATE"], [26973, 26979, "GPE"], [27017, 27025, "GPE"], [27027, 27032, "GPE"], [27034, 27040, "GPE"], [27042, 27055, "PERSON"], [27114, 27118, "DATE"], [27121, 27131, "GPE"], [27133, 27136, "ORG"], [27143, 27144, "CARDINAL"], [27162, 27170, "ORG"], [27180, 27235, "ORG"], [27301, 27304, "ORG"], [27364, 27367, "ORG"], [27459, 27462, "ORG"], [27468, 27471, "ORG"], [27513, 27516, "ORG"], [27525, 27537, "CARDINAL"], [27572, 27575, "ORG"], [27583, 27594, "PERSON"], [27659, 27665, "PERSON"], [27684, 27687, "ORG"], [27765, 27779, "PERSON"], [27802, 27829, "WORK_OF_ART"], [27892, 27895, "ORG"], [27933, 27936, "ORG"], [28001, 28004, "ORG"], [28168, 28171, "ORG"], [28206, 28217, "PERSON"], [28241, 28244, "ORG"], [28248, 28253, "PRODUCT"], [28271, 28274, "ORG"], [28278, 28283, "PRODUCT"], [28291, 28306, "PERSON"], [28407, 28422, "PERSON"]]}], ["Expert Choice is decision-making software that is based on multi-criteria decision making.\nExpert Choice implements the Analytic Hierarchy Process (AHP) and has been used in fields such as manufacturing, environmental management, shipbuilding and agriculture.Created by Thomas Saaty and Ernest Forman in 1983, the software is supplied by Expert Choice Inc.\n\n\n== References ==", {"entities": [[0, 13, "TRAINED_CATEGORY"], [17, 41, "TRAINED_CATEGORY"], [59, 89, "TRAINED_CATEGORY"], [91, 104, "TRAINED_CATEGORY"], [116, 146, "TRAINED_CATEGORY"], [148, 151, "TRAINED_CATEGORY"], [174, 180, "TRAINED_CATEGORY"], [189, 202, "TRAINED_CATEGORY"], [204, 228, "TRAINED_CATEGORY"], [230, 242, "TRAINED_CATEGORY"], [247, 258, "TRAINED_CATEGORY"], [270, 282, "TRAINED_CATEGORY"], [287, 300, "TRAINED_CATEGORY"], [310, 322, "TRAINED_CATEGORY"], [338, 356, "TRAINED_CATEGORY"], [362, 372, "TRAINED_CATEGORY"], [0, 13, "ORG"], [148, 151, "ORG"], [270, 282, "PERSON"], [287, 300, "PERSON"], [304, 308, "DATE"], [338, 356, "ORG"]]}], ["Online analytical processing, or OLAP (), is an approach to answer multi-dimensional analytical (MDA) queries swiftly in computing. OLAP is part of the broader category of business intelligence, which also encompasses relational databases, report writing and data mining.  Typical applications of OLAP include business reporting for sales, marketing, management reporting, business process management (BPM), budgeting and forecasting, financial reporting and similar areas, with new applications emerging, such as agriculture.The term OLAP was created as a slight modification of the traditional database term online transaction processing (OLTP).OLAP tools enable users to analyze multidimensional data interactively from multiple perspectives. OLAP consists of three basic analytical operations: consolidation (roll-up), drill-down, and slicing and dicing. Consolidation involves the aggregation of data that can be accumulated and computed in one or more dimensions. For example, all sales offices are rolled up to the sales department or sales division to anticipate sales trends. By contrast, the drill-down is a technique that allows users to navigate through the details. For instance, users can view the sales by individual products that make up a region's sales. Slicing and dicing is a feature whereby users can take out (slicing) a specific set of data of the OLAP cube and view (dicing) the slices from different viewpoints.  These viewpoints are sometimes called dimensions (such as looking at the same sales by salesperson, or by date, or by customer, or by product, or by region, etc.)\nDatabases configured for OLAP use a multidimensional data model, allowing for complex analytical and ad hoc queries with a rapid execution time.  They borrow aspects of navigational databases, hierarchical databases and relational databases.\nOLAP is typically contrasted to OLTP (online transaction processing), which is generally characterized by much less complex queries, in a larger volume, to process transactions rather than for the purpose of business intelligence or reporting. Whereas OLAP systems are mostly optimized for read, OLTP has to process all kinds of queries (read, insert, update and delete).\n\n\n== Overview of OLAP systems ==\nAt the core of any OLAP system is an OLAP cube (also called a 'multidimensional cube' or a hypercube). It consists of numeric facts called measures that are categorized by dimensions. The measures are placed at the intersections of the hypercube, which is spanned by the dimensions as a vector space. The usual interface to manipulate an OLAP cube is a matrix interface, like Pivot tables in a spreadsheet program, which performs projection operations along the dimensions, such as aggregation or averaging.\nThe cube metadata is typically created from a star schema or snowflake schema or fact constellation of tables in a relational database. Measures are derived from the records in the fact table and dimensions are derived from the dimension tables.\nEach measure can be thought of as having a set of labels, or meta-data associated with it. A dimension is what describes these labels; it provides information about the measure.\nA simple example would be a cube that contains a store's sales as a measure, and Date/Time as a dimension. Each Sale has a Date/Time label that describes more about that sale.\nFor example:\n\n Sales Fact Table\n+-------------+----------+\n| sale_amount | time_id  |\n+-------------+----------+            Time Dimension\n|      2008.10|     1234 |----+     +---------+-------------------+\n+-------------+----------+    |     | time_id | timestamp         |\n                              |     +---------+-------------------+\n                              +---->|   1234  | 20080902 12:35:43 |\n                                    +---------+-------------------+\n\n\n=== Multidimensional databases ===\nMultidimensional structure is defined as \"a variation of the relational model that uses multidimensional structures to organize data and express the relationships between data\".  The structure is broken into cubes and the cubes are able to store and access data within the confines of each cube. \"Each cell within a multidimensional structure contains aggregated data related to elements along each of its dimensions\".  Even when data is manipulated it remains easy to access and continues to constitute a compact database format.  The data still remains interrelated.\nMultidimensional structure is quite popular for analytical databases that use online analytical processing (OLAP) applications.  Analytical databases use these databases because of their ability to deliver answers to complex business queries swiftly.  Data can be viewed from different angles, which gives a broader perspective of a problem unlike other models.\n\n\n=== Aggregations ===\nIt has been claimed that for complex queries OLAP cubes can produce an answer in around 0.1% of the time required for the same query on OLTP relational data.  The most important mechanism in OLAP which allows it to achieve such performance is the use of aggregations. Aggregations are built from the fact table by changing the granularity on specific dimensions and aggregating up data along these dimensions, using an aggregate function (or aggregation function). The number of possible aggregations is determined by every possible combination of dimension granularities.\nThe combination of all possible aggregations and the base data contains the answers to every query which can be answered from the data.Because usually there are many aggregations that can be calculated, often only a predetermined number are fully calculated; the remainder are solved on demand.  The problem of deciding which aggregations (views) to calculate is known as the view selection problem.  View selection can be constrained by the total size of the selected set of aggregations, the time to update them from changes in the base data, or both.  The objective of view selection is typically to minimize the average time to answer OLAP queries, although some studies also minimize the update time.  View selection is NP-Complete. Many approaches to the problem have been explored, including greedy algorithms, randomized search, genetic algorithms and A* search algorithm.\nSome aggregation functions can be computed for the entire OLAP cube by precomputing values for each cell, and then computing the aggregation for a roll-up of cells by aggregating these aggregates, applying a divide and conquer algorithm to the multidimensional problem to compute them efficiently. For example, the overall sum of a roll-up is just the sum of the sub-sums in each cell. Functions that can be decomposed in this way are called decomposable aggregation functions, and include COUNT, MAX, MIN, and SUM, which can be computed for each cell and then directly aggregated; these are known as self-decomposable aggregation functions. In other cases the aggregate function can be computed by computing auxiliary numbers for cells, aggregating these auxiliary numbers, and finally computing the overall number at the end; examples include AVERAGE (tracking sum and count, dividing at the end) and RANGE (tracking max and min, subtracting at the end). In other cases the aggregate function cannot be computed without analyzing the entire set at once, though in some cases approximations can be computed; examples include DISTINCT COUNT, MEDIAN, and MODE; for example, the median of a set is not the median of medians of subsets. These latter are difficult to implement efficiently in OLAP, as they require computing the aggregate function on the base data, either computing them online (slow) or precomputing them for possible rollouts (large space).\n\n\n== Types ==\nOLAP systems have been traditionally categorized using the following taxonomy.\n\n\n=== Multidimensional OLAP (MOLAP) ===\nMOLAP (multi-dimensional online analytical processing) is the classic form of OLAP and is sometimes referred to as just OLAP. MOLAP stores this data in an optimized multi-dimensional array storage, rather than in a relational database.\nSome MOLAP tools require the pre-computation and storage of derived data, such as consolidations \u2013 the operation known as processing. Such MOLAP tools generally utilize a pre-calculated data set referred to as a data cube. The data cube contains all the possible answers to a given range of questions. As a result, they  have a very fast response to queries. On the other hand, updating can take a long time depending on the degree of pre-computation. Pre-computation can also lead to what is known as data explosion.\nOther MOLAP tools, particularly those that implement the functional database model do not pre-compute derived data but make all calculations on demand other than those that were previously requested and stored in a cache.\nAdvantages of MOLAP\n\nFast query performance due to optimized storage, multidimensional indexing and caching.\nSmaller on-disk size of data compared to data stored in relational database due to compression techniques.\nAutomated computation of higher level aggregates of the data.\nIt is very compact for low dimension data sets.\nArray models provide natural indexing.\nEffective data extraction achieved through the pre-structuring of aggregated data.Disadvantages of MOLAP\n\nWithin some MOLAP systems the processing step (data load) can be quite lengthy, especially on large data volumes. This is usually remedied by doing only incremental processing, i.e., processing only the data which have changed (usually new data) instead of reprocessing the entire data set.\nSome MOLAP methodologies introduce data redundancy.\n\n\n==== Products ====\nExamples of commercial products that use MOLAP are Cognos Powerplay, Oracle Database OLAP Option, MicroStrategy, Microsoft Analysis Services, Essbase, TM1, Jedox, and icCube.\n\n\n=== Relational OLAP (ROLAP) ===\nROLAP works directly with relational databases and does not require pre-computation. The base data and the dimension tables are stored as relational tables and new tables are created to hold the aggregated information. It depends on a specialized schema design. This methodology relies on manipulating the data stored in the relational database to give the appearance of traditional OLAP's slicing and dicing functionality. In essence, each action of slicing and dicing is equivalent to adding a \"WHERE\" clause in the SQL statement. ROLAP tools do not use pre-calculated data cubes but instead pose the query to the standard relational database and its tables in order to bring back the data required to answer the question. ROLAP tools feature the ability to ask any question because the methodology is not limited to the contents of a cube.  ROLAP also has the ability to drill down to the lowest level of detail in the database.\nWhile ROLAP uses a relational database source, generally the database must be carefully designed for ROLAP use.  A database which was designed for OLTP will not function well as a ROLAP database.  Therefore, ROLAP still involves creating an additional copy of the data.  However, since it is a database, a variety of technologies can be used to populate the database.\n\n\n==== Advantages of ROLAP ====\nROLAP is considered to be more scalable in handling large data volumes, especially models with dimensions with very high cardinality (i.e., millions of members).\nWith a variety of data loading tools available, and the ability to fine-tune the extract, transform, load (ETL) code to the particular data model, load times are generally much shorter than with the automated MOLAP loads.\nThe data are stored in a standard relational database and can be accessed by any SQL reporting tool (the tool does not have to be an OLAP tool).\nROLAP tools are better at handling non-aggregatable facts (e.g., textual descriptions).  MOLAP tools tend to suffer from slow performance when querying these elements.\nBy decoupling the data storage from the multi-dimensional model, it is possible to successfully model data that would not otherwise fit into a strict dimensional model.\nThe ROLAP approach can leverage database authorization controls such as row-level security, whereby the query results are filtered depending on preset criteria applied, for example, to a given user or group of users (SQL WHERE clause).\n\n\n==== Disadvantages of ROLAP ====\nThere is a consensus in the industry that ROLAP tools have slower performance than MOLAP tools. However, see the discussion below about ROLAP performance.\nThe loading of aggregate tables must be managed by custom ETL code.  The ROLAP tools do not help with this task.  This means additional development time and more code to support.\nWhen the step of creating aggregate tables is skipped, the query performance then suffers because the larger detailed tables must be queried. This can be partially remedied by adding additional aggregate tables, however it is still not practical to create aggregate tables for all combinations of dimensions/attributes.\nROLAP relies on the general purpose database for querying and caching, and therefore several special techniques employed by MOLAP tools are not available (such as special hierarchical indexing).  However, modern ROLAP tools take advantage of latest improvements in SQL language such as CUBE and ROLLUP operators, DB2 Cube Views, as well as other SQL OLAP extensions.  These SQL improvements can mitigate the benefits of the MOLAP tools.\nSince ROLAP tools rely on SQL for all of the computations, they are not suitable when the model is heavy on calculations which don't translate well into SQL. Examples of such models include budgeting, allocations, financial reporting and other scenarios.\n\n\n==== Performance of ROLAP ====\nIn the OLAP industry ROLAP is usually perceived as being able to scale for large data volumes, but suffering from slower query performance as opposed to MOLAP. The OLAP Survey, the largest independent survey across all major OLAP products, being conducted for 6 years (2001 to 2006) have consistently found that companies using ROLAP report slower performance than those using MOLAP even when data volumes were taken into consideration.\nHowever, as with any survey there are a number of subtle issues that must be taken into account when interpreting the results.\n\nThe survey shows that ROLAP tools have 7 times more users than MOLAP tools within each company.  Systems with more users will tend to suffer more performance problems at peak usage times.\nThere is also a question about complexity of the model, measured both in number of dimensions and richness of calculations. The survey does not offer a good way to control for these variations in the data being analyzed.\n\n\n==== Downside of flexibility ====\nSome companies select ROLAP because they intend to re-use existing relational database tables\u2014these tables will frequently not be optimally designed for OLAP use.  The superior flexibility of ROLAP tools allows this less than optimal design to work, but performance suffers.  MOLAP tools in contrast would force the data to be re-loaded into an optimal OLAP design.\n\n\n=== Hybrid OLAP (HOLAP) ===\nThe undesirable trade-off between additional ETL cost and slow query performance has ensured that most commercial OLAP tools now use a \"Hybrid OLAP\" (HOLAP) approach, which allows the model designer to decide which portion of the data will be stored in MOLAP and which portion in ROLAP.\nThere is no clear agreement across the industry as to what constitutes \"Hybrid OLAP\", except that a database will divide data between relational and specialized storage. For example, for some vendors, a HOLAP database will use relational tables to hold the larger quantities of detailed data, and use specialized storage for at least some aspects of the smaller quantities of more-aggregate or less-detailed data. HOLAP addresses the shortcomings of MOLAP and ROLAP by combining the capabilities of both approaches. HOLAP tools can utilize both pre-calculated cubes and relational data sources.\n\n\n==== Vertical partitioning ====\nIn this mode HOLAP stores aggregations in MOLAP for fast query performance, and detailed data in ROLAP to optimize time of cube processing.\n\n\n==== Horizontal partitioning ====\nIn this mode HOLAP stores some slice of data, usually the more recent one (i.e. sliced by Time dimension) in MOLAP for fast query performance, and older data in ROLAP. Moreover, we can store some dices in MOLAP and others in ROLAP, leveraging the fact that in a large cuboid, there will be dense and sparse subregions.\n\n\n==== Products ====\nThe first product to provide HOLAP storage was Holos, but the technology also became available in other commercial products such as Microsoft Analysis Services, Oracle Database OLAP Option, MicroStrategy and SAP AG BI Accelerator. The hybrid OLAP approach combines ROLAP and MOLAP technology, benefiting from the greater scalability of ROLAP and the faster computation of MOLAP. For example, a HOLAP server may store large volumes of detailed data in a relational database, while aggregations are kept in a separate MOLAP store. The Microsoft SQL Server 7.0 OLAP Services supports a hybrid OLAP server\n\n\n=== Comparison ===\nEach type has certain benefits, although there is disagreement about the specifics of the benefits between providers.\n\nSome MOLAP implementations are prone to database explosion, a phenomenon causing vast amounts of storage space to be used by MOLAP databases when certain common conditions are met: high number of dimensions, pre-calculated results and sparse multidimensional data.\nMOLAP generally delivers better performance due to specialized indexing and storage optimizations. MOLAP also needs less storage space compared to ROLAP because the specialized storage typically includes compression techniques.\nROLAP is generally more scalable. However, large volume pre-processing is difficult to implement efficiently so it is frequently skipped.  ROLAP query performance can therefore suffer tremendously.\nSince ROLAP relies more on the database to perform calculations, it has more limitations in the specialized functions it can use.\nHOLAP attempts to mix the best of ROLAP and MOLAP.  It can generally pre-process swiftly, scale well, and offer good function support.\n\n\n=== Other types ===\nThe following acronyms are also sometimes used, although they are not as widespread as the ones above:\n\nWOLAP \u2013 Web-based OLAP\nDOLAP \u2013 Desktop OLAP\nRTOLAP \u2013 Real-Time OLAP\nGOLAP  \u2013 Graph OLAP\nCaseOLAP \u2013 Context-aware Semantic OLAP, developed for biomedical applications. The CaseOLAP platform includes data preprocessing (e.g., downloading, extraction, and parsing text documents), indexing and searching with Elasticsearch, creating a functional document structure called Text-Cube, and quantifying user-defined phrase-category relationships using the core CaseOLAP algorithm.\n\n\n== APIs and query languages ==\nUnlike relational databases, which had SQL as the standard query language, and widespread APIs such as ODBC, JDBC and OLEDB, there was no such unification in the OLAP world for a long time. The first real standard API was OLE DB for OLAP specification from Microsoft which appeared in 1997 and introduced the MDX query language. Several OLAP vendors \u2013 both server and client \u2013 adopted it. In 2001 Microsoft and Hyperion announced the XML for Analysis specification, which was endorsed by most of the OLAP vendors. Since this also used MDX as a query language, MDX became the de facto standard.\nSince September-2011 LINQ can be used to query SSAS OLAP cubes from Microsoft .NET.\n\n\n== Products ==\n\n\n=== History ===\nThe first product that performed OLAP queries was Express, which was released in 1970 (and acquired by Oracle in 1995 from Information Resources). However, the term did not appear until 1993 when it was coined by Edgar F. Codd, who has been described as \"the father of the relational database\". Codd's paper resulted from a short consulting assignment which Codd undertook for former Arbor Software (later Hyperion Solutions, and in 2007 acquired by Oracle), as a sort of marketing coup.  The company had released its own OLAP product, Essbase, a year earlier. As a result, Codd's \"twelve laws of online analytical processing\" were explicit in their reference to Essbase. There was some ensuing controversy and when Computerworld learned that Codd was paid by Arbor, it retracted the article. OLAP market experienced strong growth in late 1990s with dozens of commercial products going into market. In 1998, Microsoft released its first OLAP Server \u2013  Microsoft Analysis Services, which drove wide adoption of OLAP technology and moved it into mainstream.\n\n\n=== Product comparison ===\n\n\n=== OLAP clients ===\nOLAP clients include many spreadsheet programs like Excel, web application, SQL,dashboard tools, etc. Many clients support interactive data exploration where users select dimensions and measures of interest. Some dimensions are used as filters (for slicing and dicing the data) while others are selected as the axes of a pivot table or pivot chart. Users can also vary aggregation level (for drilling-down or rolling-up) the displayed view. Clients can also offer a variety of graphical widgets such as sliders, geographic maps, heatmaps and more which can be grouped and coordinated as dashboards. An extensive list of clients appears in the visualization column of the comparison of OLAP servers table.\n\n\n=== Market structure ===\nBelow is a list of top OLAP vendors in 2006, with figures in millions of US Dollars.\n\n\n=== Open-source ===\nMondrian OLAP server is an open-source OLAP server written in Java. It supports the MDX query language, the XML for Analysis and the olap4j interface specifications.\nDruid (open-source data store) is a popular open-source distributed data store for OLAP queries that is used at scale in production by various organizations.\nApache Kylin is a distributed data store for OLAP queries originally developed by eBay.\nCubes (OLAP server) is another light-weight open-source toolkit implementation of OLAP functionality in the Python programming language with built-in ROLAP.\nApache Pinot (incubating) is used at LinkedIn, Uber, Slack and Microsoft to deliver scalable real time analytics with low latency. It can ingest data from offline data sources (such as Hadoop and flat files) as well as online sources (such as Kafka). Pinot is designed to scale horizontally.\n\n\n== See also ==\nComparison of OLAP servers\nThomsen Diagrams\nFunctional Database Model\n\n\n== Bibliography ==\nDaniel Lemire (December 2007). \"Data Warehousing and OLAP-A Research-Oriented Bibliography\".Erik Thomsen. (1997). OLAP Solutions: Building Multidimensional Information Systems, 2nd Edition. John Wiley & Sons. ISBN 978-0-471-14931-6.Ling Liu and Tamer M. \u00d6zsu (Eds.) (2009).  \"Encyclopedia of Database Systems, 4100 p. 60 illus. ISBN 978-0-387-49616-0.\n\n\n== References ==\n\n\n=== Citations ===\n\n\n=== Sources ===", {"entities": [[0, 28, "TRAINED_CATEGORY"], [33, 37, "TRAINED_CATEGORY"], [45, 56, "TRAINED_CATEGORY"], [97, 100, "TRAINED_CATEGORY"], [121, 130, "TRAINED_CATEGORY"], [132, 136, "TRAINED_CATEGORY"], [140, 144, "TRAINED_CATEGORY"], [148, 168, "TRAINED_CATEGORY"], [172, 193, "TRAINED_CATEGORY"], [218, 238, "TRAINED_CATEGORY"], [247, 254, "TRAINED_CATEGORY"], [259, 270, "TRAINED_CATEGORY"], [273, 293, "TRAINED_CATEGORY"], [297, 301, "TRAINED_CATEGORY"], [333, 338, "TRAINED_CATEGORY"], [340, 349, "TRAINED_CATEGORY"], [351, 371, "TRAINED_CATEGORY"], [373, 400, "TRAINED_CATEGORY"], [402, 405, "TRAINED_CATEGORY"], [408, 417, "TRAINED_CATEGORY"], [422, 433, "TRAINED_CATEGORY"], [435, 454, "TRAINED_CATEGORY"], [459, 472, "TRAINED_CATEGORY"], [479, 495, "TRAINED_CATEGORY"], [514, 525, "TRAINED_CATEGORY"], [526, 534, "TRAINED_CATEGORY"], [535, 539, "TRAINED_CATEGORY"], [555, 576, "TRAINED_CATEGORY"], [580, 639, "TRAINED_CATEGORY"], [641, 657, "TRAINED_CATEGORY"], [665, 670, "TRAINED_CATEGORY"], [682, 703, "TRAINED_CATEGORY"], [723, 744, "TRAINED_CATEGORY"], [763, 796, "TRAINED_CATEGORY"], [798, 811, "TRAINED_CATEGORY"], [812, 820, "TRAINED_CATEGORY"], [823, 833, "TRAINED_CATEGORY"], [839, 846, "TRAINED_CATEGORY"], [851, 857, "TRAINED_CATEGORY"], [859, 872, "TRAINED_CATEGORY"], [882, 897, "TRAINED_CATEGORY"], [901, 905, "TRAINED_CATEGORY"], [946, 968, "TRAINED_CATEGORY"], [974, 981, "TRAINED_CATEGORY"], [983, 1000, "TRAINED_CATEGORY"], [1018, 1056, "TRAINED_CATEGORY"], [1071, 1083, "TRAINED_CATEGORY"], [1088, 1096, "TRAINED_CATEGORY"], [1098, 1112, "TRAINED_CATEGORY"], [1116, 1127, "TRAINED_CATEGORY"], [1140, 1145, "TRAINED_CATEGORY"], [1166, 1177, "TRAINED_CATEGORY"], [1183, 1191, "TRAINED_CATEGORY"], [1193, 1198, "TRAINED_CATEGORY"], [1208, 1217, "TRAINED_CATEGORY"], [1221, 1240, "TRAINED_CATEGORY"], [1254, 1270, "TRAINED_CATEGORY"], [1294, 1303, "TRAINED_CATEGORY"], [1312, 1317, "TRAINED_CATEGORY"], [1341, 1355, "TRAINED_CATEGORY"], [1359, 1363, "TRAINED_CATEGORY"], [1367, 1380, "TRAINED_CATEGORY"], [1385, 1389, "TRAINED_CATEGORY"], [1399, 1409, "TRAINED_CATEGORY"], [1415, 1435, "TRAINED_CATEGORY"], [1438, 1454, "TRAINED_CATEGORY"], [1507, 1521, "TRAINED_CATEGORY"], [1525, 1536, "TRAINED_CATEGORY"], [1544, 1548, "TRAINED_CATEGORY"], [1556, 1564, "TRAINED_CATEGORY"], [1572, 1579, "TRAINED_CATEGORY"], [1587, 1593, "TRAINED_CATEGORY"], [1601, 1610, "TRAINED_CATEGORY"], [1626, 1634, "TRAINED_CATEGORY"], [1635, 1664, "TRAINED_CATEGORY"], [1722, 1744, "TRAINED_CATEGORY"], [1747, 1751, "TRAINED_CATEGORY"], [1759, 1766, "TRAINED_CATEGORY"], [1770, 1792, "TRAINED_CATEGORY"], [1794, 1816, "TRAINED_CATEGORY"], [1821, 1841, "TRAINED_CATEGORY"], [1843, 1847, "TRAINED_CATEGORY"], [1875, 1879, "TRAINED_CATEGORY"], [1880, 1910, "TRAINED_CATEGORY"], [1949, 1974, "TRAINED_CATEGORY"], [1979, 1994, "TRAINED_CATEGORY"], [2007, 2019, "TRAINED_CATEGORY"], [2036, 2047, "TRAINED_CATEGORY"], [2051, 2072, "TRAINED_CATEGORY"], [2076, 2085, "TRAINED_CATEGORY"], [2095, 2107, "TRAINED_CATEGORY"], [2133, 2137, "TRAINED_CATEGORY"], [2139, 2143, "TRAINED_CATEGORY"], [2159, 2168, "TRAINED_CATEGORY"], [2172, 2179, "TRAINED_CATEGORY"], [2195, 2201, "TRAINED_CATEGORY"], [2220, 2228, "TRAINED_CATEGORY"], [2232, 2244, "TRAINED_CATEGORY"], [2251, 2259, "TRAINED_CATEGORY"], [2263, 2278, "TRAINED_CATEGORY"], [2282, 2294, "TRAINED_CATEGORY"], [2351, 2353, "TRAINED_CATEGORY"], [2366, 2379, "TRAINED_CATEGORY"], [2420, 2430, "TRAINED_CATEGORY"], [2432, 2444, "TRAINED_CATEGORY"], [2459, 2476, "TRAINED_CATEGORY"], [2480, 2493, "TRAINED_CATEGORY"], [2515, 2529, "TRAINED_CATEGORY"], [2533, 2547, "TRAINED_CATEGORY"], [2549, 2568, "TRAINED_CATEGORY"], [2583, 2595, "TRAINED_CATEGORY"], [2599, 2617, "TRAINED_CATEGORY"], [2624, 2636, "TRAINED_CATEGORY"], [2640, 2661, "TRAINED_CATEGORY"], [2678, 2699, "TRAINED_CATEGORY"], [2706, 2720, "TRAINED_CATEGORY"], [2730, 2741, "TRAINED_CATEGORY"], [2745, 2754, "TRAINED_CATEGORY"], [2756, 2773, "TRAINED_CATEGORY"], [2800, 2813, "TRAINED_CATEGORY"], [2817, 2833, "TRAINED_CATEGORY"], [2837, 2855, "TRAINED_CATEGORY"], [2859, 2865, "TRAINED_CATEGORY"], [2869, 2890, "TRAINED_CATEGORY"], [2892, 2900, "TRAINED_CATEGORY"], [2918, 2929, "TRAINED_CATEGORY"], [2933, 2947, "TRAINED_CATEGORY"], [2952, 2962, "TRAINED_CATEGORY"], [2980, 3000, "TRAINED_CATEGORY"], [3002, 3014, "TRAINED_CATEGORY"], [3043, 3048, "TRAINED_CATEGORY"], [3052, 3058, "TRAINED_CATEGORY"], [3063, 3072, "TRAINED_CATEGORY"], [3089, 3091, "TRAINED_CATEGORY"], [3093, 3104, "TRAINED_CATEGORY"], [3108, 3112, "TRAINED_CATEGORY"], [3123, 3135, "TRAINED_CATEGORY"], [3137, 3139, "TRAINED_CATEGORY"], [3149, 3160, "TRAINED_CATEGORY"], [3167, 3178, "TRAINED_CATEGORY"], [3180, 3196, "TRAINED_CATEGORY"], [3206, 3212, "TRAINED_CATEGORY"], [3227, 3242, "TRAINED_CATEGORY"], [3246, 3255, "TRAINED_CATEGORY"], [3261, 3270, "TRAINED_CATEGORY"], [3274, 3285, "TRAINED_CATEGORY"], [3287, 3296, "TRAINED_CATEGORY"], [3301, 3318, "TRAINED_CATEGORY"], [3345, 3354, "TRAINED_CATEGORY"], [3360, 3367, "TRAINED_CATEGORY"], [3415, 3428, "TRAINED_CATEGORY"], [3429, 3430, "TRAINED_CATEGORY"], [3440, 3441, "TRAINED_CATEGORY"], [3480, 3494, "TRAINED_CATEGORY"], [3495, 3496, "TRAINED_CATEGORY"], [3502, 3526, "TRAINED_CATEGORY"], [3593, 3594, "TRAINED_CATEGORY"], [3609, 3620, "TRAINED_CATEGORY"], [3629, 3630, "TRAINED_CATEGORY"], [3661, 3662, "TRAINED_CATEGORY"], [3765, 3766, "TRAINED_CATEGORY"], [3841, 3867, "TRAINED_CATEGORY"], [3872, 3898, "TRAINED_CATEGORY"], [3914, 3925, "TRAINED_CATEGORY"], [3929, 3949, "TRAINED_CATEGORY"], [3960, 3987, "TRAINED_CATEGORY"], [4000, 4004, "TRAINED_CATEGORY"], [4017, 4034, "TRAINED_CATEGORY"], [4043, 4047, "TRAINED_CATEGORY"], [4051, 4064, "TRAINED_CATEGORY"], [4080, 4085, "TRAINED_CATEGORY"], [4090, 4099, "TRAINED_CATEGORY"], [4129, 4133, "TRAINED_CATEGORY"], [4141, 4153, "TRAINED_CATEGORY"], [4157, 4166, "TRAINED_CATEGORY"], [4169, 4178, "TRAINED_CATEGORY"], [4186, 4214, "TRAINED_CATEGORY"], [4224, 4239, "TRAINED_CATEGORY"], [4251, 4259, "TRAINED_CATEGORY"], [4274, 4288, "TRAINED_CATEGORY"], [4302, 4306, "TRAINED_CATEGORY"], [4322, 4324, "TRAINED_CATEGORY"], [4376, 4401, "TRAINED_CATEGORY"], [4404, 4412, "TRAINED_CATEGORY"], [4441, 4467, "TRAINED_CATEGORY"], [4489, 4509, "TRAINED_CATEGORY"], [4519, 4567, "TRAINED_CATEGORY"], [4570, 4590, "TRAINED_CATEGORY"], [4595, 4610, "TRAINED_CATEGORY"], [4622, 4635, "TRAINED_CATEGORY"], [4647, 4654, "TRAINED_CATEGORY"], [4658, 4682, "TRAINED_CATEGORY"], [4693, 4697, "TRAINED_CATEGORY"], [4717, 4733, "TRAINED_CATEGORY"], [4747, 4768, "TRAINED_CATEGORY"], [4772, 4781, "TRAINED_CATEGORY"], [4789, 4801, "TRAINED_CATEGORY"], [4809, 4821, "TRAINED_CATEGORY"], [4826, 4828, "TRAINED_CATEGORY"], [4855, 4870, "TRAINED_CATEGORY"], [4871, 4881, "TRAINED_CATEGORY"], [4894, 4903, "TRAINED_CATEGORY"], [4907, 4918, "TRAINED_CATEGORY"], [4922, 4930, "TRAINED_CATEGORY"], [4944, 4958, "TRAINED_CATEGORY"], [4962, 4982, "TRAINED_CATEGORY"], [4985, 5013, "TRAINED_CATEGORY"], [5017, 5021, "TRAINED_CATEGORY"], [5035, 5037, "TRAINED_CATEGORY"], [5049, 5065, "TRAINED_CATEGORY"], [5069, 5076, "TRAINED_CATEGORY"], [5080, 5092, "TRAINED_CATEGORY"], [5094, 5106, "TRAINED_CATEGORY"], [5122, 5136, "TRAINED_CATEGORY"], [5149, 5164, "TRAINED_CATEGORY"], [5168, 5187, "TRAINED_CATEGORY"], [5207, 5211, "TRAINED_CATEGORY"], [5218, 5234, "TRAINED_CATEGORY"], [5242, 5263, "TRAINED_CATEGORY"], [5268, 5288, "TRAINED_CATEGORY"], [5291, 5301, "TRAINED_CATEGORY"], [5305, 5326, "TRAINED_CATEGORY"], [5344, 5370, "TRAINED_CATEGORY"], [5374, 5397, "TRAINED_CATEGORY"], [5399, 5414, "TRAINED_CATEGORY"], [5418, 5443, "TRAINED_CATEGORY"], [5448, 5461, "TRAINED_CATEGORY"], [5471, 5482, "TRAINED_CATEGORY"], [5486, 5497, "TRAINED_CATEGORY"], [5525, 5533, "TRAINED_CATEGORY"], [5560, 5577, "TRAINED_CATEGORY"], [5608, 5635, "TRAINED_CATEGORY"], [5658, 5671, "TRAINED_CATEGORY"], [5686, 5692, "TRAINED_CATEGORY"], [5695, 5706, "TRAINED_CATEGORY"], [5719, 5737, "TRAINED_CATEGORY"], [5739, 5744, "TRAINED_CATEGORY"], [5771, 5797, "TRAINED_CATEGORY"], [5800, 5814, "TRAINED_CATEGORY"], [5837, 5851, "TRAINED_CATEGORY"], [5855, 5871, "TRAINED_CATEGORY"], [5875, 5887, "TRAINED_CATEGORY"], [5908, 5912, "TRAINED_CATEGORY"], [5918, 5925, "TRAINED_CATEGORY"], [5929, 5942, "TRAINED_CATEGORY"], [5954, 5967, "TRAINED_CATEGORY"], [5971, 5985, "TRAINED_CATEGORY"], [6011, 6027, "TRAINED_CATEGORY"], [6038, 6050, "TRAINED_CATEGORY"], [6061, 6073, "TRAINED_CATEGORY"], [6088, 6103, "TRAINED_CATEGORY"], [6106, 6120, "TRAINED_CATEGORY"], [6137, 6152, "TRAINED_CATEGORY"], [6156, 6167, "TRAINED_CATEGORY"], [6198, 6215, "TRAINED_CATEGORY"], [6217, 6234, "TRAINED_CATEGORY"], [6236, 6254, "TRAINED_CATEGORY"], [6259, 6278, "TRAINED_CATEGORY"], [6280, 6306, "TRAINED_CATEGORY"], [6327, 6347, "TRAINED_CATEGORY"], [6364, 6370, "TRAINED_CATEGORY"], [6375, 6384, "TRAINED_CATEGORY"], [6405, 6420, "TRAINED_CATEGORY"], [6425, 6434, "TRAINED_CATEGORY"], [6438, 6443, "TRAINED_CATEGORY"], [6459, 6475, "TRAINED_CATEGORY"], [6486, 6516, "TRAINED_CATEGORY"], [6520, 6548, "TRAINED_CATEGORY"], [6560, 6564, "TRAINED_CATEGORY"], [6582, 6589, "TRAINED_CATEGORY"], [6591, 6606, "TRAINED_CATEGORY"], [6610, 6619, "TRAINED_CATEGORY"], [6623, 6635, "TRAINED_CATEGORY"], [6639, 6651, "TRAINED_CATEGORY"], [6655, 6664, "TRAINED_CATEGORY"], [6666, 6675, "TRAINED_CATEGORY"], [6702, 6710, "TRAINED_CATEGORY"], [6770, 6775, "TRAINED_CATEGORY"], [6777, 6780, "TRAINED_CATEGORY"], [6782, 6785, "TRAINED_CATEGORY"], [6791, 6794, "TRAINED_CATEGORY"], [6822, 6831, "TRAINED_CATEGORY"], [6881, 6920, "TRAINED_CATEGORY"], [6925, 6936, "TRAINED_CATEGORY"], [6937, 6959, "TRAINED_CATEGORY"], [6989, 7006, "TRAINED_CATEGORY"], [7011, 7016, "TRAINED_CATEGORY"], [7030, 7053, "TRAINED_CATEGORY"], [7077, 7095, "TRAINED_CATEGORY"], [7099, 7106, "TRAINED_CATEGORY"], [7108, 7116, "TRAINED_CATEGORY"], [7125, 7132, "TRAINED_CATEGORY"], [7143, 7146, "TRAINED_CATEGORY"], [7170, 7177, "TRAINED_CATEGORY"], [7183, 7188, "TRAINED_CATEGORY"], [7199, 7202, "TRAINED_CATEGORY"], [7207, 7210, "TRAINED_CATEGORY"], [7227, 7234, "TRAINED_CATEGORY"], [7240, 7251, "TRAINED_CATEGORY"], [7252, 7274, "TRAINED_CATEGORY"], [7312, 7326, "TRAINED_CATEGORY"], [7346, 7356, "TRAINED_CATEGORY"], [7357, 7371, "TRAINED_CATEGORY"], [7389, 7397, "TRAINED_CATEGORY"], [7406, 7420, "TRAINED_CATEGORY"], [7422, 7428, "TRAINED_CATEGORY"], [7434, 7438, "TRAINED_CATEGORY"], [7444, 7451, "TRAINED_CATEGORY"], [7453, 7463, "TRAINED_CATEGORY"], [7467, 7472, "TRAINED_CATEGORY"], [7480, 7490, "TRAINED_CATEGORY"], [7494, 7501, "TRAINED_CATEGORY"], [7505, 7512, "TRAINED_CATEGORY"], [7569, 7573, "TRAINED_CATEGORY"], [7578, 7582, "TRAINED_CATEGORY"], [7601, 7623, "TRAINED_CATEGORY"], [7627, 7640, "TRAINED_CATEGORY"], [7659, 7663, "TRAINED_CATEGORY"], [7694, 7698, "TRAINED_CATEGORY"], [7703, 7720, "TRAINED_CATEGORY"], [7722, 7733, "TRAINED_CATEGORY"], [7741, 7746, "TRAINED_CATEGORY"], [7750, 7762, "TRAINED_CATEGORY"], [7805, 7827, "TRAINED_CATEGORY"], [7835, 7856, "TRAINED_CATEGORY"], [7858, 7863, "TRAINED_CATEGORY"], [7869, 7874, "TRAINED_CATEGORY"], [7876, 7922, "TRAINED_CATEGORY"], [7927, 7943, "TRAINED_CATEGORY"], [7947, 7951, "TRAINED_CATEGORY"], [7984, 7993, "TRAINED_CATEGORY"], [7995, 8007, "TRAINED_CATEGORY"], [8008, 8017, "TRAINED_CATEGORY"], [8021, 8065, "TRAINED_CATEGORY"], [8082, 8103, "TRAINED_CATEGORY"], [8105, 8121, "TRAINED_CATEGORY"], [8130, 8149, "TRAINED_CATEGORY"], [8154, 8161, "TRAINED_CATEGORY"], [8165, 8177, "TRAINED_CATEGORY"], [8187, 8201, "TRAINED_CATEGORY"], [8204, 8217, "TRAINED_CATEGORY"], [8227, 8237, "TRAINED_CATEGORY"], [8239, 8255, "TRAINED_CATEGORY"], [8274, 8299, "TRAINED_CATEGORY"], [8315, 8326, "TRAINED_CATEGORY"], [8328, 8341, "TRAINED_CATEGORY"], [8351, 8375, "TRAINED_CATEGORY"], [8379, 8392, "TRAINED_CATEGORY"], [8396, 8405, "TRAINED_CATEGORY"], [8410, 8418, "TRAINED_CATEGORY"], [8420, 8424, "TRAINED_CATEGORY"], [8431, 8451, "TRAINED_CATEGORY"], [8455, 8462, "TRAINED_CATEGORY"], [8467, 8481, "TRAINED_CATEGORY"], [8501, 8512, "TRAINED_CATEGORY"], [8526, 8536, "TRAINED_CATEGORY"], [8540, 8555, "TRAINED_CATEGORY"], [8557, 8572, "TRAINED_CATEGORY"], [8590, 8594, "TRAINED_CATEGORY"], [8607, 8621, "TRAINED_CATEGORY"], [8623, 8640, "TRAINED_CATEGORY"], [8676, 8705, "TRAINED_CATEGORY"], [8725, 8737, "TRAINED_CATEGORY"], [8747, 8763, "TRAINED_CATEGORY"], [8767, 8773, "TRAINED_CATEGORY"], [8836, 8843, "TRAINED_CATEGORY"], [8845, 8855, "TRAINED_CATEGORY"], [8859, 8864, "TRAINED_CATEGORY"], [8866, 8888, "TRAINED_CATEGORY"], [8896, 8913, "TRAINED_CATEGORY"], [8915, 8940, "TRAINED_CATEGORY"], [8945, 8952, "TRAINED_CATEGORY"], [8965, 8969, "TRAINED_CATEGORY"], [8978, 8982, "TRAINED_CATEGORY"], [8995, 8999, "TRAINED_CATEGORY"], [9010, 9029, "TRAINED_CATEGORY"], [9037, 9059, "TRAINED_CATEGORY"], [9061, 9082, "TRAINED_CATEGORY"], [9086, 9109, "TRAINED_CATEGORY"], [9113, 9121, "TRAINED_CATEGORY"], [9123, 9125, "TRAINED_CATEGORY"], [9146, 9169, "TRAINED_CATEGORY"], [9171, 9183, "TRAINED_CATEGORY"], [9192, 9208, "TRAINED_CATEGORY"], [9210, 9235, "TRAINED_CATEGORY"], [9253, 9272, "TRAINED_CATEGORY"], [9276, 9291, "TRAINED_CATEGORY"], [9292, 9305, "TRAINED_CATEGORY"], [9309, 9314, "TRAINED_CATEGORY"], [9323, 9341, "TRAINED_CATEGORY"], [9342, 9361, "TRAINED_CATEGORY"], [9362, 9372, "TRAINED_CATEGORY"], [9410, 9428, "TRAINED_CATEGORY"], [9464, 9491, "TRAINED_CATEGORY"], [9510, 9523, "TRAINED_CATEGORY"], [9543, 9560, "TRAINED_CATEGORY"], [9586, 9605, "TRAINED_CATEGORY"], [9607, 9631, "TRAINED_CATEGORY"], [9642, 9657, "TRAINED_CATEGORY"], [9666, 9674, "TRAINED_CATEGORY"], [9680, 9688, "TRAINED_CATEGORY"], [9692, 9711, "TRAINED_CATEGORY"], [9721, 9726, "TRAINED_CATEGORY"], [9731, 9747, "TRAINED_CATEGORY"], [9749, 9776, "TRAINED_CATEGORY"], [9778, 9791, "TRAINED_CATEGORY"], [9793, 9820, "TRAINED_CATEGORY"], [9822, 9829, "TRAINED_CATEGORY"], [9831, 9834, "TRAINED_CATEGORY"], [9836, 9841, "TRAINED_CATEGORY"], [9847, 9853, "TRAINED_CATEGORY"], [9861, 9876, "TRAINED_CATEGORY"], [9877, 9883, "TRAINED_CATEGORY"], [9889, 9894, "TRAINED_CATEGORY"], [9915, 9935, "TRAINED_CATEGORY"], [9957, 9972, "TRAINED_CATEGORY"], [9974, 9987, "TRAINED_CATEGORY"], [9992, 10012, "TRAINED_CATEGORY"], [10027, 10044, "TRAINED_CATEGORY"], [10049, 10059, "TRAINED_CATEGORY"], [10080, 10106, "TRAINED_CATEGORY"], [10108, 10110, "TRAINED_CATEGORY"], [10122, 10149, "TRAINED_CATEGORY"], [10151, 10167, "TRAINED_CATEGORY"], [10191, 10199, "TRAINED_CATEGORY"], [10210, 10233, "TRAINED_CATEGORY"], [10242, 10256, "TRAINED_CATEGORY"], [10260, 10286, "TRAINED_CATEGORY"], [10291, 10297, "TRAINED_CATEGORY"], [10298, 10311, "TRAINED_CATEGORY"], [10316, 10323, "TRAINED_CATEGORY"], [10325, 10336, "TRAINED_CATEGORY"], [10340, 10347, "TRAINED_CATEGORY"], [10352, 10358, "TRAINED_CATEGORY"], [10383, 10399, "TRAINED_CATEGORY"], [10403, 10420, "TRAINED_CATEGORY"], [10422, 10433, "TRAINED_CATEGORY"], [10445, 10470, "TRAINED_CATEGORY"], [10488, 10497, "TRAINED_CATEGORY"], [10501, 10533, "TRAINED_CATEGORY"], [10538, 10548, "TRAINED_CATEGORY"], [10552, 10557, "TRAINED_CATEGORY"], [10572, 10580, "TRAINED_CATEGORY"], [10600, 10612, "TRAINED_CATEGORY"], [10614, 10625, "TRAINED_CATEGORY"], [10634, 10645, "TRAINED_CATEGORY"], [10653, 10665, "TRAINED_CATEGORY"], [10674, 10689, "TRAINED_CATEGORY"], [10708, 10720, "TRAINED_CATEGORY"], [10724, 10730, "TRAINED_CATEGORY"], [10733, 10738, "TRAINED_CATEGORY"], [10748, 10759, "TRAINED_CATEGORY"], [10777, 10793, "TRAINED_CATEGORY"], [10797, 10803, "TRAINED_CATEGORY"], [10807, 10819, "TRAINED_CATEGORY"], [10827, 10832, "TRAINED_CATEGORY"], [10838, 10866, "TRAINED_CATEGORY"], [10878, 10890, "TRAINED_CATEGORY"], [10922, 10931, "TRAINED_CATEGORY"], [10934, 10944, "TRAINED_CATEGORY"], [10968, 10972, "TRAINED_CATEGORY"], [10999, 11015, "TRAINED_CATEGORY"], [11029, 11034, "TRAINED_CATEGORY"], [11059, 11077, "TRAINED_CATEGORY"], [11081, 11089, "TRAINED_CATEGORY"], [11107, 11109, "TRAINED_CATEGORY"], [11113, 11123, "TRAINED_CATEGORY"], [11125, 11134, "TRAINED_CATEGORY"], [11138, 11150, "TRAINED_CATEGORY"], [11175, 11187, "TRAINED_CATEGORY"], [11196, 11206, "TRAINED_CATEGORY"], [11210, 11215, "TRAINED_CATEGORY"], [11221, 11226, "TRAINED_CATEGORY"], [11273, 11291, "TRAINED_CATEGORY"], [11293, 11310, "TRAINED_CATEGORY"], [11316, 11326, "TRAINED_CATEGORY"], [11332, 11353, "TRAINED_CATEGORY"], [11354, 11369, "TRAINED_CATEGORY"], [11373, 11380, "TRAINED_CATEGORY"], [11388, 11397, "TRAINED_CATEGORY"], [11401, 11419, "TRAINED_CATEGORY"], [11435, 11446, "TRAINED_CATEGORY"], [11460, 11471, "TRAINED_CATEGORY"], [11503, 11528, "TRAINED_CATEGORY"], [11530, 11540, "TRAINED_CATEGORY"], [11578, 11603, "TRAINED_CATEGORY"], [11605, 11613, "TRAINED_CATEGORY"], [11628, 11658, "TRAINED_CATEGORY"], [11682, 11704, "TRAINED_CATEGORY"], [11706, 11714, "TRAINED_CATEGORY"], [11735, 11747, "TRAINED_CATEGORY"], [11750, 11761, "TRAINED_CATEGORY"], [11785, 11807, "TRAINED_CATEGORY"], [11839, 11850, "TRAINED_CATEGORY"], [11871, 11887, "TRAINED_CATEGORY"], [11902, 11916, "TRAINED_CATEGORY"], [11932, 11948, "TRAINED_CATEGORY"], [11954, 11981, "TRAINED_CATEGORY"], [11983, 11985, "TRAINED_CATEGORY"], [12020, 12024, "TRAINED_CATEGORY"], [12059, 12085, "TRAINED_CATEGORY"], [12087, 12105, "TRAINED_CATEGORY"], [12119, 12150, "TRAINED_CATEGORY"], [12159, 12177, "TRAINED_CATEGORY"], [12187, 12204, "TRAINED_CATEGORY"], [12231, 12246, "TRAINED_CATEGORY"], [12260, 12267, "TRAINED_CATEGORY"], [12272, 12284, "TRAINED_CATEGORY"], [12288, 12293, "TRAINED_CATEGORY"], [12297, 12302, "TRAINED_CATEGORY"], [12303, 12320, "TRAINED_CATEGORY"], [12330, 12343, "TRAINED_CATEGORY"], [12347, 12352, "TRAINED_CATEGORY"], [12367, 12378, "TRAINED_CATEGORY"], [12382, 12394, "TRAINED_CATEGORY"], [12400, 12411, "TRAINED_CATEGORY"], [12417, 12435, "TRAINED_CATEGORY"], [12441, 12452, "TRAINED_CATEGORY"], [12467, 12481, "TRAINED_CATEGORY"], [12494, 12511, "TRAINED_CATEGORY"], [12513, 12524, "TRAINED_CATEGORY"], [12528, 12544, "TRAINED_CATEGORY"], [12564, 12579, "TRAINED_CATEGORY"], [12582, 12597, "TRAINED_CATEGORY"], [12615, 12624, "TRAINED_CATEGORY"], [12638, 12665, "TRAINED_CATEGORY"], [12670, 12679, "TRAINED_CATEGORY"], [12697, 12705, "TRAINED_CATEGORY"], [12718, 12734, "TRAINED_CATEGORY"], [12747, 12768, "TRAINED_CATEGORY"], [12790, 12816, "TRAINED_CATEGORY"], [12875, 12902, "TRAINED_CATEGORY"], [12912, 12914, "TRAINED_CATEGORY"], [12948, 12964, "TRAINED_CATEGORY"], [12969, 12985, "TRAINED_CATEGORY"], [12989, 13010, "TRAINED_CATEGORY"], [13012, 13017, "TRAINED_CATEGORY"], [13028, 13056, "TRAINED_CATEGORY"], [13097, 13123, "TRAINED_CATEGORY"], [13136, 13147, "TRAINED_CATEGORY"], [13175, 13204, "TRAINED_CATEGORY"], [13217, 13235, "TRAINED_CATEGORY"], [13241, 13250, "TRAINED_CATEGORY"], [13254, 13273, "TRAINED_CATEGORY"], [13277, 13289, "TRAINED_CATEGORY"], [13298, 13302, "TRAINED_CATEGORY"], [13307, 13323, "TRAINED_CATEGORY"], [13325, 13339, "TRAINED_CATEGORY"], [13352, 13377, "TRAINED_CATEGORY"], [13380, 13402, "TRAINED_CATEGORY"], [13416, 13428, "TRAINED_CATEGORY"], [13432, 13447, "TRAINED_CATEGORY"], [13455, 13466, "TRAINED_CATEGORY"], [13475, 13478, "TRAINED_CATEGORY"], [13490, 13506, "TRAINED_CATEGORY"], [13508, 13512, "TRAINED_CATEGORY"], [13535, 13544, "TRAINED_CATEGORY"], [13557, 13569, "TRAINED_CATEGORY"], [13602, 13605, "TRAINED_CATEGORY"], [13607, 13615, "TRAINED_CATEGORY"], [13619, 13630, "TRAINED_CATEGORY"], [13639, 13648, "TRAINED_CATEGORY"], [13650, 13661, "TRAINED_CATEGORY"], [13663, 13682, "TRAINED_CATEGORY"], [13687, 13702, "TRAINED_CATEGORY"], [13711, 13722, "TRAINED_CATEGORY"], [13726, 13731, "TRAINED_CATEGORY"], [13740, 13763, "TRAINED_CATEGORY"], [13812, 13830, "TRAINED_CATEGORY"], [13851, 13875, "TRAINED_CATEGORY"], [13890, 13895, "TRAINED_CATEGORY"], [13897, 13912, "TRAINED_CATEGORY"], [13914, 13944, "TRAINED_CATEGORY"], [13952, 13975, "TRAINED_CATEGORY"], [13997, 14004, "TRAINED_CATEGORY"], [14065, 14077, "TRAINED_CATEGORY"], [14078, 14096, "TRAINED_CATEGORY"], [14114, 14119, "TRAINED_CATEGORY"], [14130, 14142, "TRAINED_CATEGORY"], [14159, 14172, "TRAINED_CATEGORY"], [14191, 14201, "TRAINED_CATEGORY"], [14212, 14220, "TRAINED_CATEGORY"], [14224, 14237, "TRAINED_CATEGORY"], [14262, 14269, "TRAINED_CATEGORY"], [14288, 14299, "TRAINED_CATEGORY"], [14302, 14312, "TRAINED_CATEGORY"], [14324, 14335, "TRAINED_CATEGORY"], [14341, 14359, "TRAINED_CATEGORY"], [14365, 14376, "TRAINED_CATEGORY"], [14384, 14396, "TRAINED_CATEGORY"], [14399, 14406, "TRAINED_CATEGORY"], [14412, 14422, "TRAINED_CATEGORY"], [14443, 14468, "TRAINED_CATEGORY"], [14472, 14488, "TRAINED_CATEGORY"], [14504, 14514, "TRAINED_CATEGORY"], [14521, 14531, "TRAINED_CATEGORY"], [14535, 14544, "TRAINED_CATEGORY"], [14563, 14569, "TRAINED_CATEGORY"], [14573, 14583, "TRAINED_CATEGORY"], [14588, 14596, "TRAINED_CATEGORY"], [14600, 14612, "TRAINED_CATEGORY"], [14614, 14624, "TRAINED_CATEGORY"], [14640, 14650, "TRAINED_CATEGORY"], [14666, 14682, "TRAINED_CATEGORY"], [14686, 14694, "TRAINED_CATEGORY"], [14718, 14726, "TRAINED_CATEGORY"], [14730, 14741, "TRAINED_CATEGORY"], [14747, 14761, "TRAINED_CATEGORY"], [14769, 14774, "TRAINED_CATEGORY"], [14783, 14787, "TRAINED_CATEGORY"], [14805, 14840, "TRAINED_CATEGORY"], [14841, 14853, "TRAINED_CATEGORY"], [14900, 14908, "TRAINED_CATEGORY"], [14911, 14935, "TRAINED_CATEGORY"], [14939, 14950, "TRAINED_CATEGORY"], [14963, 14987, "TRAINED_CATEGORY"], [15001, 15012, "TRAINED_CATEGORY"], [15023, 15034, "TRAINED_CATEGORY"], [15038, 15046, "TRAINED_CATEGORY"], [15059, 15067, "TRAINED_CATEGORY"], [15089, 15111, "TRAINED_CATEGORY"], [15119, 15130, "TRAINED_CATEGORY"], [15131, 15137, "TRAINED_CATEGORY"], [15143, 15168, "TRAINED_CATEGORY"], [15177, 15196, "TRAINED_CATEGORY"], [15201, 15223, "TRAINED_CATEGORY"], [15241, 15267, "TRAINED_CATEGORY"], [15276, 15290, "TRAINED_CATEGORY"], [15293, 15308, "TRAINED_CATEGORY"], [15323, 15341, "TRAINED_CATEGORY"], [15352, 15365, "TRAINED_CATEGORY"], [15369, 15377, "TRAINED_CATEGORY"], [15396, 15401, "TRAINED_CATEGORY"], [15423, 15428, "TRAINED_CATEGORY"], [15439, 15457, "TRAINED_CATEGORY"], [15465, 15477, "TRAINED_CATEGORY"], [15484, 15488, "TRAINED_CATEGORY"], [15501, 15513, "TRAINED_CATEGORY"], [15528, 15538, "TRAINED_CATEGORY"], [15551, 15555, "TRAINED_CATEGORY"], [15564, 15598, "TRAINED_CATEGORY"], [15604, 15611, "TRAINED_CATEGORY"], [15617, 15629, "TRAINED_CATEGORY"], [15631, 15647, "TRAINED_CATEGORY"], [15657, 15674, "TRAINED_CATEGORY"], [15683, 15704, "TRAINED_CATEGORY"], [15708, 15721, "TRAINED_CATEGORY"], [15731, 15750, "TRAINED_CATEGORY"], [15755, 15776, "TRAINED_CATEGORY"], [15780, 15802, "TRAINED_CATEGORY"], [15806, 15842, "TRAINED_CATEGORY"], [15844, 15849, "TRAINED_CATEGORY"], [15860, 15876, "TRAINED_CATEGORY"], [15880, 15885, "TRAINED_CATEGORY"], [15890, 15895, "TRAINED_CATEGORY"], [15909, 15925, "TRAINED_CATEGORY"], [15929, 15944, "TRAINED_CATEGORY"], [15946, 15957, "TRAINED_CATEGORY"], [15970, 15995, "TRAINED_CATEGORY"], [16000, 16023, "TRAINED_CATEGORY"], [16032, 16053, "TRAINED_CATEGORY"], [16062, 16097, "TRAINED_CATEGORY"], [16101, 16106, "TRAINED_CATEGORY"], [16111, 16133, "TRAINED_CATEGORY"], [16139, 16152, "TRAINED_CATEGORY"], [16156, 16161, "TRAINED_CATEGORY"], [16174, 16178, "TRAINED_CATEGORY"], [16182, 16197, "TRAINED_CATEGORY"], [16206, 16229, "TRAINED_CATEGORY"], [16238, 16247, "TRAINED_CATEGORY"], [16261, 16271, "TRAINED_CATEGORY"], [16275, 16279, "TRAINED_CATEGORY"], [16325, 16339, "TRAINED_CATEGORY"], [16344, 16349, "TRAINED_CATEGORY"], [16354, 16376, "TRAINED_CATEGORY"], [16382, 16392, "TRAINED_CATEGORY"], [16396, 16401, "TRAINED_CATEGORY"], [16413, 16415, "TRAINED_CATEGORY"], [16426, 16436, "TRAINED_CATEGORY"], [16440, 16445, "TRAINED_CATEGORY"], [16450, 16456, "TRAINED_CATEGORY"], [16460, 16465, "TRAINED_CATEGORY"], [16478, 16486, "TRAINED_CATEGORY"], [16495, 16509, "TRAINED_CATEGORY"], [16525, 16552, "TRAINED_CATEGORY"], [16561, 16569, "TRAINED_CATEGORY"], [16575, 16592, "TRAINED_CATEGORY"], [16604, 16617, "TRAINED_CATEGORY"], [16622, 16627, "TRAINED_CATEGORY"], [16633, 16647, "TRAINED_CATEGORY"], [16673, 16698, "TRAINED_CATEGORY"], [16707, 16734, "TRAINED_CATEGORY"], [16736, 16763, "TRAINED_CATEGORY"], [16765, 16778, "TRAINED_CATEGORY"], [16783, 16804, "TRAINED_CATEGORY"], [16806, 16830, "TRAINED_CATEGORY"], [16840, 16845, "TRAINED_CATEGORY"], [16850, 16866, "TRAINED_CATEGORY"], [16884, 16907, "TRAINED_CATEGORY"], [16911, 16916, "TRAINED_CATEGORY"], [16921, 16943, "TRAINED_CATEGORY"], [16947, 16952, "TRAINED_CATEGORY"], [16958, 16965, "TRAINED_CATEGORY"], [16967, 16981, "TRAINED_CATEGORY"], [16992, 17005, "TRAINED_CATEGORY"], [17009, 17022, "TRAINED_CATEGORY"], [17026, 17047, "TRAINED_CATEGORY"], [17055, 17067, "TRAINED_CATEGORY"], [17080, 17102, "TRAINED_CATEGORY"], [17104, 17128, "TRAINED_CATEGORY"], [17129, 17146, "TRAINED_CATEGORY"], [17156, 17176, "TRAINED_CATEGORY"], [17183, 17193, "TRAINED_CATEGORY"], [17198, 17207, "TRAINED_CATEGORY"], [17212, 17228, "TRAINED_CATEGORY"], [17248, 17260, "TRAINED_CATEGORY"], [17267, 17280, "TRAINED_CATEGORY"], [17284, 17296, "TRAINED_CATEGORY"], [17305, 17314, "TRAINED_CATEGORY"], [17317, 17343, "TRAINED_CATEGORY"], [17366, 17375, "TRAINED_CATEGORY"], [17377, 17389, "TRAINED_CATEGORY"], [17398, 17410, "TRAINED_CATEGORY"], [17414, 17427, "TRAINED_CATEGORY"], [17442, 17457, "TRAINED_CATEGORY"], [17463, 17488, "TRAINED_CATEGORY"], [17498, 17509, "TRAINED_CATEGORY"], [17513, 17523, "TRAINED_CATEGORY"], [17523, 17547, "TRAINED_CATEGORY"], [17552, 17580, "TRAINED_CATEGORY"], [17582, 17587, "TRAINED_CATEGORY"], [17607, 17625, "TRAINED_CATEGORY"], [17633, 17653, "TRAINED_CATEGORY"], [17658, 17679, "TRAINED_CATEGORY"], [17681, 17686, "TRAINED_CATEGORY"], [17698, 17716, "TRAINED_CATEGORY"], [17729, 17734, "TRAINED_CATEGORY"], [17743, 17766, "TRAINED_CATEGORY"], [17786, 17808, "TRAINED_CATEGORY"], [17810, 17815, "TRAINED_CATEGORY"], [17853, 17880, "TRAINED_CATEGORY"], [17922, 17924, "TRAINED_CATEGORY"], [17949, 17972, "TRAINED_CATEGORY"], [18014, 18019, "TRAINED_CATEGORY"], [18035, 18047, "TRAINED_CATEGORY"], [18059, 18071, "TRAINED_CATEGORY"], [18073, 18075, "TRAINED_CATEGORY"], [18080, 18096, "TRAINED_CATEGORY"], [18100, 18125, "TRAINED_CATEGORY"], [18126, 18128, "TRAINED_CATEGORY"], [18138, 18143, "TRAINED_CATEGORY"], [18172, 18177, "TRAINED_CATEGORY"], [18182, 18187, "TRAINED_CATEGORY"], [18190, 18192, "TRAINED_CATEGORY"], [18226, 18233, "TRAINED_CATEGORY"], [18250, 18271, "TRAINED_CATEGORY"], [18279, 18290, "TRAINED_CATEGORY"], [18295, 18317, "TRAINED_CATEGORY"], [18352, 18356, "TRAINED_CATEGORY"], [18382, 18390, "TRAINED_CATEGORY"], [18399, 18404, "TRAINED_CATEGORY"], [18407, 18427, "TRAINED_CATEGORY"], [18430, 18449, "TRAINED_CATEGORY"], [18452, 18472, "TRAINED_CATEGORY"], [18476, 18495, "TRAINED_CATEGORY"], [18498, 18525, "TRAINED_CATEGORY"], [18541, 18564, "TRAINED_CATEGORY"], [18566, 18587, "TRAINED_CATEGORY"], [18597, 18615, "TRAINED_CATEGORY"], [18660, 18674, "TRAINED_CATEGORY"], [18705, 18718, "TRAINED_CATEGORY"], [18729, 18760, "TRAINED_CATEGORY"], [18795, 18837, "TRAINED_CATEGORY"], [18844, 18871, "TRAINED_CATEGORY"], [18878, 18882, "TRAINED_CATEGORY"], [18887, 18902, "TRAINED_CATEGORY"], [18913, 18933, "TRAINED_CATEGORY"], [18945, 18948, "TRAINED_CATEGORY"], [18952, 18979, "TRAINED_CATEGORY"], [19009, 19013, "TRAINED_CATEGORY"], [19015, 19019, "TRAINED_CATEGORY"], [19024, 19029, "TRAINED_CATEGORY"], [19041, 19060, "TRAINED_CATEGORY"], [19064, 19078, "TRAINED_CATEGORY"], [19083, 19094, "TRAINED_CATEGORY"], [19096, 19123, "TRAINED_CATEGORY"], [19128, 19134, "TRAINED_CATEGORY"], [19139, 19157, "TRAINED_CATEGORY"], [19163, 19172, "TRAINED_CATEGORY"], [19211, 19233, "TRAINED_CATEGORY"], [19235, 19255, "TRAINED_CATEGORY"], [19258, 19269, "TRAINED_CATEGORY"], [19274, 19280, "TRAINED_CATEGORY"], [19291, 19293, "TRAINED_CATEGORY"], [19303, 19312, "TRAINED_CATEGORY"], [19317, 19325, "TRAINED_CATEGORY"], [19336, 19343, "TRAINED_CATEGORY"], [19348, 19370, "TRAINED_CATEGORY"], [19402, 19418, "TRAINED_CATEGORY"], [19441, 19444, "TRAINED_CATEGORY"], [19448, 19464, "TRAINED_CATEGORY"], [19466, 19469, "TRAINED_CATEGORY"], [19477, 19498, "TRAINED_CATEGORY"], [19506, 19525, "TRAINED_CATEGORY"], [19547, 19562, "TRAINED_CATEGORY"], [19568, 19577, "TRAINED_CATEGORY"], [19578, 19582, "TRAINED_CATEGORY"], [19589, 19597, "TRAINED_CATEGORY"], [19607, 19614, "TRAINED_CATEGORY"], [19619, 19636, "TRAINED_CATEGORY"], [19652, 19664, "TRAINED_CATEGORY"], [19669, 19676, "TRAINED_CATEGORY"], [19722, 19728, "TRAINED_CATEGORY"], [19742, 19763, "TRAINED_CATEGORY"], [19775, 19783, "TRAINED_CATEGORY"], [19815, 19817, "TRAINED_CATEGORY"], [19832, 19845, "TRAINED_CATEGORY"], [19847, 19850, "TRAINED_CATEGORY"], [19874, 19884, "TRAINED_CATEGORY"], [19888, 19911, "TRAINED_CATEGORY"], [19914, 19926, "TRAINED_CATEGORY"], [19941, 19970, "TRAINED_CATEGORY"], [19977, 19981, "TRAINED_CATEGORY"], [19996, 20017, "TRAINED_CATEGORY"], [20018, 20043, "TRAINED_CATEGORY"], [20069, 20075, "TRAINED_CATEGORY"], [20081, 20087, "TRAINED_CATEGORY"], [20091, 20105, "TRAINED_CATEGORY"], [20108, 20119, "TRAINED_CATEGORY"], [20133, 20153, "TRAINED_CATEGORY"], [20155, 20162, "TRAINED_CATEGORY"], [20183, 20191, "TRAINED_CATEGORY"], [20193, 20212, "TRAINED_CATEGORY"], [20216, 20244, "TRAINED_CATEGORY"], [20263, 20278, "TRAINED_CATEGORY"], [20282, 20289, "TRAINED_CATEGORY"], [20301, 20325, "TRAINED_CATEGORY"], [20335, 20348, "TRAINED_CATEGORY"], [20362, 20366, "TRAINED_CATEGORY"], [20379, 20384, "TRAINED_CATEGORY"], [20386, 20388, "TRAINED_CATEGORY"], [20399, 20410, "TRAINED_CATEGORY"], [20412, 20423, "TRAINED_CATEGORY"], [20436, 20449, "TRAINED_CATEGORY"], [20453, 20463, "TRAINED_CATEGORY"], [20469, 20475, "TRAINED_CATEGORY"], [20479, 20498, "TRAINED_CATEGORY"], [20510, 20516, "TRAINED_CATEGORY"], [20527, 20536, "TRAINED_CATEGORY"], [20546, 20567, "TRAINED_CATEGORY"], [20571, 20598, "TRAINED_CATEGORY"], [20612, 20625, "TRAINED_CATEGORY"], [20629, 20644, "TRAINED_CATEGORY"], [20655, 20657, "TRAINED_CATEGORY"], [20663, 20673, "TRAINED_CATEGORY"], [20681, 20699, "TRAINED_CATEGORY"], [20710, 20722, "TRAINED_CATEGORY"], [20727, 20739, "TRAINED_CATEGORY"], [20748, 20773, "TRAINED_CATEGORY"], [20779, 20784, "TRAINED_CATEGORY"], [20786, 20801, "TRAINED_CATEGORY"], [20803, 20806, "TRAINED_CATEGORY"], [20807, 20822, "TRAINED_CATEGORY"], [20829, 20841, "TRAINED_CATEGORY"], [20850, 20878, "TRAINED_CATEGORY"], [20885, 20890, "TRAINED_CATEGORY"], [20898, 20908, "TRAINED_CATEGORY"], [20913, 20921, "TRAINED_CATEGORY"], [20925, 20933, "TRAINED_CATEGORY"], [20935, 20950, "TRAINED_CATEGORY"], [20963, 20970, "TRAINED_CATEGORY"], [20976, 20983, "TRAINED_CATEGORY"], [20995, 21003, "TRAINED_CATEGORY"], [21011, 21017, "TRAINED_CATEGORY"], [21034, 21042, "TRAINED_CATEGORY"], [21046, 21059, "TRAINED_CATEGORY"], [21063, 21074, "TRAINED_CATEGORY"], [21076, 21081, "TRAINED_CATEGORY"], [21096, 21113, "TRAINED_CATEGORY"], [21119, 21132, "TRAINED_CATEGORY"], [21148, 21166, "TRAINED_CATEGORY"], [21168, 21175, "TRAINED_CATEGORY"], [21191, 21200, "TRAINED_CATEGORY"], [21204, 21221, "TRAINED_CATEGORY"], [21230, 21237, "TRAINED_CATEGORY"], [21239, 21254, "TRAINED_CATEGORY"], [21256, 21264, "TRAINED_CATEGORY"], [21326, 21343, "TRAINED_CATEGORY"], [21347, 21354, "TRAINED_CATEGORY"], [21366, 21390, "TRAINED_CATEGORY"], [21394, 21408, "TRAINED_CATEGORY"], [21412, 21430, "TRAINED_CATEGORY"], [21438, 21454, "TRAINED_CATEGORY"], [21468, 21474, "TRAINED_CATEGORY"], [21478, 21494, "TRAINED_CATEGORY"], [21509, 21516, "TRAINED_CATEGORY"], [21520, 21528, "TRAINED_CATEGORY"], [21532, 21542, "TRAINED_CATEGORY"], [21550, 21561, "TRAINED_CATEGORY"], [21566, 21586, "TRAINED_CATEGORY"], [21590, 21616, "TRAINED_CATEGORY"], [21628, 21632, "TRAINED_CATEGORY"], [21634, 21636, "TRAINED_CATEGORY"], [21646, 21668, "TRAINED_CATEGORY"], [21670, 21677, "TRAINED_CATEGORY"], [21682, 21690, "TRAINED_CATEGORY"], [21695, 21730, "TRAINED_CATEGORY"], [21732, 21737, "TRAINED_CATEGORY"], [21738, 21761, "TRAINED_CATEGORY"], [21766, 21810, "TRAINED_CATEGORY"], [21815, 21827, "TRAINED_CATEGORY"], [21844, 21849, "TRAINED_CATEGORY"], [21853, 21863, "TRAINED_CATEGORY"], [21867, 21888, "TRAINED_CATEGORY"], [21890, 21902, "TRAINED_CATEGORY"], [21906, 21930, "TRAINED_CATEGORY"], [21935, 21947, "TRAINED_CATEGORY"], [21972, 21976, "TRAINED_CATEGORY"], [21978, 21983, "TRAINED_CATEGORY"], [21985, 21996, "TRAINED_CATEGORY"], [22001, 22056, "TRAINED_CATEGORY"], [22060, 22078, "TRAINED_CATEGORY"], [22082, 22113, "TRAINED_CATEGORY"], [22119, 22133, "TRAINED_CATEGORY"], [22135, 22147, "TRAINED_CATEGORY"], [22172, 22180, "TRAINED_CATEGORY"], [22182, 22186, "TRAINED_CATEGORY"], [22188, 22193, "TRAINED_CATEGORY"], [22198, 22207, "TRAINED_CATEGORY"], [22219, 22247, "TRAINED_CATEGORY"], [22253, 22264, "TRAINED_CATEGORY"], [22266, 22268, "TRAINED_CATEGORY"], [22280, 22284, "TRAINED_CATEGORY"], [22290, 22310, "TRAINED_CATEGORY"], [22320, 22326, "TRAINED_CATEGORY"], [22331, 22341, "TRAINED_CATEGORY"], [22354, 22368, "TRAINED_CATEGORY"], [22378, 22383, "TRAINED_CATEGORY"], [22386, 22391, "TRAINED_CATEGORY"], [22444, 22454, "TRAINED_CATEGORY"], [22458, 22470, "TRAINED_CATEGORY"], [22471, 22487, "TRAINED_CATEGORY"], [22488, 22513, "TRAINED_CATEGORY"], [22519, 22531, "TRAINED_CATEGORY"], [22533, 22548, "TRAINED_CATEGORY"], [22550, 22558, "TRAINED_CATEGORY"], [22567, 22583, "TRAINED_CATEGORY"], [22588, 22594, "TRAINED_CATEGORY"], [22595, 22626, "TRAINED_CATEGORY"], [22627, 22639, "TRAINED_CATEGORY"], [22649, 22663, "TRAINED_CATEGORY"], [22674, 22710, "TRAINED_CATEGORY"], [22712, 22723, "TRAINED_CATEGORY"], [22725, 22735, "TRAINED_CATEGORY"], [22738, 22742, "TRAINED_CATEGORY"], [22744, 22775, "TRAINED_CATEGORY"], [22780, 22793, "TRAINED_CATEGORY"], [22794, 22798, "TRAINED_CATEGORY"], [22810, 22823, "TRAINED_CATEGORY"], [22827, 22843, "TRAINED_CATEGORY"], [22845, 22852, "TRAINED_CATEGORY"], [22863, 22867, "TRAINED_CATEGORY"], [22892, 22902, "TRAINED_CATEGORY"], [22912, 22921, "TRAINED_CATEGORY"], [22932, 22939, "TRAINED_CATEGORY"], [33, 37, "ORG"], [97, 100, "ORG"], [132, 136, "ORG"], [297, 301, "ORG"], [402, 405, "ORG"], [535, 539, "ORG"], [746, 750, "ORG"], [763, 768, "CARDINAL"], [946, 949, "CARDINAL"], [1371, 1375, "ORG"], [1601, 1610, "PERSON"], [1626, 1630, "ORG"], [1843, 1847, "ORG"], [2095, 2099, "ORG"], [2139, 2143, "PERSON"], [2220, 2228, "ORG"], [2232, 2236, "ORG"], [2267, 2271, "ORG"], [2285, 2289, "ORG"], [2586, 2590, "ORG"], [2624, 2629, "NORP"], [3261, 3270, "ORG"], [3515, 3519, "DATE"], [3739, 3743, "DATE"], [4549, 4553, "ORG"], [4570, 4580, "ORG"], [4693, 4697, "ORG"], [4871, 4875, "ORG"], [4907, 4918, "PERCENT"], [5017, 5021, "ORG"], [6038, 6042, "ORG"], [6106, 6110, "ORG"], [6124, 6135, "ORG"], [6269, 6278, "ORG"], [6338, 6342, "ORG"], [6770, 6775, "ORG"], [6777, 6780, "ORG"], [6782, 6785, "ORG"], [6791, 6794, "ORG"], [7125, 7132, "ORG"], [7183, 7188, "ORG"], [7406, 7420, "ORG"], [7434, 7438, "PERSON"], [7494, 7501, "NORP"], [7569, 7573, "ORG"], [7750, 7754, "ORG"], [7852, 7856, "ORG"], [7858, 7863, "ORG"], [7869, 7874, "PERSON"], [7947, 7951, "ORG"], [7989, 7993, "ORG"], [7995, 8000, "ORG"], [8110, 8115, "PERSON"], [8244, 8249, "PERSON"], [8629, 8634, "ORG"], [8859, 8864, "ORG"], [9309, 9314, "PERSON"], [9328, 9333, "ORG"], [9612, 9617, "ORG"], [9721, 9726, "ORG"], [9731, 9747, "ORG"], [9778, 9791, "ORG"], [9793, 9820, "ORG"], [9822, 9829, "ORG"], [9831, 9834, "ORG"], [9847, 9853, "PRODUCT"], [9861, 9871, "PERSON"], [9878, 9883, "ORG"], [9889, 9894, "LAW"], [10272, 10276, "ORG"], [10407, 10410, "ORG"], [10422, 10427, "ORG"], [10614, 10619, "ORG"], [10733, 10738, "ORG"], [10827, 10832, "ORG"], [10922, 10927, "LAW"], [10968, 10972, "ORG"], [11001, 11006, "ORG"], [11029, 11034, "ORG"], [11196, 11206, "ORG"], [11210, 11215, "ORG"], [11221, 11226, "PRODUCT"], [11361, 11369, "CARDINAL"], [11592, 11597, "PERSON"], [11686, 11689, "ORG"], [11738, 11742, "ORG"], [11750, 11755, "ORG"], [11839, 11844, "ORG"], [12091, 12096, "ORG"], [12304, 12307, "ORG"], [12347, 12352, "PRODUCT"], [12400, 12405, "ORG"], [12441, 12446, "ORG"], [12494, 12499, "ORG"], [12586, 12591, "ORG"], [13012, 13017, "LAW"], [13136, 13141, "ORG"], [13224, 13229, "LAW"], [13277, 13280, "ORG"], [13298, 13302, "ORG"], [13307, 13313, "ORG"], [13325, 13339, "PERSON"], [13358, 13361, "ORG"], [13386, 13389, "ORG"], [13436, 13441, "ORG"], [13455, 13460, "LAW"], [13475, 13478, "ORG"], [13602, 13605, "ORG"], [13726, 13731, "ORG"], [13744, 13748, "ORG"], [13758, 13763, "EVENT"], [13890, 13895, "ORG"], [13901, 13905, "ORG"], [13962, 13966, "ORG"], [13997, 14004, "DATE"], [14065, 14070, "ORG"], [14114, 14119, "ORG"], [14324, 14329, "ORG"], [14341, 14342, "CARDINAL"], [14365, 14370, "ORG"], [14399, 14406, "ORG"], [14769, 14774, "LAW"], [14900, 14904, "ORG"], [14939, 14944, "ORG"], [15023, 15028, "PERSON"], [15100, 15104, "ORG"], [15126, 15130, "ORG"], [15132, 15137, "ORG"], [15188, 15191, "ORG"], [15257, 15261, "ORG"], [15293, 15298, "ORG"], [15396, 15401, "ORG"], [15423, 15428, "ORG"], [15633, 15638, "ORG"], [15844, 15849, "ORG"], [15880, 15885, "ORG"], [15890, 15895, "ORG"], [15946, 15951, "ORG"], [16072, 16077, "ORG"], [16101, 16106, "ORG"], [16156, 16161, "ORG"], [16206, 16216, "NORP"], [16248, 16253, "ORG"], [16325, 16329, "ORG"], [16344, 16349, "ORG"], [16396, 16401, "ORG"], [16440, 16445, "ORG"], [16460, 16465, "ORG"], [16579, 16584, "ORDINAL"], [16604, 16609, "ORG"], [16622, 16627, "PERSON"], [16707, 16734, "ORG"], [16765, 16778, "ORG"], [16783, 16804, "ORG"], [16817, 16821, "ORG"], [16840, 16845, "ORG"], [16850, 16855, "ORG"], [16911, 16916, "ORG"], [16947, 16952, "ORG"], [16969, 16974, "ORG"], [17091, 17096, "ORG"], [17108, 17117, "ORG"], [17118, 17121, "ORG"], [17129, 17132, "CARDINAL"], [17133, 17146, "ORG"], [17165, 17169, "ORG"], [17183, 17193, "ORG"], [17322, 17327, "ORG"], [17442, 17447, "PERSON"], [17582, 17587, "PERSON"], [17681, 17686, "ORG"], [17729, 17734, "ORG"], [17810, 17815, "LAW"], [17949, 17954, "ORG"], [18014, 18019, "ORG"], [18138, 18143, "ORG"], [18172, 18177, "ORG"], [18182, 18187, "ORG"], [18399, 18404, "ORG"], [18417, 18421, "ORG"], [18438, 18442, "ORG"], [18443, 18449, "EVENT"], [18467, 18472, "ORG"], [18512, 18520, "ORG"], [18521, 18525, "ORG"], [18570, 18578, "CARDINAL"], [18705, 18718, "ORG"], [18768, 18777, "PRODUCT"], [18945, 18948, "ORG"], [19009, 19013, "ORG"], [19015, 19019, "ORG"], [19024, 19029, "ORG"], [19068, 19072, "ORG"], [19100, 19105, "ORDINAL"], [19128, 19134, "ORG"], [19139, 19143, "ORG"], [19163, 19172, "ORG"], [19191, 19195, "DATE"], [19243, 19247, "ORG"], [19298, 19302, "DATE"], [19303, 19312, "ORG"], [19317, 19325, "ORG"], [19348, 19356, "ORG"], [19406, 19410, "ORG"], [19547, 19551, "ORG"], [19552, 19556, "PRODUCT"], [19568, 19577, "ORG"], [19623, 19628, "ORDINAL"], [19652, 19656, "ORG"], [19669, 19676, "ORG"], [19700, 19704, "DATE"], [19722, 19728, "ORG"], [19732, 19736, "DATE"], [19742, 19763, "ORG"], [19805, 19809, "DATE"], [19832, 19845, "PERSON"], [19914, 19918, "PERSON"], [19977, 19981, "ORG"], [20003, 20017, "ORG"], [20052, 20056, "DATE"], [20069, 20075, "ORG"], [20141, 20145, "ORG"], [20155, 20162, "ORG"], [20164, 20178, "DATE"], [20193, 20197, "PERSON"], [20201, 20207, "CARDINAL"], [20282, 20289, "ORG"], [20335, 20348, "ORG"], [20362, 20366, "PERSON"], [20379, 20384, "ORG"], [20412, 20416, "ORG"], [20453, 20463, "DATE"], [20469, 20475, "CARDINAL"], [20521, 20525, "DATE"], [20527, 20536, "ORG"], [20550, 20555, "ORDINAL"], [20571, 20598, "ORG"], [20629, 20633, "ORG"], [20710, 20714, "ORG"], [20727, 20731, "ORG"], [20779, 20784, "PRODUCT"], [20803, 20806, "ORG"], [21412, 21416, "ORG"], [21482, 21486, "ORG"], [21498, 21502, "DATE"], [21520, 21542, "MONEY"], [21566, 21574, "NORP"], [21575, 21579, "ORG"], [21605, 21609, "ORG"], [21628, 21632, "ORG"], [21682, 21690, "ORG"], [21699, 21705, "CARDINAL"], [21732, 21737, "PERSON"], [21815, 21819, "ORG"], [21890, 21902, "PERSON"], [21935, 21939, "ORG"], [21972, 21976, "ORG"], [21985, 21989, "ORG"], [22060, 22064, "ORG"], [22086, 22092, "GPE"], [22128, 22133, "ORG"], [22135, 22147, "ORG"], [22172, 22193, "ORG"], [22198, 22207, "ORG"], [22320, 22326, "GPE"], [22378, 22383, "PERSON"], [22444, 22454, "PERSON"], [22458, 22462, "ORG"], [22471, 22487, "PERSON"], [22519, 22531, "GPE"], [22535, 22548, "PERSON"], [22550, 22563, "DATE"], [22588, 22612, "ORG"], [22627, 22639, "PERSON"], [22642, 22646, "DATE"], [22649, 22664, "ORG"], [22665, 22710, "ORG"], [22712, 22723, "ORG"], [22725, 22742, "ORG"], [22749, 22752, "CARDINAL"], [22780, 22793, "PERSON"], [22802, 22806, "DATE"], [22811, 22843, "PRODUCT"], [22845, 22849, "CARDINAL"], [22853, 22855, "CARDINAL"], [22868, 22871, "CARDINAL"], [22912, 22921, "ORG"]]}], ["The following tables compare general and technical information for a number of online analytical processing (OLAP) servers. Please see the individual products articles for further information.\n\n\n== General information ==\n\n\n== Data storage modes ==\n\n\n== APIs and query languages ==\nAPIs and query languages OLAP servers support.\n\n\n== OLAP distinctive features ==\nA list of OLAP features that are not supported by all vendors. All vendors support features such as parent-child, multilevel hierarchy, drilldown.\nData processing, management and performance related features:\n\nData modeling features:\n\n\n== System limits ==\n\n\n== Security ==\n\n\n== Operating systems ==\nThe OLAP servers can run on the following operating systems:\n\nNote (1):The server availability depends on Java Virtual Machine not on the operating system\n\n\n== Support information ==\n\n\n== See also ==\nCubes (light-weight open-source OLAP server)\nDruid (open-source data store)\nApache Pinot (Incubating)\nicCube\nOracle Retail Predictive Application Server (RPAS), a retail specific MOLAP/OLAP server using Berkeley DB for persistence\nPalo (OLAP database)\n\n\n== References ==", {"entities": [[0, 20, "TRAINED_CATEGORY"], [29, 62, "TRAINED_CATEGORY"], [67, 75, "TRAINED_CATEGORY"], [79, 107, "TRAINED_CATEGORY"], [108, 122, "TRAINED_CATEGORY"], [135, 167, "TRAINED_CATEGORY"], [172, 191, "TRAINED_CATEGORY"], [198, 217, "TRAINED_CATEGORY"], [226, 238, "TRAINED_CATEGORY"], [253, 257, "TRAINED_CATEGORY"], [262, 277, "TRAINED_CATEGORY"], [281, 285, "TRAINED_CATEGORY"], [290, 305, "TRAINED_CATEGORY"], [362, 368, "TRAINED_CATEGORY"], [372, 385, "TRAINED_CATEGORY"], [412, 423, "TRAINED_CATEGORY"], [425, 436, "TRAINED_CATEGORY"], [445, 453, "TRAINED_CATEGORY"], [462, 474, "TRAINED_CATEGORY"], [476, 496, "TRAINED_CATEGORY"], [509, 569, "TRAINED_CATEGORY"], [572, 585, "TRAINED_CATEGORY"], [601, 607, "TRAINED_CATEGORY"], [623, 631, "TRAINED_CATEGORY"], [640, 657, "TRAINED_CATEGORY"], [661, 677, "TRAINED_CATEGORY"], [689, 720, "TRAINED_CATEGORY"], [723, 727, "TRAINED_CATEGORY"], [729, 755, "TRAINED_CATEGORY"], [767, 787, "TRAINED_CATEGORY"], [795, 815, "TRAINED_CATEGORY"], [821, 840, "TRAINED_CATEGORY"], [861, 866, "TRAINED_CATEGORY"], [868, 904, "TRAINED_CATEGORY"], [906, 911, "TRAINED_CATEGORY"], [912, 935, "TRAINED_CATEGORY"], [937, 949, "TRAINED_CATEGORY"], [950, 961, "TRAINED_CATEGORY"], [963, 969, "TRAINED_CATEGORY"], [970, 1013, "TRAINED_CATEGORY"], [1015, 1019, "TRAINED_CATEGORY"], [1022, 1057, "TRAINED_CATEGORY"], [1064, 1075, "TRAINED_CATEGORY"], [1080, 1091, "TRAINED_CATEGORY"], [1092, 1096, "TRAINED_CATEGORY"], [1098, 1111, "TRAINED_CATEGORY"], [1118, 1128, "TRAINED_CATEGORY"], [109, 113, "ORG"], [226, 230, "ORG"], [306, 310, "ORG"], [333, 337, "ORG"], [372, 376, "ORG"], [640, 649, "ORG"], [665, 669, "ORG"], [767, 787, "ORG"], [821, 828, "ORG"], [893, 897, "ORG"], [906, 911, "PERSON"], [1015, 1019, "ORG"], [1040, 1045, "ORG"], [1046, 1050, "ORG"], [1064, 1075, "ORG"], [1092, 1096, "PERSON"], [1098, 1102, "ORG"]]}], ["Thomsen Diagrams are the diagrammatic methodology developed by Erik Thomsen in 1997. They are essentially a metaphor for describing multidimensional data spaces in the OLAP system. It may be thought of as a multi-dimensional domain structure. In the structure, each dimension is represented by a vertical line, and hence each dimension is described independently.\nEvery member of a dimension is represented by a unit interval on the line. A multi-dimensional model is built by combining the resultant lines for the particular dimensions.\nThe Thomsen diagrammatical technique is not based on angular defined dimensions, and is thus able to represent any number of dimensions. It may be referred to as a multi-dimensional type structure (MTS). The MTS permits the viewing of information about hierarchies and data flows, both within and between structures, hence enhancing the capabilities of the OLAP system.\n\n\n== References ==\n\n\n== External links ==\nPeter O'Donnell and Nick Draper 2004, An Experimental Evaluation of an Alternative to the Pivot Table for Ad Hoc Access to OLAP Data (PDF, PDF (alternative link)) - Wherein Mr. Thomsen's diagrams are called \"Thomsen Diagrams\".", {"entities": [[0, 16, "TRAINED_CATEGORY"], [21, 49, "TRAINED_CATEGORY"], [63, 75, "TRAINED_CATEGORY"], [85, 89, "TRAINED_CATEGORY"], [106, 116, "TRAINED_CATEGORY"], [132, 160, "TRAINED_CATEGORY"], [164, 179, "TRAINED_CATEGORY"], [181, 183, "TRAINED_CATEGORY"], [205, 241, "TRAINED_CATEGORY"], [246, 259, "TRAINED_CATEGORY"], [261, 275, "TRAINED_CATEGORY"], [294, 309, "TRAINED_CATEGORY"], [321, 335, "TRAINED_CATEGORY"], [364, 376, "TRAINED_CATEGORY"], [380, 391, "TRAINED_CATEGORY"], [410, 425, "TRAINED_CATEGORY"], [429, 437, "TRAINED_CATEGORY"], [439, 464, "TRAINED_CATEGORY"], [487, 506, "TRAINED_CATEGORY"], [511, 536, "TRAINED_CATEGORY"], [538, 574, "TRAINED_CATEGORY"], [591, 617, "TRAINED_CATEGORY"], [649, 659, "TRAINED_CATEGORY"], [663, 673, "TRAINED_CATEGORY"], [675, 677, "TRAINED_CATEGORY"], [700, 734, "TRAINED_CATEGORY"], [736, 739, "TRAINED_CATEGORY"], [742, 749, "TRAINED_CATEGORY"], [758, 769, "TRAINED_CATEGORY"], [773, 784, "TRAINED_CATEGORY"], [791, 802, "TRAINED_CATEGORY"], [807, 817, "TRAINED_CATEGORY"], [843, 853, "TRAINED_CATEGORY"], [871, 887, "TRAINED_CATEGORY"], [891, 906, "TRAINED_CATEGORY"], [913, 923, "TRAINED_CATEGORY"], [932, 946, "TRAINED_CATEGORY"], [950, 965, "TRAINED_CATEGORY"], [970, 981, "TRAINED_CATEGORY"], [988, 1014, "TRAINED_CATEGORY"], [1018, 1032, "TRAINED_CATEGORY"], [1036, 1051, "TRAINED_CATEGORY"], [1056, 1069, "TRAINED_CATEGORY"], [1073, 1082, "TRAINED_CATEGORY"], [1083, 1087, "TRAINED_CATEGORY"], [1089, 1092, "TRAINED_CATEGORY"], [1093, 1110, "TRAINED_CATEGORY"], [1115, 1145, "TRAINED_CATEGORY"], [0, 16, "PERSON"], [63, 75, "PERSON"], [79, 83, "DATE"], [168, 172, "ORG"], [542, 549, "PERSON"], [746, 749, "ORG"], [895, 899, "ORG"], [932, 940, "ORG"], [950, 965, "PERSON"], [970, 981, "PERSON"], [982, 986, "DATE"], [1073, 1082, "ORG"], [1127, 1134, "PERSON"], [1158, 1174, "WORK_OF_ART"]]}], ["The functional database model is used to support analytics applications such as financial planning and performance management. The functional database model, or the functional model for short, is different from but complementary to the relational model. The functional model is also distinct from other similarly named concepts, including the DAPLEX functional database model and functional language databases.\nThe functional model is part of the online analytical processing (OLAP) category since it comprises multidimensional hierarchical consolidation. But it goes beyond OLAP by requiring a spreadsheet-like cell orientation, where cells can be input or calculated as functions of other cells. Also as in spreadsheets, it supports interactive calculations where the values of all dependent cells are automatically up to date whenever the value of a cell is changed.\n\n\n== Overview ==\nAnalytics, especially forward looking or prospective analytics requires interactive modeling, \"what if\", and experimentation of the kind that most business analysts do with spreadsheets. This interaction with the data is enabled by the spreadsheet\u2019s cell orientation and its ability to let users define cells calculated as a function of other cells.\nThe relational database model has no such concepts and is thus very limited in the business performance modeling and interactivity it can support. Accordingly, relational-based analytics is almost exclusively restricted to historical data, which is static. This misses most of the strategic benefits of analytics, which come from interactively constructing views of the future.\nThe functional model is based on multidimensional arrays, or \"cubes\", of cells that, as in a spreadsheet, can be either externally input, or calculated in terms of other cells. Such cubes are constructed using dimensions which correspond to hierarchically organized sets of real entities such as products, geographies, time, etc. A cube can be seen as a function over the cartesian product of the dimensions. I.e., it assigns a value to each cell, which is identified by an  n-tuple of dimension elements; thus the name \"functional\". The model retains the flexibility and potential for interactivity of spreadsheets, as well as the multidimensional hierarchical consolidations of relational-based OLAP tools. At the same time, the functional model overcomes the limitations of both the relational database model and classical spreadsheets.\nProducts that implement the principles of the functional model to varying degrees have been in existence for some time, including products such as Essbase, TM1, Alea, Microsoft Analysis Services, etc.\n\n\n== Analytics context ==\nThe management system of an enterprise generally consists of a series of interconnected control loops. Each loop starts by developing a plan, the plan is then executed, and the results are reviewed and compared against the plan. Based on those results, and a new assessment of what the future holds, a new plan is developed and the process is repeated. The three components of the control loop, planning, execution and assessment, have different time perspectives. Planning looks at the future, execution looks at the present and review looks at the past.\nInformation Technology (IT) plays now a central role in making management control loops more efficient and effective. Operational computer systems are concerned with execution while analytic computer systems, or simply Analytics, are used to improve planning and assessment. The information needs of each component are different. Operational systems are typically concerned with recording transactions and keeping track of the current state of the business \u2013 inventory, work in progress etc.  Analytics has two principal components: forward-looking or prospective analytics, which applies to planning, and backward looking or retrospective analytics, which applies to assessment.\nIn retrospective analytics, transactions resulting from operations are boiled down and accumulated into arrays of cells. These cells are identified by as many dimensions as are relevant to the business: time, product, customer, account, region, etc. The cells are typically arrayed in cubes that form the basis for retrospective analyses such as comparing actual performance to plan. This is the main realm of OLAP systems.\nProspective analytics develops similar cubes of data but for future time periods. The development of prospective data is typically the result of human input or mathematical models that are driven and controlled through user interaction.\nThe application of IT to the tree components of the management control loop evolved over time as new technologies were developed. Recording of operational transactions was one of the first needs to be automated through the use of 80 column punch cards. As electronics progressed, the records were moved, first to magnetic tape, then to disk. Software technology progressed as well and gave rise to database management systems that centralized the access and control of the data.\nDatabases made it then possible to develop languages that made it easy to produce reports for retrospective analytics. At about the same time, languages and systems were developed to handle multidimensional data and to automate mathematical techniques for forecasting and optimization as part of prospective analytics. Unfortunately, this technology required a high level of expertise and was not comprehensible to most end users. Thus its user acceptance was limited, and so were the benefits derived from it.\nNo wide-use tool was available for prospective analytics until the introduction of the electronic spreadsheet. For the first time end users had a tool that they could understand and control, and use it to model their business as they understood it.  They could interact, experiment, adapt to changing situations, and derive insights and value very quickly. As a result, spreadsheets were adopted broadly and ultimately became pervasive. To this day, spreadsheets remain an indispensable tool for anyone doing planning.\n\n\n== Spreadsheets and the functional model ==\nSpreadsheets have a key set of characteristics that facilitate modeling and analysis. Data from multiple sources can be brought together in one worksheet. Cells can be defined by means of calculation formulas in terms of other cells, so facts from different sources can be logically interlinked to calculate derived values. Calculated cells are updated automatically whenever any of the input cells on which they depend changes. When users have a \"what if\" question, they simply change some data cells, and automatically all dependent cells are brought up to date. Also, cells are organized in rectangular grids and juxtaposed so that significant differences can be spotted at a glance or through associated graphic displays. Spreadsheet grids normally also contain consolidation calculations along rows and or columns. This permits discovering trends in the aggregate that may not be evident at a detailed level.\nBut spreadsheets suffer from a number of shortcomings. Cells are identified by row and column position, not the business concepts they represent. Spreadsheets are two dimensional, and multiple pages provide the semblance of three dimensions, but business data often has more dimensions. If users want to perform another analysis on the same set of data, the data needs to be duplicated. Spreadsheet links can sometimes be used, but most often are not practical. The combined effect of these limitations is that there is a limit on the complexity of spreadsheets that can be built and managed. \nWhile the functional model retains the key features of the spreadsheet, it also overcomes its main limitations. With the functional model, data is arranged in a grid of cells, but cells are identified by business concept instead of just row or column. Rather than worksheets, the objects of the functional model are dimensions and cubes. Rather than two or three dimensions: row, column and sheet, the functional model supports as many dimensions as are necessary.\nAnother advantage of the functional model is that it is a database with features such as data independence, concurrent multiuser access, integrity, scalability, security, audit trail, backup/recovery, and data integration.\nData independence is of particularly high value for analytics. Data need no longer reside in spreadsheets. Instead the functional database acts as a central information resource. The spreadsheet acts as a user interface to the database, so the same data can be shared by multiple spreadsheets and multiple users. Updates submitted by multiple users are available to all users subject to security rules. Accordingly, there is always a single consistent shared version of the data.\n\n\n== Components of the functional model ==\nA functional database consists of a set of dimensions which are used to construct a set of cubes. A dimension is a finite set of elements, or members, that identify business data, e.g., time periods, products, areas or regions, line items, etc. Cubes are built using any number of dimensions. A cube is a collection of cells, each of which is identified by a tuple of elements, one from each dimension of the cube. Each cell in a cube contains a value. A cube is effectively a function that assigns a value to each n-tuple of the cartesian product of the dimensions.\nThe value of a cell may be assigned externally (input), or the result of a calculation that uses other cells in the same cube or other cubes. The definition of a cube includes the formulas that specify the calculation of such cells. Cells may also be empty and deemed to have a zero value for purposes of consolidation.\nAs with spreadsheets, users need not worry about executing recalculation. When the value of a cell is requested, the value that is returned is up to date with respect to the values of all of the cells that go into its calculation i.e. the cells on which it depends.\nDimensions typically contain consolidation hierarchies where some elements are defined as parents of other elements, and a parent is interpreted as the sum of its children. Cells that are identified by a consolidated element in one or more dimensions are automatically calculated by the functional model as sums of cells having child elements in those dimensions. When the value of a consolidated cell is requested, the value that is returned is always up to date with respect to the values of all of the cells that it consolidates.\n\n\n=== An example ===\n\nThe cubes and their dimensions (in parentheses) are as follows:\n\nProfit and Loss - P&L (Region, Account, Currency, Time)\nSales - Sales(Region, Product, Time)\nPayroll - Payroll(Region, Employee, Time)\nOverhead - Ovhd(Account, Time)\nForeign Exchange - Fx(Currency, Time)The cubes in the model are interconnected through formulas:\nThe P&L cube picks up the dollar costs from the payroll cube through a formula of the form:\nP&L( \"Payroll\", \"Dollars\") = Payroll (\"All Employees\")\nNote: The expression syntax used is for illustration purposes and may not reflect syntax used in the formal model or in particular products that implement the functional model. The dimensions that are omitted from the expression are assumed to range over all the leaf elements of those dimensions. Thus this expression is equivalent to:\nP&L( xRegion, \"Payroll\", \"Dollars\", xTime) = Payroll (xRegion, \"All Employees\", xTime), for all leaves xRegion in Region and all leaves xTime in Time.\nSimilarly, P&L also picks up sales revenue from the Sales cube through:\nP&L( \"Sales\", \"Dollars\") = Sales(\"All Products\")\nOverhead accounts are allocated by region on the basis of sales:\nP&L(\"Region\", \"Dollars\") = Ovhd() * Sales(\"Region\") / Sales(\"All Regions\")\nFinally, other currencies are derived from the dollar exchange rate:\nP&L() = P&L(\"Dollars\") * Fx()\nThe historical portion of the cubes is also populated from the data warehouse. In this simplified example, the calculations just discussed may be done in the data warehouse for the historical portion of the cubes, but generally, the functional model supports the calculation of other functions, such as ratios and percentages.\nWhile the history is static, the future portion is typically dynamic and developed interactively by business analysts in various organizations and various backgrounds. Sales forecasts should be developed by experts from each region. They could use forecasting models and parameters that incorporate their knowledge and experience of that region, or they could simply enter them through a spreadsheet. Each region can use a different method with different assumptions. The payroll forecast could be developed by HR experts in each region. The overhead cube would be populated by people in headquarters finance, and so would the exchange rate forecasts. The forecasts developed by regional experts are first reviewed and recycled within the region and then reviewed and recycled with headquarters.\nThe model can be expanded to include a Version dimension that varies based on, for example, various economic climate scenarios. As time progresses, each planning cycle can be stored in a different version, and those versions compared to actual and to one another.\nAt any time the data in all the cubes, subject to security constraints, is available to all interested parties. Users can bring slices of cubes dynamically into spreadsheets to do further analyses, but with a guarantee that the data is the same as what other users are seeing.\n\n\n== Functional databases and prospective analytics ==\nA functional database brings together data from multiple disparate sources and ties the disparate data sets into coherent consumable models. It also brings data scattered over multiple spreadsheets under control. This lets users see a summary picture that combines multiple components, e.g., to roll manpower planning into a complete financial picture automatically. It gives them a single point of entry to develop global insights based on various sources.\nA functional database, like spreadsheets, also lets users change input values while all dependent values are up to date. This facilitates what-if experimentation and creating and comparing multiple scenarios. Users can then see the scenarios side by side and choose the most appropriate. When planning, users can converge on a most advantageous course of action by repeatedly recycling and interacting with results. Actionable insights come from this intimate interaction with data that users normally do with spreadsheets\nA functional database does not only provide a common interactive data store. It also brings together models developed by analysts with knowledge of a particular area of the business that can be shared by all users. To facilitate this, a functional database retains the spreadsheet\u2019s interactive cell-based modelling capability. This makes possible models that more closely reflect the complexities of business reality.\nPerhaps a functional database\u2019s largest single contribution to analytics comes from promoting collaboration. It lets multiple individuals and organizations not only share a single version of the truth, but a truth that is dynamic and constantly changing. Its automatic calculations quickly consolidate and reconcile inputs from multiple sources. This promotes interaction of various departments, facilitates multiple iterations of thought processes and makes it possible for differing viewpoints to converge and be reconciled. Also, since each portion of the model is developed by the people that are more experts in their particular area, it is able to leverage experience and insights that exist up and down the organization.\n\n\n== References ==\n\n\n== Further reading ==\n\"Basic Set Theory\". Stanford Encyclopedia of Philosophy. http://plato.stanford.edu/entries/set-theory/primer.html\nBird R.S., Wadler P.L. Introduction to Functional Programming. Prentice Hall (1988).\nBuneman P., Functional Database Languages and the Functional Data Model. A position paper for the FDM workshop (June 1997) http://www.cis.upenn.edu/~peter/fdm-position.html.\nCodd, E. F.  A Relational Model of Data for Large Shared Data Banks. Comm. ACM 13, 6 (June, 1970)\nHenderson P. Functional Programming Application and Implementation. Prentice Hall (1980).\nHrbacek, K and Jech, T  Introduction to Set Theory, Third Edition, Marcel Dekker, Inc., New York 1999.\nLang, Serge (1987), Linear algebra, Berlin, New York: Springer-Verlag, ISBN 978-0-387-96412-6\nC.M. Necco, J.N. Oliveira, L. Quintas. A functional approach for on line analytical processing, 2006. WISBD, III Workshop de I\tngenier\u00eda de Software y Bases de Datos. CACIC'06, XII Congreso Argentino de Ciencias de la Computaci\u00f3n, Universidad Nacional de San Luis, Argentina.\nE. F. Codd. Providing olap to user-analysts: an it mandate, Apr. 1993. Technical Report, E. F. Codd and Associates.\nP. Trinder, A functional data base, D.Phil Thesis, Oxford University 1989.\nG. Colliat, Olap relational and multidimensional database systems, SIGMOD Record, 25(3), (1996)\nT. B. Pedersen, C. S. Jensen, Multidimensional database technology, IEEE Computer 34(12), 40-46, (2001)\nC. J. Date with Hugh Darwen: A Guide to the SQL standard : a users guide to the standard database language SQL, 4th ed., Addison Wesley, USA 1997, ISBN 978-0-201-96426-4\nRalph Kimball and Margy Ross, The Data Warehouse Toolkit: The Complete Guide to Dimensional Modeling (Second Edition), p. 393\nKarsten Oehler Jochen Gruenes Christopher Ilacqua,  IBM Cognos TM1 The Official Guide, McGraw Hill 2012\nThe definitive history of TM1, Manny Perez, https://cubewise.com/history/", {"entities": [[0, 29, "TRAINED_CATEGORY"], [49, 71, "TRAINED_CATEGORY"], [80, 125, "TRAINED_CATEGORY"], [127, 156, "TRAINED_CATEGORY"], [161, 181, "TRAINED_CATEGORY"], [232, 252, "TRAINED_CATEGORY"], [254, 274, "TRAINED_CATEGORY"], [297, 327, "TRAINED_CATEGORY"], [339, 375, "TRAINED_CATEGORY"], [380, 409, "TRAINED_CATEGORY"], [411, 431, "TRAINED_CATEGORY"], [435, 439, "TRAINED_CATEGORY"], [443, 491, "TRAINED_CATEGORY"], [498, 500, "TRAINED_CATEGORY"], [511, 554, "TRAINED_CATEGORY"], [560, 562, "TRAINED_CATEGORY"], [575, 579, "TRAINED_CATEGORY"], [593, 628, "TRAINED_CATEGORY"], [636, 641, "TRAINED_CATEGORY"], [672, 681, "TRAINED_CATEGORY"], [685, 696, "TRAINED_CATEGORY"], [709, 721, "TRAINED_CATEGORY"], [723, 725, "TRAINED_CATEGORY"], [735, 759, "TRAINED_CATEGORY"], [766, 776, "TRAINED_CATEGORY"], [780, 799, "TRAINED_CATEGORY"], [824, 828, "TRAINED_CATEGORY"], [838, 847, "TRAINED_CATEGORY"], [851, 857, "TRAINED_CATEGORY"], [887, 896, "TRAINED_CATEGORY"], [898, 949, "TRAINED_CATEGORY"], [959, 979, "TRAINED_CATEGORY"], [982, 986, "TRAINED_CATEGORY"], [996, 1011, "TRAINED_CATEGORY"], [1015, 1023, "TRAINED_CATEGORY"], [1029, 1051, "TRAINED_CATEGORY"], [1060, 1072, "TRAINED_CATEGORY"], [1074, 1090, "TRAINED_CATEGORY"], [1096, 1104, "TRAINED_CATEGORY"], [1119, 1153, "TRAINED_CATEGORY"], [1158, 1169, "TRAINED_CATEGORY"], [1177, 1182, "TRAINED_CATEGORY"], [1190, 1195, "TRAINED_CATEGORY"], [1210, 1220, "TRAINED_CATEGORY"], [1224, 1235, "TRAINED_CATEGORY"], [1237, 1266, "TRAINED_CATEGORY"], [1271, 1287, "TRAINED_CATEGORY"], [1316, 1349, "TRAINED_CATEGORY"], [1354, 1367, "TRAINED_CATEGORY"], [1368, 1370, "TRAINED_CATEGORY"], [1397, 1423, "TRAINED_CATEGORY"], [1460, 1475, "TRAINED_CATEGORY"], [1514, 1536, "TRAINED_CATEGORY"], [1540, 1549, "TRAINED_CATEGORY"], [1594, 1599, "TRAINED_CATEGORY"], [1603, 1613, "TRAINED_CATEGORY"], [1615, 1635, "TRAINED_CATEGORY"], [1648, 1671, "TRAINED_CATEGORY"], [1676, 1682, "TRAINED_CATEGORY"], [1688, 1693, "TRAINED_CATEGORY"], [1706, 1719, "TRAINED_CATEGORY"], [1728, 1751, "TRAINED_CATEGORY"], [1770, 1775, "TRAINED_CATEGORY"], [1779, 1790, "TRAINED_CATEGORY"], [1792, 1802, "TRAINED_CATEGORY"], [1825, 1835, "TRAINED_CATEGORY"], [1856, 1885, "TRAINED_CATEGORY"], [1889, 1902, "TRAINED_CATEGORY"], [1911, 1919, "TRAINED_CATEGORY"], [1921, 1932, "TRAINED_CATEGORY"], [1934, 1938, "TRAINED_CATEGORY"], [1945, 1951, "TRAINED_CATEGORY"], [1967, 1977, "TRAINED_CATEGORY"], [1983, 2004, "TRAINED_CATEGORY"], [2008, 2022, "TRAINED_CATEGORY"], [2030, 2032, "TRAINED_CATEGORY"], [2041, 2048, "TRAINED_CATEGORY"], [2052, 2061, "TRAINED_CATEGORY"], [2086, 2097, "TRAINED_CATEGORY"], [2101, 2119, "TRAINED_CATEGORY"], [2121, 2134, "TRAINED_CATEGORY"], [2149, 2158, "TRAINED_CATEGORY"], [2167, 2182, "TRAINED_CATEGORY"], [2187, 2196, "TRAINED_CATEGORY"], [2201, 2214, "TRAINED_CATEGORY"], [2218, 2230, "TRAINED_CATEGORY"], [2243, 2291, "TRAINED_CATEGORY"], [2295, 2322, "TRAINED_CATEGORY"], [2327, 2340, "TRAINED_CATEGORY"], [2342, 2362, "TRAINED_CATEGORY"], [2373, 2388, "TRAINED_CATEGORY"], [2392, 2426, "TRAINED_CATEGORY"], [2431, 2453, "TRAINED_CATEGORY"], [2455, 2463, "TRAINED_CATEGORY"], [2479, 2493, "TRAINED_CATEGORY"], [2497, 2517, "TRAINED_CATEGORY"], [2521, 2536, "TRAINED_CATEGORY"], [2550, 2559, "TRAINED_CATEGORY"], [2564, 2573, "TRAINED_CATEGORY"], [2585, 2593, "TRAINED_CATEGORY"], [2602, 2609, "TRAINED_CATEGORY"], [2611, 2614, "TRAINED_CATEGORY"], [2616, 2620, "TRAINED_CATEGORY"], [2622, 2649, "TRAINED_CATEGORY"], [2661, 2678, "TRAINED_CATEGORY"], [2682, 2703, "TRAINED_CATEGORY"], [2707, 2720, "TRAINED_CATEGORY"], [2743, 2751, "TRAINED_CATEGORY"], [2755, 2783, "TRAINED_CATEGORY"], [2785, 2794, "TRAINED_CATEGORY"], [2816, 2822, "TRAINED_CATEGORY"], [2824, 2832, "TRAINED_CATEGORY"], [2855, 2866, "TRAINED_CATEGORY"], [2901, 2909, "TRAINED_CATEGORY"], [2920, 2933, "TRAINED_CATEGORY"], [2959, 2963, "TRAINED_CATEGORY"], [2964, 2974, "TRAINED_CATEGORY"], [2982, 2992, "TRAINED_CATEGORY"], [3010, 3021, "TRAINED_CATEGORY"], [3035, 3055, "TRAINED_CATEGORY"], [3059, 3075, "TRAINED_CATEGORY"], [3077, 3085, "TRAINED_CATEGORY"], [3087, 3096, "TRAINED_CATEGORY"], [3101, 3111, "TRAINED_CATEGORY"], [3118, 3145, "TRAINED_CATEGORY"], [3147, 3155, "TRAINED_CATEGORY"], [3165, 3175, "TRAINED_CATEGORY"], [3177, 3186, "TRAINED_CATEGORY"], [3212, 3218, "TRAINED_CATEGORY"], [3228, 3236, "TRAINED_CATEGORY"], [3238, 3260, "TRAINED_CATEGORY"], [3262, 3264, "TRAINED_CATEGORY"], [3276, 3290, "TRAINED_CATEGORY"], [3301, 3325, "TRAINED_CATEGORY"], [3356, 3384, "TRAINED_CATEGORY"], [3404, 3413, "TRAINED_CATEGORY"], [3420, 3445, "TRAINED_CATEGORY"], [3450, 3466, "TRAINED_CATEGORY"], [3488, 3496, "TRAINED_CATEGORY"], [3501, 3511, "TRAINED_CATEGORY"], [3538, 3552, "TRAINED_CATEGORY"], [3568, 3587, "TRAINED_CATEGORY"], [3617, 3639, "TRAINED_CATEGORY"], [3652, 3657, "TRAINED_CATEGORY"], [3661, 3678, "TRAINED_CATEGORY"], [3682, 3694, "TRAINED_CATEGORY"], [3731, 3740, "TRAINED_CATEGORY"], [3745, 3769, "TRAINED_CATEGORY"], [3771, 3811, "TRAINED_CATEGORY"], [3830, 3838, "TRAINED_CATEGORY"], [3844, 3887, "TRAINED_CATEGORY"], [3906, 3916, "TRAINED_CATEGORY"], [3921, 3944, "TRAINED_CATEGORY"], [3946, 3958, "TRAINED_CATEGORY"], [3974, 3984, "TRAINED_CATEGORY"], [4022, 4028, "TRAINED_CATEGORY"], [4032, 4037, "TRAINED_CATEGORY"], [4039, 4050, "TRAINED_CATEGORY"], [4069, 4087, "TRAINED_CATEGORY"], [4107, 4119, "TRAINED_CATEGORY"], [4121, 4125, "TRAINED_CATEGORY"], [4127, 4134, "TRAINED_CATEGORY"], [4136, 4144, "TRAINED_CATEGORY"], [4146, 4153, "TRAINED_CATEGORY"], [4155, 4161, "TRAINED_CATEGORY"], [4168, 4177, "TRAINED_CATEGORY"], [4203, 4208, "TRAINED_CATEGORY"], [4219, 4228, "TRAINED_CATEGORY"], [4233, 4255, "TRAINED_CATEGORY"], [4274, 4292, "TRAINED_CATEGORY"], [4310, 4324, "TRAINED_CATEGORY"], [4328, 4340, "TRAINED_CATEGORY"], [4342, 4363, "TRAINED_CATEGORY"], [4373, 4386, "TRAINED_CATEGORY"], [4390, 4394, "TRAINED_CATEGORY"], [4403, 4422, "TRAINED_CATEGORY"], [4424, 4439, "TRAINED_CATEGORY"], [4443, 4459, "TRAINED_CATEGORY"], [4473, 4483, "TRAINED_CATEGORY"], [4487, 4498, "TRAINED_CATEGORY"], [4502, 4521, "TRAINED_CATEGORY"], [4561, 4577, "TRAINED_CATEGORY"], [4579, 4594, "TRAINED_CATEGORY"], [4598, 4600, "TRAINED_CATEGORY"], [4604, 4623, "TRAINED_CATEGORY"], [4627, 4654, "TRAINED_CATEGORY"], [4668, 4672, "TRAINED_CATEGORY"], [4676, 4692, "TRAINED_CATEGORY"], [4722, 4746, "TRAINED_CATEGORY"], [4758, 4773, "TRAINED_CATEGORY"], [4798, 4805, "TRAINED_CATEGORY"], [4809, 4830, "TRAINED_CATEGORY"], [4835, 4846, "TRAINED_CATEGORY"], [4859, 4870, "TRAINED_CATEGORY"], [4892, 4905, "TRAINED_CATEGORY"], [4921, 4940, "TRAINED_CATEGORY"], [4969, 4973, "TRAINED_CATEGORY"], [4986, 5004, "TRAINED_CATEGORY"], [5022, 5032, "TRAINED_CATEGORY"], [5037, 5044, "TRAINED_CATEGORY"], [5048, 5056, "TRAINED_CATEGORY"], [5058, 5067, "TRAINED_CATEGORY"], [5073, 5075, "TRAINED_CATEGORY"], [5101, 5110, "TRAINED_CATEGORY"], [5121, 5123, "TRAINED_CATEGORY"], [5140, 5147, "TRAINED_CATEGORY"], [5152, 5175, "TRAINED_CATEGORY"], [5180, 5199, "TRAINED_CATEGORY"], [5201, 5210, "TRAINED_CATEGORY"], [5215, 5222, "TRAINED_CATEGORY"], [5248, 5269, "TRAINED_CATEGORY"], [5286, 5309, "TRAINED_CATEGORY"], [5314, 5325, "TRAINED_CATEGORY"], [5330, 5342, "TRAINED_CATEGORY"], [5346, 5350, "TRAINED_CATEGORY"], [5354, 5375, "TRAINED_CATEGORY"], [5392, 5407, "TRAINED_CATEGORY"], [5417, 5429, "TRAINED_CATEGORY"], [5433, 5442, "TRAINED_CATEGORY"], [5482, 5487, "TRAINED_CATEGORY"], [5494, 5513, "TRAINED_CATEGORY"], [5539, 5551, "TRAINED_CATEGORY"], [5565, 5567, "TRAINED_CATEGORY"], [5569, 5585, "TRAINED_CATEGORY"], [5604, 5625, "TRAINED_CATEGORY"], [5632, 5648, "TRAINED_CATEGORY"], [5652, 5678, "TRAINED_CATEGORY"], [5684, 5698, "TRAINED_CATEGORY"], [5699, 5702, "TRAINED_CATEGORY"], [5703, 5708, "TRAINED_CATEGORY"], [5713, 5719, "TRAINED_CATEGORY"], [5725, 5729, "TRAINED_CATEGORY"], [5768, 5770, "TRAINED_CATEGORY"], [5780, 5794, "TRAINED_CATEGORY"], [5798, 5802, "TRAINED_CATEGORY"], [5814, 5816, "TRAINED_CATEGORY"], [5819, 5823, "TRAINED_CATEGORY"], [5870, 5880, "TRAINED_CATEGORY"], [5893, 5901, "TRAINED_CATEGORY"], [5906, 5911, "TRAINED_CATEGORY"], [5929, 5937, "TRAINED_CATEGORY"], [5939, 5951, "TRAINED_CATEGORY"], [6009, 6017, "TRAINED_CATEGORY"], [6019, 6031, "TRAINED_CATEGORY"], [6039, 6060, "TRAINED_CATEGORY"], [6065, 6071, "TRAINED_CATEGORY"], [6078, 6086, "TRAINED_CATEGORY"], [6134, 6146, "TRAINED_CATEGORY"], [6152, 6161, "TRAINED_CATEGORY"], [6165, 6180, "TRAINED_CATEGORY"], [6197, 6205, "TRAINED_CATEGORY"], [6210, 6218, "TRAINED_CATEGORY"], [6220, 6224, "TRAINED_CATEGORY"], [6230, 6246, "TRAINED_CATEGORY"], [6274, 6287, "TRAINED_CATEGORY"], [6289, 6294, "TRAINED_CATEGORY"], [6313, 6318, "TRAINED_CATEGORY"], [6322, 6342, "TRAINED_CATEGORY"], [6346, 6351, "TRAINED_CATEGORY"], [6355, 6366, "TRAINED_CATEGORY"], [6371, 6376, "TRAINED_CATEGORY"], [6382, 6399, "TRAINED_CATEGORY"], [6442, 6456, "TRAINED_CATEGORY"], [6458, 6474, "TRAINED_CATEGORY"], [6517, 6532, "TRAINED_CATEGORY"], [6542, 6546, "TRAINED_CATEGORY"], [6554, 6561, "TRAINED_CATEGORY"], [6568, 6573, "TRAINED_CATEGORY"], [6581, 6586, "TRAINED_CATEGORY"], [6601, 6605, "TRAINED_CATEGORY"], [6620, 6635, "TRAINED_CATEGORY"], [6655, 6674, "TRAINED_CATEGORY"], [6693, 6697, "TRAINED_CATEGORY"], [6705, 6710, "TRAINED_CATEGORY"], [6728, 6745, "TRAINED_CATEGORY"], [6769, 6792, "TRAINED_CATEGORY"], [6811, 6819, "TRAINED_CATEGORY"], [6831, 6858, "TRAINED_CATEGORY"], [6860, 6877, "TRAINED_CATEGORY"], [6900, 6926, "TRAINED_CATEGORY"], [6933, 6937, "TRAINED_CATEGORY"], [6945, 6952, "TRAINED_CATEGORY"], [6979, 6985, "TRAINED_CATEGORY"], [6989, 7002, "TRAINED_CATEGORY"], [7030, 7046, "TRAINED_CATEGORY"], [7052, 7064, "TRAINED_CATEGORY"], [7077, 7085, "TRAINED_CATEGORY"], [7089, 7101, "TRAINED_CATEGORY"], [7103, 7108, "TRAINED_CATEGORY"], [7127, 7150, "TRAINED_CATEGORY"], [7152, 7177, "TRAINED_CATEGORY"], [7178, 7182, "TRAINED_CATEGORY"], [7194, 7206, "TRAINED_CATEGORY"], [7232, 7246, "TRAINED_CATEGORY"], [7255, 7268, "TRAINED_CATEGORY"], [7272, 7288, "TRAINED_CATEGORY"], [7294, 7307, "TRAINED_CATEGORY"], [7318, 7333, "TRAINED_CATEGORY"], [7338, 7343, "TRAINED_CATEGORY"], [7360, 7376, "TRAINED_CATEGORY"], [7380, 7392, "TRAINED_CATEGORY"], [7396, 7400, "TRAINED_CATEGORY"], [7402, 7410, "TRAINED_CATEGORY"], [7435, 7452, "TRAINED_CATEGORY"], [7510, 7529, "TRAINED_CATEGORY"], [7533, 7550, "TRAINED_CATEGORY"], [7568, 7575, "TRAINED_CATEGORY"], [7579, 7593, "TRAINED_CATEGORY"], [7597, 7609, "TRAINED_CATEGORY"], [7648, 7668, "TRAINED_CATEGORY"], [7677, 7693, "TRAINED_CATEGORY"], [7697, 7712, "TRAINED_CATEGORY"], [7714, 7716, "TRAINED_CATEGORY"], [7732, 7752, "TRAINED_CATEGORY"], [7759, 7779, "TRAINED_CATEGORY"], [7781, 7785, "TRAINED_CATEGORY"], [7801, 7807, "TRAINED_CATEGORY"], [7811, 7816, "TRAINED_CATEGORY"], [7822, 7827, "TRAINED_CATEGORY"], [7846, 7862, "TRAINED_CATEGORY"], [7874, 7882, "TRAINED_CATEGORY"], [7886, 7892, "TRAINED_CATEGORY"], [7906, 7916, "TRAINED_CATEGORY"], [7918, 7929, "TRAINED_CATEGORY"], [7933, 7953, "TRAINED_CATEGORY"], [7958, 7968, "TRAINED_CATEGORY"], [7973, 7978, "TRAINED_CATEGORY"], [7992, 8015, "TRAINED_CATEGORY"], [8017, 8020, "TRAINED_CATEGORY"], [8022, 8028, "TRAINED_CATEGORY"], [8033, 8038, "TRAINED_CATEGORY"], [8040, 8060, "TRAINED_CATEGORY"], [8070, 8088, "TRAINED_CATEGORY"], [8107, 8124, "TRAINED_CATEGORY"], [8128, 8148, "TRAINED_CATEGORY"], [8157, 8159, "TRAINED_CATEGORY"], [8163, 8173, "TRAINED_CATEGORY"], [8179, 8187, "TRAINED_CATEGORY"], [8196, 8213, "TRAINED_CATEGORY"], [8215, 8242, "TRAINED_CATEGORY"], [8244, 8253, "TRAINED_CATEGORY"], [8255, 8266, "TRAINED_CATEGORY"], [8268, 8276, "TRAINED_CATEGORY"], [8278, 8289, "TRAINED_CATEGORY"], [8291, 8306, "TRAINED_CATEGORY"], [8312, 8328, "TRAINED_CATEGORY"], [8330, 8347, "TRAINED_CATEGORY"], [8354, 8377, "TRAINED_CATEGORY"], [8382, 8391, "TRAINED_CATEGORY"], [8393, 8397, "TRAINED_CATEGORY"], [8423, 8435, "TRAINED_CATEGORY"], [8477, 8507, "TRAINED_CATEGORY"], [8509, 8524, "TRAINED_CATEGORY"], [8533, 8549, "TRAINED_CATEGORY"], [8553, 8565, "TRAINED_CATEGORY"], [8570, 8583, "TRAINED_CATEGORY"], [8601, 8622, "TRAINED_CATEGORY"], [8627, 8641, "TRAINED_CATEGORY"], [8643, 8650, "TRAINED_CATEGORY"], [8664, 8678, "TRAINED_CATEGORY"], [8696, 8705, "TRAINED_CATEGORY"], [8717, 8731, "TRAINED_CATEGORY"], [8762, 8796, "TRAINED_CATEGORY"], [8800, 8808, "TRAINED_CATEGORY"], [8815, 8825, "TRAINED_CATEGORY"], [8829, 8849, "TRAINED_CATEGORY"], [8853, 8874, "TRAINED_CATEGORY"], [8887, 8892, "TRAINED_CATEGORY"], [8896, 8906, "TRAINED_CATEGORY"], [8935, 8940, "TRAINED_CATEGORY"], [8944, 8949, "TRAINED_CATEGORY"], [8951, 8962, "TRAINED_CATEGORY"], [8966, 8978, "TRAINED_CATEGORY"], [8982, 8990, "TRAINED_CATEGORY"], [8995, 9002, "TRAINED_CATEGORY"], [9018, 9031, "TRAINED_CATEGORY"], [9098, 9103, "TRAINED_CATEGORY"], [9120, 9130, "TRAINED_CATEGORY"], [9134, 9144, "TRAINED_CATEGORY"], [9146, 9152, "TRAINED_CATEGORY"], [9156, 9168, "TRAINED_CATEGORY"], [9172, 9177, "TRAINED_CATEGORY"], [9210, 9217, "TRAINED_CATEGORY"], [9221, 9229, "TRAINED_CATEGORY"], [9240, 9254, "TRAINED_CATEGORY"], [9258, 9266, "TRAINED_CATEGORY"], [9268, 9277, "TRAINED_CATEGORY"], [9281, 9287, "TRAINED_CATEGORY"], [9297, 9304, "TRAINED_CATEGORY"], [9306, 9312, "TRAINED_CATEGORY"], [9328, 9338, "TRAINED_CATEGORY"], [9352, 9359, "TRAINED_CATEGORY"], [9363, 9375, "TRAINED_CATEGORY"], [9379, 9400, "TRAINED_CATEGORY"], [9404, 9418, "TRAINED_CATEGORY"], [9420, 9429, "TRAINED_CATEGORY"], [9433, 9439, "TRAINED_CATEGORY"], [9479, 9489, "TRAINED_CATEGORY"], [9493, 9506, "TRAINED_CATEGORY"], [9517, 9528, "TRAINED_CATEGORY"], [9532, 9545, "TRAINED_CATEGORY"], [9549, 9560, "TRAINED_CATEGORY"], [9562, 9576, "TRAINED_CATEGORY"], [9580, 9586, "TRAINED_CATEGORY"], [9596, 9608, "TRAINED_CATEGORY"], [9622, 9637, "TRAINED_CATEGORY"], [9641, 9651, "TRAINED_CATEGORY"], [9653, 9658, "TRAINED_CATEGORY"], [9696, 9708, "TRAINED_CATEGORY"], [9713, 9721, "TRAINED_CATEGORY"], [9725, 9738, "TRAINED_CATEGORY"], [9748, 9760, "TRAINED_CATEGORY"], [9762, 9767, "TRAINED_CATEGORY"], [9799, 9812, "TRAINED_CATEGORY"], [9819, 9828, "TRAINED_CATEGORY"], [9832, 9838, "TRAINED_CATEGORY"], [9853, 9862, "TRAINED_CATEGORY"], [9889, 9893, "TRAINED_CATEGORY"], [9899, 9906, "TRAINED_CATEGORY"], [9910, 9920, "TRAINED_CATEGORY"], [9931, 9940, "TRAINED_CATEGORY"], [9954, 9969, "TRAINED_CATEGORY"], [9970, 9984, "TRAINED_CATEGORY"], [9994, 9996, "TRAINED_CATEGORY"], [10006, 10016, "TRAINED_CATEGORY"], [10035, 10060, "TRAINED_CATEGORY"], [10067, 10080, "TRAINED_CATEGORY"], [10096, 10103, "TRAINED_CATEGORY"], [10107, 10121, "TRAINED_CATEGORY"], [10127, 10135, "TRAINED_CATEGORY"], [10154, 10161, "TRAINED_CATEGORY"], [10165, 10177, "TRAINED_CATEGORY"], [10179, 10184, "TRAINED_CATEGORY"], [10208, 10230, "TRAINED_CATEGORY"], [10234, 10256, "TRAINED_CATEGORY"], [10289, 10309, "TRAINED_CATEGORY"], [10313, 10317, "TRAINED_CATEGORY"], [10321, 10326, "TRAINED_CATEGORY"], [10334, 10348, "TRAINED_CATEGORY"], [10352, 10368, "TRAINED_CATEGORY"], [10375, 10384, "TRAINED_CATEGORY"], [10388, 10407, "TRAINED_CATEGORY"], [10422, 10431, "TRAINED_CATEGORY"], [10465, 10469, "TRAINED_CATEGORY"], [10475, 10482, "TRAINED_CATEGORY"], [10486, 10496, "TRAINED_CATEGORY"], [10507, 10516, "TRAINED_CATEGORY"], [10522, 10524, "TRAINED_CATEGORY"], [10545, 10555, "TRAINED_CATEGORY"], [10561, 10570, "TRAINED_CATEGORY"], [10575, 10591, "TRAINED_CATEGORY"], [10596, 10607, "TRAINED_CATEGORY"], [10682, 10702, "TRAINED_CATEGORY"], [10704, 10711, "TRAINED_CATEGORY"], [10755, 10759, "TRAINED_CATEGORY"], [10761, 10784, "TRAINED_CATEGORY"], [10792, 10808, "TRAINED_CATEGORY"], [10824, 10838, "TRAINED_CATEGORY"], [10842, 10851, "TRAINED_CATEGORY"], [10879, 10887, "TRAINED_CATEGORY"], [10889, 10901, "TRAINED_CATEGORY"], [10911, 10927, "TRAINED_CATEGORY"], [10933, 10949, "TRAINED_CATEGORY"], [10958, 10967, "TRAINED_CATEGORY"], [10971, 10979, "TRAINED_CATEGORY"], [10981, 10984, "TRAINED_CATEGORY"], [10984, 10994, "TRAINED_CATEGORY"], [10997, 11005, "TRAINED_CATEGORY"], [11010, 11017, "TRAINED_CATEGORY"], [11019, 11033, "TRAINED_CATEGORY"], [11042, 11063, "TRAINED_CATEGORY"], [11076, 11097, "TRAINED_CATEGORY"], [11118, 11124, "TRAINED_CATEGORY"], [11133, 11149, "TRAINED_CATEGORY"], [11156, 11175, "TRAINED_CATEGORY"], [11191, 11211, "TRAINED_CATEGORY"], [11213, 11227, "TRAINED_CATEGORY"], [11250, 11264, "TRAINED_CATEGORY"], [11291, 11312, "TRAINED_CATEGORY"], [11316, 11332, "TRAINED_CATEGORY"], [11339, 11354, "TRAINED_CATEGORY"], [11373, 11376, "TRAINED_CATEGORY"], [11378, 11385, "TRAINED_CATEGORY"], [11387, 11395, "TRAINED_CATEGORY"], [11398, 11406, "TRAINED_CATEGORY"], [11409, 11414, "TRAINED_CATEGORY"], [11418, 11425, "TRAINED_CATEGORY"], [11426, 11434, "TRAINED_CATEGORY"], [11437, 11450, "TRAINED_CATEGORY"], [11453, 11458, "TRAINED_CATEGORY"], [11465, 11475, "TRAINED_CATEGORY"], [11476, 11483, "TRAINED_CATEGORY"], [11487, 11493, "TRAINED_CATEGORY"], [11509, 11514, "TRAINED_CATEGORY"], [11518, 11522, "TRAINED_CATEGORY"], [11535, 11538, "TRAINED_CATEGORY"], [11553, 11566, "TRAINED_CATEGORY"], [11572, 11586, "TRAINED_CATEGORY"], [11596, 11599, "TRAINED_CATEGORY"], [11601, 11607, "TRAINED_CATEGORY"], [11610, 11618, "TRAINED_CATEGORY"], [11623, 11642, "TRAINED_CATEGORY"], [11645, 11662, "TRAINED_CATEGORY"], [11680, 11686, "TRAINED_CATEGORY"], [11690, 11699, "TRAINED_CATEGORY"], [11703, 11708, "TRAINED_CATEGORY"], [11737, 11741, "TRAINED_CATEGORY"], [11760, 11782, "TRAINED_CATEGORY"], [11794, 11810, "TRAINED_CATEGORY"], [11828, 11852, "TRAINED_CATEGORY"], [11854, 11857, "TRAINED_CATEGORY"], [11879, 11881, "TRAINED_CATEGORY"], [11884, 11906, "TRAINED_CATEGORY"], [11910, 11919, "TRAINED_CATEGORY"], [11943, 11961, "TRAINED_CATEGORY"], [11966, 11989, "TRAINED_CATEGORY"], [11991, 12007, "TRAINED_CATEGORY"], [12038, 12056, "TRAINED_CATEGORY"], [12061, 12083, "TRAINED_CATEGORY"], [12087, 12096, "TRAINED_CATEGORY"], [12113, 12133, "TRAINED_CATEGORY"], [12143, 12158, "TRAINED_CATEGORY"], [12162, 12177, "TRAINED_CATEGORY"], [12187, 12193, "TRAINED_CATEGORY"], [12198, 12209, "TRAINED_CATEGORY"], [12217, 12228, "TRAINED_CATEGORY"], [12240, 12258, "TRAINED_CATEGORY"], [12311, 12328, "TRAINED_CATEGORY"], [12332, 12353, "TRAINED_CATEGORY"], [12358, 12377, "TRAINED_CATEGORY"], [12379, 12394, "TRAINED_CATEGORY"], [12418, 12425, "TRAINED_CATEGORY"], [12431, 12442, "TRAINED_CATEGORY"], [12444, 12448, "TRAINED_CATEGORY"], [12459, 12477, "TRAINED_CATEGORY"], [12482, 12492, "TRAINED_CATEGORY"], [12510, 12525, "TRAINED_CATEGORY"], [12530, 12540, "TRAINED_CATEGORY"], [12544, 12555, "TRAINED_CATEGORY"], [12560, 12564, "TRAINED_CATEGORY"], [12584, 12588, "TRAINED_CATEGORY"], [12597, 12610, "TRAINED_CATEGORY"], [12612, 12623, "TRAINED_CATEGORY"], [12632, 12650, "TRAINED_CATEGORY"], [12656, 12677, "TRAINED_CATEGORY"], [12679, 12699, "TRAINED_CATEGORY"], [12722, 12732, "TRAINED_CATEGORY"], [12736, 12747, "TRAINED_CATEGORY"], [12749, 12766, "TRAINED_CATEGORY"], [12789, 12795, "TRAINED_CATEGORY"], [12799, 12819, "TRAINED_CATEGORY"], [12834, 12851, "TRAINED_CATEGORY"], [12863, 12876, "TRAINED_CATEGORY"], [12890, 12906, "TRAINED_CATEGORY"], [12946, 12956, "TRAINED_CATEGORY"], [12993, 13005, "TRAINED_CATEGORY"], [13007, 13016, "TRAINED_CATEGORY"], [13044, 13063, "TRAINED_CATEGORY"], [13090, 13097, "TRAINED_CATEGORY"], [13138, 13142, "TRAINED_CATEGORY"], [13155, 13174, "TRAINED_CATEGORY"], [13192, 13211, "TRAINED_CATEGORY"], [13217, 13231, "TRAINED_CATEGORY"], [13274, 13282, "TRAINED_CATEGORY"], [13283, 13291, "TRAINED_CATEGORY"], [13295, 13308, "TRAINED_CATEGORY"], [13321, 13341, "TRAINED_CATEGORY"], [13359, 13381, "TRAINED_CATEGORY"], [13383, 13388, "TRAINED_CATEGORY"], [13399, 13405, "TRAINED_CATEGORY"], [13409, 13414, "TRAINED_CATEGORY"], [13432, 13444, "TRAINED_CATEGORY"], [13451, 13467, "TRAINED_CATEGORY"], [13478, 13489, "TRAINED_CATEGORY"], [13495, 13503, "TRAINED_CATEGORY"], [13524, 13535, "TRAINED_CATEGORY"], [13553, 13573, "TRAINED_CATEGORY"], [13578, 13599, "TRAINED_CATEGORY"], [13603, 13624, "TRAINED_CATEGORY"], [13641, 13645, "TRAINED_CATEGORY"], [13651, 13677, "TRAINED_CATEGORY"], [13687, 13710, "TRAINED_CATEGORY"], [13716, 13742, "TRAINED_CATEGORY"], [13744, 13746, "TRAINED_CATEGORY"], [13759, 13763, "TRAINED_CATEGORY"], [13779, 13800, "TRAINED_CATEGORY"], [13807, 13814, "TRAINED_CATEGORY"], [13826, 13831, "TRAINED_CATEGORY"], [13836, 13853, "TRAINED_CATEGORY"], [13868, 13887, "TRAINED_CATEGORY"], [13903, 13920, "TRAINED_CATEGORY"], [13926, 13954, "TRAINED_CATEGORY"], [13970, 13972, "TRAINED_CATEGORY"], [13979, 13983, "TRAINED_CATEGORY"], [13984, 13998, "TRAINED_CATEGORY"], [14002, 14007, "TRAINED_CATEGORY"], [14019, 14034, "TRAINED_CATEGORY"], [14044, 14059, "TRAINED_CATEGORY"], [14061, 14082, "TRAINED_CATEGORY"], [14089, 14101, "TRAINED_CATEGORY"], [14113, 14118, "TRAINED_CATEGORY"], [14126, 14138, "TRAINED_CATEGORY"], [14145, 14165, "TRAINED_CATEGORY"], [14176, 14180, "TRAINED_CATEGORY"], [14199, 14203, "TRAINED_CATEGORY"], [14207, 14222, "TRAINED_CATEGORY"], [14250, 14268, "TRAINED_CATEGORY"], [14270, 14275, "TRAINED_CATEGORY"], [14289, 14302, "TRAINED_CATEGORY"], [14311, 14315, "TRAINED_CATEGORY"], [14364, 14369, "TRAINED_CATEGORY"], [14386, 14412, "TRAINED_CATEGORY"], [14416, 14422, "TRAINED_CATEGORY"], [14468, 14475, "TRAINED_CATEGORY"], [14477, 14496, "TRAINED_CATEGORY"], [14507, 14532, "TRAINED_CATEGORY"], [14538, 14542, "TRAINED_CATEGORY"], [14548, 14553, "TRAINED_CATEGORY"], [14571, 14583, "TRAINED_CATEGORY"], [14584, 14605, "TRAINED_CATEGORY"], [14628, 14659, "TRAINED_CATEGORY"], [14661, 14663, "TRAINED_CATEGORY"], [14685, 14691, "TRAINED_CATEGORY"], [14705, 14713, "TRAINED_CATEGORY"], [14719, 14728, "TRAINED_CATEGORY"], [14732, 14749, "TRAINED_CATEGORY"], [14753, 14765, "TRAINED_CATEGORY"], [14788, 14797, "TRAINED_CATEGORY"], [14819, 14840, "TRAINED_CATEGORY"], [14849, 14910, "TRAINED_CATEGORY"], [14923, 14938, "TRAINED_CATEGORY"], [14965, 14981, "TRAINED_CATEGORY"], [14985, 15001, "TRAINED_CATEGORY"], [15011, 15032, "TRAINED_CATEGORY"], [15035, 15062, "TRAINED_CATEGORY"], [15066, 15075, "TRAINED_CATEGORY"], [15097, 15110, "TRAINED_CATEGORY"], [15112, 15114, "TRAINED_CATEGORY"], [15120, 15140, "TRAINED_CATEGORY"], [15145, 15158, "TRAINED_CATEGORY"], [15174, 15190, "TRAINED_CATEGORY"], [15194, 15203, "TRAINED_CATEGORY"], [15209, 15216, "TRAINED_CATEGORY"], [15258, 15284, "TRAINED_CATEGORY"], [15309, 15325, "TRAINED_CATEGORY"], [15331, 15347, "TRAINED_CATEGORY"], [15363, 15374, "TRAINED_CATEGORY"], [15378, 15397, "TRAINED_CATEGORY"], [15411, 15430, "TRAINED_CATEGORY"], [15434, 15451, "TRAINED_CATEGORY"], [15462, 15464, "TRAINED_CATEGORY"], [15478, 15498, "TRAINED_CATEGORY"], [15542, 15554, "TRAINED_CATEGORY"], [15558, 15567, "TRAINED_CATEGORY"], [15584, 15594, "TRAINED_CATEGORY"], [15604, 15616, "TRAINED_CATEGORY"], [15620, 15641, "TRAINED_CATEGORY"], [15643, 15645, "TRAINED_CATEGORY"], [15666, 15676, "TRAINED_CATEGORY"], [15681, 15689, "TRAINED_CATEGORY"], [15713, 15729, "TRAINED_CATEGORY"], [15734, 15735, "TRAINED_CATEGORY"], [15736, 15746, "TRAINED_CATEGORY"], [15755, 15770, "TRAINED_CATEGORY"], [15774, 15791, "TRAINED_CATEGORY"], [15794, 15815, "TRAINED_CATEGORY"], [15819, 15829, "TRAINED_CATEGORY"], [15831, 15887, "TRAINED_CATEGORY"], [15888, 15897, "TRAINED_CATEGORY"], [15899, 15923, "TRAINED_CATEGORY"], [15927, 15949, "TRAINED_CATEGORY"], [15951, 15964, "TRAINED_CATEGORY"], [15973, 15983, "TRAINED_CATEGORY"], [15985, 16014, "TRAINED_CATEGORY"], [16019, 16044, "TRAINED_CATEGORY"], [16046, 16062, "TRAINED_CATEGORY"], [16067, 16083, "TRAINED_CATEGORY"], [16096, 16127, "TRAINED_CATEGORY"], [16128, 16145, "TRAINED_CATEGORY"], [16147, 16151, "TRAINED_CATEGORY"], [16153, 16158, "TRAINED_CATEGORY"], [16160, 16178, "TRAINED_CATEGORY"], [16182, 16186, "TRAINED_CATEGORY"], [16191, 16214, "TRAINED_CATEGORY"], [16216, 16220, "TRAINED_CATEGORY"], [16222, 16225, "TRAINED_CATEGORY"], [16245, 16292, "TRAINED_CATEGORY"], [16297, 16311, "TRAINED_CATEGORY"], [16313, 16326, "TRAINED_CATEGORY"], [16335, 16342, "TRAINED_CATEGORY"], [16344, 16345, "TRAINED_CATEGORY"], [16350, 16354, "TRAINED_CATEGORY"], [16356, 16371, "TRAINED_CATEGORY"], [16375, 16385, "TRAINED_CATEGORY"], [16387, 16400, "TRAINED_CATEGORY"], [16402, 16421, "TRAINED_CATEGORY"], [16438, 16472, "TRAINED_CATEGORY"], [16492, 16507, "TRAINED_CATEGORY"], [16509, 16513, "TRAINED_CATEGORY"], [16517, 16542, "TRAINED_CATEGORY"], [16559, 16569, "TRAINED_CATEGORY"], [16571, 16592, "TRAINED_CATEGORY"], [16600, 16626, "TRAINED_CATEGORY"], [16634, 16697, "TRAINED_CATEGORY"], [16699, 16707, "TRAINED_CATEGORY"], [16709, 16761, "TRAINED_CATEGORY"], [16763, 16795, "TRAINED_CATEGORY"], [16808, 16818, "TRAINED_CATEGORY"], [16830, 16834, "TRAINED_CATEGORY"], [16838, 16851, "TRAINED_CATEGORY"], [16856, 16858, "TRAINED_CATEGORY"], [16879, 16895, "TRAINED_CATEGORY"], [16897, 16907, "TRAINED_CATEGORY"], [16912, 16922, "TRAINED_CATEGORY"], [16924, 16934, "TRAINED_CATEGORY"], [16936, 16958, "TRAINED_CATEGORY"], [16960, 16973, "TRAINED_CATEGORY"], [16975, 16992, "TRAINED_CATEGORY"], [16999, 17009, "TRAINED_CATEGORY"], [17011, 17064, "TRAINED_CATEGORY"], [17066, 17079, "TRAINED_CATEGORY"], [17095, 17109, "TRAINED_CATEGORY"], [17111, 17123, "TRAINED_CATEGORY"], [17125, 17161, "TRAINED_CATEGORY"], [17163, 17176, "TRAINED_CATEGORY"], [17199, 17209, "TRAINED_CATEGORY"], [17215, 17226, "TRAINED_CATEGORY"], [17228, 17235, "TRAINED_CATEGORY"], [17239, 17255, "TRAINED_CATEGORY"], [17275, 17305, "TRAINED_CATEGORY"], [17306, 17309, "TRAINED_CATEGORY"], [17311, 17317, "TRAINED_CATEGORY"], [17320, 17334, "TRAINED_CATEGORY"], [17336, 17339, "TRAINED_CATEGORY"], [17346, 17350, "TRAINED_CATEGORY"], [17351, 17382, "TRAINED_CATEGORY"], [17387, 17397, "TRAINED_CATEGORY"], [17399, 17425, "TRAINED_CATEGORY"], [17427, 17445, "TRAINED_CATEGORY"], [17449, 17469, "TRAINED_CATEGORY"], [17470, 17485, "TRAINED_CATEGORY"], [17488, 17490, "TRAINED_CATEGORY"], [17495, 17544, "TRAINED_CATEGORY"], [17547, 17557, "TRAINED_CATEGORY"], [17558, 17561, "TRAINED_CATEGORY"], [17562, 17580, "TRAINED_CATEGORY"], [17582, 17593, "TRAINED_CATEGORY"], [17625, 17628, "TRAINED_CATEGORY"], [17630, 17641, "TRAINED_CATEGORY"], [343, 349, "ORG"], [477, 481, "ORG"], [575, 579, "ORG"], [875, 883, "GPE"], [2312, 2316, "ORG"], [2602, 2609, "ORG"], [2611, 2614, "ORG"], [2616, 2620, "ORG"], [2622, 2649, "ORG"], [2661, 2670, "ORG"], [3039, 3044, "CARDINAL"], [3238, 3264, "ORG"], [3457, 3466, "ORG"], [3731, 3740, "ORG"], [3745, 3748, "CARDINAL"], [4328, 4332, "ORG"], [4751, 4754, "CARDINAL"], [4762, 4767, "ORDINAL"], [4809, 4811, "CARDINAL"], [4883, 4888, "ORDINAL"], [5058, 5067, "PERSON"], [5688, 5693, "ORDINAL"], [6009, 6017, "DATE"], [6093, 6105, "NORP"], [6274, 6277, "CARDINAL"], [7211, 7214, "CARDINAL"], [7272, 7277, "CARDINAL"], [7992, 7995, "CARDINAL"], [7999, 8004, "CARDINAL"], [9698, 9702, "CARDINAL"], [10234, 10237, "CARDINAL"], [10626, 10647, "ORG"], [10676, 10680, "ORG"], [10713, 10717, "ORG"], [10761, 10784, "ORG"], [10786, 10790, "ORG"], [10792, 10808, "ORG"], [10893, 10896, "ORG"], [10987, 10994, "WORK_OF_ART"], [11010, 11017, "WORK_OF_ART"], [11020, 11033, "WORK_OF_ART"], [11378, 11385, "PERSON"], [11388, 11395, "WORK_OF_ART"], [11427, 11434, "PERSON"], [11437, 11450, "WORK_OF_ART"], [11476, 11483, "PERSON"], [11509, 11514, "ORG"], [11518, 11522, "ORG"], [11535, 11538, "ORG"], [11602, 11607, "WORK_OF_ART"], [11737, 11741, "NORP"], [12911, 12916, "ORDINAL"], [13553, 13563, "LOC"], [15775, 15791, "WORK_OF_ART"], [15794, 15829, "ORG"], [15888, 15897, "GPE"], [15899, 15923, "ORG"], [15951, 15964, "ORG"], [15966, 15970, "DATE"], [15973, 15983, "PERSON"], [15985, 16014, "ORG"], [16071, 16074, "ORG"], [16085, 16094, "DATE"], [16147, 16151, "PERSON"], [16160, 16214, "WORK_OF_ART"], [16216, 16220, "GPE"], [16226, 16228, "CARDINAL"], [16230, 16231, "CARDINAL"], [16233, 16243, "DATE"], [16245, 16268, "PERSON"], [16313, 16326, "ORG"], [16328, 16332, "DATE"], [16335, 16342, "PERSON"], [16344, 16345, "ORG"], [16350, 16354, "ORG"], [16402, 16421, "ORG"], [16423, 16431, "GPE"], [16432, 16436, "DATE"], [16438, 16442, "PERSON"], [16444, 16449, "GPE"], [16451, 16455, "DATE"], [16458, 16464, "ORG"], [16474, 16480, "GPE"], [16482, 16490, "GPE"], [16492, 16507, "ORG"], [16509, 16513, "ORG"], [16514, 16517, "CARDINAL"], [16532, 16542, "GPE"], [16544, 16557, "ORG"], [16559, 16569, "PERSON"], [16628, 16632, "DATE"], [16641, 16656, "PERSON"], [16709, 16761, "ORG"], [16763, 16795, "ORG"], [16797, 16806, "GPE"], [16808, 16818, "PERSON"], [16873, 16877, "DATE"], [16879, 16895, "ORG"], [16897, 16907, "PERSON"], [16912, 16922, "ORG"], [16924, 16934, "PERSON"], [16967, 16973, "ORG"], [16975, 16992, "ORG"], [16993, 16997, "DATE"], [16999, 17009, "PERSON"], [17011, 17015, "ORG"], [17066, 17079, "PERSON"], [17081, 17085, "DATE"], [17089, 17093, "DATE"], [17095, 17109, "PERSON"], [17111, 17123, "PERSON"], [17163, 17176, "ORG"], [17177, 17182, "CARDINAL"], [17185, 17190, "DATE"], [17193, 17197, "DATE"], [17199, 17209, "PERSON"], [17215, 17226, "PERSON"], [17243, 17246, "ORG"], [17306, 17309, "ORG"], [17311, 17314, "ORDINAL"], [17315, 17318, "GPE"], [17320, 17334, "PERSON"], [17340, 17344, "DATE"], [17351, 17354, "CARDINAL"], [17369, 17382, "PERSON"], [17387, 17397, "PERSON"], [17399, 17425, "ORG"], [17427, 17445, "ORG"], [17471, 17477, "ORDINAL"], [17491, 17494, "CARDINAL"], [17510, 17524, "PERSON"], [17525, 17544, "PERSON"], [17547, 17550, "ORG"], [17582, 17598, "ORG"], [17625, 17628, "ORG"], [17630, 17641, "PERSON"]]}], ["Bibliography (from Ancient Greek: \u03b2\u03b9\u03b2\u03bb\u03af\u03bf\u03bd, romanized: biblion, lit. 'book' and -\u03b3\u03c1\u03b1\u03c6\u03af\u03b1, -graph\u00eda, 'writing'), as a discipline, is traditionally the academic study of books as physical, cultural objects; in this sense, it is also known as bibliology (from Ancient Greek: -\u03bb\u03bf\u03b3\u03af\u03b1, romanized: -log\u00eda). Carter and Barker (2010) describe bibliography as a twofold scholarly discipline\u2014the organized listing of books (enumerative bibliography) and the systematic description of books as objects (descriptive bibliography).\n\n\n== Etymology ==\nThe word bibliographia\u2009(\u03b2\u03b9\u03b2\u03bb\u03b9\u03bf\u03b3\u03c1\u03b1\u03c6\u03af\u03b1) was used by Greek writers in the first three centuries CE to mean the copying of books by hand. In the 12th century, the word started being used for \"the intellectual activity of composing books.\" The 17th century then saw the emergence of the modern meaning, that of description of books. Currently, the field of bibliography has expanded to include studies that consider the book as a material object. Bibliography, in its systematic pursuit of understanding the past and the present through written and printed documents, describes a way and means of extracting information from this material. Bibliographers are interested in comparing versions of texts to each other rather than in interpreting their meaning or assessing their significance.\n\n\n== Field of study ==\nBibliography is a specialized aspect of library science (or library and information science, LIS) and documentation science. It was established by a Belgian, named Paul Otlet (1868\u20131944), who was the founder of the field of documentation, as a branch of the information sciences, who wrote about \"the science of bibliography.\" However, there have recently been voices claiming that \"the bibliographical paradigm\" is obsolete, and it is not today common in LIS. A defence of the bibliographical paradigm was provided by Hj\u00f8rland (2007).The quantitative study of bibliographies is known as bibliometrics, which is today an influential subfield in LIS and is used for major collection decisions such as the cancellation of big deals, through data analysis tools like Unpaywall Journals.\n\n\n== Branches ==\nCarter and Barker (2010) describe bibliography as a twofold scholarly discipline\u2014the organized listing of books (enumerative bibliography) and the systematic description of books as physical objects (descriptive bibliography). These two distinct concepts and practices have separate rationales and serve differing purposes. Innovators and originators in the field include W. W. Greg, Fredson Bowers, Philip Gaskell and G. Thomas Tanselle.\nBowers (1949) refers to enumerative bibliography as a procedure that identifies books in \u201cspecific collections or libraries,\u201d in a specific discipline, by an author, printer, or period of production (3). He refers to descriptive bibliography as the systematic description of a book as a material or physical artefact. Analytical bibliography, the cornerstone of descriptive bibliography, investigates the printing and all physical features of a book that yield evidence establishing a book's history and transmission (Feather 10). It is the preliminary phase of bibliographic description and provides the vocabulary, principles and techniques of analysis that descriptive bibliographers apply and on which they base their descriptive practice.\nDescriptive bibliographers follow specific conventions and associated classification in their description. Titles and title pages are transcribed in a quasi-facsimile style and representation. Illustration, typeface, binding, paper, and all physical elements related to identifying a book follow formulaic conventions, as Bowers established in his foundational opus, The Principles of Bibliographic Description. The thought expressed in this book expands substantively on W. W. Greg's groundbreaking theory that argued for the adoption of formal bibliographic principles (Greg 29). Fundamentally, analytical bibliography is concerned with objective, physical analysis and history of a book while descriptive bibliography employs all data that analytical bibliography furnishes and then codifies it with a view to identifying the ideal copy or form of a book that most nearly represents the printer's initial conception and intention in printing.\nIn addition to viewing bibliographic study as being composed of four interdependent approaches (enumerative, descriptive, analytical, and textual), Bowers notes two further subcategories of research, namely historical bibliography and aesthetic bibliography. Both historical bibliography, which involves the investigation of printing practices, tools, and related documents, and aesthetic bibliography, which examines the art of designing type and books, are often employed by analytical bibliographers.\nD. F. McKenzie extended previous notions of bibliography as set forth by Greg, Bowers, Gaskell and Tanselle. He describes the nature of bibliography as \"the discipline that studies texts as recorded forms, and the processes of their transmission, including their production and reception\" (1999 12). This concept broadens the scope of bibliography to include \"non-book texts\" and an accounting for their material form and structure, as well as textual variations, technical and production processes that bring sociocultural context and effects into play. McKenzie's perspective contextualizes textual objects or artefacts with sociological and technical factors that have an effect on production, transmission and, ultimately, ideal copy (2002 14). Bibliography, generally, concerns the material conditions of books [as well as other texts] how they are designed, edited, printed, circulated, reprinted, collected.Bibliographic works differ in the amount of detail depending on the purpose and can generally be divided into two categories: enumerative bibliography (also called compilative, reference or systematic), which results in an overview of publications in a particular category and analytical or critical bibliography, which studies the production of books. In earlier times, bibliography mostly focused on books. Now, both categories of bibliography cover works in other media including audio recordings, motion pictures and videos, graphic objects, databases, CD-ROMs and websites.\n\n\n=== Enumerative bibliography ===\n\nAn enumerative bibliography is a systematic list of books and other works such as journal articles. Bibliographies range from \"works cited\" lists at the end of books and articles, to complete and independent publications. A notable example of a complete, independent publication is Gow's A. E. Housman: A Sketch, Together with a List of His Classical Papers (1936). As separate works, they may be in bound volumes such as those shown on the right, or computerized bibliographic databases. A library catalog, while not referred to as a \"bibliography,\" is bibliographic in nature. Bibliographical works are almost always considered to be tertiary sources.\nEnumerative bibliographies are based on a unifying principle such as creator, subject, date, topic or other characteristic. An entry in an enumerative bibliography provides the core elements of a text resource including a title, the creator(s), publication date and place of publication. Belanger (1977) distinguishes an enumerative bibliography from other bibliographic forms such as descriptive bibliography, analytical bibliography or textual bibliography in that its function is to record and list, rather than describe a source in detail or with any reference to the source's physical nature, materiality or textual transmission. The enumerative list may be comprehensive or selective. One noted example would be Tanselle's bibliography that exhaustively enumerates topics and sources related to all forms of bibliography. A more common and particular instance of an enumerative bibliography relates to specific sources used or considered in preparing a scholarly paper or academic term paper.\nCitation styles vary.\nAn entry for a book in a bibliography usually contains the following elements:\n\ncreator(s)\ntitle\nplace of publication\npublisher or printer\ndate of publicationAn entry for a journal or periodical article usually contains:\n\ncreator(s)\narticle title\njournal title\nvolume\npages\ndate of publicationA bibliography may be arranged by author, topic, or some other scheme. Annotated bibliographies give descriptions about how each source is useful to an author in constructing a paper or argument. These descriptions, usually a few sentences long, provide a summary of the source and describe its relevance. Reference management software may be used to keep track of references and generate bibliographies as required.\nBibliographies differ from library catalogs by including only relevant items rather than all items present in a particular library. However, the catalogs of some national libraries effectively serve as national bibliographies, as the national libraries own almost all their countries' publications.\n\n\n=== Descriptive bibliography ===\nFredson Bowers described and formulated a standardized practice of descriptive bibliography in his Principles of Bibliographical Description\n(1949). Scholars to this day treat Bowers' scholarly guide as authoritative. In this classic text, Bowers describes the basic function of bibliography as, \"[providing] sufficient data so that a reader may identify the book described, understand the printing, and recognize the precise contents\" (124).\n\n\n==== Descriptive bibliographies as scholarly product ====\nDescriptive bibliographies as a scholarly product usually include information on the following aspect of a given book as a material object:\n\nFormat and Collation/Pagination Statement\u2014a conventional, symbolic formula that describes the book block in terms of sheets, folds, quires, signatures, and pagesAccording to Bowers (193), the format of a book is usually abbreviated in the collation formula:\nBroadsheet: I\u00b0 or b.s. or bs.\nFolio: 2\u00b0 or fol.\nQuarto: 4\u00b0 or 4to or Q\u00b0 or Q\nOctavo: 8\u00b0 or 8vo\nDuodecimo: 12\u00b0 or 12mo\nSexto-decimo: 16\u00b0 or 16mo\nTricesimo-secundo: 32\u00b0 or 32mo\nSexagesimo-quarto: 64\u00b0 or 64mo\nThe collation, which follows the format, is the statement of the order and size of the gatherings.\nFor example, a quarto that consists of the signed gatherings:\n2 leaves signed A, 4 leaves signed B, 4 leaves signed C, and 2 leaves signed D\nwould be represented in the collation formula:\n4\u00b0: A2B-C4D2Binding\u2014a description of the binding techniques (generally for books printed after 1800)\nTitle Page Transcription\u2014a transcription of the title page, including rule lines and ornaments\nContents\u2014a listing of the contents (by section) in the book\nPaper\u2014a description of the physical properties of the paper, including production process, an account of chain-line measurements, and a description of watermarks (if present)\nIllustrations\u2014a description of the illustrations found in the book, including printing process (e.g. woodblock, intaglio, etc.), measurements, and locations in the text\nPresswork\u2014miscellaneous details gleaned from the text about its production\nCopies Examined\u2014an enumeration of the copies examined, including those copies' location (i.e. belonging to which library or collector)\n\n\n=== Analytical bibliography ===\nThis branch of the bibliographic discipline examines the material features of a textual artefact\u2014such as type, ink, paper, imposition, format, impressions and states of a book\u2014to essentially recreate the conditions of its production. Analytical bibliography often uses collateral evidence\u2014such as general printing practices, trends in format, responses and non-responses to design, etc.\u2014to scrutinize the historical conventions and influences underlying the physical appearance of a text. The bibliographer utilizes knowledge gained from the investigation of physical evidence in the form of a descriptive bibliography or textual bibliography. Descriptive bibliography is the close examination and cataloging of a text as a physical object, recording its size, format, binding, and so on, while textual bibliography (or textual criticism) identifies variations\u2014and the aetiology of variations\u2014in a text with a view to determining \"the establishment of the most correct form of [a] text\" (Bowers 498[1]).\n\n\n== Bibliographers ==\n\nA bibliographer is a person who describes and lists books and other publications, with particular attention to such characteristics as authorship, publication date, edition, typography, etc. A person who limits such efforts to a specific field or discipline is a subject bibliographer.\"A bibliographer, in the technical meaning of the word, is anyone who writes about books. But the accepted meaning since at least the 18th century is a person who attempts a comprehensive account\u2014sometimes just a list, sometimes a fuller reckoning\u2014of the books written on a particular subject. In the present, bibliography is no longer a career, generally speaking; bibliographies tend to be written on highly specific subjects and by specialists in the field.\nThe term bibliographer is sometimes\u2014in particular subject bibliographer\u2014today used about certain roles performed in libraries and bibliographic databases.\nOne of the first bibliographers was Conrad Gessner who sought to list all books printed in Latin, Greek and Hebrew in Bibliotheca Universalis (1545).\n\n\n== Non-book material ==\nSystematic lists of media other than books can be referred to with terms formed analogously to bibliography:\n\nDiscography\u2014recorded music\nFilmography\u2014films\nWebography (or webliography)\u2014websitesArachniography is a term coined by NASA research historian Andrew J. Butrica, which means a reference list of URLs about a particular subject. It is equivalent to a bibliography in a book. The name derives from arachne in reference to a spider and its web.\n\n\n== See also ==\n\nBibliographic index \u2013 Resource for finding publications\nCitation \u2013 Reference to a source\nCitation creator\nHistory of books \u2013 Aspect of history\nIbid. \u2013 Latin footnote or endnote term referring to the previous source\nOp. cit.\nIndexing and abstracting service\nISO 690 \u2013 ISO standard for bibliographic referencing\nList of books (in Wikipedia)\nMetabibliography\nReference table\nLegal bibliography\nStyle guide\nTextual scholarship\n\n\n== Notes ==\n\n\n== References ==\n\n\n== Further reading ==\nBlum, Rudolf. (1980) Bibliographia. An Inquiry in Its Definition and Designations, Dawson, American Library Association.\nBowers, Fredson. (1995) Principles of Bibliographical Description, Oak Knoll Press.\nDuncan, Paul Shaner. (1973) How to Catalog a Rare Book, 2nd ed., rev., American Library Association.\nJohn Carter; Nicolas Barker (2004). \"Bibliography\". ABC for Book Collectors (8th ed.). Oak Knoll Press and British Library. ISBN 1-58456-112-2. \nGaskell, Philip. (2000) A New Introduction to Bibliography, Oak Knoll Press.\nMcKerrow, R. B. (1927) An Introduction to Bibliography for Literary Students, Oxford: Clarendon Press\nSchneider, Georg. (1934) Theory and History of Bibliography, New York: Scarecrow Press.\nNational Library of Canada, Committee on Bibliography and Information Services for the Social Sciences and Humanities, Guidelines for the Compilation of a Bibliography (National Library of Canada, 1987). N.B.: This is a brief guide to accurately practical bibliography, not a study concerning more precise and systematic bibliography.\nBritish Museum. Department of Printed Books (1881). Hand List of Bibliographies, Classified Catalogues, and Indexes Placed in the Reading Room of the British Museum for Reference. London: Printed by William Clowes and Sons.\nRobinson, A. M. Lewin (1966) Systematic Bibliography; rev. ed. London: Clive Bingley\n\n\n== External links ==\nOxford Bibliographies Online, in-depth annotated bibliographies by scholars in selected fields\nIntroduction to Bibliography, a comprehensive syllabus by G. Thomas Tanselle\nThe Bibliographical Society of America, a resource for information about current work in the field of bibliography\nStudies in Bibliography, the journal of the Bibliographical Society of the University of Virginia\nA Bibliography of Literary Theory, Criticism, and Philology, (University of Zaragoza) includes thousands of listings on literary, philological and other subjects", {"entities": [[0, 12, "TRAINED_CATEGORY"], [19, 32, "TRAINED_CATEGORY"], [34, 41, "TRAINED_CATEGORY"], [54, 61, "TRAINED_CATEGORY"], [63, 66, "TRAINED_CATEGORY"], [69, 96, "TRAINED_CATEGORY"], [113, 125, "TRAINED_CATEGORY"], [144, 162, "TRAINED_CATEGORY"], [166, 171, "TRAINED_CATEGORY"], [175, 201, "TRAINED_CATEGORY"], [206, 216, "TRAINED_CATEGORY"], [218, 220, "TRAINED_CATEGORY"], [238, 248, "TRAINED_CATEGORY"], [255, 268, "TRAINED_CATEGORY"], [298, 304, "TRAINED_CATEGORY"], [309, 315, "TRAINED_CATEGORY"], [332, 344, "TRAINED_CATEGORY"], [348, 378, "TRAINED_CATEGORY"], [379, 400, "TRAINED_CATEGORY"], [404, 409, "TRAINED_CATEGORY"], [411, 435, "TRAINED_CATEGORY"], [441, 467, "TRAINED_CATEGORY"], [471, 476, "TRAINED_CATEGORY"], [480, 487, "TRAINED_CATEGORY"], [489, 513, "TRAINED_CATEGORY"], [521, 530, "TRAINED_CATEGORY"], [534, 556, "TRAINED_CATEGORY"], [558, 570, "TRAINED_CATEGORY"], [584, 597, "TRAINED_CATEGORY"], [601, 626, "TRAINED_CATEGORY"], [627, 629, "TRAINED_CATEGORY"], [638, 649, "TRAINED_CATEGORY"], [653, 658, "TRAINED_CATEGORY"], [662, 666, "TRAINED_CATEGORY"], [671, 687, "TRAINED_CATEGORY"], [689, 697, "TRAINED_CATEGORY"], [722, 747, "TRAINED_CATEGORY"], [751, 766, "TRAINED_CATEGORY"], [769, 785, "TRAINED_CATEGORY"], [795, 808, "TRAINED_CATEGORY"], [812, 830, "TRAINED_CATEGORY"], [840, 851, "TRAINED_CATEGORY"], [855, 860, "TRAINED_CATEGORY"], [873, 882, "TRAINED_CATEGORY"], [886, 898, "TRAINED_CATEGORY"], [923, 930, "TRAINED_CATEGORY"], [945, 953, "TRAINED_CATEGORY"], [957, 974, "TRAINED_CATEGORY"], [976, 988, "TRAINED_CATEGORY"], [993, 1015, "TRAINED_CATEGORY"], [1033, 1041, "TRAINED_CATEGORY"], [1046, 1057, "TRAINED_CATEGORY"], [1066, 1095, "TRAINED_CATEGORY"], [1107, 1112, "TRAINED_CATEGORY"], [1117, 1122, "TRAINED_CATEGORY"], [1137, 1148, "TRAINED_CATEGORY"], [1154, 1167, "TRAINED_CATEGORY"], [1169, 1183, "TRAINED_CATEGORY"], [1212, 1220, "TRAINED_CATEGORY"], [1224, 1229, "TRAINED_CATEGORY"], [1272, 1285, "TRAINED_CATEGORY"], [1299, 1317, "TRAINED_CATEGORY"], [1324, 1329, "TRAINED_CATEGORY"], [1333, 1338, "TRAINED_CATEGORY"], [1342, 1354, "TRAINED_CATEGORY"], [1358, 1378, "TRAINED_CATEGORY"], [1382, 1397, "TRAINED_CATEGORY"], [1402, 1409, "TRAINED_CATEGORY"], [1414, 1433, "TRAINED_CATEGORY"], [1435, 1438, "TRAINED_CATEGORY"], [1444, 1465, "TRAINED_CATEGORY"], [1467, 1469, "TRAINED_CATEGORY"], [1489, 1498, "TRAINED_CATEGORY"], [1530, 1533, "TRAINED_CATEGORY"], [1538, 1549, "TRAINED_CATEGORY"], [1553, 1562, "TRAINED_CATEGORY"], [1566, 1579, "TRAINED_CATEGORY"], [1584, 1592, "TRAINED_CATEGORY"], [1596, 1620, "TRAINED_CATEGORY"], [1622, 1625, "TRAINED_CATEGORY"], [1639, 1650, "TRAINED_CATEGORY"], [1654, 1666, "TRAINED_CATEGORY"], [1703, 1709, "TRAINED_CATEGORY"], [1725, 1753, "TRAINED_CATEGORY"], [1772, 1774, "TRAINED_CATEGORY"], [1798, 1801, "TRAINED_CATEGORY"], [1803, 1812, "TRAINED_CATEGORY"], [1816, 1844, "TRAINED_CATEGORY"], [1861, 1869, "TRAINED_CATEGORY"], [1871, 1899, "TRAINED_CATEGORY"], [1903, 1917, "TRAINED_CATEGORY"], [1930, 1943, "TRAINED_CATEGORY"], [1960, 1983, "TRAINED_CATEGORY"], [1987, 1990, "TRAINED_CATEGORY"], [2007, 2033, "TRAINED_CATEGORY"], [2042, 2058, "TRAINED_CATEGORY"], [2062, 2071, "TRAINED_CATEGORY"], [2081, 2100, "TRAINED_CATEGORY"], [2106, 2124, "TRAINED_CATEGORY"], [2131, 2139, "TRAINED_CATEGORY"], [2143, 2149, "TRAINED_CATEGORY"], [2154, 2160, "TRAINED_CATEGORY"], [2177, 2189, "TRAINED_CATEGORY"], [2193, 2223, "TRAINED_CATEGORY"], [2224, 2245, "TRAINED_CATEGORY"], [2249, 2254, "TRAINED_CATEGORY"], [2256, 2280, "TRAINED_CATEGORY"], [2286, 2312, "TRAINED_CATEGORY"], [2316, 2321, "TRAINED_CATEGORY"], [2325, 2341, "TRAINED_CATEGORY"], [2343, 2367, "TRAINED_CATEGORY"], [2370, 2397, "TRAINED_CATEGORY"], [2402, 2411, "TRAINED_CATEGORY"], [2417, 2436, "TRAINED_CATEGORY"], [2447, 2465, "TRAINED_CATEGORY"], [2467, 2477, "TRAINED_CATEGORY"], [2482, 2493, "TRAINED_CATEGORY"], [2497, 2506, "TRAINED_CATEGORY"], [2515, 2525, "TRAINED_CATEGORY"], [2527, 2541, "TRAINED_CATEGORY"], [2543, 2557, "TRAINED_CATEGORY"], [2562, 2580, "TRAINED_CATEGORY"], [2582, 2588, "TRAINED_CATEGORY"], [2618, 2630, "TRAINED_CATEGORY"], [2634, 2645, "TRAINED_CATEGORY"], [2662, 2667, "TRAINED_CATEGORY"], [2672, 2692, "TRAINED_CATEGORY"], [2696, 2705, "TRAINED_CATEGORY"], [2711, 2732, "TRAINED_CATEGORY"], [2737, 2746, "TRAINED_CATEGORY"], [2748, 2755, "TRAINED_CATEGORY"], [2760, 2766, "TRAINED_CATEGORY"], [2770, 2780, "TRAINED_CATEGORY"], [2786, 2788, "TRAINED_CATEGORY"], [2799, 2823, "TRAINED_CATEGORY"], [2827, 2853, "TRAINED_CATEGORY"], [2857, 2863, "TRAINED_CATEGORY"], [2867, 2898, "TRAINED_CATEGORY"], [2900, 2923, "TRAINED_CATEGORY"], [2925, 2940, "TRAINED_CATEGORY"], [2944, 2968, "TRAINED_CATEGORY"], [2983, 2995, "TRAINED_CATEGORY"], [3000, 3021, "TRAINED_CATEGORY"], [3025, 3031, "TRAINED_CATEGORY"], [3043, 3051, "TRAINED_CATEGORY"], [3065, 3081, "TRAINED_CATEGORY"], [3086, 3098, "TRAINED_CATEGORY"], [3100, 3107, "TRAINED_CATEGORY"], [3113, 3115, "TRAINED_CATEGORY"], [3119, 3140, "TRAINED_CATEGORY"], [3144, 3169, "TRAINED_CATEGORY"], [3183, 3197, "TRAINED_CATEGORY"], [3199, 3209, "TRAINED_CATEGORY"], [3214, 3224, "TRAINED_CATEGORY"], [3228, 3236, "TRAINED_CATEGORY"], [3242, 3268, "TRAINED_CATEGORY"], [3288, 3292, "TRAINED_CATEGORY"], [3298, 3324, "TRAINED_CATEGORY"], [3326, 3352, "TRAINED_CATEGORY"], [3360, 3380, "TRAINED_CATEGORY"], [3385, 3410, "TRAINED_CATEGORY"], [3414, 3431, "TRAINED_CATEGORY"], [3433, 3439, "TRAINED_CATEGORY"], [3444, 3455, "TRAINED_CATEGORY"], [3475, 3498, "TRAINED_CATEGORY"], [3503, 3517, "TRAINED_CATEGORY"], [3519, 3531, "TRAINED_CATEGORY"], [3533, 3541, "TRAINED_CATEGORY"], [3543, 3550, "TRAINED_CATEGORY"], [3552, 3557, "TRAINED_CATEGORY"], [3563, 3584, "TRAINED_CATEGORY"], [3608, 3643, "TRAINED_CATEGORY"], [3648, 3654, "TRAINED_CATEGORY"], [3670, 3691, "TRAINED_CATEGORY"], [3693, 3707, "TRAINED_CATEGORY"], [3711, 3736, "TRAINED_CATEGORY"], [3738, 3749, "TRAINED_CATEGORY"], [3763, 3772, "TRAINED_CATEGORY"], [3798, 3832, "TRAINED_CATEGORY"], [3849, 3861, "TRAINED_CATEGORY"], [3865, 3896, "TRAINED_CATEGORY"], [3898, 3902, "TRAINED_CATEGORY"], [3923, 3946, "TRAINED_CATEGORY"], [3976, 3993, "TRAINED_CATEGORY"], [3998, 4005, "TRAINED_CATEGORY"], [4009, 4015, "TRAINED_CATEGORY"], [4022, 4046, "TRAINED_CATEGORY"], [4055, 4063, "TRAINED_CATEGORY"], [4121, 4123, "TRAINED_CATEGORY"], [4129, 4135, "TRAINED_CATEGORY"], [4151, 4165, "TRAINED_CATEGORY"], [4169, 4173, "TRAINED_CATEGORY"], [4177, 4183, "TRAINED_CATEGORY"], [4212, 4244, "TRAINED_CATEGORY"], [4249, 4258, "TRAINED_CATEGORY"], [4262, 4270, "TRAINED_CATEGORY"], [4275, 4283, "TRAINED_CATEGORY"], [4295, 4314, "TRAINED_CATEGORY"], [4336, 4366, "TRAINED_CATEGORY"], [4420, 4426, "TRAINED_CATEGORY"], [4433, 4458, "TRAINED_CATEGORY"], [4462, 4470, "TRAINED_CATEGORY"], [4472, 4502, "TRAINED_CATEGORY"], [4507, 4529, "TRAINED_CATEGORY"], [4531, 4559, "TRAINED_CATEGORY"], [4576, 4593, "TRAINED_CATEGORY"], [4597, 4615, "TRAINED_CATEGORY"], [4617, 4622, "TRAINED_CATEGORY"], [4628, 4645, "TRAINED_CATEGORY"], [4651, 4673, "TRAINED_CATEGORY"], [4690, 4697, "TRAINED_CATEGORY"], [4711, 4715, "TRAINED_CATEGORY"], [4720, 4725, "TRAINED_CATEGORY"], [4749, 4774, "TRAINED_CATEGORY"], [4776, 4790, "TRAINED_CATEGORY"], [4800, 4816, "TRAINED_CATEGORY"], [4820, 4832, "TRAINED_CATEGORY"], [4849, 4853, "TRAINED_CATEGORY"], [4855, 4861, "TRAINED_CATEGORY"], [4863, 4870, "TRAINED_CATEGORY"], [4875, 4883, "TRAINED_CATEGORY"], [4885, 4887, "TRAINED_CATEGORY"], [4898, 4908, "TRAINED_CATEGORY"], [4912, 4924, "TRAINED_CATEGORY"], [4929, 4943, "TRAINED_CATEGORY"], [4957, 4962, "TRAINED_CATEGORY"], [4966, 4980, "TRAINED_CATEGORY"], [5003, 5021, "TRAINED_CATEGORY"], [5033, 5049, "TRAINED_CATEGORY"], [5054, 5063, "TRAINED_CATEGORY"], [5076, 5088, "TRAINED_CATEGORY"], [5098, 5107, "TRAINED_CATEGORY"], [5111, 5123, "TRAINED_CATEGORY"], [5136, 5150, "TRAINED_CATEGORY"], [5156, 5169, "TRAINED_CATEGORY"], [5174, 5193, "TRAINED_CATEGORY"], [5198, 5207, "TRAINED_CATEGORY"], [5220, 5238, "TRAINED_CATEGORY"], [5240, 5274, "TRAINED_CATEGORY"], [5286, 5307, "TRAINED_CATEGORY"], [5312, 5319, "TRAINED_CATEGORY"], [5325, 5329, "TRAINED_CATEGORY"], [5331, 5353, "TRAINED_CATEGORY"], [5369, 5384, "TRAINED_CATEGORY"], [5388, 5397, "TRAINED_CATEGORY"], [5403, 5437, "TRAINED_CATEGORY"], [5448, 5457, "TRAINED_CATEGORY"], [5461, 5471, "TRAINED_CATEGORY"], [5473, 5485, "TRAINED_CATEGORY"], [5501, 5513, "TRAINED_CATEGORY"], [5525, 5537, "TRAINED_CATEGORY"], [5559, 5582, "TRAINED_CATEGORY"], [5586, 5591, "TRAINED_CATEGORY"], [5604, 5615, "TRAINED_CATEGORY"], [5621, 5625, "TRAINED_CATEGORY"], [5690, 5709, "TRAINED_CATEGORY"], [5720, 5730, "TRAINED_CATEGORY"], [5734, 5740, "TRAINED_CATEGORY"], [5754, 5765, "TRAINED_CATEGORY"], [5800, 5814, "TRAINED_CATEGORY"], [5816, 5840, "TRAINED_CATEGORY"], [5910, 5921, "TRAINED_CATEGORY"], [5925, 5937, "TRAINED_CATEGORY"], [5941, 5962, "TRAINED_CATEGORY"], [5967, 6002, "TRAINED_CATEGORY"], [6018, 6032, "TRAINED_CATEGORY"], [6036, 6041, "TRAINED_CATEGORY"], [6046, 6059, "TRAINED_CATEGORY"], [6061, 6073, "TRAINED_CATEGORY"], [6092, 6097, "TRAINED_CATEGORY"], [6104, 6119, "TRAINED_CATEGORY"], [6123, 6135, "TRAINED_CATEGORY"], [6142, 6147, "TRAINED_CATEGORY"], [6151, 6162, "TRAINED_CATEGORY"], [6173, 6189, "TRAINED_CATEGORY"], [6191, 6206, "TRAINED_CATEGORY"], [6211, 6217, "TRAINED_CATEGORY"], [6219, 6234, "TRAINED_CATEGORY"], [6236, 6245, "TRAINED_CATEGORY"], [6247, 6254, "TRAINED_CATEGORY"], [6259, 6267, "TRAINED_CATEGORY"], [6275, 6299, "TRAINED_CATEGORY"], [6305, 6332, "TRAINED_CATEGORY"], [6336, 6353, "TRAINED_CATEGORY"], [6357, 6362, "TRAINED_CATEGORY"], [6367, 6378, "TRAINED_CATEGORY"], [6387, 6403, "TRAINED_CATEGORY"], [6405, 6419, "TRAINED_CATEGORY"], [6431, 6450, "TRAINED_CATEGORY"], [6454, 6461, "TRAINED_CATEGORY"], [6465, 6470, "TRAINED_CATEGORY"], [6475, 6483, "TRAINED_CATEGORY"], [6513, 6525, "TRAINED_CATEGORY"], [6527, 6544, "TRAINED_CATEGORY"], [6548, 6583, "TRAINED_CATEGORY"], [6587, 6606, "TRAINED_CATEGORY"], [6608, 6616, "TRAINED_CATEGORY"], [6632, 6638, "TRAINED_CATEGORY"], [6642, 6662, "TRAINED_CATEGORY"], [6674, 6688, "TRAINED_CATEGORY"], [6690, 6694, "TRAINED_CATEGORY"], [6705, 6718, "TRAINED_CATEGORY"], [6742, 6751, "TRAINED_CATEGORY"], [6769, 6792, "TRAINED_CATEGORY"], [6794, 6811, "TRAINED_CATEGORY"], [6838, 6853, "TRAINED_CATEGORY"], [6876, 6882, "TRAINED_CATEGORY"], [6884, 6905, "TRAINED_CATEGORY"], [6941, 6957, "TRAINED_CATEGORY"], [6959, 6985, "TRAINED_CATEGORY"], [6999, 7019, "TRAINED_CATEGORY"], [7028, 7035, "TRAINED_CATEGORY"], [7037, 7044, "TRAINED_CATEGORY"], [7046, 7050, "TRAINED_CATEGORY"], [7052, 7057, "TRAINED_CATEGORY"], [7061, 7081, "TRAINED_CATEGORY"], [7083, 7091, "TRAINED_CATEGORY"], [7095, 7122, "TRAINED_CATEGORY"], [7132, 7149, "TRAINED_CATEGORY"], [7153, 7168, "TRAINED_CATEGORY"], [7179, 7186, "TRAINED_CATEGORY"], [7188, 7220, "TRAINED_CATEGORY"], [7225, 7230, "TRAINED_CATEGORY"], [7234, 7245, "TRAINED_CATEGORY"], [7247, 7255, "TRAINED_CATEGORY"], [7277, 7304, "TRAINED_CATEGORY"], [7310, 7335, "TRAINED_CATEGORY"], [7344, 7368, "TRAINED_CATEGORY"], [7370, 7393, "TRAINED_CATEGORY"], [7397, 7417, "TRAINED_CATEGORY"], [7426, 7438, "TRAINED_CATEGORY"], [7483, 7491, "TRAINED_CATEGORY"], [7495, 7501, "TRAINED_CATEGORY"], [7510, 7523, "TRAINED_CATEGORY"], [7527, 7555, "TRAINED_CATEGORY"], [7557, 7568, "TRAINED_CATEGORY"], [7572, 7592, "TRAINED_CATEGORY"], [7594, 7614, "TRAINED_CATEGORY"], [7650, 7667, "TRAINED_CATEGORY"], [7677, 7700, "TRAINED_CATEGORY"], [7730, 7736, "TRAINED_CATEGORY"], [7741, 7748, "TRAINED_CATEGORY"], [7760, 7769, "TRAINED_CATEGORY"], [7773, 7785, "TRAINED_CATEGORY"], [7787, 7824, "TRAINED_CATEGORY"], [7828, 7855, "TRAINED_CATEGORY"], [7867, 7883, "TRAINED_CATEGORY"], [7916, 7933, "TRAINED_CATEGORY"], [7937, 7956, "TRAINED_CATEGORY"], [7958, 7973, "TRAINED_CATEGORY"], [7980, 7988, "TRAINED_CATEGORY"], [7993, 7999, "TRAINED_CATEGORY"], [8003, 8017, "TRAINED_CATEGORY"], [8035, 8057, "TRAINED_CATEGORY"], [8071, 8076, "TRAINED_CATEGORY"], [8077, 8082, "TRAINED_CATEGORY"], [8086, 8097, "TRAINED_CATEGORY"], [8098, 8107, "TRAINED_CATEGORY"], [8111, 8118, "TRAINED_CATEGORY"], [8119, 8123, "TRAINED_CATEGORY"], [8127, 8146, "TRAINED_CATEGORY"], [8151, 8160, "TRAINED_CATEGORY"], [8164, 8182, "TRAINED_CATEGORY"], [8202, 8253, "TRAINED_CATEGORY"], [8254, 8258, "TRAINED_CATEGORY"], [8262, 8287, "TRAINED_CATEGORY"], [8307, 8313, "TRAINED_CATEGORY"], [8315, 8320, "TRAINED_CATEGORY"], [8325, 8342, "TRAINED_CATEGORY"], [8344, 8368, "TRAINED_CATEGORY"], [8374, 8386, "TRAINED_CATEGORY"], [8397, 8408, "TRAINED_CATEGORY"], [8422, 8431, "TRAINED_CATEGORY"], [8448, 8455, "TRAINED_CATEGORY"], [8459, 8467, "TRAINED_CATEGORY"], [8469, 8487, "TRAINED_CATEGORY"], [8527, 8536, "TRAINED_CATEGORY"], [8540, 8550, "TRAINED_CATEGORY"], [8564, 8577, "TRAINED_CATEGORY"], [8579, 8608, "TRAINED_CATEGORY"], [8629, 8634, "TRAINED_CATEGORY"], [8638, 8648, "TRAINED_CATEGORY"], [8662, 8676, "TRAINED_CATEGORY"], [8690, 8704, "TRAINED_CATEGORY"], [8717, 8733, "TRAINED_CATEGORY"], [8747, 8766, "TRAINED_CATEGORY"], [8779, 8788, "TRAINED_CATEGORY"], [8800, 8820, "TRAINED_CATEGORY"], [8831, 8843, "TRAINED_CATEGORY"], [8847, 8870, "TRAINED_CATEGORY"], [8892, 8915, "TRAINED_CATEGORY"], [8920, 8942, "TRAINED_CATEGORY"], [8947, 8987, "TRAINED_CATEGORY"], [8995, 9019, "TRAINED_CATEGORY"], [9024, 9038, "TRAINED_CATEGORY"], [9064, 9087, "TRAINED_CATEGORY"], [9091, 9115, "TRAINED_CATEGORY"], [9119, 9133, "TRAINED_CATEGORY"], [9137, 9164, "TRAINED_CATEGORY"], [9173, 9181, "TRAINED_CATEGORY"], [9185, 9193, "TRAINED_CATEGORY"], [9200, 9223, "TRAINED_CATEGORY"], [9245, 9262, "TRAINED_CATEGORY"], [9264, 9270, "TRAINED_CATEGORY"], [9281, 9299, "TRAINED_CATEGORY"], [9303, 9315, "TRAINED_CATEGORY"], [9333, 9348, "TRAINED_CATEGORY"], [9357, 9365, "TRAINED_CATEGORY"], [9379, 9387, "TRAINED_CATEGORY"], [9410, 9422, "TRAINED_CATEGORY"], [9438, 9458, "TRAINED_CATEGORY"], [9474, 9500, "TRAINED_CATEGORY"], [9504, 9521, "TRAINED_CATEGORY"], [9527, 9553, "TRAINED_CATEGORY"], [9557, 9576, "TRAINED_CATEGORY"], [9593, 9604, "TRAINED_CATEGORY"], [9608, 9628, "TRAINED_CATEGORY"], [9632, 9644, "TRAINED_CATEGORY"], [9648, 9665, "TRAINED_CATEGORY"], [9668, 9674, "TRAINED_CATEGORY"], [9679, 9709, "TRAINED_CATEGORY"], [9710, 9742, "TRAINED_CATEGORY"], [9758, 9772, "TRAINED_CATEGORY"], [9776, 9781, "TRAINED_CATEGORY"], [9785, 9791, "TRAINED_CATEGORY"], [9793, 9798, "TRAINED_CATEGORY"], [9800, 9806, "TRAINED_CATEGORY"], [9808, 9818, "TRAINED_CATEGORY"], [9842, 9848, "TRAINED_CATEGORY"], [9856, 9866, "TRAINED_CATEGORY"], [9870, 9876, "TRAINED_CATEGORY"], [9903, 9924, "TRAINED_CATEGORY"], [9926, 9936, "TRAINED_CATEGORY"], [9938, 9939, "TRAINED_CATEGORY"], [9944, 9948, "TRAINED_CATEGORY"], [9952, 9954, "TRAINED_CATEGORY"], [9956, 9961, "TRAINED_CATEGORY"], [9963, 9965, "TRAINED_CATEGORY"], [9969, 9972, "TRAINED_CATEGORY"], [9974, 9980, "TRAINED_CATEGORY"], [9982, 9984, "TRAINED_CATEGORY"], [9988, 9991, "TRAINED_CATEGORY"], [9995, 9996, "TRAINED_CATEGORY"], [9996, 9997, "TRAINED_CATEGORY"], [10001, 10002, "TRAINED_CATEGORY"], [10003, 10009, "TRAINED_CATEGORY"], [10011, 10013, "TRAINED_CATEGORY"], [10017, 10020, "TRAINED_CATEGORY"], [10021, 10030, "TRAINED_CATEGORY"], [10032, 10035, "TRAINED_CATEGORY"], [10039, 10043, "TRAINED_CATEGORY"], [10044, 10056, "TRAINED_CATEGORY"], [10058, 10061, "TRAINED_CATEGORY"], [10065, 10069, "TRAINED_CATEGORY"], [10070, 10087, "TRAINED_CATEGORY"], [10089, 10092, "TRAINED_CATEGORY"], [10101, 10118, "TRAINED_CATEGORY"], [10120, 10123, "TRAINED_CATEGORY"], [10127, 10131, "TRAINED_CATEGORY"], [10132, 10145, "TRAINED_CATEGORY"], [10161, 10171, "TRAINED_CATEGORY"], [10176, 10189, "TRAINED_CATEGORY"], [10193, 10202, "TRAINED_CATEGORY"], [10207, 10211, "TRAINED_CATEGORY"], [10215, 10229, "TRAINED_CATEGORY"], [10235, 10242, "TRAINED_CATEGORY"], [10244, 10252, "TRAINED_CATEGORY"], [10270, 10291, "TRAINED_CATEGORY"], [10293, 10301, "TRAINED_CATEGORY"], [10310, 10320, "TRAINED_CATEGORY"], [10331, 10339, "TRAINED_CATEGORY"], [10347, 10348, "TRAINED_CATEGORY"], [10354, 10362, "TRAINED_CATEGORY"], [10370, 10371, "TRAINED_CATEGORY"], [10396, 10417, "TRAINED_CATEGORY"], [10419, 10421, "TRAINED_CATEGORY"], [10423, 10438, "TRAINED_CATEGORY"], [10439, 10452, "TRAINED_CATEGORY"], [10456, 10478, "TRAINED_CATEGORY"], [10494, 10499, "TRAINED_CATEGORY"], [10520, 10544, "TRAINED_CATEGORY"], [10545, 10560, "TRAINED_CATEGORY"], [10564, 10578, "TRAINED_CATEGORY"], [10590, 10600, "TRAINED_CATEGORY"], [10605, 10614, "TRAINED_CATEGORY"], [10615, 10623, "TRAINED_CATEGORY"], [10624, 10633, "TRAINED_CATEGORY"], [10637, 10649, "TRAINED_CATEGORY"], [10654, 10661, "TRAINED_CATEGORY"], [10666, 10674, "TRAINED_CATEGORY"], [10675, 10680, "TRAINED_CATEGORY"], [10681, 10694, "TRAINED_CATEGORY"], [10698, 10721, "TRAINED_CATEGORY"], [10725, 10734, "TRAINED_CATEGORY"], [10746, 10764, "TRAINED_CATEGORY"], [10766, 10776, "TRAINED_CATEGORY"], [10780, 10803, "TRAINED_CATEGORY"], [10809, 10822, "TRAINED_CATEGORY"], [10826, 10836, "TRAINED_CATEGORY"], [10850, 10863, "TRAINED_CATEGORY"], [10864, 10877, "TRAINED_CATEGORY"], [10881, 10898, "TRAINED_CATEGORY"], [10908, 10916, "TRAINED_CATEGORY"], [10928, 10944, "TRAINED_CATEGORY"], [10945, 10960, "TRAINED_CATEGORY"], [10962, 10970, "TRAINED_CATEGORY"], [10979, 10991, "TRAINED_CATEGORY"], [10997, 11006, "TRAINED_CATEGORY"], [11010, 11018, "TRAINED_CATEGORY"], [11019, 11028, "TRAINED_CATEGORY"], [11029, 11050, "TRAINED_CATEGORY"], [11064, 11072, "TRAINED_CATEGORY"], [11079, 11093, "TRAINED_CATEGORY"], [11110, 11124, "TRAINED_CATEGORY"], [11128, 11138, "TRAINED_CATEGORY"], [11159, 11181, "TRAINED_CATEGORY"], [11201, 11214, "TRAINED_CATEGORY"], [11218, 11227, "TRAINED_CATEGORY"], [11235, 11258, "TRAINED_CATEGORY"], [11263, 11274, "TRAINED_CATEGORY"], [11278, 11306, "TRAINED_CATEGORY"], [11316, 11337, "TRAINED_CATEGORY"], [11341, 11359, "TRAINED_CATEGORY"], [11368, 11372, "TRAINED_CATEGORY"], [11374, 11377, "TRAINED_CATEGORY"], [11379, 11384, "TRAINED_CATEGORY"], [11386, 11396, "TRAINED_CATEGORY"], [11398, 11404, "TRAINED_CATEGORY"], [11406, 11417, "TRAINED_CATEGORY"], [11422, 11428, "TRAINED_CATEGORY"], [11432, 11438, "TRAINED_CATEGORY"], [11463, 11477, "TRAINED_CATEGORY"], [11481, 11495, "TRAINED_CATEGORY"], [11497, 11520, "TRAINED_CATEGORY"], [11532, 11551, "TRAINED_CATEGORY"], [11560, 11586, "TRAINED_CATEGORY"], [11588, 11594, "TRAINED_CATEGORY"], [11598, 11604, "TRAINED_CATEGORY"], [11606, 11615, "TRAINED_CATEGORY"], [11620, 11633, "TRAINED_CATEGORY"], [11645, 11652, "TRAINED_CATEGORY"], [11664, 11690, "TRAINED_CATEGORY"], [11695, 11705, "TRAINED_CATEGORY"], [11717, 11740, "TRAINED_CATEGORY"], [11744, 11750, "TRAINED_CATEGORY"], [11752, 11769, "TRAINED_CATEGORY"], [11779, 11788, "TRAINED_CATEGORY"], [11801, 11818, "TRAINED_CATEGORY"], [11822, 11839, "TRAINED_CATEGORY"], [11843, 11851, "TRAINED_CATEGORY"], [11855, 11881, "TRAINED_CATEGORY"], [11885, 11905, "TRAINED_CATEGORY"], [11907, 11931, "TRAINED_CATEGORY"], [11935, 11956, "TRAINED_CATEGORY"], [11961, 11971, "TRAINED_CATEGORY"], [11975, 11981, "TRAINED_CATEGORY"], [11985, 12002, "TRAINED_CATEGORY"], [12014, 12022, "TRAINED_CATEGORY"], [12024, 12030, "TRAINED_CATEGORY"], [12058, 12078, "TRAINED_CATEGORY"], [12083, 12100, "TRAINED_CATEGORY"], [12145, 12155, "TRAINED_CATEGORY"], [12159, 12165, "TRAINED_CATEGORY"], [12171, 12177, "TRAINED_CATEGORY"], [12194, 12211, "TRAINED_CATEGORY"], [12215, 12236, "TRAINED_CATEGORY"], [12240, 12248, "TRAINED_CATEGORY"], [12250, 12257, "TRAINED_CATEGORY"], [12272, 12286, "TRAINED_CATEGORY"], [12291, 12306, "TRAINED_CATEGORY"], [12310, 12318, "TRAINED_CATEGORY"], [12319, 12322, "TRAINED_CATEGORY"], [12343, 12348, "TRAINED_CATEGORY"], [12353, 12371, "TRAINED_CATEGORY"], [12378, 12398, "TRAINED_CATEGORY"], [12402, 12422, "TRAINED_CATEGORY"], [12426, 12436, "TRAINED_CATEGORY"], [12438, 12454, "TRAINED_CATEGORY"], [12456, 12463, "TRAINED_CATEGORY"], [12465, 12475, "TRAINED_CATEGORY"], [12482, 12490, "TRAINED_CATEGORY"], [12491, 12494, "TRAINED_CATEGORY"], [12502, 12514, "TRAINED_CATEGORY"], [12518, 12534, "TRAINED_CATEGORY"], [12538, 12548, "TRAINED_CATEGORY"], [12552, 12575, "TRAINED_CATEGORY"], [12576, 12592, "TRAINED_CATEGORY"], [12597, 12618, "TRAINED_CATEGORY"], [12622, 12630, "TRAINED_CATEGORY"], [12635, 12641, "TRAINED_CATEGORY"], [12642, 12645, "TRAINED_CATEGORY"], [12659, 12664, "TRAINED_CATEGORY"], [12670, 12690, "TRAINED_CATEGORY"], [12697, 12722, "TRAINED_CATEGORY"], [12726, 12734, "TRAINED_CATEGORY"], [12735, 12738, "TRAINED_CATEGORY"], [12748, 12771, "TRAINED_CATEGORY"], [12772, 12793, "TRAINED_CATEGORY"], [12795, 12823, "TRAINED_CATEGORY"], [12827, 12836, "TRAINED_CATEGORY"], [12848, 12868, "TRAINED_CATEGORY"], [12873, 12884, "TRAINED_CATEGORY"], [12886, 12898, "TRAINED_CATEGORY"], [12912, 12920, "TRAINED_CATEGORY"], [12942, 12956, "TRAINED_CATEGORY"], [12979, 13003, "TRAINED_CATEGORY"], [13011, 13022, "TRAINED_CATEGORY"], [13026, 13035, "TRAINED_CATEGORY"], [13037, 13059, "TRAINED_CATEGORY"], [13076, 13108, "TRAINED_CATEGORY"], [13126, 13139, "TRAINED_CATEGORY"], [13153, 13162, "TRAINED_CATEGORY"], [13167, 13190, "TRAINED_CATEGORY"], [13199, 13223, "TRAINED_CATEGORY"], [13228, 13242, "TRAINED_CATEGORY"], [13243, 13246, "TRAINED_CATEGORY"], [13262, 13271, "TRAINED_CATEGORY"], [13283, 13288, "TRAINED_CATEGORY"], [13290, 13295, "TRAINED_CATEGORY"], [13300, 13306, "TRAINED_CATEGORY"], [13310, 13333, "TRAINED_CATEGORY"], [13347, 13364, "TRAINED_CATEGORY"], [13368, 13384, "TRAINED_CATEGORY"], [13388, 13393, "TRAINED_CATEGORY"], [13405, 13410, "TRAINED_CATEGORY"], [13435, 13440, "TRAINED_CATEGORY"], [13463, 13475, "TRAINED_CATEGORY"], [13478, 13489, "TRAINED_CATEGORY"], [13490, 13504, "TRAINED_CATEGORY"], [13505, 13516, "TRAINED_CATEGORY"], [13523, 13533, "TRAINED_CATEGORY"], [13538, 13574, "TRAINED_CATEGORY"], [13578, 13584, "TRAINED_CATEGORY"], [13595, 13636, "TRAINED_CATEGORY"], [13650, 13666, "TRAINED_CATEGORY"], [13670, 13674, "TRAINED_CATEGORY"], [13681, 13701, "TRAINED_CATEGORY"], [13703, 13705, "TRAINED_CATEGORY"], [13723, 13737, "TRAINED_CATEGORY"], [13741, 13747, "TRAINED_CATEGORY"], [13749, 13757, "TRAINED_CATEGORY"], [13771, 13778, "TRAINED_CATEGORY"], [13782, 13791, "TRAINED_CATEGORY"], [13795, 13803, "TRAINED_CATEGORY"], [13808, 13815, "TRAINED_CATEGORY"], [13835, 13854, "TRAINED_CATEGORY"], [13857, 13865, "TRAINED_CATEGORY"], [13878, 13890, "TRAINED_CATEGORY"], [13891, 13911, "TRAINED_CATEGORY"], [13915, 13923, "TRAINED_CATEGORY"], [13924, 13940, "TRAINED_CATEGORY"], [13941, 13948, "TRAINED_CATEGORY"], [13952, 13957, "TRAINED_CATEGORY"], [13960, 13966, "TRAINED_CATEGORY"], [13970, 13977, "TRAINED_CATEGORY"], [13978, 13982, "TRAINED_CATEGORY"], [14030, 14049, "TRAINED_CATEGORY"], [14050, 14052, "TRAINED_CATEGORY"], [14054, 14057, "TRAINED_CATEGORY"], [14059, 14067, "TRAINED_CATEGORY"], [14084, 14091, "TRAINED_CATEGORY"], [14092, 14095, "TRAINED_CATEGORY"], [14102, 14114, "TRAINED_CATEGORY"], [14119, 14144, "TRAINED_CATEGORY"], [14145, 14149, "TRAINED_CATEGORY"], [14153, 14158, "TRAINED_CATEGORY"], [14163, 14172, "TRAINED_CATEGORY"], [14174, 14206, "TRAINED_CATEGORY"], [14207, 14225, "TRAINED_CATEGORY"], [14226, 14237, "TRAINED_CATEGORY"], [14238, 14257, "TRAINED_CATEGORY"], [14263, 14268, "TRAINED_CATEGORY"], [14277, 14287, "TRAINED_CATEGORY"], [14296, 14311, "TRAINED_CATEGORY"], [14315, 14319, "TRAINED_CATEGORY"], [14329, 14349, "TRAINED_CATEGORY"], [14351, 14361, "TRAINED_CATEGORY"], [14365, 14434, "TRAINED_CATEGORY"], [14436, 14442, "TRAINED_CATEGORY"], [14453, 14470, "TRAINED_CATEGORY"], [14474, 14501, "TRAINED_CATEGORY"], [14503, 14518, "TRAINED_CATEGORY"], [14520, 14526, "TRAINED_CATEGORY"], [14563, 14574, "TRAINED_CATEGORY"], [14591, 14619, "TRAINED_CATEGORY"], [14621, 14632, "TRAINED_CATEGORY"], [14634, 14648, "TRAINED_CATEGORY"], [14657, 14670, "TRAINED_CATEGORY"], [14673, 14676, "TRAINED_CATEGORY"], [14681, 14696, "TRAINED_CATEGORY"], [14698, 14704, "TRAINED_CATEGORY"], [14708, 14723, "TRAINED_CATEGORY"], [14728, 14743, "TRAINED_CATEGORY"], [14745, 14749, "TRAINED_CATEGORY"], [14766, 14773, "TRAINED_CATEGORY"], [14790, 14808, "TRAINED_CATEGORY"], [14812, 14824, "TRAINED_CATEGORY"], [14826, 14841, "TRAINED_CATEGORY"], [14843, 14851, "TRAINED_CATEGORY"], [14853, 14858, "TRAINED_CATEGORY"], [14866, 14881, "TRAINED_CATEGORY"], [14885, 14897, "TRAINED_CATEGORY"], [14902, 14919, "TRAINED_CATEGORY"], [14921, 14927, "TRAINED_CATEGORY"], [14929, 14944, "TRAINED_CATEGORY"], [14970, 14976, "TRAINED_CATEGORY"], [14981, 14988, "TRAINED_CATEGORY"], [14992, 15004, "TRAINED_CATEGORY"], [15006, 15014, "TRAINED_CATEGORY"], [15016, 15031, "TRAINED_CATEGORY"], [15033, 15049, "TRAINED_CATEGORY"], [15053, 15059, "TRAINED_CATEGORY"], [15061, 15070, "TRAINED_CATEGORY"], [15074, 15111, "TRAINED_CATEGORY"], [15116, 15135, "TRAINED_CATEGORY"], [15140, 15150, "TRAINED_CATEGORY"], [15152, 15162, "TRAINED_CATEGORY"], [15167, 15182, "TRAINED_CATEGORY"], [15186, 15200, "TRAINED_CATEGORY"], [15202, 15218, "TRAINED_CATEGORY"], [15222, 15228, "TRAINED_CATEGORY"], [15237, 15241, "TRAINED_CATEGORY"], [15251, 15264, "TRAINED_CATEGORY"], [15268, 15301, "TRAINED_CATEGORY"], [15307, 15314, "TRAINED_CATEGORY"], [15326, 15366, "TRAINED_CATEGORY"], [15368, 15382, "TRAINED_CATEGORY"], [15384, 15394, "TRAINED_CATEGORY"], [15398, 15411, "TRAINED_CATEGORY"], [15420, 15429, "TRAINED_CATEGORY"], [15433, 15447, "TRAINED_CATEGORY"], [15449, 15470, "TRAINED_CATEGORY"], [15494, 15510, "TRAINED_CATEGORY"], [15514, 15532, "TRAINED_CATEGORY"], [15537, 15546, "TRAINED_CATEGORY"], [15548, 15554, "TRAINED_CATEGORY"], [15567, 15581, "TRAINED_CATEGORY"], [15586, 15590, "TRAINED_CATEGORY"], [15592, 15600, "TRAINED_CATEGORY"], [15602, 15613, "TRAINED_CATEGORY"], [15621, 15644, "TRAINED_CATEGORY"], [15644, 15653, "TRAINED_CATEGORY"], [15655, 15661, "TRAINED_CATEGORY"], [15663, 15676, "TRAINED_CATEGORY"], [15682, 15696, "TRAINED_CATEGORY"], [15700, 15721, "TRAINED_CATEGORY"], [15722, 15728, "TRAINED_CATEGORY"], [15728, 15738, "TRAINED_CATEGORY"], [15749, 15763, "TRAINED_CATEGORY"], [15767, 15775, "TRAINED_CATEGORY"], [15779, 15794, "TRAINED_CATEGORY"], [15795, 15807, "TRAINED_CATEGORY"], [15811, 15823, "TRAINED_CATEGORY"], [15825, 15849, "TRAINED_CATEGORY"], [15853, 15871, "TRAINED_CATEGORY"], [15872, 15899, "TRAINED_CATEGORY"], [15903, 15910, "TRAINED_CATEGORY"], [15912, 15922, "TRAINED_CATEGORY"], [15927, 15938, "TRAINED_CATEGORY"], [15945, 15957, "TRAINED_CATEGORY"], [15961, 15970, "TRAINED_CATEGORY"], [15974, 15986, "TRAINED_CATEGORY"], [15987, 15994, "TRAINED_CATEGORY"], [15998, 16010, "TRAINED_CATEGORY"], [16012, 16023, "TRAINED_CATEGORY"], [16027, 16054, "TRAINED_CATEGORY"], [16058, 16072, "TRAINED_CATEGORY"], [16076, 16084, "TRAINED_CATEGORY"], [16085, 16099, "TRAINED_CATEGORY"], [16103, 16118, "TRAINED_CATEGORY"], [16120, 16129, "TRAINED_CATEGORY"], [16135, 16144, "TRAINED_CATEGORY"], [16147, 16157, "TRAINED_CATEGORY"], [16161, 16169, "TRAINED_CATEGORY"], [16180, 16189, "TRAINED_CATEGORY"], [16193, 16201, "TRAINED_CATEGORY"], [16205, 16246, "TRAINED_CATEGORY"], [27, 32, "NORP"], [63, 66, "PERSON"], [263, 268, "NORP"], [298, 304, "PERSON"], [309, 315, "PERSON"], [317, 321, "DATE"], [584, 589, "NORP"], [601, 626, "DATE"], [671, 687, "DATE"], [769, 785, "DATE"], [1169, 1183, "ORG"], [1342, 1354, "PERSON"], [1491, 1498, "NORP"], [1506, 1516, "PERSON"], [1782, 1787, "DATE"], [1861, 1869, "PERSON"], [1954, 1959, "DATE"], [2106, 2115, "ORG"], [2143, 2149, "PERSON"], [2154, 2160, "PERSON"], [2162, 2166, "DATE"], [2376, 2379, "CARDINAL"], [2515, 2525, "PERSON"], [2527, 2541, "PERSON"], [2543, 2557, "PERSON"], [2562, 2580, "PERSON"], [2582, 2588, "PERSON"], [2590, 2594, "DATE"], [2782, 2783, "CARDINAL"], [3108, 3110, "CARDINAL"], [3648, 3654, "PERSON"], [3693, 3736, "WORK_OF_ART"], [3798, 3810, "PERSON"], [3898, 3905, "PERSON"], [4336, 4340, "CARDINAL"], [4420, 4426, "NORP"], [4433, 4436, "CARDINAL"], [4776, 4790, "PERSON"], [4849, 4853, "PERSON"], [4855, 4861, "NORP"], [4863, 4870, "GPE"], [4875, 4883, "PERSON"], [5066, 5073, "DATE"], [5331, 5339, "PERSON"], [5515, 5522, "DATE"], [5800, 5803, "CARDINAL"], [6587, 6606, "ORG"], [6664, 6668, "DATE"], [7257, 7261, "DATE"], [7650, 7653, "CARDINAL"], [7677, 7685, "PERSON"], [8127, 8140, "CARDINAL"], [8227, 8234, "ORG"], [8262, 8274, "PRODUCT"], [8995, 9006, "GPE"], [9024, 9038, "PERSON"], [9123, 9164, "WORK_OF_ART"], [9166, 9170, "DATE"], [9185, 9193, "DATE"], [9200, 9206, "PERSON"], [9264, 9270, "PRODUCT"], [9461, 9464, "CARDINAL"], [9474, 9485, "ORG"], [9668, 9709, "ORG"], [9842, 9848, "WORK_OF_ART"], [9850, 9853, "CARDINAL"], [9944, 9948, "GPE"], [9956, 9961, "PERSON"], [9963, 9964, "CARDINAL"], [9982, 9983, "CARDINAL"], [9988, 9991, "ORDINAL"], [9995, 9997, "GPE"], [10011, 10012, "CARDINAL"], [10017, 10020, "ORDINAL"], [10032, 10034, "CARDINAL"], [10034, 10035, "PRODUCT"], [10039, 10043, "DATE"], [10058, 10060, "CARDINAL"], [10065, 10069, "ORDINAL"], [10070, 10079, "GPE"], [10089, 10091, "CARDINAL"], [10096, 10100, "CARDINAL"], [10120, 10122, "CARDINAL"], [10127, 10131, "ORDINAL"], [10293, 10294, "CARDINAL"], [10312, 10313, "CARDINAL"], [10331, 10332, "CARDINAL"], [10354, 10355, "CARDINAL"], [10419, 10420, "CARDINAL"], [10514, 10518, "DATE"], [10520, 10544, "PERSON"], [10675, 10680, "WORK_OF_ART"], [10850, 10863, "ORG"], [11094, 11100, "ORG"], [11101, 11109, "PRODUCT"], [11235, 11245, "ORG"], [12251, 12257, "PRODUCT"], [12272, 12286, "GPE"], [12697, 12722, "DATE"], [13109, 13114, "DATE"], [13192, 13195, "CARDINAL"], [13203, 13208, "ORDINAL"], [13228, 13242, "PERSON"], [13283, 13288, "NORP"], [13290, 13295, "NORP"], [13300, 13306, "LANGUAGE"], [13310, 13333, "GPE"], [13335, 13339, "DATE"], [13478, 13489, "PERSON"], [13505, 13516, "PERSON"], [13523, 13533, "PERSON"], [13595, 13599, "ORG"], [13619, 13636, "PERSON"], [13835, 13848, "NORP"], [13986, 13991, "LANGUAGE"], [14163, 14172, "GPE"], [14174, 14190, "PERSON"], [14263, 14268, "PRODUCT"], [14315, 14319, "PRODUCT"], [14321, 14327, "PERSON"], [14330, 14334, "DATE"], [14336, 14349, "GPE"], [14398, 14404, "PERSON"], [14406, 14434, "ORG"], [14444, 14451, "PERSON"], [14454, 14458, "DATE"], [14460, 14501, "WORK_OF_ART"], [14503, 14518, "ORG"], [14520, 14526, "PERSON"], [14528, 14539, "PERSON"], [14542, 14546, "DATE"], [14576, 14579, "ORDINAL"], [14580, 14583, "GPE"], [14591, 14619, "ORG"], [14621, 14632, "PERSON"], [14634, 14648, "PERSON"], [14650, 14654, "DATE"], [14658, 14670, "PERSON"], [14681, 14696, "ORG"], [14698, 14701, "ORDINAL"], [14708, 14723, "ORG"], [14728, 14735, "NORP"], [14745, 14749, "ORG"], [14750, 14761, "CARDINAL"], [14766, 14773, "GPE"], [14775, 14781, "GPE"], [14784, 14788, "DATE"], [14812, 14824, "GPE"], [14826, 14841, "ORG"], [14843, 14851, "PERSON"], [14853, 14858, "PERSON"], [14860, 14864, "DATE"], [14866, 14919, "WORK_OF_ART"], [14929, 14954, "ORG"], [14956, 14961, "GPE"], [14964, 14968, "DATE"], [14992, 15004, "GPE"], [15006, 15014, "GPE"], [15016, 15031, "ORG"], [15033, 15059, "ORG"], [15061, 15111, "ORG"], [15116, 15135, "ORG"], [15230, 15234, "DATE"], [15237, 15241, "PERSON"], [15368, 15382, "ORG"], [15384, 15411, "ORG"], [15413, 15417, "DATE"], [15449, 15470, "ORG"], [15476, 15490, "PERSON"], [15494, 15510, "FAC"], [15514, 15546, "ORG"], [15548, 15554, "GPE"], [15567, 15581, "PERSON"], [15586, 15590, "ORG"], [15592, 15600, "PERSON"], [15602, 15613, "PERSON"], [15615, 15619, "DATE"], [15621, 15644, "PERSON"], [15651, 15653, "PERSON"], [15655, 15661, "GPE"], [15663, 15676, "PERSON"], [15682, 15690, "ORG"], [15811, 15823, "EVENT"], [15853, 15871, "PERSON"], [15872, 15910, "ORG"], [15998, 16010, "GPE"], [16027, 16084, "ORG"], [16135, 16144, "ORG"], [16147, 16169, "ORG"], [16180, 16189, "CARDINAL"]]}], ["Super Decisions is decision-making software which works based on two multi-criteria decision making methods.\nSuper Decisions implements the Analytic Hierarchy Process (AHP) and the Analytic Network Process (ANP). \nIt has been used in many research and practical fields such as manufacturing, environmental management, aviation, small hydropower plants and agriculture.\n\n\n== References ==", {"entities": [[0, 15, "TRAINED_CATEGORY"], [19, 43, "TRAINED_CATEGORY"], [65, 107, "TRAINED_CATEGORY"], [109, 124, "TRAINED_CATEGORY"], [136, 166, "TRAINED_CATEGORY"], [168, 171, "TRAINED_CATEGORY"], [177, 205, "TRAINED_CATEGORY"], [207, 210, "TRAINED_CATEGORY"], [214, 216, "TRAINED_CATEGORY"], [234, 268, "TRAINED_CATEGORY"], [277, 290, "TRAINED_CATEGORY"], [292, 316, "TRAINED_CATEGORY"], [318, 326, "TRAINED_CATEGORY"], [328, 351, "TRAINED_CATEGORY"], [356, 367, "TRAINED_CATEGORY"], [374, 384, "TRAINED_CATEGORY"], [0, 15, "ORG"], [65, 68, "CARDINAL"], [177, 205, "ORG"]]}]]}